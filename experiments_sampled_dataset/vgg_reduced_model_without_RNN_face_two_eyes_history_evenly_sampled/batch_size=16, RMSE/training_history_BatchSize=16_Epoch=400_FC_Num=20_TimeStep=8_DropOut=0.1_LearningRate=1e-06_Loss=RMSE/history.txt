Epoch: 1| Step: 0
Training loss: 6.0192340279882295
Validation loss: 5.584878296654685

Epoch: 6| Step: 1
Training loss: 5.8274327907671495
Validation loss: 5.578132143834984

Epoch: 6| Step: 2
Training loss: 5.124012363451679
Validation loss: 5.570850799116174

Epoch: 6| Step: 3
Training loss: 4.119476087646866
Validation loss: 5.5663508153866985

Epoch: 6| Step: 4
Training loss: 6.130813642211558
Validation loss: 5.56107724060654

Epoch: 6| Step: 5
Training loss: 5.032208274424609
Validation loss: 5.554652183808937

Epoch: 6| Step: 6
Training loss: 6.041805221898127
Validation loss: 5.54892484048425

Epoch: 6| Step: 7
Training loss: 5.184415704660504
Validation loss: 5.543293378871191

Epoch: 6| Step: 8
Training loss: 4.687179757941011
Validation loss: 5.535676434926553

Epoch: 6| Step: 9
Training loss: 7.2958021661806916
Validation loss: 5.533946669401998

Epoch: 6| Step: 10
Training loss: 5.405621795318144
Validation loss: 5.526611582036968

Epoch: 6| Step: 11
Training loss: 5.5109681092102525
Validation loss: 5.5185171564356255

Epoch: 6| Step: 12
Training loss: 5.722678247611305
Validation loss: 5.514003367122588

Epoch: 6| Step: 13
Training loss: 5.568061020483884
Validation loss: 5.507226091893204

Epoch: 2| Step: 0
Training loss: 5.261091051843347
Validation loss: 5.504333914056618

Epoch: 6| Step: 1
Training loss: 5.056976696175696
Validation loss: 5.4974956814566545

Epoch: 6| Step: 2
Training loss: 5.457155153892661
Validation loss: 5.494395531952797

Epoch: 6| Step: 3
Training loss: 5.048894425036152
Validation loss: 5.487017442030973

Epoch: 6| Step: 4
Training loss: 5.042334057900651
Validation loss: 5.480379856562141

Epoch: 6| Step: 5
Training loss: 5.789563938514241
Validation loss: 5.477043854518544

Epoch: 6| Step: 6
Training loss: 6.843715998595616
Validation loss: 5.4716197051510465

Epoch: 6| Step: 7
Training loss: 6.6861342702261215
Validation loss: 5.466067491079874

Epoch: 6| Step: 8
Training loss: 6.017516950861563
Validation loss: 5.460177064699251

Epoch: 6| Step: 9
Training loss: 5.4321081679730545
Validation loss: 5.453522805631755

Epoch: 6| Step: 10
Training loss: 4.30728098980627
Validation loss: 5.447817236266043

Epoch: 6| Step: 11
Training loss: 5.901526121189504
Validation loss: 5.4453791137016205

Epoch: 6| Step: 12
Training loss: 4.562356188872218
Validation loss: 5.438817422035781

Epoch: 6| Step: 13
Training loss: 5.053953704163033
Validation loss: 5.4357725800521965

Epoch: 3| Step: 0
Training loss: 6.066218543357261
Validation loss: 5.429364141439642

Epoch: 6| Step: 1
Training loss: 4.396541640842061
Validation loss: 5.424060214380662

Epoch: 6| Step: 2
Training loss: 5.545225258079404
Validation loss: 5.419890492089831

Epoch: 6| Step: 3
Training loss: 5.201197911711962
Validation loss: 5.412464250838083

Epoch: 6| Step: 4
Training loss: 5.650572229625668
Validation loss: 5.409373811849738

Epoch: 6| Step: 5
Training loss: 6.34687825761164
Validation loss: 5.403812251240907

Epoch: 6| Step: 6
Training loss: 5.209809645911342
Validation loss: 5.4005739450136225

Epoch: 6| Step: 7
Training loss: 5.50195208499724
Validation loss: 5.394539119795537

Epoch: 6| Step: 8
Training loss: 4.962590844694503
Validation loss: 5.389249792017325

Epoch: 6| Step: 9
Training loss: 5.2477697449042315
Validation loss: 5.384373878932778

Epoch: 6| Step: 10
Training loss: 6.067824080731661
Validation loss: 5.378386784809542

Epoch: 6| Step: 11
Training loss: 5.418155328663746
Validation loss: 5.374203511563103

Epoch: 6| Step: 12
Training loss: 5.109579752981178
Validation loss: 5.366919466328237

Epoch: 6| Step: 13
Training loss: 5.129120077773262
Validation loss: 5.363038092363915

Epoch: 4| Step: 0
Training loss: 4.844676464446931
Validation loss: 5.357330032571144

Epoch: 6| Step: 1
Training loss: 5.218977140863005
Validation loss: 5.352393423803252

Epoch: 6| Step: 2
Training loss: 6.015197580188945
Validation loss: 5.349896086652661

Epoch: 6| Step: 3
Training loss: 6.240835566208513
Validation loss: 5.341601462941542

Epoch: 6| Step: 4
Training loss: 4.621163503937829
Validation loss: 5.335938339823082

Epoch: 6| Step: 5
Training loss: 5.8084571478557505
Validation loss: 5.329132528520505

Epoch: 6| Step: 6
Training loss: 5.622053943137755
Validation loss: 5.324453923650675

Epoch: 6| Step: 7
Training loss: 5.412150255845241
Validation loss: 5.318905472531925

Epoch: 6| Step: 8
Training loss: 4.675774927222647
Validation loss: 5.3143387567475795

Epoch: 6| Step: 9
Training loss: 4.596927711500979
Validation loss: 5.307865566536211

Epoch: 6| Step: 10
Training loss: 4.581218832828519
Validation loss: 5.305380514551371

Epoch: 6| Step: 11
Training loss: 6.476302745658048
Validation loss: 5.297780111961509

Epoch: 6| Step: 12
Training loss: 5.698358921924467
Validation loss: 5.292880617242041

Epoch: 6| Step: 13
Training loss: 4.690702234657795
Validation loss: 5.2887468790800956

Epoch: 5| Step: 0
Training loss: 6.254011773977002
Validation loss: 5.282787897358829

Epoch: 6| Step: 1
Training loss: 4.603430273392052
Validation loss: 5.275018236488102

Epoch: 6| Step: 2
Training loss: 4.448880069693014
Validation loss: 5.2705717315728995

Epoch: 6| Step: 3
Training loss: 5.164193802403641
Validation loss: 5.263258401130206

Epoch: 6| Step: 4
Training loss: 6.66596669654985
Validation loss: 5.258262734093352

Epoch: 6| Step: 5
Training loss: 6.305351817928288
Validation loss: 5.252105478208485

Epoch: 6| Step: 6
Training loss: 3.814375619252264
Validation loss: 5.246128647221605

Epoch: 6| Step: 7
Training loss: 4.562375419692558
Validation loss: 5.2421829617046045

Epoch: 6| Step: 8
Training loss: 4.246673853182937
Validation loss: 5.234817878452816

Epoch: 6| Step: 9
Training loss: 5.602160221062591
Validation loss: 5.227979682770218

Epoch: 6| Step: 10
Training loss: 5.053384556942672
Validation loss: 5.222317142681379

Epoch: 6| Step: 11
Training loss: 5.559742104566282
Validation loss: 5.216480555761494

Epoch: 6| Step: 12
Training loss: 5.4003697869173015
Validation loss: 5.208806669650946

Epoch: 6| Step: 13
Training loss: 5.973261381522026
Validation loss: 5.204422037911659

Epoch: 6| Step: 0
Training loss: 5.128529519556165
Validation loss: 5.197135677065647

Epoch: 6| Step: 1
Training loss: 5.118668902340443
Validation loss: 5.192181843285205

Epoch: 6| Step: 2
Training loss: 5.7406011972364785
Validation loss: 5.182677135167465

Epoch: 6| Step: 3
Training loss: 5.155749487426596
Validation loss: 5.1797418204993875

Epoch: 6| Step: 4
Training loss: 5.0609260278650074
Validation loss: 5.168391021679469

Epoch: 6| Step: 5
Training loss: 5.265417077914582
Validation loss: 5.163533523396491

Epoch: 6| Step: 6
Training loss: 6.057338129479297
Validation loss: 5.155146050381902

Epoch: 6| Step: 7
Training loss: 4.8420170791242825
Validation loss: 5.146126578563805

Epoch: 6| Step: 8
Training loss: 3.9448926041251178
Validation loss: 5.14291125431199

Epoch: 6| Step: 9
Training loss: 6.004978657477294
Validation loss: 5.133266306358173

Epoch: 6| Step: 10
Training loss: 5.51367775581957
Validation loss: 5.128688584364115

Epoch: 6| Step: 11
Training loss: 4.513893508256684
Validation loss: 5.121777583637504

Epoch: 6| Step: 12
Training loss: 5.042693398756977
Validation loss: 5.109880400126299

Epoch: 6| Step: 13
Training loss: 5.201327359908396
Validation loss: 5.105471935551007

Epoch: 7| Step: 0
Training loss: 4.562860553029382
Validation loss: 5.093716440418023

Epoch: 6| Step: 1
Training loss: 5.0621707008545105
Validation loss: 5.08654440989104

Epoch: 6| Step: 2
Training loss: 5.6588007618232785
Validation loss: 5.083190523935849

Epoch: 6| Step: 3
Training loss: 4.506610465479931
Validation loss: 5.073590956495788

Epoch: 6| Step: 4
Training loss: 4.2980586970436345
Validation loss: 5.059919896190307

Epoch: 6| Step: 5
Training loss: 5.806153472984973
Validation loss: 5.056747873484458

Epoch: 6| Step: 6
Training loss: 4.472990145151568
Validation loss: 5.045910113819222

Epoch: 6| Step: 7
Training loss: 5.208005706655069
Validation loss: 5.039764722178803

Epoch: 6| Step: 8
Training loss: 5.152285444668679
Validation loss: 5.029005062033393

Epoch: 6| Step: 9
Training loss: 5.709759759074602
Validation loss: 5.021542573544997

Epoch: 6| Step: 10
Training loss: 4.257508769269907
Validation loss: 5.015415090526407

Epoch: 6| Step: 11
Training loss: 5.236289331903579
Validation loss: 5.002488610109843

Epoch: 6| Step: 12
Training loss: 5.91845378839451
Validation loss: 4.99414512792597

Epoch: 6| Step: 13
Training loss: 5.327996305550334
Validation loss: 4.986705277354709

Epoch: 8| Step: 0
Training loss: 4.993940305366051
Validation loss: 4.975406088342951

Epoch: 6| Step: 1
Training loss: 5.730262716239033
Validation loss: 4.966242798411614

Epoch: 6| Step: 2
Training loss: 4.638633429116994
Validation loss: 4.957362076327969

Epoch: 6| Step: 3
Training loss: 4.5591167290519214
Validation loss: 4.944174781808516

Epoch: 6| Step: 4
Training loss: 4.903175508373932
Validation loss: 4.9374201768014965

Epoch: 6| Step: 5
Training loss: 5.469824985026604
Validation loss: 4.927178036885432

Epoch: 6| Step: 6
Training loss: 4.4504930715958055
Validation loss: 4.912521606153986

Epoch: 6| Step: 7
Training loss: 4.819168029148191
Validation loss: 4.901711589701951

Epoch: 6| Step: 8
Training loss: 3.662507270050645
Validation loss: 4.892925186100698

Epoch: 6| Step: 9
Training loss: 5.708305117497936
Validation loss: 4.882686992254583

Epoch: 6| Step: 10
Training loss: 4.7508034277613
Validation loss: 4.8748490168453396

Epoch: 6| Step: 11
Training loss: 4.554376764968524
Validation loss: 4.861363904779778

Epoch: 6| Step: 12
Training loss: 5.931257962220519
Validation loss: 4.850127637727316

Epoch: 6| Step: 13
Training loss: 5.120823530783193
Validation loss: 4.837358965880279

Epoch: 9| Step: 0
Training loss: 4.733918926568168
Validation loss: 4.828051356679107

Epoch: 6| Step: 1
Training loss: 5.102147581423626
Validation loss: 4.815267188402231

Epoch: 6| Step: 2
Training loss: 4.701018511208461
Validation loss: 4.802702819501434

Epoch: 6| Step: 3
Training loss: 4.834010022027924
Validation loss: 4.792213924806713

Epoch: 6| Step: 4
Training loss: 3.9718176332618356
Validation loss: 4.782967126328464

Epoch: 6| Step: 5
Training loss: 4.166159153865454
Validation loss: 4.76596231139303

Epoch: 6| Step: 6
Training loss: 5.639596438477811
Validation loss: 4.757458541767333

Epoch: 6| Step: 7
Training loss: 5.207296629408153
Validation loss: 4.7457519537813395

Epoch: 6| Step: 8
Training loss: 5.744079527259221
Validation loss: 4.729410131722485

Epoch: 6| Step: 9
Training loss: 4.576009320096214
Validation loss: 4.719301085769871

Epoch: 6| Step: 10
Training loss: 3.5935537533458484
Validation loss: 4.7059846676088775

Epoch: 6| Step: 11
Training loss: 4.3897647761627345
Validation loss: 4.692936147808546

Epoch: 6| Step: 12
Training loss: 5.266649276769072
Validation loss: 4.681332049713247

Epoch: 6| Step: 13
Training loss: 5.3474598995522475
Validation loss: 4.6658500178040105

Epoch: 10| Step: 0
Training loss: 4.977883060416707
Validation loss: 4.6541659386348995

Epoch: 6| Step: 1
Training loss: 5.091745555576631
Validation loss: 4.637153395083717

Epoch: 6| Step: 2
Training loss: 4.513093548992532
Validation loss: 4.623401089423963

Epoch: 6| Step: 3
Training loss: 4.470843911610248
Validation loss: 4.608362272456128

Epoch: 6| Step: 4
Training loss: 3.806823256345599
Validation loss: 4.597928416330344

Epoch: 6| Step: 5
Training loss: 5.457804161609272
Validation loss: 4.584247430091363

Epoch: 6| Step: 6
Training loss: 5.015651429484007
Validation loss: 4.568229950924693

Epoch: 6| Step: 7
Training loss: 4.8216418345278145
Validation loss: 4.555202737753966

Epoch: 6| Step: 8
Training loss: 4.722195813472928
Validation loss: 4.5381017958145335

Epoch: 6| Step: 9
Training loss: 4.857950375852767
Validation loss: 4.524453149173322

Epoch: 6| Step: 10
Training loss: 4.319755311323435
Validation loss: 4.506395569222639

Epoch: 6| Step: 11
Training loss: 4.652960107877879
Validation loss: 4.487014448222287

Epoch: 6| Step: 12
Training loss: 3.7204930684225412
Validation loss: 4.476712542101445

Epoch: 6| Step: 13
Training loss: 4.186072262726664
Validation loss: 4.463450549126299

Epoch: 11| Step: 0
Training loss: 4.003379586169904
Validation loss: 4.447111937607447

Epoch: 6| Step: 1
Training loss: 4.715458612559102
Validation loss: 4.431134812221402

Epoch: 6| Step: 2
Training loss: 4.813763539293496
Validation loss: 4.414342389792009

Epoch: 6| Step: 3
Training loss: 4.705623330673183
Validation loss: 4.395639619503866

Epoch: 6| Step: 4
Training loss: 4.84105976829204
Validation loss: 4.384719625266861

Epoch: 6| Step: 5
Training loss: 4.649142787224959
Validation loss: 4.370989344953319

Epoch: 6| Step: 6
Training loss: 4.160468692419231
Validation loss: 4.350368671873994

Epoch: 6| Step: 7
Training loss: 4.070086628509793
Validation loss: 4.323992163844228

Epoch: 6| Step: 8
Training loss: 4.068014305157111
Validation loss: 4.315562134371934

Epoch: 6| Step: 9
Training loss: 4.946266600547468
Validation loss: 4.300451456882944

Epoch: 6| Step: 10
Training loss: 4.186795986834799
Validation loss: 4.283764572495796

Epoch: 6| Step: 11
Training loss: 3.460762518943537
Validation loss: 4.259556773983061

Epoch: 6| Step: 12
Training loss: 5.204853126000043
Validation loss: 4.244338379022727

Epoch: 6| Step: 13
Training loss: 3.735557592357247
Validation loss: 4.224022544260604

Epoch: 12| Step: 0
Training loss: 4.37310008621043
Validation loss: 4.203687213125124

Epoch: 6| Step: 1
Training loss: 3.8766875745406857
Validation loss: 4.191263380196928

Epoch: 6| Step: 2
Training loss: 4.640033722787842
Validation loss: 4.168025349418969

Epoch: 6| Step: 3
Training loss: 4.732463992345084
Validation loss: 4.15622558635925

Epoch: 6| Step: 4
Training loss: 2.917281839799629
Validation loss: 4.131400093190594

Epoch: 6| Step: 5
Training loss: 4.69623291337431
Validation loss: 4.108825750447422

Epoch: 6| Step: 6
Training loss: 2.9760786649500215
Validation loss: 4.094546036115665

Epoch: 6| Step: 7
Training loss: 3.7234930997179867
Validation loss: 4.078433254487015

Epoch: 6| Step: 8
Training loss: 4.616968140014419
Validation loss: 4.059047295072779

Epoch: 6| Step: 9
Training loss: 4.743748214781655
Validation loss: 4.034181666384333

Epoch: 6| Step: 10
Training loss: 5.126327342761725
Validation loss: 4.019755163706406

Epoch: 6| Step: 11
Training loss: 4.4758626181047445
Validation loss: 4.0014178329453465

Epoch: 6| Step: 12
Training loss: 3.250890609782941
Validation loss: 3.9798302123243188

Epoch: 6| Step: 13
Training loss: 3.5555632130884787
Validation loss: 3.958895012080864

Epoch: 13| Step: 0
Training loss: 3.7452576214299205
Validation loss: 3.9377627762789813

Epoch: 6| Step: 1
Training loss: 3.1779444460373454
Validation loss: 3.913667569135171

Epoch: 6| Step: 2
Training loss: 3.0029600163610706
Validation loss: 3.894562021876675

Epoch: 6| Step: 3
Training loss: 4.485355070724461
Validation loss: 3.8694719836089577

Epoch: 6| Step: 4
Training loss: 3.9594499853390452
Validation loss: 3.8516990049863704

Epoch: 6| Step: 5
Training loss: 4.151890813431894
Validation loss: 3.8289716315516578

Epoch: 6| Step: 6
Training loss: 4.121557475390731
Validation loss: 3.8062788033508177

Epoch: 6| Step: 7
Training loss: 4.559944168552121
Validation loss: 3.7849040439555224

Epoch: 6| Step: 8
Training loss: 4.399259175443589
Validation loss: 3.7619945842544333

Epoch: 6| Step: 9
Training loss: 3.256087544025859
Validation loss: 3.739961421592762

Epoch: 6| Step: 10
Training loss: 4.010562302888657
Validation loss: 3.7150068739722273

Epoch: 6| Step: 11
Training loss: 3.636667613848998
Validation loss: 3.690906445289788

Epoch: 6| Step: 12
Training loss: 4.169596188979263
Validation loss: 3.674273745713948

Epoch: 6| Step: 13
Training loss: 4.055895792538516
Validation loss: 3.65090480147268

Epoch: 14| Step: 0
Training loss: 3.8780778536209297
Validation loss: 3.631152150627208

Epoch: 6| Step: 1
Training loss: 3.34108934877519
Validation loss: 3.6096297487917175

Epoch: 6| Step: 2
Training loss: 3.7341566460907805
Validation loss: 3.5864252998202453

Epoch: 6| Step: 3
Training loss: 3.774243760307386
Validation loss: 3.561500342856858

Epoch: 6| Step: 4
Training loss: 3.5116428456149538
Validation loss: 3.5421567043409614

Epoch: 6| Step: 5
Training loss: 4.171708578726505
Validation loss: 3.518770308973186

Epoch: 6| Step: 6
Training loss: 3.2241592139220963
Validation loss: 3.495573281233115

Epoch: 6| Step: 7
Training loss: 2.3288868931142166
Validation loss: 3.4712970609152483

Epoch: 6| Step: 8
Training loss: 4.106570138746368
Validation loss: 3.4392055721394135

Epoch: 6| Step: 9
Training loss: 3.45782978727533
Validation loss: 3.427775656453274

Epoch: 6| Step: 10
Training loss: 4.44117949619049
Validation loss: 3.406762161277834

Epoch: 6| Step: 11
Training loss: 2.9515147183591055
Validation loss: 3.3848056536523354

Epoch: 6| Step: 12
Training loss: 3.9647044791580197
Validation loss: 3.3576141351815147

Epoch: 6| Step: 13
Training loss: 3.6118901724693897
Validation loss: 3.3275559831648382

Epoch: 15| Step: 0
Training loss: 3.354193235177594
Validation loss: 3.3199553019710555

Epoch: 6| Step: 1
Training loss: 3.660276103627315
Validation loss: 3.293908544376865

Epoch: 6| Step: 2
Training loss: 3.2103208520558395
Validation loss: 3.2675989018912857

Epoch: 6| Step: 3
Training loss: 3.8446879909403133
Validation loss: 3.240986527300857

Epoch: 6| Step: 4
Training loss: 3.8802280229243866
Validation loss: 3.2257758707217183

Epoch: 6| Step: 5
Training loss: 2.7737878712444983
Validation loss: 3.2070644433350664

Epoch: 6| Step: 6
Training loss: 2.509893296849941
Validation loss: 3.1830822295455588

Epoch: 6| Step: 7
Training loss: 3.3757851711639746
Validation loss: 3.171276148140998

Epoch: 6| Step: 8
Training loss: 3.0754674292613253
Validation loss: 3.142443714828685

Epoch: 6| Step: 9
Training loss: 3.905924546989158
Validation loss: 3.1237816648597687

Epoch: 6| Step: 10
Training loss: 3.8084247258166877
Validation loss: 3.102296321227444

Epoch: 6| Step: 11
Training loss: 3.0848850435326636
Validation loss: 3.090413706534808

Epoch: 6| Step: 12
Training loss: 3.460356032735796
Validation loss: 3.0636745926819704

Epoch: 6| Step: 13
Training loss: 2.524986146190143
Validation loss: 3.03705414298869

Epoch: 16| Step: 0
Training loss: 3.1989513467115955
Validation loss: 3.022217027921162

Epoch: 6| Step: 1
Training loss: 3.510873525229334
Validation loss: 3.000751749828487

Epoch: 6| Step: 2
Training loss: 3.264011696383145
Validation loss: 2.986699790637232

Epoch: 6| Step: 3
Training loss: 2.387023606629896
Validation loss: 2.972814648452122

Epoch: 6| Step: 4
Training loss: 3.170764446805222
Validation loss: 2.9496971993471313

Epoch: 6| Step: 5
Training loss: 3.5354416537071542
Validation loss: 2.933468188428265

Epoch: 6| Step: 6
Training loss: 3.0199749658822777
Validation loss: 2.9212857202135796

Epoch: 6| Step: 7
Training loss: 3.6949842117653646
Validation loss: 2.8985776848272633

Epoch: 6| Step: 8
Training loss: 2.8983529379300266
Validation loss: 2.8767654559011504

Epoch: 6| Step: 9
Training loss: 2.3102873449247356
Validation loss: 2.858878438810144

Epoch: 6| Step: 10
Training loss: 3.2256629558149132
Validation loss: 2.853043089772486

Epoch: 6| Step: 11
Training loss: 2.8158274993730683
Validation loss: 2.82900272143075

Epoch: 6| Step: 12
Training loss: 3.5440553725332147
Validation loss: 2.8191477811472625

Epoch: 6| Step: 13
Training loss: 3.403585108959831
Validation loss: 2.8140540839261607

Epoch: 17| Step: 0
Training loss: 3.229189046146409
Validation loss: 2.7826896656999125

Epoch: 6| Step: 1
Training loss: 2.805630241214091
Validation loss: 2.777041985127702

Epoch: 6| Step: 2
Training loss: 3.2358831308053246
Validation loss: 2.7622990943625667

Epoch: 6| Step: 3
Training loss: 3.515177516008996
Validation loss: 2.7542681456607676

Epoch: 6| Step: 4
Training loss: 2.9891512533073543
Validation loss: 2.7361027794311967

Epoch: 6| Step: 5
Training loss: 2.8375103584806283
Validation loss: 2.7277167424266944

Epoch: 6| Step: 6
Training loss: 2.9103443468994
Validation loss: 2.7359844031494744

Epoch: 6| Step: 7
Training loss: 3.0406245358065873
Validation loss: 2.712790920647559

Epoch: 6| Step: 8
Training loss: 3.4548935999958785
Validation loss: 2.712857366525597

Epoch: 6| Step: 9
Training loss: 2.798045504840077
Validation loss: 2.696391317558203

Epoch: 6| Step: 10
Training loss: 3.172152051429776
Validation loss: 2.6917153372123725

Epoch: 6| Step: 11
Training loss: 2.5768729203923817
Validation loss: 2.695475978331306

Epoch: 6| Step: 12
Training loss: 2.339417687856449
Validation loss: 2.6777865868041157

Epoch: 6| Step: 13
Training loss: 3.2710870211112724
Validation loss: 2.6813137190770564

Epoch: 18| Step: 0
Training loss: 2.8419302682932437
Validation loss: 2.6678937039238613

Epoch: 6| Step: 1
Training loss: 3.52369462320551
Validation loss: 2.6437445907830286

Epoch: 6| Step: 2
Training loss: 2.6871191242815855
Validation loss: 2.641133205564261

Epoch: 6| Step: 3
Training loss: 2.7174256705723248
Validation loss: 2.633174338381936

Epoch: 6| Step: 4
Training loss: 2.5696556852185806
Validation loss: 2.640976502523672

Epoch: 6| Step: 5
Training loss: 2.675764142281077
Validation loss: 2.633205450342499

Epoch: 6| Step: 6
Training loss: 2.386629942694912
Validation loss: 2.643628509258193

Epoch: 6| Step: 7
Training loss: 2.5911972168599204
Validation loss: 2.623736002497104

Epoch: 6| Step: 8
Training loss: 2.7036998336024967
Validation loss: 2.6249830457351786

Epoch: 6| Step: 9
Training loss: 3.5937356699782232
Validation loss: 2.627706495817588

Epoch: 6| Step: 10
Training loss: 3.5809702659124554
Validation loss: 2.6262283683750045

Epoch: 6| Step: 11
Training loss: 3.4088860906859972
Validation loss: 2.595866091657521

Epoch: 6| Step: 12
Training loss: 2.8384820121072885
Validation loss: 2.600547712091472

Epoch: 6| Step: 13
Training loss: 2.6577146194797123
Validation loss: 2.6103406630703674

Epoch: 19| Step: 0
Training loss: 3.1898373280726133
Validation loss: 2.603024082354647

Epoch: 6| Step: 1
Training loss: 2.7321314735780957
Validation loss: 2.5911041307527984

Epoch: 6| Step: 2
Training loss: 2.9373767908107817
Validation loss: 2.5957519726158638

Epoch: 6| Step: 3
Training loss: 2.86503549417342
Validation loss: 2.5831779336648997

Epoch: 6| Step: 4
Training loss: 3.1530889412639467
Validation loss: 2.5806624359403814

Epoch: 6| Step: 5
Training loss: 2.4230615477953292
Validation loss: 2.5839004367170904

Epoch: 6| Step: 6
Training loss: 3.0050202326799593
Validation loss: 2.591658079620254

Epoch: 6| Step: 7
Training loss: 2.949384631613889
Validation loss: 2.5885183800803913

Epoch: 6| Step: 8
Training loss: 2.9009505325512825
Validation loss: 2.5711687187119243

Epoch: 6| Step: 9
Training loss: 2.9920982566652223
Validation loss: 2.5923284901972705

Epoch: 6| Step: 10
Training loss: 3.1941378423271174
Validation loss: 2.5711784102346287

Epoch: 6| Step: 11
Training loss: 2.659592444095329
Validation loss: 2.6043062299841977

Epoch: 6| Step: 12
Training loss: 3.009966824370906
Validation loss: 2.5902249355421505

Epoch: 6| Step: 13
Training loss: 2.981924279053018
Validation loss: 2.5723061722640774

Epoch: 20| Step: 0
Training loss: 2.9717267020496356
Validation loss: 2.589887599437436

Epoch: 6| Step: 1
Training loss: 2.8074865798425632
Validation loss: 2.5875183246303117

Epoch: 6| Step: 2
Training loss: 2.25116604154388
Validation loss: 2.5822069376613856

Epoch: 6| Step: 3
Training loss: 3.326396654545146
Validation loss: 2.5811259067395333

Epoch: 6| Step: 4
Training loss: 2.3600757897055544
Validation loss: 2.582612942161284

Epoch: 6| Step: 5
Training loss: 2.938847009768656
Validation loss: 2.5974221968454043

Epoch: 6| Step: 6
Training loss: 2.8184471830461195
Validation loss: 2.5829323313655657

Epoch: 6| Step: 7
Training loss: 3.0133484464733384
Validation loss: 2.5844760015639565

Epoch: 6| Step: 8
Training loss: 3.4044300782083434
Validation loss: 2.572848738883442

Epoch: 6| Step: 9
Training loss: 2.3818344360196684
Validation loss: 2.5967999863201885

Epoch: 6| Step: 10
Training loss: 3.1864511596825067
Validation loss: 2.5785429077921207

Epoch: 6| Step: 11
Training loss: 2.7266014992621876
Validation loss: 2.576507269630166

Epoch: 6| Step: 12
Training loss: 3.4122664486957244
Validation loss: 2.591341493965029

Epoch: 6| Step: 13
Training loss: 3.2584880613254947
Validation loss: 2.5745118309342816

Epoch: 21| Step: 0
Training loss: 3.006350947408159
Validation loss: 2.5770340944228036

Epoch: 6| Step: 1
Training loss: 2.8749379690361434
Validation loss: 2.5859731952972163

Epoch: 6| Step: 2
Training loss: 2.5995033523411752
Validation loss: 2.576791589891379

Epoch: 6| Step: 3
Training loss: 3.0815681525398
Validation loss: 2.5679961957572703

Epoch: 6| Step: 4
Training loss: 2.438564948212951
Validation loss: 2.5814791183330543

Epoch: 6| Step: 5
Training loss: 3.1164051116153284
Validation loss: 2.583740376634644

Epoch: 6| Step: 6
Training loss: 3.7360694265265817
Validation loss: 2.585884011648596

Epoch: 6| Step: 7
Training loss: 2.0174164610327967
Validation loss: 2.5802484691322225

Epoch: 6| Step: 8
Training loss: 2.6355923881801795
Validation loss: 2.5604759284010856

Epoch: 6| Step: 9
Training loss: 2.7933871722742043
Validation loss: 2.5713890253196237

Epoch: 6| Step: 10
Training loss: 3.1062612613957397
Validation loss: 2.5782298564252

Epoch: 6| Step: 11
Training loss: 2.8620549551474688
Validation loss: 2.576119559189231

Epoch: 6| Step: 12
Training loss: 3.002898405578936
Validation loss: 2.581733317942935

Epoch: 6| Step: 13
Training loss: 3.53683367812735
Validation loss: 2.575085235269807

Epoch: 22| Step: 0
Training loss: 3.1147010466276344
Validation loss: 2.5730924838112608

Epoch: 6| Step: 1
Training loss: 3.745435225250904
Validation loss: 2.5726603904757495

Epoch: 6| Step: 2
Training loss: 2.731053716733987
Validation loss: 2.5777041333167583

Epoch: 6| Step: 3
Training loss: 3.5450387646448203
Validation loss: 2.5670970107572497

Epoch: 6| Step: 4
Training loss: 2.2477732341873593
Validation loss: 2.582277589019229

Epoch: 6| Step: 5
Training loss: 3.022953596005654
Validation loss: 2.586882984446648

Epoch: 6| Step: 6
Training loss: 3.1123508034609
Validation loss: 2.576206491558336

Epoch: 6| Step: 7
Training loss: 2.3027681278670276
Validation loss: 2.5758456309432285

Epoch: 6| Step: 8
Training loss: 2.5186599526033966
Validation loss: 2.5758194633883296

Epoch: 6| Step: 9
Training loss: 2.431525807561609
Validation loss: 2.5699676492786505

Epoch: 6| Step: 10
Training loss: 2.681604706036756
Validation loss: 2.571755039942764

Epoch: 6| Step: 11
Training loss: 2.2989287245007124
Validation loss: 2.5796927902209075

Epoch: 6| Step: 12
Training loss: 3.377440806222388
Validation loss: 2.561353454483116

Epoch: 6| Step: 13
Training loss: 3.5560265335105767
Validation loss: 2.561679017265645

Epoch: 23| Step: 0
Training loss: 3.2046103406346824
Validation loss: 2.574933020268883

Epoch: 6| Step: 1
Training loss: 2.2889461552864314
Validation loss: 2.5766927430499167

Epoch: 6| Step: 2
Training loss: 2.8694354399886217
Validation loss: 2.573015201577118

Epoch: 6| Step: 3
Training loss: 3.4493597569917664
Validation loss: 2.55466842631703

Epoch: 6| Step: 4
Training loss: 2.9246933344307857
Validation loss: 2.579338829598558

Epoch: 6| Step: 5
Training loss: 3.0329253296104532
Validation loss: 2.5787485471765144

Epoch: 6| Step: 6
Training loss: 2.361592545388249
Validation loss: 2.5668525606775052

Epoch: 6| Step: 7
Training loss: 2.2665959875456534
Validation loss: 2.573579930310907

Epoch: 6| Step: 8
Training loss: 3.424649998957039
Validation loss: 2.564815118716758

Epoch: 6| Step: 9
Training loss: 3.1081367212316535
Validation loss: 2.571273132975037

Epoch: 6| Step: 10
Training loss: 2.9261005059357417
Validation loss: 2.5564996421703983

Epoch: 6| Step: 11
Training loss: 3.2497672951357885
Validation loss: 2.5695619294825356

Epoch: 6| Step: 12
Training loss: 2.4093814637014566
Validation loss: 2.56292621770581

Epoch: 6| Step: 13
Training loss: 2.903668970035811
Validation loss: 2.5554007075643104

Epoch: 24| Step: 0
Training loss: 3.865552645278288
Validation loss: 2.567218868568845

Epoch: 6| Step: 1
Training loss: 2.7342911189701087
Validation loss: 2.578192356058813

Epoch: 6| Step: 2
Training loss: 3.126668408385919
Validation loss: 2.5672787023568544

Epoch: 6| Step: 3
Training loss: 2.599189110997698
Validation loss: 2.5576132813191865

Epoch: 6| Step: 4
Training loss: 2.9482179269869664
Validation loss: 2.5740621593432356

Epoch: 6| Step: 5
Training loss: 2.77120288497387
Validation loss: 2.57365607596159

Epoch: 6| Step: 6
Training loss: 2.792595599663162
Validation loss: 2.5725709655432514

Epoch: 6| Step: 7
Training loss: 3.0682244808429107
Validation loss: 2.5682215100527537

Epoch: 6| Step: 8
Training loss: 2.723794751090716
Validation loss: 2.576467195444938

Epoch: 6| Step: 9
Training loss: 2.953885419520411
Validation loss: 2.577504835866535

Epoch: 6| Step: 10
Training loss: 2.2694801942003537
Validation loss: 2.594062136032653

Epoch: 6| Step: 11
Training loss: 2.9407625950598137
Validation loss: 2.5686973456399977

Epoch: 6| Step: 12
Training loss: 2.520471678293391
Validation loss: 2.5739173409579634

Epoch: 6| Step: 13
Training loss: 3.1541881814186783
Validation loss: 2.578201831755413

Epoch: 25| Step: 0
Training loss: 3.035521810504471
Validation loss: 2.576363337967152

Epoch: 6| Step: 1
Training loss: 3.1677125575547476
Validation loss: 2.581139526807888

Epoch: 6| Step: 2
Training loss: 2.4540410366404593
Validation loss: 2.5761401080819115

Epoch: 6| Step: 3
Training loss: 2.929604491011523
Validation loss: 2.5835328542752913

Epoch: 6| Step: 4
Training loss: 2.889590516433277
Validation loss: 2.570926066771189

Epoch: 6| Step: 5
Training loss: 2.564099161744917
Validation loss: 2.573372974330585

Epoch: 6| Step: 6
Training loss: 2.3604089353546454
Validation loss: 2.5713349113035933

Epoch: 6| Step: 7
Training loss: 3.4314831875079763
Validation loss: 2.5657206998980744

Epoch: 6| Step: 8
Training loss: 2.6567300699279235
Validation loss: 2.5777947287319836

Epoch: 6| Step: 9
Training loss: 2.5643946458666917
Validation loss: 2.568999411028698

Epoch: 6| Step: 10
Training loss: 3.623358650879434
Validation loss: 2.563341878342311

Epoch: 6| Step: 11
Training loss: 3.5745754710138145
Validation loss: 2.5672714706092403

Epoch: 6| Step: 12
Training loss: 2.4847809082098564
Validation loss: 2.569268312840865

Epoch: 6| Step: 13
Training loss: 2.2691030180381246
Validation loss: 2.585780784221009

Epoch: 26| Step: 0
Training loss: 2.801199271318536
Validation loss: 2.5791171355340987

Epoch: 6| Step: 1
Training loss: 2.610494316470439
Validation loss: 2.5649303113554525

Epoch: 6| Step: 2
Training loss: 2.802291994704332
Validation loss: 2.572915083727068

Epoch: 6| Step: 3
Training loss: 2.9311544179074995
Validation loss: 2.5615178779025447

Epoch: 6| Step: 4
Training loss: 2.7642384302228877
Validation loss: 2.580686921248393

Epoch: 6| Step: 5
Training loss: 3.697567789876202
Validation loss: 2.5671451214415826

Epoch: 6| Step: 6
Training loss: 3.256477649660636
Validation loss: 2.5625318229614145

Epoch: 6| Step: 7
Training loss: 2.707564044170274
Validation loss: 2.5705723615410423

Epoch: 6| Step: 8
Training loss: 3.0894701089173924
Validation loss: 2.553639413469665

Epoch: 6| Step: 9
Training loss: 3.0782061725892884
Validation loss: 2.5771775588942063

Epoch: 6| Step: 10
Training loss: 2.49131314715846
Validation loss: 2.5788431191058474

Epoch: 6| Step: 11
Training loss: 3.010039696415817
Validation loss: 2.5575224451457386

Epoch: 6| Step: 12
Training loss: 2.930355229895595
Validation loss: 2.5587463939566457

Epoch: 6| Step: 13
Training loss: 1.6388197640031466
Validation loss: 2.5760182115117045

Epoch: 27| Step: 0
Training loss: 2.3138413534157554
Validation loss: 2.5628158220645774

Epoch: 6| Step: 1
Training loss: 2.745907599487258
Validation loss: 2.592378825437724

Epoch: 6| Step: 2
Training loss: 2.1971015563745424
Validation loss: 2.5637895084277433

Epoch: 6| Step: 3
Training loss: 2.5368161637728694
Validation loss: 2.559053750305512

Epoch: 6| Step: 4
Training loss: 3.0477400114258586
Validation loss: 2.570381650104523

Epoch: 6| Step: 5
Training loss: 3.324745862613315
Validation loss: 2.5549303245287254

Epoch: 6| Step: 6
Training loss: 2.8053526873204992
Validation loss: 2.57031761767616

Epoch: 6| Step: 7
Training loss: 2.861258631568645
Validation loss: 2.5625269498490897

Epoch: 6| Step: 8
Training loss: 3.0089014237275973
Validation loss: 2.5585794317725803

Epoch: 6| Step: 9
Training loss: 2.929275361635896
Validation loss: 2.5614545516847445

Epoch: 6| Step: 10
Training loss: 3.001467028186227
Validation loss: 2.5762461309567177

Epoch: 6| Step: 11
Training loss: 3.7976077279336304
Validation loss: 2.5762445945110057

Epoch: 6| Step: 12
Training loss: 2.423262069717742
Validation loss: 2.5746433448721504

Epoch: 6| Step: 13
Training loss: 3.455866903143999
Validation loss: 2.5720449798328624

Epoch: 28| Step: 0
Training loss: 3.8140271989625703
Validation loss: 2.561591671943753

Epoch: 6| Step: 1
Training loss: 2.816749922144557
Validation loss: 2.5668371779040697

Epoch: 6| Step: 2
Training loss: 1.9990350064165114
Validation loss: 2.5686222636376947

Epoch: 6| Step: 3
Training loss: 2.7797002010473424
Validation loss: 2.556336315021678

Epoch: 6| Step: 4
Training loss: 2.4862679041950937
Validation loss: 2.5697970875477623

Epoch: 6| Step: 5
Training loss: 2.6260917754627457
Validation loss: 2.5655796044960897

Epoch: 6| Step: 6
Training loss: 3.0031143553482655
Validation loss: 2.560664687467156

Epoch: 6| Step: 7
Training loss: 3.0633774103833935
Validation loss: 2.5632090414204685

Epoch: 6| Step: 8
Training loss: 2.713314893817652
Validation loss: 2.551966327515618

Epoch: 6| Step: 9
Training loss: 3.2733582553057228
Validation loss: 2.559714912004375

Epoch: 6| Step: 10
Training loss: 3.4507921719178527
Validation loss: 2.5568142181180145

Epoch: 6| Step: 11
Training loss: 2.5822421404751914
Validation loss: 2.5769091531203525

Epoch: 6| Step: 12
Training loss: 2.380424528647038
Validation loss: 2.5596886556633733

Epoch: 6| Step: 13
Training loss: 3.1192346414192667
Validation loss: 2.550755424326688

Epoch: 29| Step: 0
Training loss: 2.7594614259484778
Validation loss: 2.5784857901767286

Epoch: 6| Step: 1
Training loss: 2.9696329510381583
Validation loss: 2.555811480942739

Epoch: 6| Step: 2
Training loss: 2.6877171628285743
Validation loss: 2.559254547710007

Epoch: 6| Step: 3
Training loss: 3.047256211128261
Validation loss: 2.570694309909249

Epoch: 6| Step: 4
Training loss: 3.0191399048024437
Validation loss: 2.5627827071964844

Epoch: 6| Step: 5
Training loss: 3.1148103527061153
Validation loss: 2.560588779226876

Epoch: 6| Step: 6
Training loss: 2.6932281838403394
Validation loss: 2.5756944417674017

Epoch: 6| Step: 7
Training loss: 3.9192393896250426
Validation loss: 2.572752273553416

Epoch: 6| Step: 8
Training loss: 2.7599185326204214
Validation loss: 2.5605138229001905

Epoch: 6| Step: 9
Training loss: 2.599646702017657
Validation loss: 2.561763726683151

Epoch: 6| Step: 10
Training loss: 2.611591699575519
Validation loss: 2.5592647271055466

Epoch: 6| Step: 11
Training loss: 2.142089231589695
Validation loss: 2.5630742651878755

Epoch: 6| Step: 12
Training loss: 3.1044940306498146
Validation loss: 2.571433748756662

Epoch: 6| Step: 13
Training loss: 2.389084263384971
Validation loss: 2.5597884615763755

Epoch: 30| Step: 0
Training loss: 2.737816612015018
Validation loss: 2.566061049156054

Epoch: 6| Step: 1
Training loss: 3.2412485992275615
Validation loss: 2.569704160024233

Epoch: 6| Step: 2
Training loss: 2.2613044319750104
Validation loss: 2.5632772549968452

Epoch: 6| Step: 3
Training loss: 2.6574242184331593
Validation loss: 2.559510132244735

Epoch: 6| Step: 4
Training loss: 3.2047688057720647
Validation loss: 2.574376042154524

Epoch: 6| Step: 5
Training loss: 3.316405387312167
Validation loss: 2.570316798808763

Epoch: 6| Step: 6
Training loss: 3.406721449957078
Validation loss: 2.5805169875478158

Epoch: 6| Step: 7
Training loss: 1.7210335560374992
Validation loss: 2.5716421293395797

Epoch: 6| Step: 8
Training loss: 2.6791867158019955
Validation loss: 2.570465732633213

Epoch: 6| Step: 9
Training loss: 3.4094606719192786
Validation loss: 2.57598019477934

Epoch: 6| Step: 10
Training loss: 3.086900005652509
Validation loss: 2.5702711567622445

Epoch: 6| Step: 11
Training loss: 2.5551506345952313
Validation loss: 2.5607945759550197

Epoch: 6| Step: 12
Training loss: 3.0241710945854523
Validation loss: 2.562163161002112

Epoch: 6| Step: 13
Training loss: 2.2393108349997037
Validation loss: 2.572592925951074

Epoch: 31| Step: 0
Training loss: 3.3028006431387698
Validation loss: 2.5722659120342994

Epoch: 6| Step: 1
Training loss: 3.2642264405783945
Validation loss: 2.5651826439977

Epoch: 6| Step: 2
Training loss: 3.110226001929933
Validation loss: 2.582088974257544

Epoch: 6| Step: 3
Training loss: 2.2098021271098016
Validation loss: 2.5608821877213255

Epoch: 6| Step: 4
Training loss: 2.031846413717825
Validation loss: 2.558135548518883

Epoch: 6| Step: 5
Training loss: 3.0937640257238095
Validation loss: 2.555655054456331

Epoch: 6| Step: 6
Training loss: 3.079149104899774
Validation loss: 2.564996808040942

Epoch: 6| Step: 7
Training loss: 3.359002239039164
Validation loss: 2.5629644205672752

Epoch: 6| Step: 8
Training loss: 2.4191166089807825
Validation loss: 2.551317204358089

Epoch: 6| Step: 9
Training loss: 2.9061761662118175
Validation loss: 2.558514452665702

Epoch: 6| Step: 10
Training loss: 2.418387381407349
Validation loss: 2.571119110904363

Epoch: 6| Step: 11
Training loss: 2.964573059993555
Validation loss: 2.5609447953219004

Epoch: 6| Step: 12
Training loss: 2.782807332054964
Validation loss: 2.5576036757175413

Epoch: 6| Step: 13
Training loss: 2.9740251755203597
Validation loss: 2.564731415697251

Epoch: 32| Step: 0
Training loss: 2.7595919738692625
Validation loss: 2.5537256885926736

Epoch: 6| Step: 1
Training loss: 3.3640575332711244
Validation loss: 2.5608172620399006

Epoch: 6| Step: 2
Training loss: 3.150398949684832
Validation loss: 2.5521308363778874

Epoch: 6| Step: 3
Training loss: 2.25946290833126
Validation loss: 2.567785924379701

Epoch: 6| Step: 4
Training loss: 3.422598287705039
Validation loss: 2.5656071345263696

Epoch: 6| Step: 5
Training loss: 2.589484510635805
Validation loss: 2.575475662097276

Epoch: 6| Step: 6
Training loss: 2.9750210032002165
Validation loss: 2.5480222440197378

Epoch: 6| Step: 7
Training loss: 2.3448891478082783
Validation loss: 2.5727979777052705

Epoch: 6| Step: 8
Training loss: 2.937493831546881
Validation loss: 2.5463255991719973

Epoch: 6| Step: 9
Training loss: 3.153511899229807
Validation loss: 2.5553627833897816

Epoch: 6| Step: 10
Training loss: 3.056165410842911
Validation loss: 2.5549986698299767

Epoch: 6| Step: 11
Training loss: 2.640619763250632
Validation loss: 2.557708814646788

Epoch: 6| Step: 12
Training loss: 2.8641895555283274
Validation loss: 2.5634330673473373

Epoch: 6| Step: 13
Training loss: 2.2206139055914917
Validation loss: 2.5440846511911954

Epoch: 33| Step: 0
Training loss: 2.924522791350566
Validation loss: 2.560074544487514

Epoch: 6| Step: 1
Training loss: 3.042408021086662
Validation loss: 2.552691303402644

Epoch: 6| Step: 2
Training loss: 2.267321983676146
Validation loss: 2.5553134195213536

Epoch: 6| Step: 3
Training loss: 4.00611957688872
Validation loss: 2.5605564885834933

Epoch: 6| Step: 4
Training loss: 2.8302803046311866
Validation loss: 2.5586646886712314

Epoch: 6| Step: 5
Training loss: 2.1764367586881757
Validation loss: 2.569186788505993

Epoch: 6| Step: 6
Training loss: 3.5953039375611047
Validation loss: 2.5741376802289073

Epoch: 6| Step: 7
Training loss: 2.646528247877809
Validation loss: 2.5702423336474323

Epoch: 6| Step: 8
Training loss: 2.336911205859098
Validation loss: 2.569231798736212

Epoch: 6| Step: 9
Training loss: 2.8078800828004047
Validation loss: 2.5624806303087078

Epoch: 6| Step: 10
Training loss: 3.36740217830005
Validation loss: 2.5612523312704867

Epoch: 6| Step: 11
Training loss: 2.827542661282636
Validation loss: 2.5599996582250215

Epoch: 6| Step: 12
Training loss: 2.2383022340653036
Validation loss: 2.5742775188339593

Epoch: 6| Step: 13
Training loss: 2.438953748645309
Validation loss: 2.56252683429889

Epoch: 34| Step: 0
Training loss: 2.097161886541675
Validation loss: 2.56550792770569

Epoch: 6| Step: 1
Training loss: 2.9797663229651983
Validation loss: 2.5714190414227374

Epoch: 6| Step: 2
Training loss: 2.6851430804385004
Validation loss: 2.568319380303864

Epoch: 6| Step: 3
Training loss: 3.6787308990366303
Validation loss: 2.5645378727402908

Epoch: 6| Step: 4
Training loss: 3.1507661220831507
Validation loss: 2.5818811185914936

Epoch: 6| Step: 5
Training loss: 3.0732030875134253
Validation loss: 2.5707685884610423

Epoch: 6| Step: 6
Training loss: 3.0554210825912946
Validation loss: 2.567659909043566

Epoch: 6| Step: 7
Training loss: 2.7001211421775286
Validation loss: 2.5711717019499654

Epoch: 6| Step: 8
Training loss: 2.406542871660434
Validation loss: 2.5843174621523266

Epoch: 6| Step: 9
Training loss: 2.7920005560713164
Validation loss: 2.5614837764388847

Epoch: 6| Step: 10
Training loss: 2.85045964064813
Validation loss: 2.577606463250037

Epoch: 6| Step: 11
Training loss: 3.0191463802567573
Validation loss: 2.55621701232869

Epoch: 6| Step: 12
Training loss: 2.650636463387852
Validation loss: 2.559507103362852

Epoch: 6| Step: 13
Training loss: 2.8850459515963114
Validation loss: 2.5665424384646887

Epoch: 35| Step: 0
Training loss: 2.8241664095469794
Validation loss: 2.565695632114795

Epoch: 6| Step: 1
Training loss: 2.782924619426198
Validation loss: 2.5600124343382946

Epoch: 6| Step: 2
Training loss: 2.987412110635962
Validation loss: 2.5622849252854714

Epoch: 6| Step: 3
Training loss: 2.8426904066691723
Validation loss: 2.5641000055938497

Epoch: 6| Step: 4
Training loss: 2.676036516251192
Validation loss: 2.56502641120987

Epoch: 6| Step: 5
Training loss: 2.3095854873642594
Validation loss: 2.5535168815222837

Epoch: 6| Step: 6
Training loss: 2.864705105129578
Validation loss: 2.5685539963846544

Epoch: 6| Step: 7
Training loss: 3.2938041668080733
Validation loss: 2.564563153767643

Epoch: 6| Step: 8
Training loss: 3.213451876795036
Validation loss: 2.580983362994077

Epoch: 6| Step: 9
Training loss: 2.1911005089051736
Validation loss: 2.561022903267767

Epoch: 6| Step: 10
Training loss: 3.0941707440578954
Validation loss: 2.5542638123224912

Epoch: 6| Step: 11
Training loss: 3.310931716201001
Validation loss: 2.557500031557188

Epoch: 6| Step: 12
Training loss: 2.950837879480844
Validation loss: 2.559953246889818

Epoch: 6| Step: 13
Training loss: 2.251928244963655
Validation loss: 2.5499757349354537

Epoch: 36| Step: 0
Training loss: 3.1347353544585985
Validation loss: 2.5543410707402847

Epoch: 6| Step: 1
Training loss: 3.0069872231752757
Validation loss: 2.558607172388714

Epoch: 6| Step: 2
Training loss: 3.219718417063931
Validation loss: 2.5540529795067703

Epoch: 6| Step: 3
Training loss: 2.627612312740305
Validation loss: 2.571709781793821

Epoch: 6| Step: 4
Training loss: 1.9288717545692227
Validation loss: 2.544798775215196

Epoch: 6| Step: 5
Training loss: 3.246141050065284
Validation loss: 2.542653829802207

Epoch: 6| Step: 6
Training loss: 2.9343212053691903
Validation loss: 2.558887978345436

Epoch: 6| Step: 7
Training loss: 2.5317887097948995
Validation loss: 2.5619654244169587

Epoch: 6| Step: 8
Training loss: 2.9033856787125316
Validation loss: 2.5737304891696335

Epoch: 6| Step: 9
Training loss: 3.175639807447549
Validation loss: 2.55788844448598

Epoch: 6| Step: 10
Training loss: 2.5528656882709426
Validation loss: 2.5596797659440145

Epoch: 6| Step: 11
Training loss: 2.5964400348346555
Validation loss: 2.5700718649581806

Epoch: 6| Step: 12
Training loss: 2.927164929611327
Validation loss: 2.540385841588519

Epoch: 6| Step: 13
Training loss: 3.366112628206169
Validation loss: 2.561426380507658

Epoch: 37| Step: 0
Training loss: 2.540120159821296
Validation loss: 2.5652696861649087

Epoch: 6| Step: 1
Training loss: 2.5271816761812493
Validation loss: 2.567629734174116

Epoch: 6| Step: 2
Training loss: 2.4794785332801474
Validation loss: 2.5638937772523387

Epoch: 6| Step: 3
Training loss: 2.992521660773361
Validation loss: 2.5668410450792645

Epoch: 6| Step: 4
Training loss: 3.5273978228136706
Validation loss: 2.5755507060590643

Epoch: 6| Step: 5
Training loss: 3.373319419359705
Validation loss: 2.5714574605663785

Epoch: 6| Step: 6
Training loss: 2.679997729257789
Validation loss: 2.5589671463903225

Epoch: 6| Step: 7
Training loss: 2.442334003410735
Validation loss: 2.549074446391689

Epoch: 6| Step: 8
Training loss: 3.0156544105795433
Validation loss: 2.568562798499797

Epoch: 6| Step: 9
Training loss: 2.76258596916549
Validation loss: 2.548884366341056

Epoch: 6| Step: 10
Training loss: 3.0380402637899944
Validation loss: 2.5557469671108852

Epoch: 6| Step: 11
Training loss: 2.315853676978282
Validation loss: 2.564184295104627

Epoch: 6| Step: 12
Training loss: 3.0141759365601217
Validation loss: 2.556556790720091

Epoch: 6| Step: 13
Training loss: 3.357631355039623
Validation loss: 2.544540129210285

Epoch: 38| Step: 0
Training loss: 2.628890197614206
Validation loss: 2.562685183705075

Epoch: 6| Step: 1
Training loss: 3.5419161241229675
Validation loss: 2.5670296197300404

Epoch: 6| Step: 2
Training loss: 2.1934550290807446
Validation loss: 2.5551047171192502

Epoch: 6| Step: 3
Training loss: 2.6673411668647975
Validation loss: 2.559760052731313

Epoch: 6| Step: 4
Training loss: 3.663559608679468
Validation loss: 2.543592241699508

Epoch: 6| Step: 5
Training loss: 2.188829290586655
Validation loss: 2.5608230944565884

Epoch: 6| Step: 6
Training loss: 3.394453146577021
Validation loss: 2.5632271254011605

Epoch: 6| Step: 7
Training loss: 2.7989067497842863
Validation loss: 2.5518148663173363

Epoch: 6| Step: 8
Training loss: 2.505610845406398
Validation loss: 2.560115264807145

Epoch: 6| Step: 9
Training loss: 3.0914294855354676
Validation loss: 2.5569965401186203

Epoch: 6| Step: 10
Training loss: 2.748212319974197
Validation loss: 2.560206934226706

Epoch: 6| Step: 11
Training loss: 2.9217560279818606
Validation loss: 2.555986316916133

Epoch: 6| Step: 12
Training loss: 2.542627642792987
Validation loss: 2.5451852807598816

Epoch: 6| Step: 13
Training loss: 2.849945362303501
Validation loss: 2.5635895312409733

Epoch: 39| Step: 0
Training loss: 3.231436016107435
Validation loss: 2.5579172249007365

Epoch: 6| Step: 1
Training loss: 3.1602230937287055
Validation loss: 2.5608818113162903

Epoch: 6| Step: 2
Training loss: 2.4753904246636735
Validation loss: 2.5466553561693877

Epoch: 6| Step: 3
Training loss: 2.7223870515119164
Validation loss: 2.564830291720634

Epoch: 6| Step: 4
Training loss: 2.51377516314234
Validation loss: 2.5701425586390845

Epoch: 6| Step: 5
Training loss: 3.685760863802968
Validation loss: 2.573550625757858

Epoch: 6| Step: 6
Training loss: 2.493329781905448
Validation loss: 2.574566255567282

Epoch: 6| Step: 7
Training loss: 2.6042520636225994
Validation loss: 2.573380689031688

Epoch: 6| Step: 8
Training loss: 2.6815387348063964
Validation loss: 2.5566239433966755

Epoch: 6| Step: 9
Training loss: 3.582546384288842
Validation loss: 2.558270314869985

Epoch: 6| Step: 10
Training loss: 2.230326900213874
Validation loss: 2.5712641516984545

Epoch: 6| Step: 11
Training loss: 2.4329116869670404
Validation loss: 2.57794490420099

Epoch: 6| Step: 12
Training loss: 3.1344212232929536
Validation loss: 2.5588407082770637

Epoch: 6| Step: 13
Training loss: 2.3065619653117926
Validation loss: 2.557663457797652

Epoch: 40| Step: 0
Training loss: 2.654293282052388
Validation loss: 2.564485632491365

Epoch: 6| Step: 1
Training loss: 2.9990334543242843
Validation loss: 2.5542861268434134

Epoch: 6| Step: 2
Training loss: 2.664480226941221
Validation loss: 2.5637208314959876

Epoch: 6| Step: 3
Training loss: 2.447104093269908
Validation loss: 2.5509895624451877

Epoch: 6| Step: 4
Training loss: 3.1559275849595774
Validation loss: 2.5756909695906405

Epoch: 6| Step: 5
Training loss: 2.281449191659445
Validation loss: 2.572998584288359

Epoch: 6| Step: 6
Training loss: 3.1239840572697686
Validation loss: 2.5856566978543665

Epoch: 6| Step: 7
Training loss: 3.3284785839536193
Validation loss: 2.5684517283472528

Epoch: 6| Step: 8
Training loss: 2.9297421869895928
Validation loss: 2.5681219819638246

Epoch: 6| Step: 9
Training loss: 3.5446114059980185
Validation loss: 2.570200898014557

Epoch: 6| Step: 10
Training loss: 2.5907844227513217
Validation loss: 2.5561704089540886

Epoch: 6| Step: 11
Training loss: 2.575192812765425
Validation loss: 2.566464662320264

Epoch: 6| Step: 12
Training loss: 2.3481792051563715
Validation loss: 2.559483247787894

Epoch: 6| Step: 13
Training loss: 2.720584294448206
Validation loss: 2.5644791396232454

Epoch: 41| Step: 0
Training loss: 3.4678131762982862
Validation loss: 2.5593222806984146

Epoch: 6| Step: 1
Training loss: 2.8355038313929746
Validation loss: 2.569748792570782

Epoch: 6| Step: 2
Training loss: 2.9424200856417806
Validation loss: 2.5633992143828777

Epoch: 6| Step: 3
Training loss: 2.965894269225244
Validation loss: 2.5683498535079576

Epoch: 6| Step: 4
Training loss: 2.6260226846079764
Validation loss: 2.5647169118273427

Epoch: 6| Step: 5
Training loss: 3.132748267830457
Validation loss: 2.557516311500308

Epoch: 6| Step: 6
Training loss: 3.2075061144514074
Validation loss: 2.565041071243474

Epoch: 6| Step: 7
Training loss: 2.906217513364296
Validation loss: 2.5638851395906967

Epoch: 6| Step: 8
Training loss: 2.3978204088641175
Validation loss: 2.555505280544845

Epoch: 6| Step: 9
Training loss: 2.2487420698262497
Validation loss: 2.5728096539709777

Epoch: 6| Step: 10
Training loss: 2.722168275294265
Validation loss: 2.567106068529295

Epoch: 6| Step: 11
Training loss: 2.557094361773184
Validation loss: 2.5507510855155537

Epoch: 6| Step: 12
Training loss: 2.8972369481272584
Validation loss: 2.574554950720894

Epoch: 6| Step: 13
Training loss: 2.663511515717616
Validation loss: 2.5468057672988063

Epoch: 42| Step: 0
Training loss: 2.936506062625269
Validation loss: 2.5488481868371933

Epoch: 6| Step: 1
Training loss: 2.3223914905572225
Validation loss: 2.5543357865665848

Epoch: 6| Step: 2
Training loss: 2.6521546151729547
Validation loss: 2.550784920408376

Epoch: 6| Step: 3
Training loss: 2.20793179394239
Validation loss: 2.5653142024907645

Epoch: 6| Step: 4
Training loss: 3.011770205917841
Validation loss: 2.5368559608781553

Epoch: 6| Step: 5
Training loss: 3.4026596325629224
Validation loss: 2.552302834817509

Epoch: 6| Step: 6
Training loss: 2.9449297507024284
Validation loss: 2.5436507536114537

Epoch: 6| Step: 7
Training loss: 2.639562720439326
Validation loss: 2.5606991602523856

Epoch: 6| Step: 8
Training loss: 3.5143484553054236
Validation loss: 2.5446161142134884

Epoch: 6| Step: 9
Training loss: 2.6282522853368584
Validation loss: 2.543354814960943

Epoch: 6| Step: 10
Training loss: 2.506399546891849
Validation loss: 2.5536224412016213

Epoch: 6| Step: 11
Training loss: 3.110974384512632
Validation loss: 2.5533912965141523

Epoch: 6| Step: 12
Training loss: 3.067023070674925
Validation loss: 2.535280008077943

Epoch: 6| Step: 13
Training loss: 2.332763556895111
Validation loss: 2.5590969271943345

Epoch: 43| Step: 0
Training loss: 2.8915751777122822
Validation loss: 2.5499672496927643

Epoch: 6| Step: 1
Training loss: 3.10392721050491
Validation loss: 2.5522447844301683

Epoch: 6| Step: 2
Training loss: 3.475303301850927
Validation loss: 2.5548271529133735

Epoch: 6| Step: 3
Training loss: 2.66767463906094
Validation loss: 2.560260600544841

Epoch: 6| Step: 4
Training loss: 2.7150410751973064
Validation loss: 2.5642128978794045

Epoch: 6| Step: 5
Training loss: 2.961818916158491
Validation loss: 2.5683528085780094

Epoch: 6| Step: 6
Training loss: 2.9732165015436176
Validation loss: 2.550933699161991

Epoch: 6| Step: 7
Training loss: 2.6030581645468307
Validation loss: 2.563836522266521

Epoch: 6| Step: 8
Training loss: 3.061555054910502
Validation loss: 2.5566879237126194

Epoch: 6| Step: 9
Training loss: 1.7985913910965061
Validation loss: 2.552756781222817

Epoch: 6| Step: 10
Training loss: 2.963831632045794
Validation loss: 2.567376830225418

Epoch: 6| Step: 11
Training loss: 2.805963677495457
Validation loss: 2.5557804379519653

Epoch: 6| Step: 12
Training loss: 2.6833522638004625
Validation loss: 2.5408483230436607

Epoch: 6| Step: 13
Training loss: 2.6777670515363545
Validation loss: 2.567518675578923

Epoch: 44| Step: 0
Training loss: 3.071081322465554
Validation loss: 2.5454360165162675

Epoch: 6| Step: 1
Training loss: 2.2105341566993646
Validation loss: 2.5531150662742323

Epoch: 6| Step: 2
Training loss: 3.352114331892573
Validation loss: 2.553920609042427

Epoch: 6| Step: 3
Training loss: 3.2089766480810806
Validation loss: 2.5573133586293277

Epoch: 6| Step: 4
Training loss: 3.3571128148181164
Validation loss: 2.5561647715208986

Epoch: 6| Step: 5
Training loss: 2.268444543037459
Validation loss: 2.5354051029046336

Epoch: 6| Step: 6
Training loss: 3.218080321339081
Validation loss: 2.558324812452401

Epoch: 6| Step: 7
Training loss: 2.529710277810612
Validation loss: 2.5456814908972887

Epoch: 6| Step: 8
Training loss: 2.754307321331993
Validation loss: 2.5419636755748938

Epoch: 6| Step: 9
Training loss: 2.3625056231396475
Validation loss: 2.5568061115190877

Epoch: 6| Step: 10
Training loss: 3.140167202962453
Validation loss: 2.551390759884588

Epoch: 6| Step: 11
Training loss: 2.3953644888076475
Validation loss: 2.5616789962495643

Epoch: 6| Step: 12
Training loss: 2.5111897862280452
Validation loss: 2.5413808593014253

Epoch: 6| Step: 13
Training loss: 3.2107523101344477
Validation loss: 2.5541838987836076

Epoch: 45| Step: 0
Training loss: 3.1047890741082798
Validation loss: 2.549322222239991

Epoch: 6| Step: 1
Training loss: 3.0615052145091632
Validation loss: 2.559666096788489

Epoch: 6| Step: 2
Training loss: 2.9132468383426215
Validation loss: 2.5547116883601575

Epoch: 6| Step: 3
Training loss: 3.08021265484779
Validation loss: 2.562478048139018

Epoch: 6| Step: 4
Training loss: 2.7424150247545076
Validation loss: 2.558403009404671

Epoch: 6| Step: 5
Training loss: 3.2809219923015345
Validation loss: 2.5362648943334527

Epoch: 6| Step: 6
Training loss: 3.0223866294884165
Validation loss: 2.5590717013608275

Epoch: 6| Step: 7
Training loss: 3.1065041021727957
Validation loss: 2.554339408710761

Epoch: 6| Step: 8
Training loss: 2.3417223488193386
Validation loss: 2.557489793012695

Epoch: 6| Step: 9
Training loss: 2.6675050927411186
Validation loss: 2.558794814939776

Epoch: 6| Step: 10
Training loss: 2.2228389188927933
Validation loss: 2.569833548728815

Epoch: 6| Step: 11
Training loss: 3.039869657282062
Validation loss: 2.550315690450478

Epoch: 6| Step: 12
Training loss: 2.355473810952793
Validation loss: 2.5618730904185183

Epoch: 6| Step: 13
Training loss: 2.478692519636729
Validation loss: 2.5522552901083015

Epoch: 46| Step: 0
Training loss: 2.0735225335215155
Validation loss: 2.5475653900349458

Epoch: 6| Step: 1
Training loss: 3.2426850086569696
Validation loss: 2.550970427948723

Epoch: 6| Step: 2
Training loss: 2.6696687032776203
Validation loss: 2.5431627409036697

Epoch: 6| Step: 3
Training loss: 2.3260332990314487
Validation loss: 2.5453477990591615

Epoch: 6| Step: 4
Training loss: 3.081012436566484
Validation loss: 2.5655017002340617

Epoch: 6| Step: 5
Training loss: 2.556088684513537
Validation loss: 2.5573477041668853

Epoch: 6| Step: 6
Training loss: 2.5878600381447154
Validation loss: 2.5533151213369325

Epoch: 6| Step: 7
Training loss: 2.7103622661724764
Validation loss: 2.557294205285745

Epoch: 6| Step: 8
Training loss: 3.050156611189531
Validation loss: 2.567448926140624

Epoch: 6| Step: 9
Training loss: 3.4730365832395873
Validation loss: 2.5459243084144028

Epoch: 6| Step: 10
Training loss: 2.593979331299638
Validation loss: 2.5392299256763446

Epoch: 6| Step: 11
Training loss: 2.97075737797682
Validation loss: 2.554674016876731

Epoch: 6| Step: 12
Training loss: 3.2886246414680262
Validation loss: 2.5532795854636543

Epoch: 6| Step: 13
Training loss: 2.790255849585525
Validation loss: 2.5509379452044003

Epoch: 47| Step: 0
Training loss: 3.0385291408681248
Validation loss: 2.552465484984546

Epoch: 6| Step: 1
Training loss: 2.922637350413364
Validation loss: 2.5534072492429285

Epoch: 6| Step: 2
Training loss: 3.427988661329998
Validation loss: 2.5493843645633487

Epoch: 6| Step: 3
Training loss: 2.443315074101285
Validation loss: 2.5527153520016297

Epoch: 6| Step: 4
Training loss: 2.644127142949729
Validation loss: 2.537703303803526

Epoch: 6| Step: 5
Training loss: 2.943893293064011
Validation loss: 2.5531872787407592

Epoch: 6| Step: 6
Training loss: 2.93569696160735
Validation loss: 2.5546967176747937

Epoch: 6| Step: 7
Training loss: 2.309817640034036
Validation loss: 2.5535162209134707

Epoch: 6| Step: 8
Training loss: 2.191340753185096
Validation loss: 2.551646734230697

Epoch: 6| Step: 9
Training loss: 2.2678587326713626
Validation loss: 2.5429391047847583

Epoch: 6| Step: 10
Training loss: 2.3264567907745075
Validation loss: 2.5670953240307886

Epoch: 6| Step: 11
Training loss: 3.2483460546028806
Validation loss: 2.55385236538875

Epoch: 6| Step: 12
Training loss: 3.767066521365345
Validation loss: 2.5561507154934104

Epoch: 6| Step: 13
Training loss: 2.578974543386299
Validation loss: 2.555836554392445

Epoch: 48| Step: 0
Training loss: 2.5679458807474416
Validation loss: 2.5563412199922193

Epoch: 6| Step: 1
Training loss: 2.917569011797087
Validation loss: 2.5516925612210413

Epoch: 6| Step: 2
Training loss: 3.6210588537878277
Validation loss: 2.5576983960187145

Epoch: 6| Step: 3
Training loss: 2.8148705558760407
Validation loss: 2.5473573279436885

Epoch: 6| Step: 4
Training loss: 2.981827532411027
Validation loss: 2.5415767033103087

Epoch: 6| Step: 5
Training loss: 2.8053177574357466
Validation loss: 2.5423362165407615

Epoch: 6| Step: 6
Training loss: 2.629807293725175
Validation loss: 2.5626544840797147

Epoch: 6| Step: 7
Training loss: 2.9737145924715147
Validation loss: 2.5590592220898305

Epoch: 6| Step: 8
Training loss: 2.893117294185889
Validation loss: 2.5601329961289165

Epoch: 6| Step: 9
Training loss: 2.6873095245284526
Validation loss: 2.553546538465284

Epoch: 6| Step: 10
Training loss: 1.9673967100220822
Validation loss: 2.5687597148597683

Epoch: 6| Step: 11
Training loss: 3.064164935261854
Validation loss: 2.554821599816492

Epoch: 6| Step: 12
Training loss: 2.4095455242921795
Validation loss: 2.553608952454814

Epoch: 6| Step: 13
Training loss: 3.332934991559089
Validation loss: 2.5624292255335224

Epoch: 49| Step: 0
Training loss: 2.911744533022418
Validation loss: 2.558282502371423

Epoch: 6| Step: 1
Training loss: 3.0512332361644545
Validation loss: 2.5497474243114953

Epoch: 6| Step: 2
Training loss: 2.8583914310641836
Validation loss: 2.5591589403542887

Epoch: 6| Step: 3
Training loss: 3.1923187333447256
Validation loss: 2.550164071904574

Epoch: 6| Step: 4
Training loss: 1.955462285578639
Validation loss: 2.5526608752632107

Epoch: 6| Step: 5
Training loss: 3.326934601563219
Validation loss: 2.5584637728268014

Epoch: 6| Step: 6
Training loss: 2.5729967380270238
Validation loss: 2.54628280075075

Epoch: 6| Step: 7
Training loss: 2.820290689568973
Validation loss: 2.56173426094117

Epoch: 6| Step: 8
Training loss: 2.187338250855872
Validation loss: 2.5452526971966436

Epoch: 6| Step: 9
Training loss: 3.0182971875367874
Validation loss: 2.5561570284294812

Epoch: 6| Step: 10
Training loss: 3.2363091182208166
Validation loss: 2.557187664324027

Epoch: 6| Step: 11
Training loss: 3.1360685023688966
Validation loss: 2.5578531400282025

Epoch: 6| Step: 12
Training loss: 2.541884887165831
Validation loss: 2.5568074195057737

Epoch: 6| Step: 13
Training loss: 2.12370844467488
Validation loss: 2.5595121254553943

Epoch: 50| Step: 0
Training loss: 3.422012256673938
Validation loss: 2.5526517059758733

Epoch: 6| Step: 1
Training loss: 3.328724122184987
Validation loss: 2.565647932406795

Epoch: 6| Step: 2
Training loss: 3.2246299294752987
Validation loss: 2.5558304728722328

Epoch: 6| Step: 3
Training loss: 3.5542026734102765
Validation loss: 2.543226684879036

Epoch: 6| Step: 4
Training loss: 2.410962432119293
Validation loss: 2.5585716303589634

Epoch: 6| Step: 5
Training loss: 2.5765039144671698
Validation loss: 2.55977617057823

Epoch: 6| Step: 6
Training loss: 2.7843224346024154
Validation loss: 2.5580667353279063

Epoch: 6| Step: 7
Training loss: 2.4077082587271796
Validation loss: 2.5615405670893465

Epoch: 6| Step: 8
Training loss: 2.240373149853822
Validation loss: 2.564244475636057

Epoch: 6| Step: 9
Training loss: 2.567048014347431
Validation loss: 2.5629605215358575

Epoch: 6| Step: 10
Training loss: 3.038661744041635
Validation loss: 2.5607708775363722

Epoch: 6| Step: 11
Training loss: 2.2720693554970905
Validation loss: 2.551188286407515

Epoch: 6| Step: 12
Training loss: 2.6784042088219175
Validation loss: 2.555471002539226

Epoch: 6| Step: 13
Training loss: 2.2957904357040975
Validation loss: 2.567554833627359

Epoch: 51| Step: 0
Training loss: 2.7754437134810823
Validation loss: 2.5630122057262836

Epoch: 6| Step: 1
Training loss: 2.571532357104467
Validation loss: 2.5520851197193584

Epoch: 6| Step: 2
Training loss: 2.4585959299645763
Validation loss: 2.5582047927768308

Epoch: 6| Step: 3
Training loss: 3.949840885289432
Validation loss: 2.56056232710078

Epoch: 6| Step: 4
Training loss: 2.5150706942199115
Validation loss: 2.5486348952518028

Epoch: 6| Step: 5
Training loss: 3.4887787911550485
Validation loss: 2.5572995204381805

Epoch: 6| Step: 6
Training loss: 2.7584736061347748
Validation loss: 2.548162354783631

Epoch: 6| Step: 7
Training loss: 2.2622487134117257
Validation loss: 2.564473628419901

Epoch: 6| Step: 8
Training loss: 2.531451935425041
Validation loss: 2.558956355195379

Epoch: 6| Step: 9
Training loss: 2.282613895244481
Validation loss: 2.5463264156866736

Epoch: 6| Step: 10
Training loss: 2.5791196811650576
Validation loss: 2.562394105697613

Epoch: 6| Step: 11
Training loss: 3.0392565824615145
Validation loss: 2.5492263831694033

Epoch: 6| Step: 12
Training loss: 3.1978782295294543
Validation loss: 2.5452917359080023

Epoch: 6| Step: 13
Training loss: 2.3268308178654205
Validation loss: 2.5546004605500428

Epoch: 52| Step: 0
Training loss: 3.2915367551510424
Validation loss: 2.55687471449291

Epoch: 6| Step: 1
Training loss: 1.9125261641563922
Validation loss: 2.540219843444458

Epoch: 6| Step: 2
Training loss: 3.266559375895378
Validation loss: 2.560144317594239

Epoch: 6| Step: 3
Training loss: 2.7076519231185494
Validation loss: 2.546112367117605

Epoch: 6| Step: 4
Training loss: 2.805258520116294
Validation loss: 2.5437853747798553

Epoch: 6| Step: 5
Training loss: 2.7676380826691602
Validation loss: 2.539057425343228

Epoch: 6| Step: 6
Training loss: 2.919384716216219
Validation loss: 2.5561010248358538

Epoch: 6| Step: 7
Training loss: 3.3291781912657092
Validation loss: 2.5682628997609003

Epoch: 6| Step: 8
Training loss: 2.9216414577559346
Validation loss: 2.5539048246474056

Epoch: 6| Step: 9
Training loss: 2.3879150788752264
Validation loss: 2.5587426808653007

Epoch: 6| Step: 10
Training loss: 2.8695407949320564
Validation loss: 2.5488893419758916

Epoch: 6| Step: 11
Training loss: 2.664118075420362
Validation loss: 2.5514841037111893

Epoch: 6| Step: 12
Training loss: 2.156212626700003
Validation loss: 2.5502099365961275

Epoch: 6| Step: 13
Training loss: 3.349818774203662
Validation loss: 2.5423589130533166

Epoch: 53| Step: 0
Training loss: 2.4397830541501757
Validation loss: 2.556850366117426

Epoch: 6| Step: 1
Training loss: 3.409656466186473
Validation loss: 2.5512659665456847

Epoch: 6| Step: 2
Training loss: 2.704689058494009
Validation loss: 2.552113518568832

Epoch: 6| Step: 3
Training loss: 2.5302019186450297
Validation loss: 2.5460794659527823

Epoch: 6| Step: 4
Training loss: 2.506805027413398
Validation loss: 2.548915140290648

Epoch: 6| Step: 5
Training loss: 3.736045048983246
Validation loss: 2.551218382415935

Epoch: 6| Step: 6
Training loss: 2.983161559745051
Validation loss: 2.538352517947828

Epoch: 6| Step: 7
Training loss: 2.8342135315044783
Validation loss: 2.5653804643780975

Epoch: 6| Step: 8
Training loss: 2.4402905653872584
Validation loss: 2.5547993391421535

Epoch: 6| Step: 9
Training loss: 2.6854012744621265
Validation loss: 2.5626815423453784

Epoch: 6| Step: 10
Training loss: 2.9185367220407543
Validation loss: 2.557361602244622

Epoch: 6| Step: 11
Training loss: 2.9811815681840765
Validation loss: 2.541532998795567

Epoch: 6| Step: 12
Training loss: 2.456845420517661
Validation loss: 2.5485090837530953

Epoch: 6| Step: 13
Training loss: 2.0199251657731003
Validation loss: 2.551904329439078

Epoch: 54| Step: 0
Training loss: 2.14976621288224
Validation loss: 2.547358140102093

Epoch: 6| Step: 1
Training loss: 2.523838353870649
Validation loss: 2.5616387651499735

Epoch: 6| Step: 2
Training loss: 3.1899273175895257
Validation loss: 2.551704792195404

Epoch: 6| Step: 3
Training loss: 3.1147160496498376
Validation loss: 2.548645736184036

Epoch: 6| Step: 4
Training loss: 2.5583843582316907
Validation loss: 2.5418841882344148

Epoch: 6| Step: 5
Training loss: 2.906093798305688
Validation loss: 2.5563523015205383

Epoch: 6| Step: 6
Training loss: 2.977066117582381
Validation loss: 2.5606180629200597

Epoch: 6| Step: 7
Training loss: 3.4107471142075596
Validation loss: 2.5632768539399664

Epoch: 6| Step: 8
Training loss: 2.369300629322276
Validation loss: 2.5574850756902676

Epoch: 6| Step: 9
Training loss: 3.8489406862314635
Validation loss: 2.5557068623110895

Epoch: 6| Step: 10
Training loss: 2.2168925932666577
Validation loss: 2.562730778292422

Epoch: 6| Step: 11
Training loss: 2.369703208753557
Validation loss: 2.561740127296798

Epoch: 6| Step: 12
Training loss: 2.5907838705974586
Validation loss: 2.545510643864893

Epoch: 6| Step: 13
Training loss: 2.458973127828726
Validation loss: 2.561996732684172

Epoch: 55| Step: 0
Training loss: 3.141335478172585
Validation loss: 2.5570553638952225

Epoch: 6| Step: 1
Training loss: 2.7526980949166604
Validation loss: 2.538689111053832

Epoch: 6| Step: 2
Training loss: 2.7329316607800305
Validation loss: 2.5540132907692463

Epoch: 6| Step: 3
Training loss: 3.039712949049971
Validation loss: 2.5412495750145756

Epoch: 6| Step: 4
Training loss: 2.6529916862360405
Validation loss: 2.55215188027082

Epoch: 6| Step: 5
Training loss: 3.333437552412302
Validation loss: 2.5653686593624565

Epoch: 6| Step: 6
Training loss: 3.2254429830852365
Validation loss: 2.5531739162196705

Epoch: 6| Step: 7
Training loss: 2.74241554637918
Validation loss: 2.552819326995923

Epoch: 6| Step: 8
Training loss: 2.8504842313348058
Validation loss: 2.548279539622548

Epoch: 6| Step: 9
Training loss: 2.542941373100522
Validation loss: 2.5484274888514267

Epoch: 6| Step: 10
Training loss: 2.5720777392289222
Validation loss: 2.556515789096637

Epoch: 6| Step: 11
Training loss: 2.7011494556304787
Validation loss: 2.548297717478119

Epoch: 6| Step: 12
Training loss: 2.599921456397723
Validation loss: 2.542781875327274

Epoch: 6| Step: 13
Training loss: 1.820177719954966
Validation loss: 2.5590058872217196

Epoch: 56| Step: 0
Training loss: 2.4223167754839614
Validation loss: 2.5430902205989527

Epoch: 6| Step: 1
Training loss: 3.2035415006461685
Validation loss: 2.5516819909354975

Epoch: 6| Step: 2
Training loss: 2.6122373311993914
Validation loss: 2.5637003020559916

Epoch: 6| Step: 3
Training loss: 2.8964116093144097
Validation loss: 2.5579677231423394

Epoch: 6| Step: 4
Training loss: 2.449178838328614
Validation loss: 2.559133356000672

Epoch: 6| Step: 5
Training loss: 2.3482939350766077
Validation loss: 2.5579170685516774

Epoch: 6| Step: 6
Training loss: 2.817916909405419
Validation loss: 2.5576002997654963

Epoch: 6| Step: 7
Training loss: 2.4561944698045663
Validation loss: 2.5468284531716043

Epoch: 6| Step: 8
Training loss: 2.7696362732423134
Validation loss: 2.5419692194453045

Epoch: 6| Step: 9
Training loss: 2.3396161053050215
Validation loss: 2.545825277134855

Epoch: 6| Step: 10
Training loss: 3.2347212896313398
Validation loss: 2.5444428223751347

Epoch: 6| Step: 11
Training loss: 2.937936141730821
Validation loss: 2.536391229283657

Epoch: 6| Step: 12
Training loss: 3.668116167415008
Validation loss: 2.53727775908647

Epoch: 6| Step: 13
Training loss: 2.94183565326196
Validation loss: 2.5598735700492163

Epoch: 57| Step: 0
Training loss: 2.8728868762807647
Validation loss: 2.5522490915725853

Epoch: 6| Step: 1
Training loss: 2.590613801607563
Validation loss: 2.5580307348023315

Epoch: 6| Step: 2
Training loss: 2.745793332940715
Validation loss: 2.546102006256807

Epoch: 6| Step: 3
Training loss: 2.6128062456592445
Validation loss: 2.552795896989139

Epoch: 6| Step: 4
Training loss: 2.8186079035973046
Validation loss: 2.5425641662186154

Epoch: 6| Step: 5
Training loss: 2.5938093799090556
Validation loss: 2.556116939591401

Epoch: 6| Step: 6
Training loss: 2.8186649994816655
Validation loss: 2.5395994465833858

Epoch: 6| Step: 7
Training loss: 3.077241567487488
Validation loss: 2.5484153885171112

Epoch: 6| Step: 8
Training loss: 2.7101613453486983
Validation loss: 2.549929751418426

Epoch: 6| Step: 9
Training loss: 2.6493503493997816
Validation loss: 2.54399483346953

Epoch: 6| Step: 10
Training loss: 2.159325327764269
Validation loss: 2.5455421791878172

Epoch: 6| Step: 11
Training loss: 3.239561777973321
Validation loss: 2.5512463256640983

Epoch: 6| Step: 12
Training loss: 3.2206544149496494
Validation loss: 2.5493953325321854

Epoch: 6| Step: 13
Training loss: 3.2432955032081754
Validation loss: 2.551474429317914

Epoch: 58| Step: 0
Training loss: 2.7208880206264596
Validation loss: 2.554159359144538

Epoch: 6| Step: 1
Training loss: 2.939222764021633
Validation loss: 2.5449730730682187

Epoch: 6| Step: 2
Training loss: 3.0168604716505727
Validation loss: 2.5433516388265556

Epoch: 6| Step: 3
Training loss: 2.3735689570051357
Validation loss: 2.555126021967518

Epoch: 6| Step: 4
Training loss: 2.9969632355525997
Validation loss: 2.5515484123498426

Epoch: 6| Step: 5
Training loss: 2.61631537183076
Validation loss: 2.543014073061324

Epoch: 6| Step: 6
Training loss: 2.9732052750943923
Validation loss: 2.543735473813863

Epoch: 6| Step: 7
Training loss: 2.5968186942743263
Validation loss: 2.5455541516817144

Epoch: 6| Step: 8
Training loss: 2.649637046285921
Validation loss: 2.5399767894409466

Epoch: 6| Step: 9
Training loss: 2.9189128037981464
Validation loss: 2.5468824577612406

Epoch: 6| Step: 10
Training loss: 3.182639811067565
Validation loss: 2.5520083455128577

Epoch: 6| Step: 11
Training loss: 2.6703963622020996
Validation loss: 2.5418405122038417

Epoch: 6| Step: 12
Training loss: 2.9929653979237623
Validation loss: 2.539675068632949

Epoch: 6| Step: 13
Training loss: 1.9329918126753338
Validation loss: 2.5448588923502005

Epoch: 59| Step: 0
Training loss: 2.6918137107658096
Validation loss: 2.5449632417107537

Epoch: 6| Step: 1
Training loss: 2.7212435807873874
Validation loss: 2.548697719209069

Epoch: 6| Step: 2
Training loss: 2.3870325959133103
Validation loss: 2.5363992141437635

Epoch: 6| Step: 3
Training loss: 2.6037463853566485
Validation loss: 2.553914337255316

Epoch: 6| Step: 4
Training loss: 2.9486156124783993
Validation loss: 2.539347343022745

Epoch: 6| Step: 5
Training loss: 2.8001170202052736
Validation loss: 2.5415360127850293

Epoch: 6| Step: 6
Training loss: 2.373421395343239
Validation loss: 2.5424678298983703

Epoch: 6| Step: 7
Training loss: 3.2046786378378043
Validation loss: 2.5466984815317026

Epoch: 6| Step: 8
Training loss: 2.674955766971695
Validation loss: 2.5470432004756165

Epoch: 6| Step: 9
Training loss: 2.424142280771555
Validation loss: 2.5608299149434965

Epoch: 6| Step: 10
Training loss: 3.874677829270409
Validation loss: 2.540729828820034

Epoch: 6| Step: 11
Training loss: 2.594542416781431
Validation loss: 2.5550404864516727

Epoch: 6| Step: 12
Training loss: 2.8097266192508403
Validation loss: 2.5567405639348917

Epoch: 6| Step: 13
Training loss: 2.727725068062402
Validation loss: 2.565086728895569

Epoch: 60| Step: 0
Training loss: 2.470560496439005
Validation loss: 2.5579632632695

Epoch: 6| Step: 1
Training loss: 2.9459690809109986
Validation loss: 2.534700468334018

Epoch: 6| Step: 2
Training loss: 2.0279289679869064
Validation loss: 2.5513352510450686

Epoch: 6| Step: 3
Training loss: 3.0686342734213397
Validation loss: 2.5651061538647784

Epoch: 6| Step: 4
Training loss: 2.753673354236754
Validation loss: 2.53619798294953

Epoch: 6| Step: 5
Training loss: 2.6501417949816006
Validation loss: 2.5445931869701823

Epoch: 6| Step: 6
Training loss: 2.029933678995298
Validation loss: 2.55139034741364

Epoch: 6| Step: 7
Training loss: 3.4232475976753762
Validation loss: 2.557812812670801

Epoch: 6| Step: 8
Training loss: 2.326872725648304
Validation loss: 2.5571474427663303

Epoch: 6| Step: 9
Training loss: 3.687279904796146
Validation loss: 2.5487979947326664

Epoch: 6| Step: 10
Training loss: 3.044370903587209
Validation loss: 2.549960919924617

Epoch: 6| Step: 11
Training loss: 2.7501447812895594
Validation loss: 2.5478453683436495

Epoch: 6| Step: 12
Training loss: 3.1018121652505157
Validation loss: 2.5510127839335928

Epoch: 6| Step: 13
Training loss: 1.8058576877197463
Validation loss: 2.543536411483524

Epoch: 61| Step: 0
Training loss: 3.045231302430529
Validation loss: 2.5517587629050804

Epoch: 6| Step: 1
Training loss: 3.2673446289108017
Validation loss: 2.546816921521888

Epoch: 6| Step: 2
Training loss: 2.2036138763190256
Validation loss: 2.5495457650221374

Epoch: 6| Step: 3
Training loss: 2.3898481715031425
Validation loss: 2.546926449954903

Epoch: 6| Step: 4
Training loss: 2.703479368762902
Validation loss: 2.5609488285599484

Epoch: 6| Step: 5
Training loss: 3.2473362496830935
Validation loss: 2.548841516339111

Epoch: 6| Step: 6
Training loss: 2.938892602547613
Validation loss: 2.5591279960714792

Epoch: 6| Step: 7
Training loss: 2.791694318340248
Validation loss: 2.5665790307844314

Epoch: 6| Step: 8
Training loss: 2.7735731494665674
Validation loss: 2.5541508857929958

Epoch: 6| Step: 9
Training loss: 2.87764949619039
Validation loss: 2.558854878769439

Epoch: 6| Step: 10
Training loss: 1.8761743682520715
Validation loss: 2.5567447110936685

Epoch: 6| Step: 11
Training loss: 2.3015300264158833
Validation loss: 2.571105806680006

Epoch: 6| Step: 12
Training loss: 2.8216944977915643
Validation loss: 2.56627700716729

Epoch: 6| Step: 13
Training loss: 3.91718330763481
Validation loss: 2.5631623631371303

Epoch: 62| Step: 0
Training loss: 2.4084639829508827
Validation loss: 2.560065443812084

Epoch: 6| Step: 1
Training loss: 3.2791572800097613
Validation loss: 2.5514557807500378

Epoch: 6| Step: 2
Training loss: 3.218935470422503
Validation loss: 2.558395651361318

Epoch: 6| Step: 3
Training loss: 2.4754786481312085
Validation loss: 2.55122777189595

Epoch: 6| Step: 4
Training loss: 2.683851027059665
Validation loss: 2.5551703869328937

Epoch: 6| Step: 5
Training loss: 1.816022409880582
Validation loss: 2.5491770211527194

Epoch: 6| Step: 6
Training loss: 2.594971518534806
Validation loss: 2.542179258378969

Epoch: 6| Step: 7
Training loss: 3.0029012638390578
Validation loss: 2.566839198383985

Epoch: 6| Step: 8
Training loss: 3.5292775544660016
Validation loss: 2.5530378782002385

Epoch: 6| Step: 9
Training loss: 2.6077678550889374
Validation loss: 2.55497987540557

Epoch: 6| Step: 10
Training loss: 2.5263237759606123
Validation loss: 2.542836441719585

Epoch: 6| Step: 11
Training loss: 2.539440326455981
Validation loss: 2.531544851380493

Epoch: 6| Step: 12
Training loss: 3.5631244848251304
Validation loss: 2.5387501786884976

Epoch: 6| Step: 13
Training loss: 2.022924527573036
Validation loss: 2.550574209109279

Epoch: 63| Step: 0
Training loss: 2.8289547540762032
Validation loss: 2.5438201518908503

Epoch: 6| Step: 1
Training loss: 2.197890644612477
Validation loss: 2.5421056047334725

Epoch: 6| Step: 2
Training loss: 1.9580675986430378
Validation loss: 2.5425044631866403

Epoch: 6| Step: 3
Training loss: 3.677112107348946
Validation loss: 2.5476002835966987

Epoch: 6| Step: 4
Training loss: 2.409732824687615
Validation loss: 2.541483247279025

Epoch: 6| Step: 5
Training loss: 3.0231151162507053
Validation loss: 2.5494041082810988

Epoch: 6| Step: 6
Training loss: 3.121862133102707
Validation loss: 2.550880737103281

Epoch: 6| Step: 7
Training loss: 3.4701399209342867
Validation loss: 2.5558954520084733

Epoch: 6| Step: 8
Training loss: 1.9184990982876733
Validation loss: 2.5501640196297752

Epoch: 6| Step: 9
Training loss: 2.821732266724982
Validation loss: 2.550147788755493

Epoch: 6| Step: 10
Training loss: 2.4587066711734944
Validation loss: 2.5571076546822544

Epoch: 6| Step: 11
Training loss: 2.5156016852204726
Validation loss: 2.553521105197996

Epoch: 6| Step: 12
Training loss: 3.139890974059369
Validation loss: 2.5415845306643567

Epoch: 6| Step: 13
Training loss: 2.797906099490285
Validation loss: 2.553019274189889

Epoch: 64| Step: 0
Training loss: 3.3579217650687254
Validation loss: 2.55288733014008

Epoch: 6| Step: 1
Training loss: 2.6465874345708142
Validation loss: 2.544496671055231

Epoch: 6| Step: 2
Training loss: 2.5884024405439483
Validation loss: 2.548147226902643

Epoch: 6| Step: 3
Training loss: 2.487495238333127
Validation loss: 2.550901018971122

Epoch: 6| Step: 4
Training loss: 3.768582271050905
Validation loss: 2.542600824838176

Epoch: 6| Step: 5
Training loss: 2.464607819935092
Validation loss: 2.552027496336476

Epoch: 6| Step: 6
Training loss: 3.0174795190199846
Validation loss: 2.5425430903609474

Epoch: 6| Step: 7
Training loss: 2.7707116714575912
Validation loss: 2.5512493301881656

Epoch: 6| Step: 8
Training loss: 2.5231862607430684
Validation loss: 2.5454459943502545

Epoch: 6| Step: 9
Training loss: 2.521250435446615
Validation loss: 2.5498819282038565

Epoch: 6| Step: 10
Training loss: 2.2474326215070635
Validation loss: 2.553218409990773

Epoch: 6| Step: 11
Training loss: 2.882693900793386
Validation loss: 2.5470450202565345

Epoch: 6| Step: 12
Training loss: 2.2672294460336198
Validation loss: 2.5476373844633304

Epoch: 6| Step: 13
Training loss: 3.14646467395679
Validation loss: 2.5485900071153953

Epoch: 65| Step: 0
Training loss: 3.150979353023233
Validation loss: 2.5494905227052422

Epoch: 6| Step: 1
Training loss: 2.7504956925744506
Validation loss: 2.5413056118325876

Epoch: 6| Step: 2
Training loss: 3.1095627004433086
Validation loss: 2.5342208228913123

Epoch: 6| Step: 3
Training loss: 2.4185833619746915
Validation loss: 2.540966692688532

Epoch: 6| Step: 4
Training loss: 2.109279602154128
Validation loss: 2.5477042811861144

Epoch: 6| Step: 5
Training loss: 3.0240279220018578
Validation loss: 2.5429479501966568

Epoch: 6| Step: 6
Training loss: 2.7703246794646432
Validation loss: 2.5464856542002776

Epoch: 6| Step: 7
Training loss: 2.550665906836554
Validation loss: 2.5422856941910665

Epoch: 6| Step: 8
Training loss: 2.950800389476997
Validation loss: 2.5582025520246487

Epoch: 6| Step: 9
Training loss: 2.927386140376456
Validation loss: 2.5474460519508204

Epoch: 6| Step: 10
Training loss: 2.7537117963817015
Validation loss: 2.5482316361417983

Epoch: 6| Step: 11
Training loss: 2.692716548078293
Validation loss: 2.5383203373114553

Epoch: 6| Step: 12
Training loss: 2.9864159440774554
Validation loss: 2.5376725747214963

Epoch: 6| Step: 13
Training loss: 2.2242059383686605
Validation loss: 2.540933751127526

Epoch: 66| Step: 0
Training loss: 2.3839875872692087
Validation loss: 2.5445430378797926

Epoch: 6| Step: 1
Training loss: 3.280409496378192
Validation loss: 2.5431512168255304

Epoch: 6| Step: 2
Training loss: 3.339262901793586
Validation loss: 2.5468343105773847

Epoch: 6| Step: 3
Training loss: 2.959860412038453
Validation loss: 2.547689782013937

Epoch: 6| Step: 4
Training loss: 2.3592052272320903
Validation loss: 2.543884946020167

Epoch: 6| Step: 5
Training loss: 2.780138029198418
Validation loss: 2.551742911388013

Epoch: 6| Step: 6
Training loss: 2.5382322861447757
Validation loss: 2.547758432233255

Epoch: 6| Step: 7
Training loss: 2.4193334225762944
Validation loss: 2.556446108493978

Epoch: 6| Step: 8
Training loss: 3.394850949595682
Validation loss: 2.5498913427129475

Epoch: 6| Step: 9
Training loss: 3.651767819940692
Validation loss: 2.547366497166842

Epoch: 6| Step: 10
Training loss: 2.268901691672561
Validation loss: 2.541602329735647

Epoch: 6| Step: 11
Training loss: 2.5033156342606673
Validation loss: 2.55470454145813

Epoch: 6| Step: 12
Training loss: 2.4307563614017083
Validation loss: 2.5510629133685163

Epoch: 6| Step: 13
Training loss: 1.170883573130733
Validation loss: 2.549741942095704

Epoch: 67| Step: 0
Training loss: 2.7758055127857952
Validation loss: 2.5426258077513304

Epoch: 6| Step: 1
Training loss: 3.0286684349749597
Validation loss: 2.5414428134934437

Epoch: 6| Step: 2
Training loss: 2.8014654922497897
Validation loss: 2.561353207262544

Epoch: 6| Step: 3
Training loss: 2.8281356221205045
Validation loss: 2.538900503791689

Epoch: 6| Step: 4
Training loss: 2.3454432156889324
Validation loss: 2.548104582324681

Epoch: 6| Step: 5
Training loss: 2.4349514280014035
Validation loss: 2.5515534330265384

Epoch: 6| Step: 6
Training loss: 2.9389670746403938
Validation loss: 2.547422737567249

Epoch: 6| Step: 7
Training loss: 2.4696425743800314
Validation loss: 2.5680666550804165

Epoch: 6| Step: 8
Training loss: 2.6471170830392747
Validation loss: 2.545039229191092

Epoch: 6| Step: 9
Training loss: 3.4428742446203318
Validation loss: 2.555400011326402

Epoch: 6| Step: 10
Training loss: 2.4334795145865926
Validation loss: 2.546190837438363

Epoch: 6| Step: 11
Training loss: 3.408457749263679
Validation loss: 2.5498647549800024

Epoch: 6| Step: 12
Training loss: 2.2333406842049097
Validation loss: 2.547954349488862

Epoch: 6| Step: 13
Training loss: 2.874485467395949
Validation loss: 2.54175314578785

Epoch: 68| Step: 0
Training loss: 1.97730684400441
Validation loss: 2.565008940594081

Epoch: 6| Step: 1
Training loss: 2.3568802332206737
Validation loss: 2.5606074018282974

Epoch: 6| Step: 2
Training loss: 2.5230129581622136
Validation loss: 2.5550495036855905

Epoch: 6| Step: 3
Training loss: 2.516879888264087
Validation loss: 2.5605105208706553

Epoch: 6| Step: 4
Training loss: 2.378173013570881
Validation loss: 2.5455301945522346

Epoch: 6| Step: 5
Training loss: 2.550458014251263
Validation loss: 2.562768360355136

Epoch: 6| Step: 6
Training loss: 3.4362410580826444
Validation loss: 2.550314737497169

Epoch: 6| Step: 7
Training loss: 3.012863871652094
Validation loss: 2.55197933571938

Epoch: 6| Step: 8
Training loss: 2.6150414621483313
Validation loss: 2.544150473452097

Epoch: 6| Step: 9
Training loss: 3.2463947253011884
Validation loss: 2.535556925559768

Epoch: 6| Step: 10
Training loss: 3.2596481603779828
Validation loss: 2.544514171681272

Epoch: 6| Step: 11
Training loss: 3.165639225437327
Validation loss: 2.545432667734108

Epoch: 6| Step: 12
Training loss: 2.363236658605658
Validation loss: 2.5366120478950718

Epoch: 6| Step: 13
Training loss: 3.0822051450070944
Validation loss: 2.5446219777192742

Epoch: 69| Step: 0
Training loss: 2.2085648061490533
Validation loss: 2.5509403420796577

Epoch: 6| Step: 1
Training loss: 3.3543592757056744
Validation loss: 2.5410096255457324

Epoch: 6| Step: 2
Training loss: 2.5581314251611893
Validation loss: 2.5413921301399536

Epoch: 6| Step: 3
Training loss: 2.6606351670583286
Validation loss: 2.551733911604685

Epoch: 6| Step: 4
Training loss: 2.460884892945898
Validation loss: 2.551575899856011

Epoch: 6| Step: 5
Training loss: 2.883251125802843
Validation loss: 2.5558842180441905

Epoch: 6| Step: 6
Training loss: 2.514123883395966
Validation loss: 2.5537151297342695

Epoch: 6| Step: 7
Training loss: 1.7233293044573816
Validation loss: 2.544281650372897

Epoch: 6| Step: 8
Training loss: 3.0151069472846985
Validation loss: 2.5518266546684942

Epoch: 6| Step: 9
Training loss: 2.8785497892446044
Validation loss: 2.550273122844923

Epoch: 6| Step: 10
Training loss: 2.1962619235345264
Validation loss: 2.565925227791371

Epoch: 6| Step: 11
Training loss: 3.58907777337099
Validation loss: 2.5466333100088034

Epoch: 6| Step: 12
Training loss: 3.490697214170204
Validation loss: 2.5599004003337806

Epoch: 6| Step: 13
Training loss: 2.5725744434258404
Validation loss: 2.557449522075917

Epoch: 70| Step: 0
Training loss: 2.5731013511032397
Validation loss: 2.564003491071198

Epoch: 6| Step: 1
Training loss: 2.746034971560442
Validation loss: 2.5483782682944778

Epoch: 6| Step: 2
Training loss: 2.54992726914149
Validation loss: 2.5707709000328998

Epoch: 6| Step: 3
Training loss: 3.187704191960398
Validation loss: 2.547112884675626

Epoch: 6| Step: 4
Training loss: 2.9438573343912275
Validation loss: 2.540904822737443

Epoch: 6| Step: 5
Training loss: 2.994618357190881
Validation loss: 2.5558486862949494

Epoch: 6| Step: 6
Training loss: 2.454274873879284
Validation loss: 2.550872125225286

Epoch: 6| Step: 7
Training loss: 2.6949122919591537
Validation loss: 2.540514111920216

Epoch: 6| Step: 8
Training loss: 2.455164747750878
Validation loss: 2.555283508188886

Epoch: 6| Step: 9
Training loss: 2.6457950158736274
Validation loss: 2.5592313449077384

Epoch: 6| Step: 10
Training loss: 2.8783950662389333
Validation loss: 2.5430863374684263

Epoch: 6| Step: 11
Training loss: 2.620431921642525
Validation loss: 2.5449374476585245

Epoch: 6| Step: 12
Training loss: 2.5971318454170262
Validation loss: 2.5626849476170754

Epoch: 6| Step: 13
Training loss: 3.4814672268770313
Validation loss: 2.5534120780135767

Epoch: 71| Step: 0
Training loss: 2.938393801800645
Validation loss: 2.548423855286565

Epoch: 6| Step: 1
Training loss: 2.0812336322495932
Validation loss: 2.5604788750368908

Epoch: 6| Step: 2
Training loss: 3.125732946272924
Validation loss: 2.5602017262459262

Epoch: 6| Step: 3
Training loss: 2.49844846263816
Validation loss: 2.5525446749580087

Epoch: 6| Step: 4
Training loss: 1.9957211141023807
Validation loss: 2.542433849029173

Epoch: 6| Step: 5
Training loss: 3.4391996863255665
Validation loss: 2.5476746478049166

Epoch: 6| Step: 6
Training loss: 2.7844707399770483
Validation loss: 2.550466534047163

Epoch: 6| Step: 7
Training loss: 2.4026704395503073
Validation loss: 2.540713573497533

Epoch: 6| Step: 8
Training loss: 2.5949993571609555
Validation loss: 2.529150196832786

Epoch: 6| Step: 9
Training loss: 2.169267584961241
Validation loss: 2.5385793014418145

Epoch: 6| Step: 10
Training loss: 3.2259698281908125
Validation loss: 2.5564424632615115

Epoch: 6| Step: 11
Training loss: 2.8138503329853295
Validation loss: 2.5534197214985883

Epoch: 6| Step: 12
Training loss: 3.5744666175153244
Validation loss: 2.5585480937126563

Epoch: 6| Step: 13
Training loss: 2.2223536280351
Validation loss: 2.5430832991061902

Epoch: 72| Step: 0
Training loss: 2.411184725196769
Validation loss: 2.5523394725876756

Epoch: 6| Step: 1
Training loss: 2.214092254977151
Validation loss: 2.5596890793164206

Epoch: 6| Step: 2
Training loss: 2.585300885809235
Validation loss: 2.5487732583980405

Epoch: 6| Step: 3
Training loss: 2.740708259179071
Validation loss: 2.563488483235212

Epoch: 6| Step: 4
Training loss: 2.4503332884502274
Validation loss: 2.545361680069415

Epoch: 6| Step: 5
Training loss: 3.148728425851945
Validation loss: 2.5489565799844107

Epoch: 6| Step: 6
Training loss: 2.352600274214031
Validation loss: 2.5435624656696243

Epoch: 6| Step: 7
Training loss: 2.638112515020301
Validation loss: 2.5458430415223288

Epoch: 6| Step: 8
Training loss: 3.033370230174369
Validation loss: 2.552129793696421

Epoch: 6| Step: 9
Training loss: 3.515144145717689
Validation loss: 2.5440467921147354

Epoch: 6| Step: 10
Training loss: 3.078971630177595
Validation loss: 2.5512782357396073

Epoch: 6| Step: 11
Training loss: 3.198387103109993
Validation loss: 2.536942428828897

Epoch: 6| Step: 12
Training loss: 2.5636432237490294
Validation loss: 2.5407255314112436

Epoch: 6| Step: 13
Training loss: 2.320329556900164
Validation loss: 2.5467349130351904

Epoch: 73| Step: 0
Training loss: 3.2971388001687347
Validation loss: 2.546111257530836

Epoch: 6| Step: 1
Training loss: 2.466823937153615
Validation loss: 2.549252714081614

Epoch: 6| Step: 2
Training loss: 1.9906451070060478
Validation loss: 2.555170967350523

Epoch: 6| Step: 3
Training loss: 2.742203497772067
Validation loss: 2.559472345084086

Epoch: 6| Step: 4
Training loss: 1.901062394817342
Validation loss: 2.551905195403302

Epoch: 6| Step: 5
Training loss: 2.6075507085739336
Validation loss: 2.5518501438054697

Epoch: 6| Step: 6
Training loss: 3.007994807279447
Validation loss: 2.540494548363323

Epoch: 6| Step: 7
Training loss: 2.8602056912168634
Validation loss: 2.5516349199306934

Epoch: 6| Step: 8
Training loss: 3.3333203951266643
Validation loss: 2.541488123418562

Epoch: 6| Step: 9
Training loss: 3.077143943635643
Validation loss: 2.552829941779701

Epoch: 6| Step: 10
Training loss: 2.8504250125867845
Validation loss: 2.547605509287813

Epoch: 6| Step: 11
Training loss: 2.6584915576432713
Validation loss: 2.5478983602933627

Epoch: 6| Step: 12
Training loss: 2.114507463970167
Validation loss: 2.5429779191690876

Epoch: 6| Step: 13
Training loss: 3.5105885690921443
Validation loss: 2.5516230945241807

Epoch: 74| Step: 0
Training loss: 2.6048110978356407
Validation loss: 2.5480641107412563

Epoch: 6| Step: 1
Training loss: 3.1424804065369685
Validation loss: 2.556161640388252

Epoch: 6| Step: 2
Training loss: 2.2825915428765016
Validation loss: 2.5477387874551427

Epoch: 6| Step: 3
Training loss: 2.895270002354814
Validation loss: 2.538752218492196

Epoch: 6| Step: 4
Training loss: 3.0180274999135404
Validation loss: 2.54384134213312

Epoch: 6| Step: 5
Training loss: 2.9443686513522587
Validation loss: 2.5549044565081664

Epoch: 6| Step: 6
Training loss: 3.3420327313485103
Validation loss: 2.549559966059968

Epoch: 6| Step: 7
Training loss: 2.544173041930355
Validation loss: 2.5496978526873026

Epoch: 6| Step: 8
Training loss: 1.6757968999669872
Validation loss: 2.5517715189948267

Epoch: 6| Step: 9
Training loss: 2.175682846391793
Validation loss: 2.5405385906249953

Epoch: 6| Step: 10
Training loss: 2.4307223259765762
Validation loss: 2.5397182852688265

Epoch: 6| Step: 11
Training loss: 3.1722838791264607
Validation loss: 2.542896702029646

Epoch: 6| Step: 12
Training loss: 3.314502182947563
Validation loss: 2.5477644786849534

Epoch: 6| Step: 13
Training loss: 2.197674875082159
Validation loss: 2.5529981756903553

Epoch: 75| Step: 0
Training loss: 2.720400605152603
Validation loss: 2.5326115713712505

Epoch: 6| Step: 1
Training loss: 2.63070540059004
Validation loss: 2.549372387933966

Epoch: 6| Step: 2
Training loss: 2.606666209699716
Validation loss: 2.5436565568554403

Epoch: 6| Step: 3
Training loss: 3.1947152248740407
Validation loss: 2.554666896964157

Epoch: 6| Step: 4
Training loss: 2.201332715986147
Validation loss: 2.5432705235863695

Epoch: 6| Step: 5
Training loss: 2.566874700843008
Validation loss: 2.5598883116684656

Epoch: 6| Step: 6
Training loss: 3.3042289109077645
Validation loss: 2.5556129108351744

Epoch: 6| Step: 7
Training loss: 2.9623034705793803
Validation loss: 2.535910915950418

Epoch: 6| Step: 8
Training loss: 2.813611806884757
Validation loss: 2.553204734859416

Epoch: 6| Step: 9
Training loss: 1.9219452759834559
Validation loss: 2.548590470837776

Epoch: 6| Step: 10
Training loss: 2.6463342828171905
Validation loss: 2.54753047083716

Epoch: 6| Step: 11
Training loss: 2.3881070708355816
Validation loss: 2.541651285616852

Epoch: 6| Step: 12
Training loss: 3.206713345902325
Validation loss: 2.5553773554005743

Epoch: 6| Step: 13
Training loss: 3.0891862596525597
Validation loss: 2.546767121227205

Epoch: 76| Step: 0
Training loss: 2.737098950137133
Validation loss: 2.5556626200114003

Epoch: 6| Step: 1
Training loss: 2.7488291588765463
Validation loss: 2.546561045584346

Epoch: 6| Step: 2
Training loss: 3.0102787360213807
Validation loss: 2.5355576424125177

Epoch: 6| Step: 3
Training loss: 2.5797556026533575
Validation loss: 2.5490256974446077

Epoch: 6| Step: 4
Training loss: 3.107176957467909
Validation loss: 2.5474858258953073

Epoch: 6| Step: 5
Training loss: 2.4118050201773737
Validation loss: 2.5534320119696954

Epoch: 6| Step: 6
Training loss: 2.0958416867200294
Validation loss: 2.5478000819220536

Epoch: 6| Step: 7
Training loss: 2.722813868509713
Validation loss: 2.553521402371018

Epoch: 6| Step: 8
Training loss: 2.8260949367550863
Validation loss: 2.5556339215415136

Epoch: 6| Step: 9
Training loss: 3.2222957894999795
Validation loss: 2.548102626471164

Epoch: 6| Step: 10
Training loss: 2.8272101677198487
Validation loss: 2.5547294722382428

Epoch: 6| Step: 11
Training loss: 2.4749180481569026
Validation loss: 2.5635161517280305

Epoch: 6| Step: 12
Training loss: 2.5686540905944666
Validation loss: 2.5610590238960613

Epoch: 6| Step: 13
Training loss: 3.0681441320808527
Validation loss: 2.5553351841247376

Epoch: 77| Step: 0
Training loss: 3.620630195517807
Validation loss: 2.5425805675061226

Epoch: 6| Step: 1
Training loss: 2.318126535011456
Validation loss: 2.560030879376343

Epoch: 6| Step: 2
Training loss: 2.1401026847303815
Validation loss: 2.5482121076898516

Epoch: 6| Step: 3
Training loss: 2.657001164755891
Validation loss: 2.5620438124411877

Epoch: 6| Step: 4
Training loss: 2.943974117486625
Validation loss: 2.542634424369506

Epoch: 6| Step: 5
Training loss: 2.595439498522499
Validation loss: 2.5464650160137206

Epoch: 6| Step: 6
Training loss: 2.2723530808095704
Validation loss: 2.5492366408232723

Epoch: 6| Step: 7
Training loss: 2.8460466102970625
Validation loss: 2.54940909899088

Epoch: 6| Step: 8
Training loss: 2.8682988894616805
Validation loss: 2.5592530271079847

Epoch: 6| Step: 9
Training loss: 2.7469441167578967
Validation loss: 2.5486607735947184

Epoch: 6| Step: 10
Training loss: 3.0716171016685485
Validation loss: 2.550724390156831

Epoch: 6| Step: 11
Training loss: 3.184058182429184
Validation loss: 2.5416740502771873

Epoch: 6| Step: 12
Training loss: 2.0963692295331
Validation loss: 2.5531376087279374

Epoch: 6| Step: 13
Training loss: 2.480824074113366
Validation loss: 2.5434384846652054

Epoch: 78| Step: 0
Training loss: 2.8044085775685725
Validation loss: 2.5561053996984957

Epoch: 6| Step: 1
Training loss: 2.404366486794354
Validation loss: 2.5446860764415593

Epoch: 6| Step: 2
Training loss: 2.934831096721612
Validation loss: 2.545896446721639

Epoch: 6| Step: 3
Training loss: 1.8413616163681392
Validation loss: 2.538116208062126

Epoch: 6| Step: 4
Training loss: 3.2352626890808107
Validation loss: 2.554497618836174

Epoch: 6| Step: 5
Training loss: 2.6505908595258627
Validation loss: 2.5479244010669118

Epoch: 6| Step: 6
Training loss: 2.1716417146168054
Validation loss: 2.5470384909812425

Epoch: 6| Step: 7
Training loss: 3.0204801857267936
Validation loss: 2.544294514482201

Epoch: 6| Step: 8
Training loss: 2.066128400211882
Validation loss: 2.5527479808459943

Epoch: 6| Step: 9
Training loss: 2.5491429627750435
Validation loss: 2.55481649424803

Epoch: 6| Step: 10
Training loss: 3.3477795999919215
Validation loss: 2.536525306913248

Epoch: 6| Step: 11
Training loss: 3.5529256290003484
Validation loss: 2.5545543435125753

Epoch: 6| Step: 12
Training loss: 2.9884025200066393
Validation loss: 2.550796386882886

Epoch: 6| Step: 13
Training loss: 1.8863894726131887
Validation loss: 2.5468767031375723

Epoch: 79| Step: 0
Training loss: 2.9668047504935795
Validation loss: 2.538802463792827

Epoch: 6| Step: 1
Training loss: 2.452321595246523
Validation loss: 2.553277156646347

Epoch: 6| Step: 2
Training loss: 2.7084930568449037
Validation loss: 2.5501539687744628

Epoch: 6| Step: 3
Training loss: 3.0003595136756047
Validation loss: 2.5741308402267533

Epoch: 6| Step: 4
Training loss: 2.486051078038415
Validation loss: 2.5400310365988075

Epoch: 6| Step: 5
Training loss: 2.92603026935933
Validation loss: 2.553643605821353

Epoch: 6| Step: 6
Training loss: 2.506785720304385
Validation loss: 2.5328589252902165

Epoch: 6| Step: 7
Training loss: 2.8890799027244247
Validation loss: 2.5493042940449744

Epoch: 6| Step: 8
Training loss: 2.7111512905107014
Validation loss: 2.5394039043793653

Epoch: 6| Step: 9
Training loss: 2.823636027852323
Validation loss: 2.5437245892787432

Epoch: 6| Step: 10
Training loss: 3.3250020019984134
Validation loss: 2.5460612591700267

Epoch: 6| Step: 11
Training loss: 1.2378234979901268
Validation loss: 2.552919562136007

Epoch: 6| Step: 12
Training loss: 3.154080391178017
Validation loss: 2.5546083854835144

Epoch: 6| Step: 13
Training loss: 2.7551554126140054
Validation loss: 2.5473315148584583

Epoch: 80| Step: 0
Training loss: 2.02418239241368
Validation loss: 2.565417412037116

Epoch: 6| Step: 1
Training loss: 1.5406110689411583
Validation loss: 2.548100785311389

Epoch: 6| Step: 2
Training loss: 2.925521288987126
Validation loss: 2.543777990578977

Epoch: 6| Step: 3
Training loss: 3.2692109638149285
Validation loss: 2.544042194470932

Epoch: 6| Step: 4
Training loss: 3.019753905620903
Validation loss: 2.5420484358675473

Epoch: 6| Step: 5
Training loss: 2.8506294291603425
Validation loss: 2.5469433188798503

Epoch: 6| Step: 6
Training loss: 2.3494333152099482
Validation loss: 2.5445822839391843

Epoch: 6| Step: 7
Training loss: 3.5551471790262883
Validation loss: 2.53809314634859

Epoch: 6| Step: 8
Training loss: 2.02495738797035
Validation loss: 2.548171377241903

Epoch: 6| Step: 9
Training loss: 2.568961301405947
Validation loss: 2.5420116800289176

Epoch: 6| Step: 10
Training loss: 3.349208191627427
Validation loss: 2.555454173855504

Epoch: 6| Step: 11
Training loss: 2.4195611544797404
Validation loss: 2.5429894730160347

Epoch: 6| Step: 12
Training loss: 3.052216371798277
Validation loss: 2.550830543786878

Epoch: 6| Step: 13
Training loss: 2.55173538846347
Validation loss: 2.5521190735401067

Epoch: 81| Step: 0
Training loss: 2.9114808620247743
Validation loss: 2.5455242435050796

Epoch: 6| Step: 1
Training loss: 2.99291330005857
Validation loss: 2.541571046619852

Epoch: 6| Step: 2
Training loss: 2.0708306581824028
Validation loss: 2.541278686108117

Epoch: 6| Step: 3
Training loss: 2.423282730994454
Validation loss: 2.53734698098664

Epoch: 6| Step: 4
Training loss: 2.951287399242447
Validation loss: 2.54675023402243

Epoch: 6| Step: 5
Training loss: 2.0271442881165984
Validation loss: 2.5459786896452368

Epoch: 6| Step: 6
Training loss: 3.2245934045258666
Validation loss: 2.537992888284869

Epoch: 6| Step: 7
Training loss: 2.9631574456531147
Validation loss: 2.5463019342278237

Epoch: 6| Step: 8
Training loss: 2.2771641969646685
Validation loss: 2.5562802998112746

Epoch: 6| Step: 9
Training loss: 3.4474072651496575
Validation loss: 2.5472439503033124

Epoch: 6| Step: 10
Training loss: 2.286235013467382
Validation loss: 2.5601971711315747

Epoch: 6| Step: 11
Training loss: 2.386003402669164
Validation loss: 2.5549572789683275

Epoch: 6| Step: 12
Training loss: 3.1643248649421434
Validation loss: 2.538781298644113

Epoch: 6| Step: 13
Training loss: 2.7895859512951175
Validation loss: 2.5554554730037387

Epoch: 82| Step: 0
Training loss: 2.436365597185824
Validation loss: 2.537735012415572

Epoch: 6| Step: 1
Training loss: 3.5483579518360195
Validation loss: 2.5520387251778667

Epoch: 6| Step: 2
Training loss: 2.0335819649986866
Validation loss: 2.5405127677945476

Epoch: 6| Step: 3
Training loss: 2.3724530265828836
Validation loss: 2.5473497508052794

Epoch: 6| Step: 4
Training loss: 3.3074169385518846
Validation loss: 2.537203318505338

Epoch: 6| Step: 5
Training loss: 1.8365651457895535
Validation loss: 2.5379091370338354

Epoch: 6| Step: 6
Training loss: 2.74954211151012
Validation loss: 2.5433401579395647

Epoch: 6| Step: 7
Training loss: 2.398100987787156
Validation loss: 2.5475903846411643

Epoch: 6| Step: 8
Training loss: 3.3114295525433604
Validation loss: 2.5445855210017756

Epoch: 6| Step: 9
Training loss: 2.723456507324844
Validation loss: 2.5457525204989837

Epoch: 6| Step: 10
Training loss: 2.855588813898118
Validation loss: 2.5423725774500765

Epoch: 6| Step: 11
Training loss: 2.432584060204485
Validation loss: 2.550308267859592

Epoch: 6| Step: 12
Training loss: 2.9490374983107404
Validation loss: 2.547703562719813

Epoch: 6| Step: 13
Training loss: 2.7846905290845942
Validation loss: 2.547189034481256

Epoch: 83| Step: 0
Training loss: 2.6110363999177713
Validation loss: 2.5463266965837708

Epoch: 6| Step: 1
Training loss: 2.1493902140104155
Validation loss: 2.557198147690402

Epoch: 6| Step: 2
Training loss: 3.1049512515948257
Validation loss: 2.5547076763836376

Epoch: 6| Step: 3
Training loss: 3.0061401474008873
Validation loss: 2.5414252422892574

Epoch: 6| Step: 4
Training loss: 2.8106446822420783
Validation loss: 2.5434799168265436

Epoch: 6| Step: 5
Training loss: 1.8246686817576652
Validation loss: 2.542516077919065

Epoch: 6| Step: 6
Training loss: 2.1555139142151227
Validation loss: 2.5425398769137892

Epoch: 6| Step: 7
Training loss: 3.513147863189133
Validation loss: 2.5426652023766176

Epoch: 6| Step: 8
Training loss: 3.441582769398139
Validation loss: 2.561439867120774

Epoch: 6| Step: 9
Training loss: 2.094055836673639
Validation loss: 2.5456448982929216

Epoch: 6| Step: 10
Training loss: 2.4269076326049257
Validation loss: 2.5355163264909075

Epoch: 6| Step: 11
Training loss: 2.5532711664239645
Validation loss: 2.5501746092758433

Epoch: 6| Step: 12
Training loss: 3.4219502479954116
Validation loss: 2.545490284301814

Epoch: 6| Step: 13
Training loss: 2.459376151679616
Validation loss: 2.5461437736598107

Epoch: 84| Step: 0
Training loss: 2.5595605319526507
Validation loss: 2.5534246968297825

Epoch: 6| Step: 1
Training loss: 2.6070698132519263
Validation loss: 2.5517285175465285

Epoch: 6| Step: 2
Training loss: 3.053557750445001
Validation loss: 2.5445433109137188

Epoch: 6| Step: 3
Training loss: 2.4881371377027484
Validation loss: 2.5477863570804926

Epoch: 6| Step: 4
Training loss: 2.1931276139520706
Validation loss: 2.5546242061743496

Epoch: 6| Step: 5
Training loss: 2.1356167087053484
Validation loss: 2.544401069367892

Epoch: 6| Step: 6
Training loss: 2.2577645583821235
Validation loss: 2.5431693869827243

Epoch: 6| Step: 7
Training loss: 2.5484501934846353
Validation loss: 2.551929719548866

Epoch: 6| Step: 8
Training loss: 3.378320826272219
Validation loss: 2.56052383008619

Epoch: 6| Step: 9
Training loss: 3.4860365117886296
Validation loss: 2.545863332306994

Epoch: 6| Step: 10
Training loss: 2.775415966715541
Validation loss: 2.548864122739324

Epoch: 6| Step: 11
Training loss: 3.045182134383325
Validation loss: 2.5429343443394967

Epoch: 6| Step: 12
Training loss: 2.572750153089049
Validation loss: 2.550165758771553

Epoch: 6| Step: 13
Training loss: 2.7791267605670757
Validation loss: 2.546310709563135

Epoch: 85| Step: 0
Training loss: 3.4758481095362046
Validation loss: 2.547173945607315

Epoch: 6| Step: 1
Training loss: 2.2540828959564156
Validation loss: 2.543840910297971

Epoch: 6| Step: 2
Training loss: 2.3659615442306063
Validation loss: 2.5688557991978938

Epoch: 6| Step: 3
Training loss: 2.099346367974921
Validation loss: 2.5386376516912152

Epoch: 6| Step: 4
Training loss: 2.326416822680132
Validation loss: 2.5410365435278597

Epoch: 6| Step: 5
Training loss: 2.782343617283579
Validation loss: 2.542743341511823

Epoch: 6| Step: 6
Training loss: 2.473695750439202
Validation loss: 2.534913593379539

Epoch: 6| Step: 7
Training loss: 3.0966512004464697
Validation loss: 2.5555250742810847

Epoch: 6| Step: 8
Training loss: 2.9435920041199237
Validation loss: 2.544939376731461

Epoch: 6| Step: 9
Training loss: 3.172246901784883
Validation loss: 2.5481635379267233

Epoch: 6| Step: 10
Training loss: 2.2755166735137777
Validation loss: 2.544491553837343

Epoch: 6| Step: 11
Training loss: 3.081125878238549
Validation loss: 2.540382763666832

Epoch: 6| Step: 12
Training loss: 2.593828131176866
Validation loss: 2.558451640799404

Epoch: 6| Step: 13
Training loss: 3.1346349576057255
Validation loss: 2.548144260473257

Epoch: 86| Step: 0
Training loss: 3.6233582560767963
Validation loss: 2.541819628532814

Epoch: 6| Step: 1
Training loss: 2.2083012800469577
Validation loss: 2.5450991653787822

Epoch: 6| Step: 2
Training loss: 2.834282846855875
Validation loss: 2.55126516969919

Epoch: 6| Step: 3
Training loss: 2.396084802671182
Validation loss: 2.534744517210089

Epoch: 6| Step: 4
Training loss: 2.5502188794312954
Validation loss: 2.548615793371734

Epoch: 6| Step: 5
Training loss: 2.1645586567397053
Validation loss: 2.5415689646963715

Epoch: 6| Step: 6
Training loss: 2.7914878920822574
Validation loss: 2.542348712353265

Epoch: 6| Step: 7
Training loss: 3.3836792855118745
Validation loss: 2.537846040956204

Epoch: 6| Step: 8
Training loss: 3.1568805329148395
Validation loss: 2.5423640869989184

Epoch: 6| Step: 9
Training loss: 2.497658777698029
Validation loss: 2.5377103546297324

Epoch: 6| Step: 10
Training loss: 2.931904759919775
Validation loss: 2.556198040320587

Epoch: 6| Step: 11
Training loss: 1.796568603929922
Validation loss: 2.540801330319281

Epoch: 6| Step: 12
Training loss: 2.8740315672136973
Validation loss: 2.5441779905037065

Epoch: 6| Step: 13
Training loss: 2.235455551828405
Validation loss: 2.5401002470514995

Epoch: 87| Step: 0
Training loss: 3.207107970496757
Validation loss: 2.5416820982234785

Epoch: 6| Step: 1
Training loss: 2.7171298055462842
Validation loss: 2.5471301398614674

Epoch: 6| Step: 2
Training loss: 2.260246364196074
Validation loss: 2.5506973819405983

Epoch: 6| Step: 3
Training loss: 2.687295772865692
Validation loss: 2.540802379163147

Epoch: 6| Step: 4
Training loss: 3.399291323687321
Validation loss: 2.5454396472961576

Epoch: 6| Step: 5
Training loss: 3.267590383083702
Validation loss: 2.554765921676641

Epoch: 6| Step: 6
Training loss: 2.4878548297172722
Validation loss: 2.5472431079153792

Epoch: 6| Step: 7
Training loss: 2.5015209339889233
Validation loss: 2.5512262555535403

Epoch: 6| Step: 8
Training loss: 2.5192364660703768
Validation loss: 2.5562398453453676

Epoch: 6| Step: 9
Training loss: 2.759470929976435
Validation loss: 2.5473628983186205

Epoch: 6| Step: 10
Training loss: 2.6449379995539357
Validation loss: 2.556894796414154

Epoch: 6| Step: 11
Training loss: 2.4869669702573702
Validation loss: 2.561352112285308

Epoch: 6| Step: 12
Training loss: 2.1892785607609797
Validation loss: 2.5493511255072216

Epoch: 6| Step: 13
Training loss: 2.8190344453393985
Validation loss: 2.550720739762658

Epoch: 88| Step: 0
Training loss: 2.7300110789482925
Validation loss: 2.5573049859511943

Epoch: 6| Step: 1
Training loss: 1.9423440245624404
Validation loss: 2.54972445322069

Epoch: 6| Step: 2
Training loss: 3.0208478379175396
Validation loss: 2.556924126423934

Epoch: 6| Step: 3
Training loss: 3.082649739411462
Validation loss: 2.55645864163599

Epoch: 6| Step: 4
Training loss: 2.886607744821062
Validation loss: 2.5567332061206822

Epoch: 6| Step: 5
Training loss: 2.7595534408434808
Validation loss: 2.5510177614467437

Epoch: 6| Step: 6
Training loss: 2.599581310599359
Validation loss: 2.555884242117024

Epoch: 6| Step: 7
Training loss: 3.698212918875137
Validation loss: 2.5580105295083624

Epoch: 6| Step: 8
Training loss: 2.508134387502776
Validation loss: 2.572228087016167

Epoch: 6| Step: 9
Training loss: 2.214759461751815
Validation loss: 2.5591193002499417

Epoch: 6| Step: 10
Training loss: 2.7762238595995137
Validation loss: 2.5441417853860684

Epoch: 6| Step: 11
Training loss: 2.418914067817741
Validation loss: 2.5483563014228854

Epoch: 6| Step: 12
Training loss: 2.811416926060792
Validation loss: 2.5494293664213385

Epoch: 6| Step: 13
Training loss: 1.5009239847756952
Validation loss: 2.547351267442438

Epoch: 89| Step: 0
Training loss: 2.7616350088413397
Validation loss: 2.5481014201595276

Epoch: 6| Step: 1
Training loss: 2.661151089386778
Validation loss: 2.567507227870406

Epoch: 6| Step: 2
Training loss: 2.741020019318971
Validation loss: 2.5478242139183673

Epoch: 6| Step: 3
Training loss: 2.9744896266626206
Validation loss: 2.5516575377518214

Epoch: 6| Step: 4
Training loss: 3.183720910276793
Validation loss: 2.5430886237983326

Epoch: 6| Step: 5
Training loss: 2.5927436438966174
Validation loss: 2.5554926644784803

Epoch: 6| Step: 6
Training loss: 2.0065156184448174
Validation loss: 2.5382599976448366

Epoch: 6| Step: 7
Training loss: 2.6019516845662487
Validation loss: 2.542759711901364

Epoch: 6| Step: 8
Training loss: 2.9098637581095232
Validation loss: 2.5447796072658275

Epoch: 6| Step: 9
Training loss: 2.8931370722514083
Validation loss: 2.542815844488301

Epoch: 6| Step: 10
Training loss: 3.023662864309511
Validation loss: 2.5437552815326274

Epoch: 6| Step: 11
Training loss: 2.8067033159425927
Validation loss: 2.5602197944191967

Epoch: 6| Step: 12
Training loss: 2.4689422725697705
Validation loss: 2.5429635959350785

Epoch: 6| Step: 13
Training loss: 1.8878773672031832
Validation loss: 2.538672775510427

Epoch: 90| Step: 0
Training loss: 2.709005849432729
Validation loss: 2.5547932692014

Epoch: 6| Step: 1
Training loss: 3.007543299134194
Validation loss: 2.5531237388667267

Epoch: 6| Step: 2
Training loss: 2.783149327879195
Validation loss: 2.541475325801948

Epoch: 6| Step: 3
Training loss: 3.696981492689353
Validation loss: 2.5575968095396058

Epoch: 6| Step: 4
Training loss: 2.6557732546949078
Validation loss: 2.5656211727196174

Epoch: 6| Step: 5
Training loss: 3.0027434202901357
Validation loss: 2.5469498182025245

Epoch: 6| Step: 6
Training loss: 2.287658469125648
Validation loss: 2.5409573863624817

Epoch: 6| Step: 7
Training loss: 2.057403741672985
Validation loss: 2.5473660191322063

Epoch: 6| Step: 8
Training loss: 2.9187205213083263
Validation loss: 2.542218126466388

Epoch: 6| Step: 9
Training loss: 2.2035805522061214
Validation loss: 2.545257215601317

Epoch: 6| Step: 10
Training loss: 3.0953140158651955
Validation loss: 2.550247346309539

Epoch: 6| Step: 11
Training loss: 2.378001675309216
Validation loss: 2.5492731054429627

Epoch: 6| Step: 12
Training loss: 2.2428310414462462
Validation loss: 2.545196875704335

Epoch: 6| Step: 13
Training loss: 2.432555146959523
Validation loss: 2.5424908196650597

Epoch: 91| Step: 0
Training loss: 3.2185568149702446
Validation loss: 2.556671759824451

Epoch: 6| Step: 1
Training loss: 3.12412646482387
Validation loss: 2.5483372125446055

Epoch: 6| Step: 2
Training loss: 2.7461915086951234
Validation loss: 2.5468373656032375

Epoch: 6| Step: 3
Training loss: 2.0536626428284945
Validation loss: 2.5506046922954977

Epoch: 6| Step: 4
Training loss: 2.869732550942758
Validation loss: 2.5410296184588974

Epoch: 6| Step: 5
Training loss: 2.4633982148184055
Validation loss: 2.5480845267061256

Epoch: 6| Step: 6
Training loss: 1.7071880207483432
Validation loss: 2.5488081092725916

Epoch: 6| Step: 7
Training loss: 2.2556266367360154
Validation loss: 2.5530547218070385

Epoch: 6| Step: 8
Training loss: 2.724244627243027
Validation loss: 2.54603884940401

Epoch: 6| Step: 9
Training loss: 3.0651790811765984
Validation loss: 2.550123106228624

Epoch: 6| Step: 10
Training loss: 2.783075140971837
Validation loss: 2.5414334040021145

Epoch: 6| Step: 11
Training loss: 3.5371446950024237
Validation loss: 2.5445907639664993

Epoch: 6| Step: 12
Training loss: 2.1266641271609905
Validation loss: 2.5605246560902906

Epoch: 6| Step: 13
Training loss: 2.5512586441902876
Validation loss: 2.5441986432117303

Epoch: 92| Step: 0
Training loss: 2.445905814540101
Validation loss: 2.542277259416125

Epoch: 6| Step: 1
Training loss: 2.8257259921407654
Validation loss: 2.5411884019942423

Epoch: 6| Step: 2
Training loss: 2.7007140946032355
Validation loss: 2.5359899991370307

Epoch: 6| Step: 3
Training loss: 2.681380290531571
Validation loss: 2.5396485475701045

Epoch: 6| Step: 4
Training loss: 3.357635189467694
Validation loss: 2.5462124746237467

Epoch: 6| Step: 5
Training loss: 2.4998582799796694
Validation loss: 2.5478089406441633

Epoch: 6| Step: 6
Training loss: 3.42830607545433
Validation loss: 2.5504847103877673

Epoch: 6| Step: 7
Training loss: 2.2576901095787907
Validation loss: 2.5480119472684684

Epoch: 6| Step: 8
Training loss: 3.097284013239179
Validation loss: 2.5431425394586116

Epoch: 6| Step: 9
Training loss: 2.400118757329705
Validation loss: 2.5473300928114226

Epoch: 6| Step: 10
Training loss: 2.5184560448039144
Validation loss: 2.556875293521007

Epoch: 6| Step: 11
Training loss: 2.4042215095316264
Validation loss: 2.559578221044292

Epoch: 6| Step: 12
Training loss: 2.384022389908433
Validation loss: 2.5513647675533457

Epoch: 6| Step: 13
Training loss: 2.765793876017864
Validation loss: 2.5476843944873346

Epoch: 93| Step: 0
Training loss: 2.748072121835652
Validation loss: 2.5495087733755533

Epoch: 6| Step: 1
Training loss: 2.3907410836552647
Validation loss: 2.5546390152155825

Epoch: 6| Step: 2
Training loss: 3.7164562428070784
Validation loss: 2.563018100164421

Epoch: 6| Step: 3
Training loss: 2.7967111550188615
Validation loss: 2.5541640625350737

Epoch: 6| Step: 4
Training loss: 2.089960112852738
Validation loss: 2.5580142877592413

Epoch: 6| Step: 5
Training loss: 2.1036213712756733
Validation loss: 2.546807286273129

Epoch: 6| Step: 6
Training loss: 2.4529421792880526
Validation loss: 2.5579916128950972

Epoch: 6| Step: 7
Training loss: 2.7404035976849004
Validation loss: 2.5487853887169654

Epoch: 6| Step: 8
Training loss: 2.3567517583647666
Validation loss: 2.5536437784946946

Epoch: 6| Step: 9
Training loss: 2.5546916063374874
Validation loss: 2.5484753453948685

Epoch: 6| Step: 10
Training loss: 3.0542763045452905
Validation loss: 2.569327168964901

Epoch: 6| Step: 11
Training loss: 2.588474654028101
Validation loss: 2.5393832000565055

Epoch: 6| Step: 12
Training loss: 3.3261615531254995
Validation loss: 2.5537218055720494

Epoch: 6| Step: 13
Training loss: 2.387631904992688
Validation loss: 2.5518080644320253

Epoch: 94| Step: 0
Training loss: 2.3035805322883314
Validation loss: 2.5548855540240365

Epoch: 6| Step: 1
Training loss: 1.9471277553531263
Validation loss: 2.545754433848902

Epoch: 6| Step: 2
Training loss: 3.414307749164662
Validation loss: 2.538687919455914

Epoch: 6| Step: 3
Training loss: 2.8816070931143467
Validation loss: 2.5481474507554918

Epoch: 6| Step: 4
Training loss: 2.1412394957276417
Validation loss: 2.5541707924033963

Epoch: 6| Step: 5
Training loss: 3.0346955842091243
Validation loss: 2.5548513851061605

Epoch: 6| Step: 6
Training loss: 2.952821746272333
Validation loss: 2.5552534841386643

Epoch: 6| Step: 7
Training loss: 2.6189432660075718
Validation loss: 2.5357204132928746

Epoch: 6| Step: 8
Training loss: 3.0888478908364214
Validation loss: 2.5474363898971726

Epoch: 6| Step: 9
Training loss: 2.606399850173721
Validation loss: 2.562118583923943

Epoch: 6| Step: 10
Training loss: 2.880202520455444
Validation loss: 2.543971926828024

Epoch: 6| Step: 11
Training loss: 2.7103018331477244
Validation loss: 2.559439295134271

Epoch: 6| Step: 12
Training loss: 2.50119009301746
Validation loss: 2.5405840781284863

Epoch: 6| Step: 13
Training loss: 2.346216048826752
Validation loss: 2.5367973862265787

Epoch: 95| Step: 0
Training loss: 2.931777900058843
Validation loss: 2.5605797599741456

Epoch: 6| Step: 1
Training loss: 2.4413832030162177
Validation loss: 2.554163610865424

Epoch: 6| Step: 2
Training loss: 3.3004203644246863
Validation loss: 2.564044115999296

Epoch: 6| Step: 3
Training loss: 2.464245900529484
Validation loss: 2.5625610569388604

Epoch: 6| Step: 4
Training loss: 2.1408547605296286
Validation loss: 2.559099363511221

Epoch: 6| Step: 5
Training loss: 2.4477820068548333
Validation loss: 2.5460112155226837

Epoch: 6| Step: 6
Training loss: 3.2925085286904
Validation loss: 2.5444473381878034

Epoch: 6| Step: 7
Training loss: 2.928626435457741
Validation loss: 2.5511606329374117

Epoch: 6| Step: 8
Training loss: 2.422633095501149
Validation loss: 2.5404245897806867

Epoch: 6| Step: 9
Training loss: 2.710327079713502
Validation loss: 2.5443507048987684

Epoch: 6| Step: 10
Training loss: 2.6773180036194586
Validation loss: 2.553445636186221

Epoch: 6| Step: 11
Training loss: 2.5039630948902802
Validation loss: 2.552237688879329

Epoch: 6| Step: 12
Training loss: 2.5650430481627833
Validation loss: 2.5482910877920943

Epoch: 6| Step: 13
Training loss: 2.692781537141251
Validation loss: 2.5441421773674175

Epoch: 96| Step: 0
Training loss: 2.793237377133105
Validation loss: 2.550045401329663

Epoch: 6| Step: 1
Training loss: 3.3127242678171935
Validation loss: 2.5388271084473693

Epoch: 6| Step: 2
Training loss: 3.292400487556
Validation loss: 2.54529435666436

Epoch: 6| Step: 3
Training loss: 2.3349654302549836
Validation loss: 2.5468482791121225

Epoch: 6| Step: 4
Training loss: 2.332310134339801
Validation loss: 2.5482414199294907

Epoch: 6| Step: 5
Training loss: 2.557443234884834
Validation loss: 2.5604197063808645

Epoch: 6| Step: 6
Training loss: 2.6314632229707593
Validation loss: 2.5427962694025634

Epoch: 6| Step: 7
Training loss: 2.8549473569596238
Validation loss: 2.546850547972606

Epoch: 6| Step: 8
Training loss: 1.9391026790123331
Validation loss: 2.5572274762259237

Epoch: 6| Step: 9
Training loss: 2.472142267065316
Validation loss: 2.548971372168608

Epoch: 6| Step: 10
Training loss: 2.845057092774242
Validation loss: 2.5471110548782985

Epoch: 6| Step: 11
Training loss: 2.2931573585520777
Validation loss: 2.5560717686270524

Epoch: 6| Step: 12
Training loss: 3.24192217005428
Validation loss: 2.553783290723286

Epoch: 6| Step: 13
Training loss: 2.3886341456929343
Validation loss: 2.547356483580463

Epoch: 97| Step: 0
Training loss: 2.4152732208054926
Validation loss: 2.5463661749026625

Epoch: 6| Step: 1
Training loss: 2.488394790047197
Validation loss: 2.5460378364489276

Epoch: 6| Step: 2
Training loss: 2.781073918287152
Validation loss: 2.552395045966548

Epoch: 6| Step: 3
Training loss: 2.988520274856361
Validation loss: 2.5517256371610175

Epoch: 6| Step: 4
Training loss: 2.785226700628741
Validation loss: 2.5483454084562642

Epoch: 6| Step: 5
Training loss: 2.261385825629045
Validation loss: 2.54218365316592

Epoch: 6| Step: 6
Training loss: 2.3728262339555863
Validation loss: 2.5482136620438087

Epoch: 6| Step: 7
Training loss: 2.5265437515308653
Validation loss: 2.5465727832566687

Epoch: 6| Step: 8
Training loss: 2.637490573522708
Validation loss: 2.5543213922814694

Epoch: 6| Step: 9
Training loss: 3.550151101778484
Validation loss: 2.5471069010925773

Epoch: 6| Step: 10
Training loss: 3.3120530024816266
Validation loss: 2.5455934586913163

Epoch: 6| Step: 11
Training loss: 2.212779864698307
Validation loss: 2.556974997196086

Epoch: 6| Step: 12
Training loss: 2.7145203761433727
Validation loss: 2.531005535628736

Epoch: 6| Step: 13
Training loss: 2.1771147389557512
Validation loss: 2.5417336754830897

Epoch: 98| Step: 0
Training loss: 2.7990204664479035
Validation loss: 2.5612291035261427

Epoch: 6| Step: 1
Training loss: 2.2553190302532937
Validation loss: 2.5624398905509325

Epoch: 6| Step: 2
Training loss: 2.8569687688106553
Validation loss: 2.5439123913700645

Epoch: 6| Step: 3
Training loss: 2.629134600444302
Validation loss: 2.5591010605167606

Epoch: 6| Step: 4
Training loss: 2.362655481136932
Validation loss: 2.546347957081635

Epoch: 6| Step: 5
Training loss: 2.038469133238354
Validation loss: 2.5440155168881633

Epoch: 6| Step: 6
Training loss: 3.6125898039852116
Validation loss: 2.525619976712304

Epoch: 6| Step: 7
Training loss: 2.5116908426351063
Validation loss: 2.5520230964012565

Epoch: 6| Step: 8
Training loss: 3.165114239744715
Validation loss: 2.547536330654117

Epoch: 6| Step: 9
Training loss: 2.281128553528312
Validation loss: 2.5429759702099086

Epoch: 6| Step: 10
Training loss: 2.520354758828916
Validation loss: 2.539275716785395

Epoch: 6| Step: 11
Training loss: 2.965024196275145
Validation loss: 2.554871022355794

Epoch: 6| Step: 12
Training loss: 2.420318694134464
Validation loss: 2.5455894444291034

Epoch: 6| Step: 13
Training loss: 3.229567340891127
Validation loss: 2.5352310682067505

Epoch: 99| Step: 0
Training loss: 2.61000976151435
Validation loss: 2.540489717745049

Epoch: 6| Step: 1
Training loss: 2.4519740034657533
Validation loss: 2.5423469608054554

Epoch: 6| Step: 2
Training loss: 2.6350201596207317
Validation loss: 2.5417133628258046

Epoch: 6| Step: 3
Training loss: 3.727604430467249
Validation loss: 2.5475842250703815

Epoch: 6| Step: 4
Training loss: 2.2913760839090025
Validation loss: 2.536101589285268

Epoch: 6| Step: 5
Training loss: 2.167733174489815
Validation loss: 2.559545115370388

Epoch: 6| Step: 6
Training loss: 1.9238706322635832
Validation loss: 2.554949901970944

Epoch: 6| Step: 7
Training loss: 2.599625424766148
Validation loss: 2.545101829646652

Epoch: 6| Step: 8
Training loss: 3.290895073830658
Validation loss: 2.531259475704451

Epoch: 6| Step: 9
Training loss: 3.188477310250678
Validation loss: 2.5500898657431463

Epoch: 6| Step: 10
Training loss: 2.812124015260239
Validation loss: 2.5491564399545665

Epoch: 6| Step: 11
Training loss: 2.8156946476357065
Validation loss: 2.551095651780526

Epoch: 6| Step: 12
Training loss: 2.3978813595220387
Validation loss: 2.5458451984958046

Epoch: 6| Step: 13
Training loss: 2.2791859943841946
Validation loss: 2.5410801188693424

Epoch: 100| Step: 0
Training loss: 2.1685590060779525
Validation loss: 2.5412178810003816

Epoch: 6| Step: 1
Training loss: 2.577534000975367
Validation loss: 2.5587159817163054

Epoch: 6| Step: 2
Training loss: 2.277148491944259
Validation loss: 2.552117686305194

Epoch: 6| Step: 3
Training loss: 2.016845215493866
Validation loss: 2.541053079273246

Epoch: 6| Step: 4
Training loss: 2.711758711819086
Validation loss: 2.5471056953158557

Epoch: 6| Step: 5
Training loss: 2.7240086703393556
Validation loss: 2.5402535541959743

Epoch: 6| Step: 6
Training loss: 2.9500333557829364
Validation loss: 2.544693176929968

Epoch: 6| Step: 7
Training loss: 2.4559260613373732
Validation loss: 2.5570508031759607

Epoch: 6| Step: 8
Training loss: 2.4712430703235304
Validation loss: 2.547050640633638

Epoch: 6| Step: 9
Training loss: 3.171791714481534
Validation loss: 2.54565539193262

Epoch: 6| Step: 10
Training loss: 3.055532041131679
Validation loss: 2.5473552859730244

Epoch: 6| Step: 11
Training loss: 2.4529889305913133
Validation loss: 2.5431070474293853

Epoch: 6| Step: 12
Training loss: 3.5342702187302977
Validation loss: 2.556940642641744

Epoch: 6| Step: 13
Training loss: 2.8422222015795766
Validation loss: 2.540638643289262

Epoch: 101| Step: 0
Training loss: 2.199421251639414
Validation loss: 2.5459926014514886

Epoch: 6| Step: 1
Training loss: 2.385048139554152
Validation loss: 2.561130286667918

Epoch: 6| Step: 2
Training loss: 2.9430499303369038
Validation loss: 2.5417587566856423

Epoch: 6| Step: 3
Training loss: 2.848918870353875
Validation loss: 2.5463285732574863

Epoch: 6| Step: 4
Training loss: 2.35343052880391
Validation loss: 2.545603908231304

Epoch: 6| Step: 5
Training loss: 1.8734026144436875
Validation loss: 2.557701003060227

Epoch: 6| Step: 6
Training loss: 2.8508114178337487
Validation loss: 2.5556408451558656

Epoch: 6| Step: 7
Training loss: 2.471159326706546
Validation loss: 2.5625111779490135

Epoch: 6| Step: 8
Training loss: 2.628918765351431
Validation loss: 2.5444694738158136

Epoch: 6| Step: 9
Training loss: 2.1916756149902232
Validation loss: 2.560112433912699

Epoch: 6| Step: 10
Training loss: 2.684031976847608
Validation loss: 2.54965164144333

Epoch: 6| Step: 11
Training loss: 3.3658829925744818
Validation loss: 2.5453639648591238

Epoch: 6| Step: 12
Training loss: 3.838240978760343
Validation loss: 2.5658790954871735

Epoch: 6| Step: 13
Training loss: 2.041693499122812
Validation loss: 2.563322231977517

Epoch: 102| Step: 0
Training loss: 2.650573049520561
Validation loss: 2.544566612387458

Epoch: 6| Step: 1
Training loss: 2.192140289690105
Validation loss: 2.5370148156561543

Epoch: 6| Step: 2
Training loss: 3.195711815093306
Validation loss: 2.5483174555307526

Epoch: 6| Step: 3
Training loss: 2.5469084193371536
Validation loss: 2.550785628961411

Epoch: 6| Step: 4
Training loss: 3.346044448393141
Validation loss: 2.5505112474315044

Epoch: 6| Step: 5
Training loss: 2.2076678682915625
Validation loss: 2.5546262603983165

Epoch: 6| Step: 6
Training loss: 3.2216481614572228
Validation loss: 2.5632781041170625

Epoch: 6| Step: 7
Training loss: 2.4591313591644464
Validation loss: 2.547989875618349

Epoch: 6| Step: 8
Training loss: 2.503416587809864
Validation loss: 2.5620698715402583

Epoch: 6| Step: 9
Training loss: 2.4989287942463223
Validation loss: 2.5554422214099524

Epoch: 6| Step: 10
Training loss: 2.953021819719051
Validation loss: 2.554086952335278

Epoch: 6| Step: 11
Training loss: 2.369498858684805
Validation loss: 2.5569727333088275

Epoch: 6| Step: 12
Training loss: 2.6316473219170393
Validation loss: 2.557397315466985

Epoch: 6| Step: 13
Training loss: 2.2796017688844095
Validation loss: 2.5582763084182782

Epoch: 103| Step: 0
Training loss: 2.703486600294818
Validation loss: 2.5506656088283

Epoch: 6| Step: 1
Training loss: 2.272528502702059
Validation loss: 2.5376497473934476

Epoch: 6| Step: 2
Training loss: 3.016085732797231
Validation loss: 2.5550651992356097

Epoch: 6| Step: 3
Training loss: 1.9357120508875838
Validation loss: 2.5495648156917436

Epoch: 6| Step: 4
Training loss: 2.7396075945071225
Validation loss: 2.5370768986951973

Epoch: 6| Step: 5
Training loss: 1.9202544660621839
Validation loss: 2.5502442179641402

Epoch: 6| Step: 6
Training loss: 2.499161293487861
Validation loss: 2.5526704557774837

Epoch: 6| Step: 7
Training loss: 3.0749675221782704
Validation loss: 2.5465300358021787

Epoch: 6| Step: 8
Training loss: 3.0606101296709984
Validation loss: 2.5507962868818628

Epoch: 6| Step: 9
Training loss: 2.9896988442110937
Validation loss: 2.553046877403532

Epoch: 6| Step: 10
Training loss: 2.3764088116371846
Validation loss: 2.5541484357224746

Epoch: 6| Step: 11
Training loss: 3.3205146997255937
Validation loss: 2.555726259266029

Epoch: 6| Step: 12
Training loss: 2.6268583713162195
Validation loss: 2.5517364805346885

Epoch: 6| Step: 13
Training loss: 2.481150808201374
Validation loss: 2.5428854257618907

Epoch: 104| Step: 0
Training loss: 2.705434881709394
Validation loss: 2.554167133886575

Epoch: 6| Step: 1
Training loss: 2.1535387546868603
Validation loss: 2.5502554104264146

Epoch: 6| Step: 2
Training loss: 2.7584151779279424
Validation loss: 2.5500744009534517

Epoch: 6| Step: 3
Training loss: 2.82888412825124
Validation loss: 2.553779827404287

Epoch: 6| Step: 4
Training loss: 2.723290871608598
Validation loss: 2.5473690332648844

Epoch: 6| Step: 5
Training loss: 2.8898172435591625
Validation loss: 2.546782304113824

Epoch: 6| Step: 6
Training loss: 2.3629383185138013
Validation loss: 2.549027820044358

Epoch: 6| Step: 7
Training loss: 2.979313257696779
Validation loss: 2.5462508723720485

Epoch: 6| Step: 8
Training loss: 2.7852856791893474
Validation loss: 2.5337772279081974

Epoch: 6| Step: 9
Training loss: 2.5550710407690165
Validation loss: 2.544272070010184

Epoch: 6| Step: 10
Training loss: 2.781225311512614
Validation loss: 2.5372820582932176

Epoch: 6| Step: 11
Training loss: 2.9634525618652616
Validation loss: 2.556306605200354

Epoch: 6| Step: 12
Training loss: 2.407388987294122
Validation loss: 2.5555271789428207

Epoch: 6| Step: 13
Training loss: 2.6128549727067587
Validation loss: 2.5442062710479334

Epoch: 105| Step: 0
Training loss: 3.5657388787635416
Validation loss: 2.5492881376445555

Epoch: 6| Step: 1
Training loss: 2.487976630472166
Validation loss: 2.533621422220051

Epoch: 6| Step: 2
Training loss: 2.7273028661045173
Validation loss: 2.5472949338801443

Epoch: 6| Step: 3
Training loss: 2.496965664970878
Validation loss: 2.5502411871245623

Epoch: 6| Step: 4
Training loss: 2.1194664208086778
Validation loss: 2.5636562637027005

Epoch: 6| Step: 5
Training loss: 1.7853917607187935
Validation loss: 2.549591239637796

Epoch: 6| Step: 6
Training loss: 2.8684716116604423
Validation loss: 2.551104837714751

Epoch: 6| Step: 7
Training loss: 2.916585448814558
Validation loss: 2.554357015530166

Epoch: 6| Step: 8
Training loss: 3.0720148002347463
Validation loss: 2.5488641066465676

Epoch: 6| Step: 9
Training loss: 1.538261708706505
Validation loss: 2.5546369108256495

Epoch: 6| Step: 10
Training loss: 2.793262386225251
Validation loss: 2.557520849336805

Epoch: 6| Step: 11
Training loss: 2.488488780040254
Validation loss: 2.554878189362424

Epoch: 6| Step: 12
Training loss: 2.896909244009861
Validation loss: 2.555572909263101

Epoch: 6| Step: 13
Training loss: 3.2977513599394395
Validation loss: 2.5526440139929973

Epoch: 106| Step: 0
Training loss: 3.218317243501917
Validation loss: 2.548073222085036

Epoch: 6| Step: 1
Training loss: 2.6497916301642617
Validation loss: 2.5617322564498064

Epoch: 6| Step: 2
Training loss: 2.588275233065137
Validation loss: 2.5635410628166175

Epoch: 6| Step: 3
Training loss: 3.4546049925131634
Validation loss: 2.559294807273268

Epoch: 6| Step: 4
Training loss: 3.1037322557535907
Validation loss: 2.5603909711171604

Epoch: 6| Step: 5
Training loss: 1.5355597589379755
Validation loss: 2.5519072045999063

Epoch: 6| Step: 6
Training loss: 2.798737571726196
Validation loss: 2.554282527707945

Epoch: 6| Step: 7
Training loss: 2.2595797159779263
Validation loss: 2.551005292019353

Epoch: 6| Step: 8
Training loss: 2.7608871826698946
Validation loss: 2.5390580917332755

Epoch: 6| Step: 9
Training loss: 2.3941504718654576
Validation loss: 2.5584279221814783

Epoch: 6| Step: 10
Training loss: 2.5281698064994775
Validation loss: 2.5601483751247276

Epoch: 6| Step: 11
Training loss: 2.634699204882318
Validation loss: 2.5565413981411487

Epoch: 6| Step: 12
Training loss: 2.3950073366311617
Validation loss: 2.548515834590135

Epoch: 6| Step: 13
Training loss: 2.671417732595628
Validation loss: 2.555143631393183

Epoch: 107| Step: 0
Training loss: 2.812717853162059
Validation loss: 2.5639051960993764

Epoch: 6| Step: 1
Training loss: 2.42214944576549
Validation loss: 2.541953355290568

Epoch: 6| Step: 2
Training loss: 3.248472294843564
Validation loss: 2.549781639506559

Epoch: 6| Step: 3
Training loss: 2.639553868571648
Validation loss: 2.5671354726133324

Epoch: 6| Step: 4
Training loss: 2.6946889847188737
Validation loss: 2.5429482173530227

Epoch: 6| Step: 5
Training loss: 2.876616976925081
Validation loss: 2.558244971655691

Epoch: 6| Step: 6
Training loss: 2.210605340276501
Validation loss: 2.54513160378355

Epoch: 6| Step: 7
Training loss: 3.3014549515877514
Validation loss: 2.533169279942069

Epoch: 6| Step: 8
Training loss: 2.513645412065687
Validation loss: 2.562157813914909

Epoch: 6| Step: 9
Training loss: 1.9211633496671037
Validation loss: 2.541660885440324

Epoch: 6| Step: 10
Training loss: 2.601247224233412
Validation loss: 2.566868603527598

Epoch: 6| Step: 11
Training loss: 3.105279112969686
Validation loss: 2.539112494822879

Epoch: 6| Step: 12
Training loss: 1.51740922810343
Validation loss: 2.555197568596798

Epoch: 6| Step: 13
Training loss: 3.4024198503885246
Validation loss: 2.5487280940777763

Epoch: 108| Step: 0
Training loss: 2.3698347038860486
Validation loss: 2.5500690968799495

Epoch: 6| Step: 1
Training loss: 2.9791460014284543
Validation loss: 2.556605135851379

Epoch: 6| Step: 2
Training loss: 2.9252000137151746
Validation loss: 2.5413948134253896

Epoch: 6| Step: 3
Training loss: 2.8386059861668276
Validation loss: 2.5445911175942078

Epoch: 6| Step: 4
Training loss: 2.6641480552382015
Validation loss: 2.5452175327352777

Epoch: 6| Step: 5
Training loss: 2.8377803983238956
Validation loss: 2.5527128533520966

Epoch: 6| Step: 6
Training loss: 2.7580902564900875
Validation loss: 2.561844238363629

Epoch: 6| Step: 7
Training loss: 2.0300944636122145
Validation loss: 2.569649178477039

Epoch: 6| Step: 8
Training loss: 2.643322351375952
Validation loss: 2.558465550415742

Epoch: 6| Step: 9
Training loss: 2.3889189972076754
Validation loss: 2.540653818401424

Epoch: 6| Step: 10
Training loss: 3.185718262796406
Validation loss: 2.539043845083713

Epoch: 6| Step: 11
Training loss: 2.078986656127793
Validation loss: 2.536887249588705

Epoch: 6| Step: 12
Training loss: 2.2722766967104984
Validation loss: 2.5533304033423523

Epoch: 6| Step: 13
Training loss: 3.4458304986784474
Validation loss: 2.54417142666395

Epoch: 109| Step: 0
Training loss: 3.2692658055702206
Validation loss: 2.5374455399495774

Epoch: 6| Step: 1
Training loss: 3.0657984817679305
Validation loss: 2.5473421776699245

Epoch: 6| Step: 2
Training loss: 1.9493492556746637
Validation loss: 2.550140357130904

Epoch: 6| Step: 3
Training loss: 2.3188934610822676
Validation loss: 2.5526609184481663

Epoch: 6| Step: 4
Training loss: 2.1305132758786245
Validation loss: 2.564339086605576

Epoch: 6| Step: 5
Training loss: 3.2390178583494325
Validation loss: 2.545789012869218

Epoch: 6| Step: 6
Training loss: 2.2861752577421854
Validation loss: 2.5610384751208866

Epoch: 6| Step: 7
Training loss: 2.4363106980647773
Validation loss: 2.5485322549131055

Epoch: 6| Step: 8
Training loss: 2.667887249395724
Validation loss: 2.5601435460418727

Epoch: 6| Step: 9
Training loss: 2.8044179292729514
Validation loss: 2.5510584273553336

Epoch: 6| Step: 10
Training loss: 2.7010715159806744
Validation loss: 2.549456577116524

Epoch: 6| Step: 11
Training loss: 2.7907357632824836
Validation loss: 2.5547793190200494

Epoch: 6| Step: 12
Training loss: 2.919667925045844
Validation loss: 2.54287885757752

Epoch: 6| Step: 13
Training loss: 2.475011875625017
Validation loss: 2.5524532938130964

Epoch: 110| Step: 0
Training loss: 2.6798008486071874
Validation loss: 2.546742821675888

Epoch: 6| Step: 1
Training loss: 1.7615777274314963
Validation loss: 2.5530068737840588

Epoch: 6| Step: 2
Training loss: 2.2356296031415015
Validation loss: 2.5629897691281798

Epoch: 6| Step: 3
Training loss: 2.109014522692409
Validation loss: 2.5707170093528537

Epoch: 6| Step: 4
Training loss: 2.437759385612853
Validation loss: 2.555504588348162

Epoch: 6| Step: 5
Training loss: 2.673282899293631
Validation loss: 2.5445635153429276

Epoch: 6| Step: 6
Training loss: 2.98654303766008
Validation loss: 2.545010704058149

Epoch: 6| Step: 7
Training loss: 2.6973876041616562
Validation loss: 2.5558905331430464

Epoch: 6| Step: 8
Training loss: 2.3297310224493493
Validation loss: 2.5598117950314707

Epoch: 6| Step: 9
Training loss: 3.407716487912001
Validation loss: 2.5514522891522717

Epoch: 6| Step: 10
Training loss: 3.1587372601232935
Validation loss: 2.5587532294972504

Epoch: 6| Step: 11
Training loss: 3.169437467801611
Validation loss: 2.5485301500073367

Epoch: 6| Step: 12
Training loss: 2.8105299089567835
Validation loss: 2.5527328274157877

Epoch: 6| Step: 13
Training loss: 2.27520704060899
Validation loss: 2.5527518161389042

Epoch: 111| Step: 0
Training loss: 3.0451290507914637
Validation loss: 2.547629700485409

Epoch: 6| Step: 1
Training loss: 2.572396311991935
Validation loss: 2.5541978050431884

Epoch: 6| Step: 2
Training loss: 2.863085730982239
Validation loss: 2.555243005836664

Epoch: 6| Step: 3
Training loss: 1.8336450427389785
Validation loss: 2.548705255123235

Epoch: 6| Step: 4
Training loss: 2.618495693923647
Validation loss: 2.550283862823567

Epoch: 6| Step: 5
Training loss: 3.140259982480489
Validation loss: 2.5382595502151397

Epoch: 6| Step: 6
Training loss: 2.434114207645277
Validation loss: 2.5509089564026755

Epoch: 6| Step: 7
Training loss: 2.461756978514461
Validation loss: 2.5546978621673944

Epoch: 6| Step: 8
Training loss: 3.232888880067525
Validation loss: 2.5393246549278947

Epoch: 6| Step: 9
Training loss: 2.508287996746303
Validation loss: 2.546050939384504

Epoch: 6| Step: 10
Training loss: 2.051108604825464
Validation loss: 2.5390026636385334

Epoch: 6| Step: 11
Training loss: 2.9021276955775033
Validation loss: 2.553508161070602

Epoch: 6| Step: 12
Training loss: 2.9096105691209657
Validation loss: 2.5395220657572737

Epoch: 6| Step: 13
Training loss: 2.284735851253633
Validation loss: 2.5253573097130513

Epoch: 112| Step: 0
Training loss: 3.0774482718984792
Validation loss: 2.5614546472662476

Epoch: 6| Step: 1
Training loss: 1.884482501808277
Validation loss: 2.5534762015553363

Epoch: 6| Step: 2
Training loss: 2.8880070559027113
Validation loss: 2.535421513596878

Epoch: 6| Step: 3
Training loss: 3.137764306353191
Validation loss: 2.540564857189503

Epoch: 6| Step: 4
Training loss: 2.640526583490982
Validation loss: 2.5631898451168618

Epoch: 6| Step: 5
Training loss: 2.9821048110871424
Validation loss: 2.5450305562467896

Epoch: 6| Step: 6
Training loss: 2.484401582779608
Validation loss: 2.565162971754912

Epoch: 6| Step: 7
Training loss: 2.6517283831147114
Validation loss: 2.534956078092731

Epoch: 6| Step: 8
Training loss: 3.415806654334007
Validation loss: 2.545134879431053

Epoch: 6| Step: 9
Training loss: 2.486061051881152
Validation loss: 2.5414679273238203

Epoch: 6| Step: 10
Training loss: 2.7968859112915654
Validation loss: 2.5443601469272488

Epoch: 6| Step: 11
Training loss: 1.9934173976221283
Validation loss: 2.5423232558013975

Epoch: 6| Step: 12
Training loss: 1.8341200253306014
Validation loss: 2.5468998443561404

Epoch: 6| Step: 13
Training loss: 2.4304887732156457
Validation loss: 2.5492777152739072

Epoch: 113| Step: 0
Training loss: 2.9865743312299986
Validation loss: 2.5487761310558983

Epoch: 6| Step: 1
Training loss: 2.9850651607078653
Validation loss: 2.5508032311646933

Epoch: 6| Step: 2
Training loss: 2.2752730572496978
Validation loss: 2.5584737068677628

Epoch: 6| Step: 3
Training loss: 1.8918236329862241
Validation loss: 2.541549273085771

Epoch: 6| Step: 4
Training loss: 3.2719143257583228
Validation loss: 2.5500885146009873

Epoch: 6| Step: 5
Training loss: 2.3649597764576664
Validation loss: 2.539172514369219

Epoch: 6| Step: 6
Training loss: 3.185930950463014
Validation loss: 2.532703972079464

Epoch: 6| Step: 7
Training loss: 2.5201387840988807
Validation loss: 2.5495248589957717

Epoch: 6| Step: 8
Training loss: 2.4145030388195816
Validation loss: 2.5540337465059024

Epoch: 6| Step: 9
Training loss: 3.065579637042131
Validation loss: 2.5459437340840814

Epoch: 6| Step: 10
Training loss: 2.0929632274388226
Validation loss: 2.551220746871938

Epoch: 6| Step: 11
Training loss: 2.73702055333887
Validation loss: 2.549785277671835

Epoch: 6| Step: 12
Training loss: 2.8059330886617513
Validation loss: 2.5417857141384506

Epoch: 6| Step: 13
Training loss: 2.1734764726382054
Validation loss: 2.549235752833888

Epoch: 114| Step: 0
Training loss: 2.404175594936918
Validation loss: 2.5384920959656614

Epoch: 6| Step: 1
Training loss: 2.833751834554125
Validation loss: 2.5601872878373513

Epoch: 6| Step: 2
Training loss: 2.223056428681314
Validation loss: 2.549771009518996

Epoch: 6| Step: 3
Training loss: 3.088095998961773
Validation loss: 2.5378965350152343

Epoch: 6| Step: 4
Training loss: 2.770136800617349
Validation loss: 2.5617189715260618

Epoch: 6| Step: 5
Training loss: 3.308324809667976
Validation loss: 2.5478536825562275

Epoch: 6| Step: 6
Training loss: 3.2925073700911427
Validation loss: 2.5565489219650925

Epoch: 6| Step: 7
Training loss: 2.232193956062714
Validation loss: 2.562446386585282

Epoch: 6| Step: 8
Training loss: 2.6487525595004078
Validation loss: 2.5574812845846377

Epoch: 6| Step: 9
Training loss: 2.7352921174034224
Validation loss: 2.5391127108901363

Epoch: 6| Step: 10
Training loss: 2.3310650176836982
Validation loss: 2.5531784396838804

Epoch: 6| Step: 11
Training loss: 2.1075757300186564
Validation loss: 2.5533850796518323

Epoch: 6| Step: 12
Training loss: 2.4066387704657277
Validation loss: 2.5543757101601976

Epoch: 6| Step: 13
Training loss: 2.6599492960234734
Validation loss: 2.5467370883794

Epoch: 115| Step: 0
Training loss: 2.3800819636103747
Validation loss: 2.5516983200541246

Epoch: 6| Step: 1
Training loss: 2.6052817945305558
Validation loss: 2.5503105728457753

Epoch: 6| Step: 2
Training loss: 2.7222660173625775
Validation loss: 2.5548024950239854

Epoch: 6| Step: 3
Training loss: 2.0709632858344964
Validation loss: 2.5270818028821025

Epoch: 6| Step: 4
Training loss: 2.664663834259281
Validation loss: 2.5640816758127727

Epoch: 6| Step: 5
Training loss: 3.0565878964102184
Validation loss: 2.5481191696848056

Epoch: 6| Step: 6
Training loss: 2.3626065386612005
Validation loss: 2.5469809225213504

Epoch: 6| Step: 7
Training loss: 2.8785951774994087
Validation loss: 2.5356736940550246

Epoch: 6| Step: 8
Training loss: 3.3968013639636903
Validation loss: 2.542089138360168

Epoch: 6| Step: 9
Training loss: 2.762764696239017
Validation loss: 2.541961205689495

Epoch: 6| Step: 10
Training loss: 2.545325433875019
Validation loss: 2.5370196852266

Epoch: 6| Step: 11
Training loss: 2.759124184568201
Validation loss: 2.533536331428549

Epoch: 6| Step: 12
Training loss: 1.7924599185223857
Validation loss: 2.5587449181387396

Epoch: 6| Step: 13
Training loss: 3.1882508833321697
Validation loss: 2.5542724870366227

Epoch: 116| Step: 0
Training loss: 3.3988484452059646
Validation loss: 2.541601659977996

Epoch: 6| Step: 1
Training loss: 2.7185851299237584
Validation loss: 2.5469733060144804

Epoch: 6| Step: 2
Training loss: 2.752812074853278
Validation loss: 2.530327798461571

Epoch: 6| Step: 3
Training loss: 2.7623190220718
Validation loss: 2.549410523900584

Epoch: 6| Step: 4
Training loss: 2.2035801194221194
Validation loss: 2.557798639412114

Epoch: 6| Step: 5
Training loss: 2.0503473313263654
Validation loss: 2.5377138615990367

Epoch: 6| Step: 6
Training loss: 2.807179908202861
Validation loss: 2.5577126640507526

Epoch: 6| Step: 7
Training loss: 2.9682221595925546
Validation loss: 2.5404263133889122

Epoch: 6| Step: 8
Training loss: 3.0318728721357973
Validation loss: 2.5279145855283884

Epoch: 6| Step: 9
Training loss: 1.8745075850802624
Validation loss: 2.540264951140466

Epoch: 6| Step: 10
Training loss: 1.9920583645723207
Validation loss: 2.5327168340081734

Epoch: 6| Step: 11
Training loss: 3.2003294119561723
Validation loss: 2.5412427897424386

Epoch: 6| Step: 12
Training loss: 2.7117391934471846
Validation loss: 2.538179060066353

Epoch: 6| Step: 13
Training loss: 1.6334820702359572
Validation loss: 2.545963662070217

Epoch: 117| Step: 0
Training loss: 2.315241451648435
Validation loss: 2.5348869769896796

Epoch: 6| Step: 1
Training loss: 2.9452445024892855
Validation loss: 2.5588041936503583

Epoch: 6| Step: 2
Training loss: 3.351282210289508
Validation loss: 2.5518796493351577

Epoch: 6| Step: 3
Training loss: 2.064321118540049
Validation loss: 2.5513633166051406

Epoch: 6| Step: 4
Training loss: 2.706888566653654
Validation loss: 2.54678259804669

Epoch: 6| Step: 5
Training loss: 2.5644846418177076
Validation loss: 2.559441803243378

Epoch: 6| Step: 6
Training loss: 2.764668789663696
Validation loss: 2.559550970717857

Epoch: 6| Step: 7
Training loss: 2.7699453800200966
Validation loss: 2.559690570614651

Epoch: 6| Step: 8
Training loss: 1.9740837144579844
Validation loss: 2.5552850863329395

Epoch: 6| Step: 9
Training loss: 1.9114913175337302
Validation loss: 2.560158584011221

Epoch: 6| Step: 10
Training loss: 2.475982116659287
Validation loss: 2.5552621123520214

Epoch: 6| Step: 11
Training loss: 2.7761717307210283
Validation loss: 2.551621118259311

Epoch: 6| Step: 12
Training loss: 3.1150096656808555
Validation loss: 2.537130011485081

Epoch: 6| Step: 13
Training loss: 3.1344384138513632
Validation loss: 2.5448151399379424

Epoch: 118| Step: 0
Training loss: 2.3799245875295885
Validation loss: 2.542747318930319

Epoch: 6| Step: 1
Training loss: 2.929256153141574
Validation loss: 2.548042187442887

Epoch: 6| Step: 2
Training loss: 3.3011121956411067
Validation loss: 2.554430148320191

Epoch: 6| Step: 3
Training loss: 2.753465203213067
Validation loss: 2.547221562013197

Epoch: 6| Step: 4
Training loss: 2.411954385202761
Validation loss: 2.54482903342386

Epoch: 6| Step: 5
Training loss: 2.091802345931221
Validation loss: 2.5640568859576818

Epoch: 6| Step: 6
Training loss: 2.9207839968909273
Validation loss: 2.565529845647511

Epoch: 6| Step: 7
Training loss: 2.870798607013179
Validation loss: 2.557059469437919

Epoch: 6| Step: 8
Training loss: 2.50708253878741
Validation loss: 2.5697499283643768

Epoch: 6| Step: 9
Training loss: 2.584889179267033
Validation loss: 2.5646395761282106

Epoch: 6| Step: 10
Training loss: 2.1956172202189905
Validation loss: 2.5414970646646022

Epoch: 6| Step: 11
Training loss: 2.7982029665884
Validation loss: 2.5435189827470808

Epoch: 6| Step: 12
Training loss: 2.9702170511689356
Validation loss: 2.569305486967086

Epoch: 6| Step: 13
Training loss: 2.2713076128289464
Validation loss: 2.5564181167860407

Epoch: 119| Step: 0
Training loss: 2.9913142351776854
Validation loss: 2.543349016068353

Epoch: 6| Step: 1
Training loss: 2.2069400734761784
Validation loss: 2.5521795586599434

Epoch: 6| Step: 2
Training loss: 2.2524002835538615
Validation loss: 2.5697270936789582

Epoch: 6| Step: 3
Training loss: 2.6557586215422506
Validation loss: 2.5566449247368084

Epoch: 6| Step: 4
Training loss: 2.6856882065083663
Validation loss: 2.549766304057525

Epoch: 6| Step: 5
Training loss: 2.583463378422254
Validation loss: 2.5351201344691243

Epoch: 6| Step: 6
Training loss: 2.6391291246874755
Validation loss: 2.555933833678547

Epoch: 6| Step: 7
Training loss: 2.628519877230362
Validation loss: 2.559637776726074

Epoch: 6| Step: 8
Training loss: 2.109645345812282
Validation loss: 2.549988615560323

Epoch: 6| Step: 9
Training loss: 2.641132373709069
Validation loss: 2.5561169576443827

Epoch: 6| Step: 10
Training loss: 2.591082568650308
Validation loss: 2.5597437259654985

Epoch: 6| Step: 11
Training loss: 3.4047012307816718
Validation loss: 2.5416663502881764

Epoch: 6| Step: 12
Training loss: 2.997455312413273
Validation loss: 2.542896343125515

Epoch: 6| Step: 13
Training loss: 2.0923550641945656
Validation loss: 2.538492043450503

Epoch: 120| Step: 0
Training loss: 2.668675967045033
Validation loss: 2.5546404813631955

Epoch: 6| Step: 1
Training loss: 2.9820227814999614
Validation loss: 2.5507423887750678

Epoch: 6| Step: 2
Training loss: 2.396852845807002
Validation loss: 2.536559147619102

Epoch: 6| Step: 3
Training loss: 2.6624380399989587
Validation loss: 2.549152948224423

Epoch: 6| Step: 4
Training loss: 2.8242302310019056
Validation loss: 2.5584682218069457

Epoch: 6| Step: 5
Training loss: 2.127071717093865
Validation loss: 2.55075388760244

Epoch: 6| Step: 6
Training loss: 3.0137152282405038
Validation loss: 2.552972645579903

Epoch: 6| Step: 7
Training loss: 2.875507144150327
Validation loss: 2.542469867727753

Epoch: 6| Step: 8
Training loss: 2.3088310623188986
Validation loss: 2.5442692799293214

Epoch: 6| Step: 9
Training loss: 2.4662542161552636
Validation loss: 2.5441400199577506

Epoch: 6| Step: 10
Training loss: 2.965372513372714
Validation loss: 2.550620489574948

Epoch: 6| Step: 11
Training loss: 2.4701131606338746
Validation loss: 2.541413962518865

Epoch: 6| Step: 12
Training loss: 2.520626143671141
Validation loss: 2.5560650247075016

Epoch: 6| Step: 13
Training loss: 2.197851809829865
Validation loss: 2.543290119213928

Epoch: 121| Step: 0
Training loss: 2.9205459591214824
Validation loss: 2.540778715243313

Epoch: 6| Step: 1
Training loss: 2.46938595849736
Validation loss: 2.550522038674893

Epoch: 6| Step: 2
Training loss: 2.171157279222725
Validation loss: 2.547140293231639

Epoch: 6| Step: 3
Training loss: 2.9562971244427176
Validation loss: 2.534694847880247

Epoch: 6| Step: 4
Training loss: 2.5125800238623754
Validation loss: 2.54368327398143

Epoch: 6| Step: 5
Training loss: 2.5598711625103996
Validation loss: 2.5328751196856603

Epoch: 6| Step: 6
Training loss: 2.358042460679707
Validation loss: 2.550095747827641

Epoch: 6| Step: 7
Training loss: 3.268923612984007
Validation loss: 2.542719921498643

Epoch: 6| Step: 8
Training loss: 1.9162957067444617
Validation loss: 2.5341184126064458

Epoch: 6| Step: 9
Training loss: 3.18947734461487
Validation loss: 2.5607045744588315

Epoch: 6| Step: 10
Training loss: 2.5910731830987213
Validation loss: 2.5547098328970623

Epoch: 6| Step: 11
Training loss: 2.3480703588468583
Validation loss: 2.5432729286956994

Epoch: 6| Step: 12
Training loss: 3.044591899264801
Validation loss: 2.5370639262454313

Epoch: 6| Step: 13
Training loss: 2.078094023280055
Validation loss: 2.5328726571320783

Epoch: 122| Step: 0
Training loss: 2.7216048762480187
Validation loss: 2.5344343938921337

Epoch: 6| Step: 1
Training loss: 1.6071923278581803
Validation loss: 2.5644566388839434

Epoch: 6| Step: 2
Training loss: 2.144936445134963
Validation loss: 2.5596159054831027

Epoch: 6| Step: 3
Training loss: 2.744116297712452
Validation loss: 2.5442184518588955

Epoch: 6| Step: 4
Training loss: 1.7422559237194033
Validation loss: 2.532819647378255

Epoch: 6| Step: 5
Training loss: 2.3085745408861365
Validation loss: 2.5362962914137457

Epoch: 6| Step: 6
Training loss: 3.225275628191739
Validation loss: 2.5535687026388487

Epoch: 6| Step: 7
Training loss: 2.8390193618915007
Validation loss: 2.5382645017323933

Epoch: 6| Step: 8
Training loss: 2.305059474086764
Validation loss: 2.5433060012383293

Epoch: 6| Step: 9
Training loss: 2.1213909243077644
Validation loss: 2.5373262492706012

Epoch: 6| Step: 10
Training loss: 3.058255114754789
Validation loss: 2.538403310469351

Epoch: 6| Step: 11
Training loss: 3.368128527782615
Validation loss: 2.5438883704065685

Epoch: 6| Step: 12
Training loss: 3.4771845914626778
Validation loss: 2.5460520036866923

Epoch: 6| Step: 13
Training loss: 2.1784219109821943
Validation loss: 2.5374911414973353

Epoch: 123| Step: 0
Training loss: 3.1561382009515775
Validation loss: 2.540622778898622

Epoch: 6| Step: 1
Training loss: 2.165761673042573
Validation loss: 2.537464800682002

Epoch: 6| Step: 2
Training loss: 1.8933886041543486
Validation loss: 2.548013056027542

Epoch: 6| Step: 3
Training loss: 3.36777061139728
Validation loss: 2.549111242195397

Epoch: 6| Step: 4
Training loss: 2.4837822356913533
Validation loss: 2.5520057346650398

Epoch: 6| Step: 5
Training loss: 2.4330111521109776
Validation loss: 2.564552357629868

Epoch: 6| Step: 6
Training loss: 2.6213056816914118
Validation loss: 2.555665498969062

Epoch: 6| Step: 7
Training loss: 2.899269498701118
Validation loss: 2.539895848028374

Epoch: 6| Step: 8
Training loss: 2.4377447152172897
Validation loss: 2.5409573914071166

Epoch: 6| Step: 9
Training loss: 2.093709005837021
Validation loss: 2.557164324468747

Epoch: 6| Step: 10
Training loss: 2.685224501247676
Validation loss: 2.549979641756896

Epoch: 6| Step: 11
Training loss: 2.49138300715287
Validation loss: 2.5458810420522373

Epoch: 6| Step: 12
Training loss: 3.3252812087382173
Validation loss: 2.549592070189293

Epoch: 6| Step: 13
Training loss: 2.2961427728144854
Validation loss: 2.541818200376339

Epoch: 124| Step: 0
Training loss: 2.2012336133339394
Validation loss: 2.537975098244036

Epoch: 6| Step: 1
Training loss: 2.509602225955247
Validation loss: 2.536651653149261

Epoch: 6| Step: 2
Training loss: 2.379270929656344
Validation loss: 2.542797860337593

Epoch: 6| Step: 3
Training loss: 2.399788441870421
Validation loss: 2.5335735502108756

Epoch: 6| Step: 4
Training loss: 2.633292225223097
Validation loss: 2.5465723599383234

Epoch: 6| Step: 5
Training loss: 2.989154284235081
Validation loss: 2.5411096188045557

Epoch: 6| Step: 6
Training loss: 1.831818004959239
Validation loss: 2.5413744415690114

Epoch: 6| Step: 7
Training loss: 4.192100389210374
Validation loss: 2.557041451119463

Epoch: 6| Step: 8
Training loss: 2.4196048063947173
Validation loss: 2.539837865329037

Epoch: 6| Step: 9
Training loss: 2.4220657765712303
Validation loss: 2.5448765899452295

Epoch: 6| Step: 10
Training loss: 2.7119512503920813
Validation loss: 2.5590937155000266

Epoch: 6| Step: 11
Training loss: 2.8187707295469657
Validation loss: 2.5555644927627257

Epoch: 6| Step: 12
Training loss: 2.1278697439139007
Validation loss: 2.55341827322409

Epoch: 6| Step: 13
Training loss: 2.338779927260523
Validation loss: 2.5381851838795493

Epoch: 125| Step: 0
Training loss: 2.6934113362634116
Validation loss: 2.5350751931025215

Epoch: 6| Step: 1
Training loss: 2.5892753149866694
Validation loss: 2.5441759918293934

Epoch: 6| Step: 2
Training loss: 2.2363748204049583
Validation loss: 2.556191811229125

Epoch: 6| Step: 3
Training loss: 2.216326074558595
Validation loss: 2.541059714727886

Epoch: 6| Step: 4
Training loss: 3.3344034066818025
Validation loss: 2.545428635089534

Epoch: 6| Step: 5
Training loss: 2.7968061214895057
Validation loss: 2.5444893120916716

Epoch: 6| Step: 6
Training loss: 3.3638571003648186
Validation loss: 2.5253274932853618

Epoch: 6| Step: 7
Training loss: 2.745527097752748
Validation loss: 2.5507658627704943

Epoch: 6| Step: 8
Training loss: 2.9369217323730235
Validation loss: 2.5487834882035645

Epoch: 6| Step: 9
Training loss: 2.4392671292747345
Validation loss: 2.535886836885182

Epoch: 6| Step: 10
Training loss: 2.0870181366991942
Validation loss: 2.5403799783967798

Epoch: 6| Step: 11
Training loss: 2.4178628482336735
Validation loss: 2.531182548893286

Epoch: 6| Step: 12
Training loss: 2.4567657472807047
Validation loss: 2.5414919414070964

Epoch: 6| Step: 13
Training loss: 1.839277435421664
Validation loss: 2.547421135431445

Epoch: 126| Step: 0
Training loss: 3.299093503424227
Validation loss: 2.549045140714095

Epoch: 6| Step: 1
Training loss: 2.6149663353352226
Validation loss: 2.523109011583692

Epoch: 6| Step: 2
Training loss: 2.7871016760908907
Validation loss: 2.5354995402835883

Epoch: 6| Step: 3
Training loss: 2.780298305945595
Validation loss: 2.544852451152609

Epoch: 6| Step: 4
Training loss: 2.682959691288359
Validation loss: 2.5394541913001376

Epoch: 6| Step: 5
Training loss: 2.754019833650554
Validation loss: 2.5477210040861022

Epoch: 6| Step: 6
Training loss: 2.51938741110733
Validation loss: 2.542671288162644

Epoch: 6| Step: 7
Training loss: 2.287456482853763
Validation loss: 2.5488865599665864

Epoch: 6| Step: 8
Training loss: 2.394879314272776
Validation loss: 2.5567845058284693

Epoch: 6| Step: 9
Training loss: 2.5243138542429504
Validation loss: 2.5457415388496667

Epoch: 6| Step: 10
Training loss: 2.283358814162296
Validation loss: 2.5157155722708726

Epoch: 6| Step: 11
Training loss: 2.4982797426155625
Validation loss: 2.5487871559567865

Epoch: 6| Step: 12
Training loss: 2.5198427466116544
Validation loss: 2.549539862563685

Epoch: 6| Step: 13
Training loss: 3.0018654427663156
Validation loss: 2.5413002077452465

Epoch: 127| Step: 0
Training loss: 2.718825415957423
Validation loss: 2.540836352591167

Epoch: 6| Step: 1
Training loss: 2.9883816172380966
Validation loss: 2.5364788268779725

Epoch: 6| Step: 2
Training loss: 2.3472932607922354
Validation loss: 2.5381199018358593

Epoch: 6| Step: 3
Training loss: 2.358252049675217
Validation loss: 2.551801407196684

Epoch: 6| Step: 4
Training loss: 1.8777199408347605
Validation loss: 2.535492690079716

Epoch: 6| Step: 5
Training loss: 2.70801441564625
Validation loss: 2.547932460461847

Epoch: 6| Step: 6
Training loss: 3.2006722340211264
Validation loss: 2.5580038819006865

Epoch: 6| Step: 7
Training loss: 2.619757731061788
Validation loss: 2.5595305811101166

Epoch: 6| Step: 8
Training loss: 2.8006661576335143
Validation loss: 2.5456539840552574

Epoch: 6| Step: 9
Training loss: 3.314617128197911
Validation loss: 2.547425902587593

Epoch: 6| Step: 10
Training loss: 2.2350324183764867
Validation loss: 2.5448390650145076

Epoch: 6| Step: 11
Training loss: 2.62551039320531
Validation loss: 2.557147266319419

Epoch: 6| Step: 12
Training loss: 2.3476215175909334
Validation loss: 2.5448897169923694

Epoch: 6| Step: 13
Training loss: 1.8750607798579813
Validation loss: 2.535607911585314

Epoch: 128| Step: 0
Training loss: 2.5934741321609964
Validation loss: 2.5602518620086148

Epoch: 6| Step: 1
Training loss: 2.4101091624502735
Validation loss: 2.5496129163399366

Epoch: 6| Step: 2
Training loss: 1.660398577787433
Validation loss: 2.548271267040661

Epoch: 6| Step: 3
Training loss: 2.740557759589949
Validation loss: 2.536566212237762

Epoch: 6| Step: 4
Training loss: 2.6888444775555915
Validation loss: 2.5581617772074288

Epoch: 6| Step: 5
Training loss: 3.0787380789163175
Validation loss: 2.555782867399572

Epoch: 6| Step: 6
Training loss: 2.9614099613782936
Validation loss: 2.543092879914932

Epoch: 6| Step: 7
Training loss: 2.7581549153627853
Validation loss: 2.552980784434922

Epoch: 6| Step: 8
Training loss: 2.3096571278939644
Validation loss: 2.545418389786842

Epoch: 6| Step: 9
Training loss: 3.129670581971872
Validation loss: 2.546333787463303

Epoch: 6| Step: 10
Training loss: 2.2385952448006194
Validation loss: 2.5440054074789304

Epoch: 6| Step: 11
Training loss: 2.391954239449025
Validation loss: 2.54441376864173

Epoch: 6| Step: 12
Training loss: 3.172575473954789
Validation loss: 2.5369318809598256

Epoch: 6| Step: 13
Training loss: 1.889852318620121
Validation loss: 2.5595600381667296

Epoch: 129| Step: 0
Training loss: 2.6022571632916276
Validation loss: 2.560224862176443

Epoch: 6| Step: 1
Training loss: 2.4002547446792954
Validation loss: 2.55718821470935

Epoch: 6| Step: 2
Training loss: 2.3016778465108128
Validation loss: 2.546332737374054

Epoch: 6| Step: 3
Training loss: 3.2076180556611504
Validation loss: 2.5485891722137164

Epoch: 6| Step: 4
Training loss: 1.6080474563209866
Validation loss: 2.533393638847813

Epoch: 6| Step: 5
Training loss: 3.2743329482664887
Validation loss: 2.544055902730765

Epoch: 6| Step: 6
Training loss: 2.7951516750719834
Validation loss: 2.549669215278076

Epoch: 6| Step: 7
Training loss: 2.923635839587751
Validation loss: 2.5465301294270613

Epoch: 6| Step: 8
Training loss: 2.8380396594447976
Validation loss: 2.5378485481819424

Epoch: 6| Step: 9
Training loss: 2.731384036618279
Validation loss: 2.536298595993858

Epoch: 6| Step: 10
Training loss: 1.7348147685308282
Validation loss: 2.542747820014033

Epoch: 6| Step: 11
Training loss: 2.534539992750857
Validation loss: 2.53847371407901

Epoch: 6| Step: 12
Training loss: 2.5194772167474007
Validation loss: 2.5466955984770383

Epoch: 6| Step: 13
Training loss: 2.8664494949701025
Validation loss: 2.539659986597872

Epoch: 130| Step: 0
Training loss: 2.5888000502599327
Validation loss: 2.5558804967826347

Epoch: 6| Step: 1
Training loss: 2.363601637631861
Validation loss: 2.544371816665821

Epoch: 6| Step: 2
Training loss: 2.9291824108874547
Validation loss: 2.5421039306705038

Epoch: 6| Step: 3
Training loss: 2.420492060423912
Validation loss: 2.536316181488414

Epoch: 6| Step: 4
Training loss: 2.587529271646684
Validation loss: 2.5550902699752163

Epoch: 6| Step: 5
Training loss: 2.5568621884036458
Validation loss: 2.5352093079734206

Epoch: 6| Step: 6
Training loss: 2.470553741160849
Validation loss: 2.5415860134207198

Epoch: 6| Step: 7
Training loss: 2.745842999531505
Validation loss: 2.5482135639535386

Epoch: 6| Step: 8
Training loss: 2.628655476959016
Validation loss: 2.546721322376659

Epoch: 6| Step: 9
Training loss: 1.9380647390002617
Validation loss: 2.556092914972096

Epoch: 6| Step: 10
Training loss: 2.6495647000923728
Validation loss: 2.548436867488947

Epoch: 6| Step: 11
Training loss: 3.326948504183271
Validation loss: 2.5577907995347

Epoch: 6| Step: 12
Training loss: 2.4144504074972573
Validation loss: 2.549360246329668

Epoch: 6| Step: 13
Training loss: 3.010104012450647
Validation loss: 2.5664753555186675

Epoch: 131| Step: 0
Training loss: 2.6603703573722606
Validation loss: 2.5397927510572105

Epoch: 6| Step: 1
Training loss: 2.237523561492129
Validation loss: 2.5492150604817803

Epoch: 6| Step: 2
Training loss: 3.020293422111808
Validation loss: 2.5534835185556557

Epoch: 6| Step: 3
Training loss: 1.8372492872198625
Validation loss: 2.547751160171242

Epoch: 6| Step: 4
Training loss: 2.3438057447797793
Validation loss: 2.5523822668783307

Epoch: 6| Step: 5
Training loss: 2.7917102886226943
Validation loss: 2.5250065659980114

Epoch: 6| Step: 6
Training loss: 2.3939202230700647
Validation loss: 2.5353959258131735

Epoch: 6| Step: 7
Training loss: 2.8440155911346876
Validation loss: 2.5355333471589097

Epoch: 6| Step: 8
Training loss: 3.207790791270385
Validation loss: 2.537704713061136

Epoch: 6| Step: 9
Training loss: 2.998996884803897
Validation loss: 2.54895204399912

Epoch: 6| Step: 10
Training loss: 2.3044152050478792
Validation loss: 2.5466537152973427

Epoch: 6| Step: 11
Training loss: 2.5154437835059076
Validation loss: 2.556237311027976

Epoch: 6| Step: 12
Training loss: 2.450452381330628
Validation loss: 2.5489230376406886

Epoch: 6| Step: 13
Training loss: 2.8110438497971137
Validation loss: 2.5446287620405514

Epoch: 132| Step: 0
Training loss: 2.2408122985957215
Validation loss: 2.556166643980517

Epoch: 6| Step: 1
Training loss: 2.4559513017194043
Validation loss: 2.533259356000942

Epoch: 6| Step: 2
Training loss: 2.8435809745440803
Validation loss: 2.5443850631950737

Epoch: 6| Step: 3
Training loss: 2.1379773549449883
Validation loss: 2.5459922651362814

Epoch: 6| Step: 4
Training loss: 2.355518954170616
Validation loss: 2.555752713798988

Epoch: 6| Step: 5
Training loss: 2.5693916132080616
Validation loss: 2.565589339614603

Epoch: 6| Step: 6
Training loss: 3.064365675038873
Validation loss: 2.53337408709277

Epoch: 6| Step: 7
Training loss: 2.3029476516743794
Validation loss: 2.5492739984475143

Epoch: 6| Step: 8
Training loss: 3.0772533441237657
Validation loss: 2.5447947264550304

Epoch: 6| Step: 9
Training loss: 2.519684921427972
Validation loss: 2.5321517587867

Epoch: 6| Step: 10
Training loss: 3.0334936274280326
Validation loss: 2.5559181163811173

Epoch: 6| Step: 11
Training loss: 2.7426692180884396
Validation loss: 2.547098195935469

Epoch: 6| Step: 12
Training loss: 2.2583482364101806
Validation loss: 2.545908044972471

Epoch: 6| Step: 13
Training loss: 3.0525214669537344
Validation loss: 2.5543055717223946

Epoch: 133| Step: 0
Training loss: 2.8619443262471207
Validation loss: 2.5385482108212876

Epoch: 6| Step: 1
Training loss: 2.618616972027678
Validation loss: 2.5401849595161083

Epoch: 6| Step: 2
Training loss: 2.715181134892455
Validation loss: 2.541210028305149

Epoch: 6| Step: 3
Training loss: 2.85874706940361
Validation loss: 2.552389207348391

Epoch: 6| Step: 4
Training loss: 2.144801055111994
Validation loss: 2.5607579019786013

Epoch: 6| Step: 5
Training loss: 2.339638014777425
Validation loss: 2.5435042631729683

Epoch: 6| Step: 6
Training loss: 2.9108377977088162
Validation loss: 2.5414988389898086

Epoch: 6| Step: 7
Training loss: 2.6353476795520474
Validation loss: 2.5587523252732494

Epoch: 6| Step: 8
Training loss: 2.366810885140959
Validation loss: 2.5440282604103874

Epoch: 6| Step: 9
Training loss: 2.04397015800266
Validation loss: 2.544322542840694

Epoch: 6| Step: 10
Training loss: 2.396145100971489
Validation loss: 2.538768009748737

Epoch: 6| Step: 11
Training loss: 3.264798730602359
Validation loss: 2.561454854943323

Epoch: 6| Step: 12
Training loss: 2.7314894791633875
Validation loss: 2.5483059789079467

Epoch: 6| Step: 13
Training loss: 2.2443247322013264
Validation loss: 2.5398100458813944

Epoch: 134| Step: 0
Training loss: 3.084744998031581
Validation loss: 2.543549448688923

Epoch: 6| Step: 1
Training loss: 2.5852211135653698
Validation loss: 2.540910280130881

Epoch: 6| Step: 2
Training loss: 2.457354064985733
Validation loss: 2.550464998154016

Epoch: 6| Step: 3
Training loss: 2.7211272271304163
Validation loss: 2.5441562443188053

Epoch: 6| Step: 4
Training loss: 2.7799333177431853
Validation loss: 2.5616910004067663

Epoch: 6| Step: 5
Training loss: 2.846956729657905
Validation loss: 2.533377882903609

Epoch: 6| Step: 6
Training loss: 2.257977647912326
Validation loss: 2.558391250353464

Epoch: 6| Step: 7
Training loss: 2.730589769816739
Validation loss: 2.5328627117515756

Epoch: 6| Step: 8
Training loss: 2.9335771704965916
Validation loss: 2.552654851456906

Epoch: 6| Step: 9
Training loss: 1.8325504307488492
Validation loss: 2.530548888346887

Epoch: 6| Step: 10
Training loss: 2.10778647053951
Validation loss: 2.5507999738516625

Epoch: 6| Step: 11
Training loss: 2.391231883688787
Validation loss: 2.551851438760798

Epoch: 6| Step: 12
Training loss: 3.1792111801557543
Validation loss: 2.5314251793398928

Epoch: 6| Step: 13
Training loss: 2.3815296159112536
Validation loss: 2.5521153869692

Epoch: 135| Step: 0
Training loss: 2.6910472791041826
Validation loss: 2.5297350232019795

Epoch: 6| Step: 1
Training loss: 2.944948533131431
Validation loss: 2.5387333350982884

Epoch: 6| Step: 2
Training loss: 2.701475224317958
Validation loss: 2.5552730300100035

Epoch: 6| Step: 3
Training loss: 2.9635396107072633
Validation loss: 2.5362667208370526

Epoch: 6| Step: 4
Training loss: 3.0964781167150077
Validation loss: 2.53824555259479

Epoch: 6| Step: 5
Training loss: 2.3206665590953426
Validation loss: 2.55153188333221

Epoch: 6| Step: 6
Training loss: 2.4012536033273695
Validation loss: 2.5413698274898264

Epoch: 6| Step: 7
Training loss: 2.317798318437649
Validation loss: 2.5502942006636973

Epoch: 6| Step: 8
Training loss: 1.979908218664832
Validation loss: 2.5533603184779636

Epoch: 6| Step: 9
Training loss: 2.7102107852167467
Validation loss: 2.537139355090335

Epoch: 6| Step: 10
Training loss: 2.705295286860813
Validation loss: 2.537199346541738

Epoch: 6| Step: 11
Training loss: 2.5836479446637717
Validation loss: 2.5473175781594346

Epoch: 6| Step: 12
Training loss: 2.620953119771981
Validation loss: 2.5446594051053606

Epoch: 6| Step: 13
Training loss: 1.894296092746976
Validation loss: 2.5411134827607174

Epoch: 136| Step: 0
Training loss: 2.9494425101373767
Validation loss: 2.543399860001909

Epoch: 6| Step: 1
Training loss: 2.464710745872938
Validation loss: 2.542839281765259

Epoch: 6| Step: 2
Training loss: 2.050505701354332
Validation loss: 2.5595768343465184

Epoch: 6| Step: 3
Training loss: 2.6706468760074076
Validation loss: 2.5334215611355866

Epoch: 6| Step: 4
Training loss: 2.7881016719126945
Validation loss: 2.541223346800906

Epoch: 6| Step: 5
Training loss: 2.810982443093453
Validation loss: 2.541044565244262

Epoch: 6| Step: 6
Training loss: 2.75418743023762
Validation loss: 2.544954179673299

Epoch: 6| Step: 7
Training loss: 2.745505214260348
Validation loss: 2.543300576201543

Epoch: 6| Step: 8
Training loss: 2.7094293186326186
Validation loss: 2.53590134844527

Epoch: 6| Step: 9
Training loss: 2.693294399880241
Validation loss: 2.539981796655465

Epoch: 6| Step: 10
Training loss: 2.705636858474641
Validation loss: 2.535629028405114

Epoch: 6| Step: 11
Training loss: 2.0368613570330845
Validation loss: 2.5350747046599893

Epoch: 6| Step: 12
Training loss: 2.5113013411609812
Validation loss: 2.5442995142069824

Epoch: 6| Step: 13
Training loss: 2.6164662748088143
Validation loss: 2.53946487810156

Epoch: 137| Step: 0
Training loss: 2.0498607495162267
Validation loss: 2.5392093496712698

Epoch: 6| Step: 1
Training loss: 2.0927883615820524
Validation loss: 2.527826550185331

Epoch: 6| Step: 2
Training loss: 2.393821424409701
Validation loss: 2.5378309561327876

Epoch: 6| Step: 3
Training loss: 2.837386168494701
Validation loss: 2.562320495849206

Epoch: 6| Step: 4
Training loss: 3.5807315044973427
Validation loss: 2.5534530697369364

Epoch: 6| Step: 5
Training loss: 2.2016704979554462
Validation loss: 2.5381471226714827

Epoch: 6| Step: 6
Training loss: 3.0281255290972835
Validation loss: 2.5382181237414865

Epoch: 6| Step: 7
Training loss: 2.1604201309141993
Validation loss: 2.5337117402169422

Epoch: 6| Step: 8
Training loss: 2.573262200467717
Validation loss: 2.5758480185750647

Epoch: 6| Step: 9
Training loss: 2.616782723625015
Validation loss: 2.56728007640657

Epoch: 6| Step: 10
Training loss: 2.1257550637154474
Validation loss: 2.5409909047158035

Epoch: 6| Step: 11
Training loss: 3.0271881260403117
Validation loss: 2.5355562147732735

Epoch: 6| Step: 12
Training loss: 2.8180620085511436
Validation loss: 2.5615776036612212

Epoch: 6| Step: 13
Training loss: 2.25220720325128
Validation loss: 2.54262689264425

Epoch: 138| Step: 0
Training loss: 2.3162405331084153
Validation loss: 2.558459959122799

Epoch: 6| Step: 1
Training loss: 3.3224834929114313
Validation loss: 2.542995899778148

Epoch: 6| Step: 2
Training loss: 2.22844501353404
Validation loss: 2.533025137618495

Epoch: 6| Step: 3
Training loss: 2.8494447133714575
Validation loss: 2.5474971381546756

Epoch: 6| Step: 4
Training loss: 2.585615247487207
Validation loss: 2.5427746717057347

Epoch: 6| Step: 5
Training loss: 2.1697847475798326
Validation loss: 2.533284346031849

Epoch: 6| Step: 6
Training loss: 3.156054197979803
Validation loss: 2.5418654945212524

Epoch: 6| Step: 7
Training loss: 2.672039450776797
Validation loss: 2.5430070565986043

Epoch: 6| Step: 8
Training loss: 2.794601283423628
Validation loss: 2.5502494653793706

Epoch: 6| Step: 9
Training loss: 1.9223157175781755
Validation loss: 2.545108666074736

Epoch: 6| Step: 10
Training loss: 3.424341157905073
Validation loss: 2.5383640385629356

Epoch: 6| Step: 11
Training loss: 1.7492465031932223
Validation loss: 2.5597890464551583

Epoch: 6| Step: 12
Training loss: 1.8798621396996438
Validation loss: 2.543433525581548

Epoch: 6| Step: 13
Training loss: 3.0050295947961287
Validation loss: 2.5509560247236163

Epoch: 139| Step: 0
Training loss: 2.747201449250654
Validation loss: 2.5512344492181076

Epoch: 6| Step: 1
Training loss: 2.960484291358406
Validation loss: 2.5361172080166523

Epoch: 6| Step: 2
Training loss: 2.7716202920997497
Validation loss: 2.530718459075884

Epoch: 6| Step: 3
Training loss: 2.3471400856629914
Validation loss: 2.5378201750708214

Epoch: 6| Step: 4
Training loss: 2.677782454778967
Validation loss: 2.545637111621763

Epoch: 6| Step: 5
Training loss: 2.506495525101191
Validation loss: 2.5426108349718466

Epoch: 6| Step: 6
Training loss: 2.8565007339708965
Validation loss: 2.5443521820127817

Epoch: 6| Step: 7
Training loss: 2.705842344666343
Validation loss: 2.548760282111538

Epoch: 6| Step: 8
Training loss: 3.0139177460663573
Validation loss: 2.5513182976131374

Epoch: 6| Step: 9
Training loss: 1.8659147130277243
Validation loss: 2.556101231443474

Epoch: 6| Step: 10
Training loss: 2.220265475371792
Validation loss: 2.5455716168389

Epoch: 6| Step: 11
Training loss: 2.878178042441805
Validation loss: 2.551174301440312

Epoch: 6| Step: 12
Training loss: 2.256251339898808
Validation loss: 2.540805055503999

Epoch: 6| Step: 13
Training loss: 2.226825899304979
Validation loss: 2.5553837510072994

Epoch: 140| Step: 0
Training loss: 2.883574594389098
Validation loss: 2.556463856740709

Epoch: 6| Step: 1
Training loss: 2.557543356967016
Validation loss: 2.5485676039931966

Epoch: 6| Step: 2
Training loss: 2.6932196854071795
Validation loss: 2.5493719585441093

Epoch: 6| Step: 3
Training loss: 2.5516552209213295
Validation loss: 2.5378154691696344

Epoch: 6| Step: 4
Training loss: 2.616989902609505
Validation loss: 2.5356218600703166

Epoch: 6| Step: 5
Training loss: 3.1482580242637845
Validation loss: 2.5456956908331763

Epoch: 6| Step: 6
Training loss: 2.402526947727768
Validation loss: 2.531984604198426

Epoch: 6| Step: 7
Training loss: 2.3365775669903406
Validation loss: 2.545073836059955

Epoch: 6| Step: 8
Training loss: 2.224897652318744
Validation loss: 2.5636473737414804

Epoch: 6| Step: 9
Training loss: 2.1859759880205996
Validation loss: 2.5300485729013498

Epoch: 6| Step: 10
Training loss: 2.942961141253935
Validation loss: 2.5300776978680655

Epoch: 6| Step: 11
Training loss: 2.989938393663052
Validation loss: 2.5448499306795487

Epoch: 6| Step: 12
Training loss: 2.063970446212381
Validation loss: 2.543799981869375

Epoch: 6| Step: 13
Training loss: 2.122339715196231
Validation loss: 2.546065277722866

Epoch: 141| Step: 0
Training loss: 2.808743829656732
Validation loss: 2.53500996597754

Epoch: 6| Step: 1
Training loss: 2.4215483414406744
Validation loss: 2.536626419373989

Epoch: 6| Step: 2
Training loss: 2.484758071636059
Validation loss: 2.54365467720249

Epoch: 6| Step: 3
Training loss: 2.536019811510746
Validation loss: 2.5426292197178353

Epoch: 6| Step: 4
Training loss: 2.6035244162454725
Validation loss: 2.5434500840450758

Epoch: 6| Step: 5
Training loss: 2.3065699244298186
Validation loss: 2.556950502390923

Epoch: 6| Step: 6
Training loss: 2.198120493424617
Validation loss: 2.5470129157282555

Epoch: 6| Step: 7
Training loss: 2.515183688484085
Validation loss: 2.5349557767206634

Epoch: 6| Step: 8
Training loss: 2.9113375525537517
Validation loss: 2.5264134009936505

Epoch: 6| Step: 9
Training loss: 2.8747774120907836
Validation loss: 2.5500093760309

Epoch: 6| Step: 10
Training loss: 2.533150042210792
Validation loss: 2.5404590597047663

Epoch: 6| Step: 11
Training loss: 3.562612966787586
Validation loss: 2.530607852281567

Epoch: 6| Step: 12
Training loss: 1.835245789429917
Validation loss: 2.5508205724423134

Epoch: 6| Step: 13
Training loss: 2.0975255374922446
Validation loss: 2.540338532006595

Epoch: 142| Step: 0
Training loss: 2.536019059407428
Validation loss: 2.561379149278252

Epoch: 6| Step: 1
Training loss: 2.8098292915919614
Validation loss: 2.534639755243304

Epoch: 6| Step: 2
Training loss: 2.7608499630758137
Validation loss: 2.554529695032662

Epoch: 6| Step: 3
Training loss: 2.7273670310275504
Validation loss: 2.532706830572659

Epoch: 6| Step: 4
Training loss: 2.3634823043674054
Validation loss: 2.5518497670728033

Epoch: 6| Step: 5
Training loss: 2.374587976955736
Validation loss: 2.55414345226576

Epoch: 6| Step: 6
Training loss: 2.853981810289252
Validation loss: 2.5355953744646005

Epoch: 6| Step: 7
Training loss: 2.4936463681058467
Validation loss: 2.538211476818216

Epoch: 6| Step: 8
Training loss: 2.9045835249638134
Validation loss: 2.569408516234026

Epoch: 6| Step: 9
Training loss: 2.5178127845327465
Validation loss: 2.5395195117278533

Epoch: 6| Step: 10
Training loss: 2.6069411388230157
Validation loss: 2.5209469960709914

Epoch: 6| Step: 11
Training loss: 2.4964674787765837
Validation loss: 2.549753920005567

Epoch: 6| Step: 12
Training loss: 2.095372268996302
Validation loss: 2.529542299071114

Epoch: 6| Step: 13
Training loss: 2.4901964611084386
Validation loss: 2.5452124421477103

Epoch: 143| Step: 0
Training loss: 1.9153109468841854
Validation loss: 2.527071831668076

Epoch: 6| Step: 1
Training loss: 2.5249585743140326
Validation loss: 2.5261303719381423

Epoch: 6| Step: 2
Training loss: 2.8979026115802466
Validation loss: 2.5333420607875796

Epoch: 6| Step: 3
Training loss: 2.351420249311741
Validation loss: 2.5377006903609973

Epoch: 6| Step: 4
Training loss: 2.7362733191502464
Validation loss: 2.558650111335631

Epoch: 6| Step: 5
Training loss: 2.306031846891047
Validation loss: 2.5394778443435997

Epoch: 6| Step: 6
Training loss: 3.039721890577838
Validation loss: 2.5527504453160983

Epoch: 6| Step: 7
Training loss: 2.6858178130374184
Validation loss: 2.540214049505909

Epoch: 6| Step: 8
Training loss: 2.6023510720096446
Validation loss: 2.551227182039865

Epoch: 6| Step: 9
Training loss: 2.298144035353891
Validation loss: 2.547298303361651

Epoch: 6| Step: 10
Training loss: 2.92688521577892
Validation loss: 2.5275208635145536

Epoch: 6| Step: 11
Training loss: 2.3256731884051027
Validation loss: 2.5393499557801413

Epoch: 6| Step: 12
Training loss: 2.7211776067718247
Validation loss: 2.5463621452466514

Epoch: 6| Step: 13
Training loss: 2.595612190668734
Validation loss: 2.5341748721583417

Epoch: 144| Step: 0
Training loss: 2.6863468268806976
Validation loss: 2.526204663874458

Epoch: 6| Step: 1
Training loss: 2.481980039112076
Validation loss: 2.55001492251639

Epoch: 6| Step: 2
Training loss: 2.5308522983410286
Validation loss: 2.5560676895808725

Epoch: 6| Step: 3
Training loss: 2.031423708017148
Validation loss: 2.543818050644452

Epoch: 6| Step: 4
Training loss: 2.209567343015993
Validation loss: 2.547907933057947

Epoch: 6| Step: 5
Training loss: 2.4800234898100797
Validation loss: 2.5403905513060585

Epoch: 6| Step: 6
Training loss: 2.741843003590003
Validation loss: 2.551299412772125

Epoch: 6| Step: 7
Training loss: 3.239411638786113
Validation loss: 2.530735913161173

Epoch: 6| Step: 8
Training loss: 2.4561820450329583
Validation loss: 2.5476380989231693

Epoch: 6| Step: 9
Training loss: 2.101383811416201
Validation loss: 2.5363718249580876

Epoch: 6| Step: 10
Training loss: 2.9402235675327812
Validation loss: 2.547752097983643

Epoch: 6| Step: 11
Training loss: 2.145151406482111
Validation loss: 2.551300998404782

Epoch: 6| Step: 12
Training loss: 2.839945837229724
Validation loss: 2.557910398651827

Epoch: 6| Step: 13
Training loss: 3.295429220072377
Validation loss: 2.5474607578059048

Epoch: 145| Step: 0
Training loss: 3.1383642153875786
Validation loss: 2.5522068334502235

Epoch: 6| Step: 1
Training loss: 2.654983936843125
Validation loss: 2.5434041982501174

Epoch: 6| Step: 2
Training loss: 2.431216430432306
Validation loss: 2.531698420405383

Epoch: 6| Step: 3
Training loss: 2.7623882426445032
Validation loss: 2.5516398080675335

Epoch: 6| Step: 4
Training loss: 3.1526733377404503
Validation loss: 2.540741416349565

Epoch: 6| Step: 5
Training loss: 2.5144385152063133
Validation loss: 2.5446986589407734

Epoch: 6| Step: 6
Training loss: 2.2857265706243077
Validation loss: 2.5526677918768934

Epoch: 6| Step: 7
Training loss: 2.454294108356311
Validation loss: 2.5415514518597413

Epoch: 6| Step: 8
Training loss: 2.567925733502514
Validation loss: 2.5492397201226824

Epoch: 6| Step: 9
Training loss: 2.1387141254031534
Validation loss: 2.5438407571148898

Epoch: 6| Step: 10
Training loss: 2.199783279841786
Validation loss: 2.545393149757567

Epoch: 6| Step: 11
Training loss: 3.059770886190102
Validation loss: 2.5503359622362796

Epoch: 6| Step: 12
Training loss: 2.187006867546668
Validation loss: 2.5513981702830764

Epoch: 6| Step: 13
Training loss: 1.703655055444944
Validation loss: 2.537531265958465

Epoch: 146| Step: 0
Training loss: 1.8954427826863423
Validation loss: 2.5409598067773174

Epoch: 6| Step: 1
Training loss: 2.7079301582920303
Validation loss: 2.5456549931348196

Epoch: 6| Step: 2
Training loss: 3.0103146932857876
Validation loss: 2.547621003152421

Epoch: 6| Step: 3
Training loss: 2.948104546876098
Validation loss: 2.5318285525106896

Epoch: 6| Step: 4
Training loss: 2.650329724078079
Validation loss: 2.547788221610596

Epoch: 6| Step: 5
Training loss: 2.8781921246350173
Validation loss: 2.5541064950889685

Epoch: 6| Step: 6
Training loss: 2.3641920620246015
Validation loss: 2.526329239990285

Epoch: 6| Step: 7
Training loss: 2.6659396094359806
Validation loss: 2.5355252978956186

Epoch: 6| Step: 8
Training loss: 2.4917658625561208
Validation loss: 2.5542808094351237

Epoch: 6| Step: 9
Training loss: 2.2311196254392143
Validation loss: 2.5437907322677167

Epoch: 6| Step: 10
Training loss: 1.9354571370744729
Validation loss: 2.552326104623525

Epoch: 6| Step: 11
Training loss: 2.221977787349726
Validation loss: 2.5385160432696257

Epoch: 6| Step: 12
Training loss: 2.7175527106738016
Validation loss: 2.5479956015682843

Epoch: 6| Step: 13
Training loss: 3.322325188463337
Validation loss: 2.552701538094676

Epoch: 147| Step: 0
Training loss: 2.8041255462337142
Validation loss: 2.549397209963764

Epoch: 6| Step: 1
Training loss: 3.631880051913446
Validation loss: 2.5559855265562166

Epoch: 6| Step: 2
Training loss: 2.570494949683122
Validation loss: 2.5468894001332023

Epoch: 6| Step: 3
Training loss: 2.2858359866440363
Validation loss: 2.5314623734622734

Epoch: 6| Step: 4
Training loss: 1.8316653929484101
Validation loss: 2.536078108948125

Epoch: 6| Step: 5
Training loss: 2.786134438392226
Validation loss: 2.542038871292308

Epoch: 6| Step: 6
Training loss: 2.31985232738246
Validation loss: 2.542520980310386

Epoch: 6| Step: 7
Training loss: 2.0355108321971525
Validation loss: 2.5256453803407615

Epoch: 6| Step: 8
Training loss: 2.0677915951918946
Validation loss: 2.553064255154892

Epoch: 6| Step: 9
Training loss: 3.385569517157397
Validation loss: 2.5452074623466174

Epoch: 6| Step: 10
Training loss: 2.245316611480665
Validation loss: 2.555659696913091

Epoch: 6| Step: 11
Training loss: 2.633056810402898
Validation loss: 2.5408611460155504

Epoch: 6| Step: 12
Training loss: 2.0331072019729692
Validation loss: 2.532980174263007

Epoch: 6| Step: 13
Training loss: 2.6521794264036638
Validation loss: 2.541832572677147

Epoch: 148| Step: 0
Training loss: 2.7611300908064678
Validation loss: 2.563709152834719

Epoch: 6| Step: 1
Training loss: 2.1814929772175886
Validation loss: 2.548911287155429

Epoch: 6| Step: 2
Training loss: 1.9016810835487694
Validation loss: 2.543838352542422

Epoch: 6| Step: 3
Training loss: 3.0389131249440204
Validation loss: 2.537251691895258

Epoch: 6| Step: 4
Training loss: 3.538242405067324
Validation loss: 2.541681030074159

Epoch: 6| Step: 5
Training loss: 2.2921954383010545
Validation loss: 2.54814280769125

Epoch: 6| Step: 6
Training loss: 2.9532604691046918
Validation loss: 2.5418141014821143

Epoch: 6| Step: 7
Training loss: 2.5207777621446614
Validation loss: 2.5308428282027835

Epoch: 6| Step: 8
Training loss: 2.598123104047967
Validation loss: 2.550082666680576

Epoch: 6| Step: 9
Training loss: 2.4723220285945215
Validation loss: 2.529490260389598

Epoch: 6| Step: 10
Training loss: 1.5635238344860174
Validation loss: 2.543019128733309

Epoch: 6| Step: 11
Training loss: 3.147682572721284
Validation loss: 2.5402892172882274

Epoch: 6| Step: 12
Training loss: 2.3753920783609472
Validation loss: 2.5426695630514837

Epoch: 6| Step: 13
Training loss: 1.0694751666281466
Validation loss: 2.5314896760125873

Epoch: 149| Step: 0
Training loss: 2.0600550638635613
Validation loss: 2.539536169404706

Epoch: 6| Step: 1
Training loss: 2.8650176857607144
Validation loss: 2.5392062238808366

Epoch: 6| Step: 2
Training loss: 3.0606035861449676
Validation loss: 2.5447612592112114

Epoch: 6| Step: 3
Training loss: 2.325511412621042
Validation loss: 2.5447971044350024

Epoch: 6| Step: 4
Training loss: 2.1978139506801297
Validation loss: 2.5386102654490905

Epoch: 6| Step: 5
Training loss: 2.8748271724335543
Validation loss: 2.54363998663378

Epoch: 6| Step: 6
Training loss: 1.8063697405661938
Validation loss: 2.5461376725121836

Epoch: 6| Step: 7
Training loss: 2.6679554348301977
Validation loss: 2.541932372701157

Epoch: 6| Step: 8
Training loss: 3.004368779918183
Validation loss: 2.540251184577788

Epoch: 6| Step: 9
Training loss: 2.12407978553131
Validation loss: 2.531694727388813

Epoch: 6| Step: 10
Training loss: 2.806899109938368
Validation loss: 2.546118423016184

Epoch: 6| Step: 11
Training loss: 2.577775133842267
Validation loss: 2.5438062957261103

Epoch: 6| Step: 12
Training loss: 2.63292949654271
Validation loss: 2.545789912130968

Epoch: 6| Step: 13
Training loss: 2.6256910958400885
Validation loss: 2.5367517914090247

Epoch: 150| Step: 0
Training loss: 1.721673871321004
Validation loss: 2.551320265571527

Epoch: 6| Step: 1
Training loss: 3.354197642181352
Validation loss: 2.5305430869553414

Epoch: 6| Step: 2
Training loss: 2.8867575677680173
Validation loss: 2.5432304599365687

Epoch: 6| Step: 3
Training loss: 2.3917579708769994
Validation loss: 2.5512264906921835

Epoch: 6| Step: 4
Training loss: 2.200312990985778
Validation loss: 2.550961818383459

Epoch: 6| Step: 5
Training loss: 2.499273576102289
Validation loss: 2.551519071787888

Epoch: 6| Step: 6
Training loss: 2.4245916081683005
Validation loss: 2.5251566828643566

Epoch: 6| Step: 7
Training loss: 2.515570693288771
Validation loss: 2.549564440632431

Epoch: 6| Step: 8
Training loss: 2.931278213983353
Validation loss: 2.5317967871390508

Epoch: 6| Step: 9
Training loss: 2.627937580551831
Validation loss: 2.5389099469040133

Epoch: 6| Step: 10
Training loss: 2.213801493635474
Validation loss: 2.5323496457702936

Epoch: 6| Step: 11
Training loss: 1.7698733102319049
Validation loss: 2.549954366949235

Epoch: 6| Step: 12
Training loss: 3.3660901044910747
Validation loss: 2.5140519795641594

Epoch: 6| Step: 13
Training loss: 2.4280480253569823
Validation loss: 2.5362722124694503

Epoch: 151| Step: 0
Training loss: 2.4040713665440574
Validation loss: 2.5238547331173797

Epoch: 6| Step: 1
Training loss: 2.1870406622226604
Validation loss: 2.531231008732128

Epoch: 6| Step: 2
Training loss: 3.334952358609024
Validation loss: 2.5429255956623025

Epoch: 6| Step: 3
Training loss: 2.6943054971776275
Validation loss: 2.5323219313469716

Epoch: 6| Step: 4
Training loss: 2.101270690852407
Validation loss: 2.5442168089113717

Epoch: 6| Step: 5
Training loss: 2.1555490874928616
Validation loss: 2.5388632217342084

Epoch: 6| Step: 6
Training loss: 2.804505663744478
Validation loss: 2.5469031640317543

Epoch: 6| Step: 7
Training loss: 2.739282879230228
Validation loss: 2.5233309996441555

Epoch: 6| Step: 8
Training loss: 2.886921422551676
Validation loss: 2.555582241614841

Epoch: 6| Step: 9
Training loss: 1.970974709707086
Validation loss: 2.549765976283603

Epoch: 6| Step: 10
Training loss: 2.2989540292491877
Validation loss: 2.5271398601511943

Epoch: 6| Step: 11
Training loss: 2.540664871484781
Validation loss: 2.5326731357777805

Epoch: 6| Step: 12
Training loss: 2.5510722953813376
Validation loss: 2.5270729333831476

Epoch: 6| Step: 13
Training loss: 3.017088539875204
Validation loss: 2.5245178240683703

Epoch: 152| Step: 0
Training loss: 2.3482535264167312
Validation loss: 2.5470995406119283

Epoch: 6| Step: 1
Training loss: 2.4291493104954798
Validation loss: 2.5381544596215337

Epoch: 6| Step: 2
Training loss: 2.8035088828054815
Validation loss: 2.5391032109810694

Epoch: 6| Step: 3
Training loss: 2.9535336489229005
Validation loss: 2.551245627287596

Epoch: 6| Step: 4
Training loss: 2.1492951501920716
Validation loss: 2.544670838734612

Epoch: 6| Step: 5
Training loss: 2.5070089318413435
Validation loss: 2.5410172412635728

Epoch: 6| Step: 6
Training loss: 1.9121977149577074
Validation loss: 2.531431664830253

Epoch: 6| Step: 7
Training loss: 3.1719636951692367
Validation loss: 2.543896684450898

Epoch: 6| Step: 8
Training loss: 2.723448453389835
Validation loss: 2.534824337665053

Epoch: 6| Step: 9
Training loss: 1.952735923160581
Validation loss: 2.5291584944530077

Epoch: 6| Step: 10
Training loss: 3.046987678204953
Validation loss: 2.5465799273094016

Epoch: 6| Step: 11
Training loss: 2.935641410965313
Validation loss: 2.5615300489515818

Epoch: 6| Step: 12
Training loss: 1.6151018192094189
Validation loss: 2.5294642923364443

Epoch: 6| Step: 13
Training loss: 2.732809610512516
Validation loss: 2.5317539284181123

Epoch: 153| Step: 0
Training loss: 2.0870918194651664
Validation loss: 2.5319669795067976

Epoch: 6| Step: 1
Training loss: 2.327647217746277
Validation loss: 2.5347068503709678

Epoch: 6| Step: 2
Training loss: 2.4596246032854108
Validation loss: 2.5432773518329883

Epoch: 6| Step: 3
Training loss: 3.4039550889814536
Validation loss: 2.534545357643729

Epoch: 6| Step: 4
Training loss: 3.4174731783592227
Validation loss: 2.557243954394469

Epoch: 6| Step: 5
Training loss: 2.3922590268714528
Validation loss: 2.5463129134602878

Epoch: 6| Step: 6
Training loss: 2.73029533130216
Validation loss: 2.551091566787665

Epoch: 6| Step: 7
Training loss: 2.1513620896869923
Validation loss: 2.5386186432327573

Epoch: 6| Step: 8
Training loss: 2.575781849799464
Validation loss: 2.544621452825235

Epoch: 6| Step: 9
Training loss: 2.7608959045903716
Validation loss: 2.5471695020618332

Epoch: 6| Step: 10
Training loss: 2.1745267638214822
Validation loss: 2.5458573780106213

Epoch: 6| Step: 11
Training loss: 2.206895132002703
Validation loss: 2.542306399581862

Epoch: 6| Step: 12
Training loss: 1.8562143855419215
Validation loss: 2.522923412510264

Epoch: 6| Step: 13
Training loss: 2.8481347790019265
Validation loss: 2.5142463437953126

Epoch: 154| Step: 0
Training loss: 3.2033989021611387
Validation loss: 2.543208635087254

Epoch: 6| Step: 1
Training loss: 2.211094072277333
Validation loss: 2.5383681935260465

Epoch: 6| Step: 2
Training loss: 2.126715920973111
Validation loss: 2.5415680316632505

Epoch: 6| Step: 3
Training loss: 2.8124835543681512
Validation loss: 2.561857277467245

Epoch: 6| Step: 4
Training loss: 2.763719581219213
Validation loss: 2.5457107678246076

Epoch: 6| Step: 5
Training loss: 3.0126953125
Validation loss: 2.538964376391495

Epoch: 6| Step: 6
Training loss: 2.2247572691456052
Validation loss: 2.5381843556556367

Epoch: 6| Step: 7
Training loss: 2.4020038147132943
Validation loss: 2.564122278506088

Epoch: 6| Step: 8
Training loss: 2.5251103103261023
Validation loss: 2.5394191565282416

Epoch: 6| Step: 9
Training loss: 1.965150721935678
Validation loss: 2.5471408825244324

Epoch: 6| Step: 10
Training loss: 2.8350531089692605
Validation loss: 2.53695872347241

Epoch: 6| Step: 11
Training loss: 2.5521544985028854
Validation loss: 2.5367706935956567

Epoch: 6| Step: 12
Training loss: 1.9681178697860904
Validation loss: 2.5332019338575655

Epoch: 6| Step: 13
Training loss: 3.035922823883724
Validation loss: 2.5344624958897413

Epoch: 155| Step: 0
Training loss: 2.3975088701292915
Validation loss: 2.545582384710258

Epoch: 6| Step: 1
Training loss: 2.8456491689076646
Validation loss: 2.542316264658582

Epoch: 6| Step: 2
Training loss: 2.6841535803321794
Validation loss: 2.528438154346808

Epoch: 6| Step: 3
Training loss: 2.6220935898640896
Validation loss: 2.5403291497094322

Epoch: 6| Step: 4
Training loss: 3.0111620199193996
Validation loss: 2.551607054282392

Epoch: 6| Step: 5
Training loss: 2.0217527939244233
Validation loss: 2.5486962154434982

Epoch: 6| Step: 6
Training loss: 2.66916702192695
Validation loss: 2.5549573722843983

Epoch: 6| Step: 7
Training loss: 2.4065949824357364
Validation loss: 2.557519437967271

Epoch: 6| Step: 8
Training loss: 2.4638890565195735
Validation loss: 2.562563991673031

Epoch: 6| Step: 9
Training loss: 2.576351411129299
Validation loss: 2.5539889612883035

Epoch: 6| Step: 10
Training loss: 2.1772184436494166
Validation loss: 2.564205745466007

Epoch: 6| Step: 11
Training loss: 2.496419249610173
Validation loss: 2.562593085726476

Epoch: 6| Step: 12
Training loss: 2.852812359864508
Validation loss: 2.548385596914176

Epoch: 6| Step: 13
Training loss: 2.314311786955511
Validation loss: 2.5493124084091225

Epoch: 156| Step: 0
Training loss: 2.910130197293199
Validation loss: 2.5562594819576896

Epoch: 6| Step: 1
Training loss: 2.2515340449846852
Validation loss: 2.528151961532336

Epoch: 6| Step: 2
Training loss: 3.002681646259993
Validation loss: 2.5389564955222714

Epoch: 6| Step: 3
Training loss: 2.7698457913217185
Validation loss: 2.536016784900067

Epoch: 6| Step: 4
Training loss: 3.061648191985692
Validation loss: 2.551031412626183

Epoch: 6| Step: 5
Training loss: 2.109594150038048
Validation loss: 2.5355207661926196

Epoch: 6| Step: 6
Training loss: 2.8961817762746844
Validation loss: 2.536690738324393

Epoch: 6| Step: 7
Training loss: 2.678410973965531
Validation loss: 2.5441693740750297

Epoch: 6| Step: 8
Training loss: 2.209815074036284
Validation loss: 2.5293840148867783

Epoch: 6| Step: 9
Training loss: 2.08432984996663
Validation loss: 2.5336337950713665

Epoch: 6| Step: 10
Training loss: 2.1589880987266037
Validation loss: 2.553925981406079

Epoch: 6| Step: 11
Training loss: 2.4239086841656357
Validation loss: 2.542338520687695

Epoch: 6| Step: 12
Training loss: 2.119216453496438
Validation loss: 2.525020865450916

Epoch: 6| Step: 13
Training loss: 2.8236589101121115
Validation loss: 2.5368228537643915

Epoch: 157| Step: 0
Training loss: 2.488993640050123
Validation loss: 2.5445630418191962

Epoch: 6| Step: 1
Training loss: 2.594939453212468
Validation loss: 2.549193008299571

Epoch: 6| Step: 2
Training loss: 2.3486494606998307
Validation loss: 2.5498443452256896

Epoch: 6| Step: 3
Training loss: 2.3192644931430424
Validation loss: 2.537733159693117

Epoch: 6| Step: 4
Training loss: 2.4649385412884235
Validation loss: 2.5361761329618475

Epoch: 6| Step: 5
Training loss: 3.3163626839839444
Validation loss: 2.5439910323377135

Epoch: 6| Step: 6
Training loss: 2.2099386054784715
Validation loss: 2.538501438597027

Epoch: 6| Step: 7
Training loss: 2.1498021456146392
Validation loss: 2.5438451218213034

Epoch: 6| Step: 8
Training loss: 2.558450802602696
Validation loss: 2.5560525718788925

Epoch: 6| Step: 9
Training loss: 3.349515418689555
Validation loss: 2.53394208196422

Epoch: 6| Step: 10
Training loss: 2.09405082705076
Validation loss: 2.5312387194496697

Epoch: 6| Step: 11
Training loss: 2.9907412706691123
Validation loss: 2.542140594414147

Epoch: 6| Step: 12
Training loss: 2.2491065476665058
Validation loss: 2.5494539344941147

Epoch: 6| Step: 13
Training loss: 1.7492509328685115
Validation loss: 2.5461877554585604

Epoch: 158| Step: 0
Training loss: 3.1715755227310476
Validation loss: 2.5430958063689917

Epoch: 6| Step: 1
Training loss: 2.164732460952725
Validation loss: 2.541514351925877

Epoch: 6| Step: 2
Training loss: 2.3033408158323847
Validation loss: 2.5349562656917684

Epoch: 6| Step: 3
Training loss: 2.839371884692979
Validation loss: 2.55169422396989

Epoch: 6| Step: 4
Training loss: 1.8975999656550193
Validation loss: 2.5463339304284403

Epoch: 6| Step: 5
Training loss: 3.1327336555890533
Validation loss: 2.528572637466537

Epoch: 6| Step: 6
Training loss: 2.2882277493198897
Validation loss: 2.556122646333024

Epoch: 6| Step: 7
Training loss: 1.7732937792379837
Validation loss: 2.5416431957138204

Epoch: 6| Step: 8
Training loss: 2.573010173956886
Validation loss: 2.5507037289775245

Epoch: 6| Step: 9
Training loss: 3.079352119721596
Validation loss: 2.528487744815794

Epoch: 6| Step: 10
Training loss: 2.1168541452277645
Validation loss: 2.5605446478112968

Epoch: 6| Step: 11
Training loss: 3.0792782554658746
Validation loss: 2.5399608573290804

Epoch: 6| Step: 12
Training loss: 2.212823285983093
Validation loss: 2.53874155090661

Epoch: 6| Step: 13
Training loss: 2.3517393128087467
Validation loss: 2.5403121848902037

Epoch: 159| Step: 0
Training loss: 2.7088581652624923
Validation loss: 2.548454212294298

Epoch: 6| Step: 1
Training loss: 2.7394041188925056
Validation loss: 2.528698116825784

Epoch: 6| Step: 2
Training loss: 2.4493085975533146
Validation loss: 2.5360369703234404

Epoch: 6| Step: 3
Training loss: 1.6742833696890178
Validation loss: 2.5451014378131025

Epoch: 6| Step: 4
Training loss: 3.097932242837693
Validation loss: 2.549829308259817

Epoch: 6| Step: 5
Training loss: 2.0724228952971697
Validation loss: 2.5586515531419254

Epoch: 6| Step: 6
Training loss: 2.2090275471024396
Validation loss: 2.5395824481196345

Epoch: 6| Step: 7
Training loss: 2.361534292656591
Validation loss: 2.5550297815178826

Epoch: 6| Step: 8
Training loss: 2.7286162852763653
Validation loss: 2.5453679271036393

Epoch: 6| Step: 9
Training loss: 3.37021962454793
Validation loss: 2.5347056649922615

Epoch: 6| Step: 10
Training loss: 1.7762461196889245
Validation loss: 2.5464163218148137

Epoch: 6| Step: 11
Training loss: 2.575637264467812
Validation loss: 2.5268253468600648

Epoch: 6| Step: 12
Training loss: 2.5865840967836107
Validation loss: 2.536668117425704

Epoch: 6| Step: 13
Training loss: 2.4165601926126863
Validation loss: 2.534119711564583

Epoch: 160| Step: 0
Training loss: 1.9770638655523751
Validation loss: 2.53842368294175

Epoch: 6| Step: 1
Training loss: 3.4171290821302653
Validation loss: 2.5351695684454802

Epoch: 6| Step: 2
Training loss: 2.3097967895696896
Validation loss: 2.539772766071971

Epoch: 6| Step: 3
Training loss: 2.7458004530316207
Validation loss: 2.5567675343843317

Epoch: 6| Step: 4
Training loss: 2.4364085565978226
Validation loss: 2.5452415149667265

Epoch: 6| Step: 5
Training loss: 3.018863026653221
Validation loss: 2.523463443719379

Epoch: 6| Step: 6
Training loss: 2.044104411808387
Validation loss: 2.5330106596792317

Epoch: 6| Step: 7
Training loss: 2.001161119058726
Validation loss: 2.545241098477571

Epoch: 6| Step: 8
Training loss: 1.5679465922874634
Validation loss: 2.5522547351435962

Epoch: 6| Step: 9
Training loss: 2.471999046405744
Validation loss: 2.5199523365313636

Epoch: 6| Step: 10
Training loss: 3.0030933961981705
Validation loss: 2.531461442780387

Epoch: 6| Step: 11
Training loss: 2.690728488398413
Validation loss: 2.534391465471253

Epoch: 6| Step: 12
Training loss: 2.734806135793233
Validation loss: 2.5495319228808135

Epoch: 6| Step: 13
Training loss: 2.209347102354644
Validation loss: 2.526797125429474

Epoch: 161| Step: 0
Training loss: 2.2896955740864255
Validation loss: 2.541490664373789

Epoch: 6| Step: 1
Training loss: 2.237663889588822
Validation loss: 2.546829960053189

Epoch: 6| Step: 2
Training loss: 2.3694454289511686
Validation loss: 2.5546312012668335

Epoch: 6| Step: 3
Training loss: 2.833318504593884
Validation loss: 2.553709207799803

Epoch: 6| Step: 4
Training loss: 2.2856210089281768
Validation loss: 2.529586574586223

Epoch: 6| Step: 5
Training loss: 2.0553030970194337
Validation loss: 2.5252689994381536

Epoch: 6| Step: 6
Training loss: 2.7911700665807113
Validation loss: 2.54155857926191

Epoch: 6| Step: 7
Training loss: 2.5188170847703018
Validation loss: 2.522246480207617

Epoch: 6| Step: 8
Training loss: 2.459316046467463
Validation loss: 2.5397430870844593

Epoch: 6| Step: 9
Training loss: 2.4494465261160037
Validation loss: 2.541101497415403

Epoch: 6| Step: 10
Training loss: 3.108477745758207
Validation loss: 2.5315330673215732

Epoch: 6| Step: 11
Training loss: 2.537311595818957
Validation loss: 2.532362589727479

Epoch: 6| Step: 12
Training loss: 2.0146574315116736
Validation loss: 2.5425345127569896

Epoch: 6| Step: 13
Training loss: 3.582461997853495
Validation loss: 2.5556991464208885

Epoch: 162| Step: 0
Training loss: 3.2358692790106227
Validation loss: 2.5540382804923807

Epoch: 6| Step: 1
Training loss: 2.636563128364708
Validation loss: 2.5506421791395466

Epoch: 6| Step: 2
Training loss: 2.8160754047831893
Validation loss: 2.5398486040125703

Epoch: 6| Step: 3
Training loss: 2.202813309068514
Validation loss: 2.534293246992391

Epoch: 6| Step: 4
Training loss: 2.770959052960031
Validation loss: 2.530901181073185

Epoch: 6| Step: 5
Training loss: 2.4410560295678887
Validation loss: 2.535510414628257

Epoch: 6| Step: 6
Training loss: 2.453650157138937
Validation loss: 2.520879490984959

Epoch: 6| Step: 7
Training loss: 2.145644935806425
Validation loss: 2.5413502044458074

Epoch: 6| Step: 8
Training loss: 2.8080548232288467
Validation loss: 2.5434235469083006

Epoch: 6| Step: 9
Training loss: 1.9106045998334944
Validation loss: 2.539455379005162

Epoch: 6| Step: 10
Training loss: 2.713065156204156
Validation loss: 2.5454677947289626

Epoch: 6| Step: 11
Training loss: 2.4963502946093112
Validation loss: 2.547987103694543

Epoch: 6| Step: 12
Training loss: 1.8944666900646219
Validation loss: 2.5311225161193636

Epoch: 6| Step: 13
Training loss: 2.5675978775460164
Validation loss: 2.5641704390055815

Epoch: 163| Step: 0
Training loss: 2.268055631449783
Validation loss: 2.5477127236531043

Epoch: 6| Step: 1
Training loss: 3.300487112449215
Validation loss: 2.5329865798642945

Epoch: 6| Step: 2
Training loss: 2.670097071851117
Validation loss: 2.541891609202037

Epoch: 6| Step: 3
Training loss: 2.008905847814501
Validation loss: 2.528964818101478

Epoch: 6| Step: 4
Training loss: 2.606126236206798
Validation loss: 2.5419862362381616

Epoch: 6| Step: 5
Training loss: 2.391967994590646
Validation loss: 2.536606438751462

Epoch: 6| Step: 6
Training loss: 2.285548614986359
Validation loss: 2.546984556131642

Epoch: 6| Step: 7
Training loss: 2.483018996892336
Validation loss: 2.547418672346955

Epoch: 6| Step: 8
Training loss: 2.434729150516943
Validation loss: 2.550189099346839

Epoch: 6| Step: 9
Training loss: 2.5551807732280922
Validation loss: 2.5467666813318393

Epoch: 6| Step: 10
Training loss: 2.8084345787052674
Validation loss: 2.5427588992824317

Epoch: 6| Step: 11
Training loss: 2.467181129761409
Validation loss: 2.5289329711415114

Epoch: 6| Step: 12
Training loss: 2.7420108227450126
Validation loss: 2.538792471461327

Epoch: 6| Step: 13
Training loss: 1.8975612046494377
Validation loss: 2.558135563050087

Epoch: 164| Step: 0
Training loss: 1.7769477151489423
Validation loss: 2.5308315701487163

Epoch: 6| Step: 1
Training loss: 2.6752903397476357
Validation loss: 2.5468127269921457

Epoch: 6| Step: 2
Training loss: 1.8797995491909636
Validation loss: 2.534840843139746

Epoch: 6| Step: 3
Training loss: 2.495631597535517
Validation loss: 2.5568431926070403

Epoch: 6| Step: 4
Training loss: 2.7327686932271407
Validation loss: 2.5473899559773914

Epoch: 6| Step: 5
Training loss: 2.9145258721737766
Validation loss: 2.5376976152438835

Epoch: 6| Step: 6
Training loss: 2.562607925747424
Validation loss: 2.534933432612592

Epoch: 6| Step: 7
Training loss: 2.147665988071604
Validation loss: 2.5367377991120916

Epoch: 6| Step: 8
Training loss: 2.6441788995096958
Validation loss: 2.537092467972475

Epoch: 6| Step: 9
Training loss: 2.4761117230108063
Validation loss: 2.541133317979474

Epoch: 6| Step: 10
Training loss: 1.4851285126176348
Validation loss: 2.5293303988828355

Epoch: 6| Step: 11
Training loss: 2.7935551381265804
Validation loss: 2.532847213641345

Epoch: 6| Step: 12
Training loss: 2.9646378798748865
Validation loss: 2.5323431732607107

Epoch: 6| Step: 13
Training loss: 3.471684769467096
Validation loss: 2.540793817880452

Epoch: 165| Step: 0
Training loss: 2.4702131546958794
Validation loss: 2.5283628745412967

Epoch: 6| Step: 1
Training loss: 1.7827287525563276
Validation loss: 2.5312417867150763

Epoch: 6| Step: 2
Training loss: 2.4066535314094053
Validation loss: 2.539790229600496

Epoch: 6| Step: 3
Training loss: 2.4950750478034007
Validation loss: 2.5249874701524613

Epoch: 6| Step: 4
Training loss: 3.0692490927401335
Validation loss: 2.537154562247111

Epoch: 6| Step: 5
Training loss: 1.9079298528496207
Validation loss: 2.539382251581763

Epoch: 6| Step: 6
Training loss: 2.64328627250633
Validation loss: 2.534962082772014

Epoch: 6| Step: 7
Training loss: 2.0727524684366334
Validation loss: 2.523811074189725

Epoch: 6| Step: 8
Training loss: 2.6000355314614567
Validation loss: 2.5275697224344693

Epoch: 6| Step: 9
Training loss: 2.855521518621519
Validation loss: 2.5506029313405536

Epoch: 6| Step: 10
Training loss: 2.2021874130420063
Validation loss: 2.541888826593857

Epoch: 6| Step: 11
Training loss: 2.921563932618612
Validation loss: 2.5242632951574975

Epoch: 6| Step: 12
Training loss: 2.8296588932067936
Validation loss: 2.5521244979126854

Epoch: 6| Step: 13
Training loss: 2.798510195982248
Validation loss: 2.5624828122950922

Epoch: 166| Step: 0
Training loss: 2.1909172614113244
Validation loss: 2.5375680690146125

Epoch: 6| Step: 1
Training loss: 2.3140386669057227
Validation loss: 2.5505559288729485

Epoch: 6| Step: 2
Training loss: 3.2194626398882518
Validation loss: 2.537303298591547

Epoch: 6| Step: 3
Training loss: 2.5500221700265575
Validation loss: 2.528811142883669

Epoch: 6| Step: 4
Training loss: 2.6498117847900087
Validation loss: 2.5403816838704714

Epoch: 6| Step: 5
Training loss: 2.5398642814601935
Validation loss: 2.5239301707464956

Epoch: 6| Step: 6
Training loss: 2.702620795529538
Validation loss: 2.5607629166124957

Epoch: 6| Step: 7
Training loss: 1.966764629747465
Validation loss: 2.5333966615087578

Epoch: 6| Step: 8
Training loss: 1.901702647502609
Validation loss: 2.519310340567416

Epoch: 6| Step: 9
Training loss: 2.551424421509349
Validation loss: 2.529903757253345

Epoch: 6| Step: 10
Training loss: 3.140754051783416
Validation loss: 2.533680466930201

Epoch: 6| Step: 11
Training loss: 2.396001019345482
Validation loss: 2.5574356886312497

Epoch: 6| Step: 12
Training loss: 2.6598688942285977
Validation loss: 2.538545707316236

Epoch: 6| Step: 13
Training loss: 1.7447451305351516
Validation loss: 2.507974913722055

Epoch: 167| Step: 0
Training loss: 2.849056616464615
Validation loss: 2.539561923425872

Epoch: 6| Step: 1
Training loss: 2.8448336705827373
Validation loss: 2.537986072083642

Epoch: 6| Step: 2
Training loss: 2.23762627783393
Validation loss: 2.5248160549169416

Epoch: 6| Step: 3
Training loss: 2.706278642674637
Validation loss: 2.5398244931366585

Epoch: 6| Step: 4
Training loss: 2.1190305901012065
Validation loss: 2.5326856883761746

Epoch: 6| Step: 5
Training loss: 1.7452294858418915
Validation loss: 2.524589809603461

Epoch: 6| Step: 6
Training loss: 3.4753997572797855
Validation loss: 2.547974881034118

Epoch: 6| Step: 7
Training loss: 2.234070016813899
Validation loss: 2.542744350738246

Epoch: 6| Step: 8
Training loss: 2.8217069185033097
Validation loss: 2.535875066937513

Epoch: 6| Step: 9
Training loss: 1.7890360467945712
Validation loss: 2.549797492659407

Epoch: 6| Step: 10
Training loss: 2.0522118800867135
Validation loss: 2.547009717482505

Epoch: 6| Step: 11
Training loss: 2.8011014747310963
Validation loss: 2.548236713655637

Epoch: 6| Step: 12
Training loss: 2.1536046262133084
Validation loss: 2.545848788412594

Epoch: 6| Step: 13
Training loss: 2.5716769878042713
Validation loss: 2.5669736331297415

Epoch: 168| Step: 0
Training loss: 2.3684368802261195
Validation loss: 2.565980120286163

Epoch: 6| Step: 1
Training loss: 2.717941514745246
Validation loss: 2.547770988993837

Epoch: 6| Step: 2
Training loss: 2.565536746552775
Validation loss: 2.5576929944928763

Epoch: 6| Step: 3
Training loss: 2.076305194927203
Validation loss: 2.5488208283300406

Epoch: 6| Step: 4
Training loss: 3.074601378616444
Validation loss: 2.539634633314387

Epoch: 6| Step: 5
Training loss: 2.5160915344944894
Validation loss: 2.530467487827983

Epoch: 6| Step: 6
Training loss: 2.399983060300173
Validation loss: 2.5287417826203393

Epoch: 6| Step: 7
Training loss: 2.663647392799299
Validation loss: 2.5489688592885673

Epoch: 6| Step: 8
Training loss: 3.161657554386771
Validation loss: 2.534424279645765

Epoch: 6| Step: 9
Training loss: 2.4413808592429675
Validation loss: 2.5213023655937854

Epoch: 6| Step: 10
Training loss: 2.1768469674569597
Validation loss: 2.526816241079885

Epoch: 6| Step: 11
Training loss: 1.6881735834886447
Validation loss: 2.5446190419381693

Epoch: 6| Step: 12
Training loss: 2.4406326899486728
Validation loss: 2.5338116496500427

Epoch: 6| Step: 13
Training loss: 2.4441772360648497
Validation loss: 2.535549350567411

Epoch: 169| Step: 0
Training loss: 2.116881851712298
Validation loss: 2.533146553718122

Epoch: 6| Step: 1
Training loss: 2.8839431654347005
Validation loss: 2.539815808441397

Epoch: 6| Step: 2
Training loss: 2.5120754433619403
Validation loss: 2.5263842961906824

Epoch: 6| Step: 3
Training loss: 2.452101184020514
Validation loss: 2.534499331874779

Epoch: 6| Step: 4
Training loss: 2.4672458750490955
Validation loss: 2.5356413004663594

Epoch: 6| Step: 5
Training loss: 3.072363248657564
Validation loss: 2.55826615014232

Epoch: 6| Step: 6
Training loss: 2.899923021018322
Validation loss: 2.5291997586431774

Epoch: 6| Step: 7
Training loss: 2.149373908146622
Validation loss: 2.526698787270858

Epoch: 6| Step: 8
Training loss: 2.3057918682811644
Validation loss: 2.545474141964659

Epoch: 6| Step: 9
Training loss: 1.6591176093816418
Validation loss: 2.5331511514026976

Epoch: 6| Step: 10
Training loss: 2.552521793821665
Validation loss: 2.535783025427566

Epoch: 6| Step: 11
Training loss: 2.5888095361484447
Validation loss: 2.5411306434976386

Epoch: 6| Step: 12
Training loss: 2.821753474562158
Validation loss: 2.543441506476075

Epoch: 6| Step: 13
Training loss: 1.6356640606342392
Validation loss: 2.526268029903903

Epoch: 170| Step: 0
Training loss: 2.413631660014048
Validation loss: 2.533410917652773

Epoch: 6| Step: 1
Training loss: 2.932966751976688
Validation loss: 2.545469468845702

Epoch: 6| Step: 2
Training loss: 2.3162320925519064
Validation loss: 2.5314604310811912

Epoch: 6| Step: 3
Training loss: 3.461171712764933
Validation loss: 2.5275469382554756

Epoch: 6| Step: 4
Training loss: 2.203416196368204
Validation loss: 2.522839701598445

Epoch: 6| Step: 5
Training loss: 2.613479310243726
Validation loss: 2.5303566481825386

Epoch: 6| Step: 6
Training loss: 2.5977208638580547
Validation loss: 2.52854680396027

Epoch: 6| Step: 7
Training loss: 2.309198652046163
Validation loss: 2.522156785877435

Epoch: 6| Step: 8
Training loss: 1.930947205345802
Validation loss: 2.533704984337387

Epoch: 6| Step: 9
Training loss: 2.680872352165152
Validation loss: 2.5354813818945585

Epoch: 6| Step: 10
Training loss: 2.372573516478461
Validation loss: 2.5226074751425918

Epoch: 6| Step: 11
Training loss: 1.8082487300413195
Validation loss: 2.554255239953692

Epoch: 6| Step: 12
Training loss: 2.711904040143976
Validation loss: 2.511371582240796

Epoch: 6| Step: 13
Training loss: 2.0591729813214807
Validation loss: 2.519799433269604

Epoch: 171| Step: 0
Training loss: 2.7911955212864106
Validation loss: 2.526065465935317

Epoch: 6| Step: 1
Training loss: 2.912690440488281
Validation loss: 2.5504802243627496

Epoch: 6| Step: 2
Training loss: 2.2040902045772377
Validation loss: 2.528217788941069

Epoch: 6| Step: 3
Training loss: 2.5064855374509314
Validation loss: 2.5418337991097193

Epoch: 6| Step: 4
Training loss: 2.2529112736975065
Validation loss: 2.540589201703145

Epoch: 6| Step: 5
Training loss: 2.468884814480589
Validation loss: 2.557208368354793

Epoch: 6| Step: 6
Training loss: 2.938653597660162
Validation loss: 2.514398719119615

Epoch: 6| Step: 7
Training loss: 2.1042803239499
Validation loss: 2.5350328863491716

Epoch: 6| Step: 8
Training loss: 2.3162849999226562
Validation loss: 2.542793558358259

Epoch: 6| Step: 9
Training loss: 2.703623642986849
Validation loss: 2.5455096211319517

Epoch: 6| Step: 10
Training loss: 2.2985603221905087
Validation loss: 2.5283336481966487

Epoch: 6| Step: 11
Training loss: 2.612883259527199
Validation loss: 2.5509212097264555

Epoch: 6| Step: 12
Training loss: 2.287581866524349
Validation loss: 2.537928742238122

Epoch: 6| Step: 13
Training loss: 2.131869935740123
Validation loss: 2.551238039590426

Epoch: 172| Step: 0
Training loss: 2.2936224712291566
Validation loss: 2.540390320210201

Epoch: 6| Step: 1
Training loss: 2.7087515777034064
Validation loss: 2.5435098893582304

Epoch: 6| Step: 2
Training loss: 2.073498042127551
Validation loss: 2.5443726841861247

Epoch: 6| Step: 3
Training loss: 2.1340625718586392
Validation loss: 2.54452874436174

Epoch: 6| Step: 4
Training loss: 2.8666364675601956
Validation loss: 2.5281253996972115

Epoch: 6| Step: 5
Training loss: 2.4044957888243683
Validation loss: 2.527460705223559

Epoch: 6| Step: 6
Training loss: 2.998857280534316
Validation loss: 2.536785685181112

Epoch: 6| Step: 7
Training loss: 2.0337900565996803
Validation loss: 2.5164084661917765

Epoch: 6| Step: 8
Training loss: 2.866763715062343
Validation loss: 2.528785383792542

Epoch: 6| Step: 9
Training loss: 2.5859633153450856
Validation loss: 2.546383587171815

Epoch: 6| Step: 10
Training loss: 2.67027895366742
Validation loss: 2.512912442161225

Epoch: 6| Step: 11
Training loss: 2.2471651656561162
Validation loss: 2.530113231322389

Epoch: 6| Step: 12
Training loss: 2.4978410935814512
Validation loss: 2.5323017163103683

Epoch: 6| Step: 13
Training loss: 2.0476954322859005
Validation loss: 2.528268058036386

Epoch: 173| Step: 0
Training loss: 2.6668418190972516
Validation loss: 2.5279984539187432

Epoch: 6| Step: 1
Training loss: 2.665462003243502
Validation loss: 2.506139326982802

Epoch: 6| Step: 2
Training loss: 2.2288672581847835
Validation loss: 2.5238189678155303

Epoch: 6| Step: 3
Training loss: 2.7372790800510205
Validation loss: 2.543960918345344

Epoch: 6| Step: 4
Training loss: 2.8500380530242966
Validation loss: 2.5839291843705

Epoch: 6| Step: 5
Training loss: 2.4795012261675544
Validation loss: 2.533680706732658

Epoch: 6| Step: 6
Training loss: 2.0782056520342778
Validation loss: 2.525624695693897

Epoch: 6| Step: 7
Training loss: 2.3130470865934796
Validation loss: 2.528981309105854

Epoch: 6| Step: 8
Training loss: 2.327098748256499
Validation loss: 2.53931728703326

Epoch: 6| Step: 9
Training loss: 3.1953695054320583
Validation loss: 2.542483948973233

Epoch: 6| Step: 10
Training loss: 2.33114591882637
Validation loss: 2.536898267545122

Epoch: 6| Step: 11
Training loss: 2.5716164478665444
Validation loss: 2.527027662236998

Epoch: 6| Step: 12
Training loss: 1.4801719992158253
Validation loss: 2.536875901387155

Epoch: 6| Step: 13
Training loss: 2.286724263384304
Validation loss: 2.5382118727454506

Epoch: 174| Step: 0
Training loss: 2.217040464487082
Validation loss: 2.5248410493181774

Epoch: 6| Step: 1
Training loss: 2.671952631307793
Validation loss: 2.530778203616867

Epoch: 6| Step: 2
Training loss: 2.8211435377512615
Validation loss: 2.5215560455416766

Epoch: 6| Step: 3
Training loss: 2.9725885571505755
Validation loss: 2.542961489444315

Epoch: 6| Step: 4
Training loss: 2.248400331445794
Validation loss: 2.5180125599506624

Epoch: 6| Step: 5
Training loss: 1.6856999156514902
Validation loss: 2.540652185761884

Epoch: 6| Step: 6
Training loss: 2.16158309637727
Validation loss: 2.541329009572275

Epoch: 6| Step: 7
Training loss: 2.2332270948088833
Validation loss: 2.5394332324803046

Epoch: 6| Step: 8
Training loss: 2.468534629215723
Validation loss: 2.5169391169090423

Epoch: 6| Step: 9
Training loss: 2.734638920717483
Validation loss: 2.5270354240769937

Epoch: 6| Step: 10
Training loss: 2.784555335578849
Validation loss: 2.5069398202100617

Epoch: 6| Step: 11
Training loss: 2.276261087020863
Validation loss: 2.53209827934764

Epoch: 6| Step: 12
Training loss: 2.8765649268177906
Validation loss: 2.5317764656382664

Epoch: 6| Step: 13
Training loss: 1.919046444933655
Validation loss: 2.541065266623783

Epoch: 175| Step: 0
Training loss: 2.3084725026985553
Validation loss: 2.5366705803372502

Epoch: 6| Step: 1
Training loss: 2.196982512142709
Validation loss: 2.523293944740219

Epoch: 6| Step: 2
Training loss: 2.8050310779828638
Validation loss: 2.5059435958494247

Epoch: 6| Step: 3
Training loss: 2.3557790675174983
Validation loss: 2.535265432795441

Epoch: 6| Step: 4
Training loss: 2.504564505238561
Validation loss: 2.540431317699143

Epoch: 6| Step: 5
Training loss: 2.383336044078788
Validation loss: 2.534742714894626

Epoch: 6| Step: 6
Training loss: 2.808982174983494
Validation loss: 2.545931693438808

Epoch: 6| Step: 7
Training loss: 2.0902523603897083
Validation loss: 2.52670893345647

Epoch: 6| Step: 8
Training loss: 2.2406339679788605
Validation loss: 2.534579765919324

Epoch: 6| Step: 9
Training loss: 3.076092353882877
Validation loss: 2.520118312641509

Epoch: 6| Step: 10
Training loss: 1.6395148017775878
Validation loss: 2.5164679932185896

Epoch: 6| Step: 11
Training loss: 2.830177363307091
Validation loss: 2.517088741230119

Epoch: 6| Step: 12
Training loss: 2.288415290029835
Validation loss: 2.525360663798036

Epoch: 6| Step: 13
Training loss: 2.967015613078973
Validation loss: 2.5234778433488976

Epoch: 176| Step: 0
Training loss: 2.1915381080818115
Validation loss: 2.508517173759532

Epoch: 6| Step: 1
Training loss: 1.9196038822006838
Validation loss: 2.531139973495422

Epoch: 6| Step: 2
Training loss: 2.3429309685469746
Validation loss: 2.551155906926466

Epoch: 6| Step: 3
Training loss: 2.480848100144382
Validation loss: 2.514493285793941

Epoch: 6| Step: 4
Training loss: 2.935267797466984
Validation loss: 2.541292078894819

Epoch: 6| Step: 5
Training loss: 2.3149619529019887
Validation loss: 2.5355373561091743

Epoch: 6| Step: 6
Training loss: 2.241135406883597
Validation loss: 2.5226229335199295

Epoch: 6| Step: 7
Training loss: 2.8189188295541157
Validation loss: 2.569499198106988

Epoch: 6| Step: 8
Training loss: 1.9821468068479955
Validation loss: 2.539351954719456

Epoch: 6| Step: 9
Training loss: 2.499807731864405
Validation loss: 2.5438949369921997

Epoch: 6| Step: 10
Training loss: 2.8318632089154288
Validation loss: 2.544727153822602

Epoch: 6| Step: 11
Training loss: 3.03929941386564
Validation loss: 2.553121556914714

Epoch: 6| Step: 12
Training loss: 2.400192165628786
Validation loss: 2.5540851456016536

Epoch: 6| Step: 13
Training loss: 2.4017928817731216
Validation loss: 2.5414219911139266

Epoch: 177| Step: 0
Training loss: 2.264455453958016
Validation loss: 2.55926132329328

Epoch: 6| Step: 1
Training loss: 2.469280137711907
Validation loss: 2.5400296235854087

Epoch: 6| Step: 2
Training loss: 2.2687016085253235
Validation loss: 2.535535184300335

Epoch: 6| Step: 3
Training loss: 2.258012069805043
Validation loss: 2.5462681817269424

Epoch: 6| Step: 4
Training loss: 2.8337435892820935
Validation loss: 2.537110512774641

Epoch: 6| Step: 5
Training loss: 2.176730430023487
Validation loss: 2.541161972388874

Epoch: 6| Step: 6
Training loss: 2.4490108127939414
Validation loss: 2.545636204249454

Epoch: 6| Step: 7
Training loss: 2.6040501886386003
Validation loss: 2.5390459684554747

Epoch: 6| Step: 8
Training loss: 2.3174253026617166
Validation loss: 2.5338396614252328

Epoch: 6| Step: 9
Training loss: 2.2314194558813765
Validation loss: 2.5409694995117498

Epoch: 6| Step: 10
Training loss: 2.851125688932671
Validation loss: 2.526022869751013

Epoch: 6| Step: 11
Training loss: 2.198114419390497
Validation loss: 2.5431045978078677

Epoch: 6| Step: 12
Training loss: 2.2884395650093525
Validation loss: 2.551923970279295

Epoch: 6| Step: 13
Training loss: 3.3986402429197264
Validation loss: 2.5403032056659165

Epoch: 178| Step: 0
Training loss: 2.344153102542144
Validation loss: 2.536747675233049

Epoch: 6| Step: 1
Training loss: 2.8943721094283843
Validation loss: 2.5327995162760333

Epoch: 6| Step: 2
Training loss: 2.416591073092587
Validation loss: 2.5506957034658013

Epoch: 6| Step: 3
Training loss: 2.588277628050071
Validation loss: 2.538869433765546

Epoch: 6| Step: 4
Training loss: 2.3946694463332823
Validation loss: 2.531094376026083

Epoch: 6| Step: 5
Training loss: 1.7774595118121796
Validation loss: 2.540529575368876

Epoch: 6| Step: 6
Training loss: 2.843111071230685
Validation loss: 2.5385176798077604

Epoch: 6| Step: 7
Training loss: 2.8682023001366685
Validation loss: 2.543124918506242

Epoch: 6| Step: 8
Training loss: 2.406869981830351
Validation loss: 2.5142286620559346

Epoch: 6| Step: 9
Training loss: 2.95881613073672
Validation loss: 2.5320436779652153

Epoch: 6| Step: 10
Training loss: 2.273054477372791
Validation loss: 2.5378875825993688

Epoch: 6| Step: 11
Training loss: 1.4748808958167072
Validation loss: 2.536286378663043

Epoch: 6| Step: 12
Training loss: 2.5138627033965717
Validation loss: 2.537566800109363

Epoch: 6| Step: 13
Training loss: 2.1308814169130943
Validation loss: 2.555358445378917

Epoch: 179| Step: 0
Training loss: 2.274980473696573
Validation loss: 2.5262415456816347

Epoch: 6| Step: 1
Training loss: 2.0247752359242157
Validation loss: 2.532087628277566

Epoch: 6| Step: 2
Training loss: 2.5385528522464686
Validation loss: 2.539564263402779

Epoch: 6| Step: 3
Training loss: 2.7818016619540287
Validation loss: 2.5252554922316404

Epoch: 6| Step: 4
Training loss: 2.7202175169811627
Validation loss: 2.5570855287026615

Epoch: 6| Step: 5
Training loss: 2.7056007293578372
Validation loss: 2.5360641720703785

Epoch: 6| Step: 6
Training loss: 2.4558446107969396
Validation loss: 2.5181954556324215

Epoch: 6| Step: 7
Training loss: 2.749765646225397
Validation loss: 2.5046428760042168

Epoch: 6| Step: 8
Training loss: 2.4791326333496184
Validation loss: 2.527841325554812

Epoch: 6| Step: 9
Training loss: 1.8971457148376945
Validation loss: 2.549908248325224

Epoch: 6| Step: 10
Training loss: 1.9006549459279094
Validation loss: 2.5355634662016735

Epoch: 6| Step: 11
Training loss: 2.9650925442693254
Validation loss: 2.523776629819302

Epoch: 6| Step: 12
Training loss: 2.13236765711351
Validation loss: 2.5323720612688088

Epoch: 6| Step: 13
Training loss: 2.2082770958223503
Validation loss: 2.528051476541586

Epoch: 180| Step: 0
Training loss: 2.246453138707046
Validation loss: 2.534916848856936

Epoch: 6| Step: 1
Training loss: 2.317262127961323
Validation loss: 2.5412793831884675

Epoch: 6| Step: 2
Training loss: 2.0439791396358724
Validation loss: 2.5474014155932174

Epoch: 6| Step: 3
Training loss: 2.798612087134945
Validation loss: 2.5247479171110645

Epoch: 6| Step: 4
Training loss: 2.6579226444661748
Validation loss: 2.541328614130676

Epoch: 6| Step: 5
Training loss: 2.301265231718745
Validation loss: 2.5407658565402955

Epoch: 6| Step: 6
Training loss: 2.565559979264205
Validation loss: 2.5182322343378614

Epoch: 6| Step: 7
Training loss: 2.457684501326959
Validation loss: 2.538026553868586

Epoch: 6| Step: 8
Training loss: 2.4125118275090576
Validation loss: 2.527137027823321

Epoch: 6| Step: 9
Training loss: 2.0068828642247643
Validation loss: 2.514006644239375

Epoch: 6| Step: 10
Training loss: 1.7800783017970205
Validation loss: 2.530903780265339

Epoch: 6| Step: 11
Training loss: 2.7496420887473585
Validation loss: 2.518818746829767

Epoch: 6| Step: 12
Training loss: 2.9844155833096315
Validation loss: 2.5305724853306755

Epoch: 6| Step: 13
Training loss: 2.6506103784346315
Validation loss: 2.5251277290624237

Epoch: 181| Step: 0
Training loss: 2.1229167150834978
Validation loss: 2.5315706310017108

Epoch: 6| Step: 1
Training loss: 2.267079695301564
Validation loss: 2.528521512113897

Epoch: 6| Step: 2
Training loss: 2.077971718089936
Validation loss: 2.5346939133281507

Epoch: 6| Step: 3
Training loss: 1.7477750257801965
Validation loss: 2.51388086191423

Epoch: 6| Step: 4
Training loss: 2.7971204085279324
Validation loss: 2.52498284034255

Epoch: 6| Step: 5
Training loss: 2.4196295388457973
Validation loss: 2.532064721237898

Epoch: 6| Step: 6
Training loss: 1.8251604349346202
Validation loss: 2.531210581661062

Epoch: 6| Step: 7
Training loss: 2.819753998381625
Validation loss: 2.533729510613579

Epoch: 6| Step: 8
Training loss: 2.906306932773583
Validation loss: 2.5251946281978555

Epoch: 6| Step: 9
Training loss: 1.519530151680596
Validation loss: 2.5401833316213933

Epoch: 6| Step: 10
Training loss: 3.627376960965507
Validation loss: 2.55276405107644

Epoch: 6| Step: 11
Training loss: 2.3574072103352397
Validation loss: 2.549111770187731

Epoch: 6| Step: 12
Training loss: 2.8584925222600974
Validation loss: 2.5334488344767276

Epoch: 6| Step: 13
Training loss: 2.1981233135061813
Validation loss: 2.5193089515482163

Epoch: 182| Step: 0
Training loss: 1.783017803811419
Validation loss: 2.529142565147056

Epoch: 6| Step: 1
Training loss: 2.6570966381090635
Validation loss: 2.512761686644764

Epoch: 6| Step: 2
Training loss: 1.954240160158587
Validation loss: 2.519355330129012

Epoch: 6| Step: 3
Training loss: 2.457202802288054
Validation loss: 2.5280416288138277

Epoch: 6| Step: 4
Training loss: 2.121170520271323
Validation loss: 2.5420398091950984

Epoch: 6| Step: 5
Training loss: 2.2339106790893988
Validation loss: 2.527176516801651

Epoch: 6| Step: 6
Training loss: 2.706615069215431
Validation loss: 2.528929020655091

Epoch: 6| Step: 7
Training loss: 2.802591714983175
Validation loss: 2.508180173420255

Epoch: 6| Step: 8
Training loss: 2.1499689366070487
Validation loss: 2.520002150960311

Epoch: 6| Step: 9
Training loss: 2.5513413472996267
Validation loss: 2.5249391308634777

Epoch: 6| Step: 10
Training loss: 2.778906188226999
Validation loss: 2.518843485228816

Epoch: 6| Step: 11
Training loss: 2.07111777712923
Validation loss: 2.5313979677466554

Epoch: 6| Step: 12
Training loss: 2.9958201535871876
Validation loss: 2.5338214334700386

Epoch: 6| Step: 13
Training loss: 2.3000272541919227
Validation loss: 2.549662128144567

Epoch: 183| Step: 0
Training loss: 2.434538582825725
Validation loss: 2.521291272366236

Epoch: 6| Step: 1
Training loss: 1.8898722513611452
Validation loss: 2.5512409868472186

Epoch: 6| Step: 2
Training loss: 2.347469785778211
Validation loss: 2.5347409419085243

Epoch: 6| Step: 3
Training loss: 2.501489576984035
Validation loss: 2.510941697447378

Epoch: 6| Step: 4
Training loss: 2.412477732343143
Validation loss: 2.523667712872857

Epoch: 6| Step: 5
Training loss: 2.471070949028343
Validation loss: 2.52388728407879

Epoch: 6| Step: 6
Training loss: 2.074708812458785
Validation loss: 2.5163607985259704

Epoch: 6| Step: 7
Training loss: 3.1150929385996307
Validation loss: 2.534917265019713

Epoch: 6| Step: 8
Training loss: 2.6996743111741415
Validation loss: 2.5293279004440037

Epoch: 6| Step: 9
Training loss: 3.2085489638225986
Validation loss: 2.525140763847471

Epoch: 6| Step: 10
Training loss: 1.9598358829063331
Validation loss: 2.525841855738308

Epoch: 6| Step: 11
Training loss: 1.9833159136073948
Validation loss: 2.5130822016670833

Epoch: 6| Step: 12
Training loss: 2.5965436115741714
Validation loss: 2.530099042724016

Epoch: 6| Step: 13
Training loss: 1.7436208260111778
Validation loss: 2.4982617139040157

Epoch: 184| Step: 0
Training loss: 2.2562079090197216
Validation loss: 2.5511141773671633

Epoch: 6| Step: 1
Training loss: 2.0460907110575466
Validation loss: 2.526366923664005

Epoch: 6| Step: 2
Training loss: 2.505084018173912
Validation loss: 2.5280135051308923

Epoch: 6| Step: 3
Training loss: 2.328325710989568
Validation loss: 2.52820065513923

Epoch: 6| Step: 4
Training loss: 2.472986377053814
Validation loss: 2.5216600599262646

Epoch: 6| Step: 5
Training loss: 2.4961829609815913
Validation loss: 2.5106581541695885

Epoch: 6| Step: 6
Training loss: 3.138595000905965
Validation loss: 2.5260424575998948

Epoch: 6| Step: 7
Training loss: 1.8937760253729436
Validation loss: 2.515743532307305

Epoch: 6| Step: 8
Training loss: 2.2271036126331905
Validation loss: 2.5165968586875755

Epoch: 6| Step: 9
Training loss: 2.150256908947184
Validation loss: 2.5084808351483088

Epoch: 6| Step: 10
Training loss: 2.781568016129919
Validation loss: 2.504875077197676

Epoch: 6| Step: 11
Training loss: 2.2444188515722114
Validation loss: 2.526287282494772

Epoch: 6| Step: 12
Training loss: 2.3908973488847347
Validation loss: 2.493071012799132

Epoch: 6| Step: 13
Training loss: 3.0346881991607453
Validation loss: 2.5396292933048277

Epoch: 185| Step: 0
Training loss: 2.361096493046207
Validation loss: 2.5208957603031426

Epoch: 6| Step: 1
Training loss: 2.270691146832118
Validation loss: 2.5354296117237376

Epoch: 6| Step: 2
Training loss: 2.745822941977983
Validation loss: 2.511391174116934

Epoch: 6| Step: 3
Training loss: 2.718246501032376
Validation loss: 2.5200254270622104

Epoch: 6| Step: 4
Training loss: 2.7826169544465404
Validation loss: 2.510987954911864

Epoch: 6| Step: 5
Training loss: 2.024824219597784
Validation loss: 2.5152933560321196

Epoch: 6| Step: 6
Training loss: 2.470516876317471
Validation loss: 2.520712377103515

Epoch: 6| Step: 7
Training loss: 2.926768565420687
Validation loss: 2.5015849759939637

Epoch: 6| Step: 8
Training loss: 2.5360677576369453
Validation loss: 2.535859203074499

Epoch: 6| Step: 9
Training loss: 2.6969790406563687
Validation loss: 2.5191302267242777

Epoch: 6| Step: 10
Training loss: 2.023719443926413
Validation loss: 2.515533695794538

Epoch: 6| Step: 11
Training loss: 2.1056270504469046
Validation loss: 2.509187036651886

Epoch: 6| Step: 12
Training loss: 1.882937098768815
Validation loss: 2.5263254787461293

Epoch: 6| Step: 13
Training loss: 1.9718890520613797
Validation loss: 2.5220085712405713

Epoch: 186| Step: 0
Training loss: 2.1112581112639757
Validation loss: 2.5184342200460437

Epoch: 6| Step: 1
Training loss: 2.7034106682449153
Validation loss: 2.524073883815359

Epoch: 6| Step: 2
Training loss: 2.0944931078023608
Validation loss: 2.528010537893223

Epoch: 6| Step: 3
Training loss: 2.780168130030591
Validation loss: 2.542923886854013

Epoch: 6| Step: 4
Training loss: 2.1670304751011438
Validation loss: 2.560112171551612

Epoch: 6| Step: 5
Training loss: 1.8254541302374465
Validation loss: 2.524016543189564

Epoch: 6| Step: 6
Training loss: 2.5530203416120796
Validation loss: 2.5294718450113534

Epoch: 6| Step: 7
Training loss: 2.1059080667019607
Validation loss: 2.539652296653536

Epoch: 6| Step: 8
Training loss: 2.3971626795444916
Validation loss: 2.5456280635645525

Epoch: 6| Step: 9
Training loss: 2.765850596736566
Validation loss: 2.5157754922227338

Epoch: 6| Step: 10
Training loss: 2.6270965196690486
Validation loss: 2.524138071675263

Epoch: 6| Step: 11
Training loss: 2.3925112594291718
Validation loss: 2.5210868899800425

Epoch: 6| Step: 12
Training loss: 2.693449930352007
Validation loss: 2.5335156555526197

Epoch: 6| Step: 13
Training loss: 2.368314065803399
Validation loss: 2.5381603350245294

Epoch: 187| Step: 0
Training loss: 2.449429200301082
Validation loss: 2.53315999658354

Epoch: 6| Step: 1
Training loss: 2.3366818470083137
Validation loss: 2.5059814024420444

Epoch: 6| Step: 2
Training loss: 2.528853235404985
Validation loss: 2.51063410452541

Epoch: 6| Step: 3
Training loss: 2.627051868497345
Validation loss: 2.5372830757542424

Epoch: 6| Step: 4
Training loss: 3.1195700199995793
Validation loss: 2.4927651263807014

Epoch: 6| Step: 5
Training loss: 2.4559925594776284
Validation loss: 2.554383347750859

Epoch: 6| Step: 6
Training loss: 2.4823961354143536
Validation loss: 2.5364606340602602

Epoch: 6| Step: 7
Training loss: 1.8078798405165017
Validation loss: 2.530806522470145

Epoch: 6| Step: 8
Training loss: 2.0081240638614375
Validation loss: 2.527077589797895

Epoch: 6| Step: 9
Training loss: 2.778571907544944
Validation loss: 2.529977731671158

Epoch: 6| Step: 10
Training loss: 2.2481187797335194
Validation loss: 2.5340684548187107

Epoch: 6| Step: 11
Training loss: 2.3598280717972617
Validation loss: 2.531011063492383

Epoch: 6| Step: 12
Training loss: 1.8287101526410456
Validation loss: 2.5257222839619815

Epoch: 6| Step: 13
Training loss: 2.8030564179637194
Validation loss: 2.5048101766812803

Epoch: 188| Step: 0
Training loss: 2.723008076992377
Validation loss: 2.5399197260789173

Epoch: 6| Step: 1
Training loss: 2.0195774095229475
Validation loss: 2.5224768083845106

Epoch: 6| Step: 2
Training loss: 2.098000610046007
Validation loss: 2.533706975588468

Epoch: 6| Step: 3
Training loss: 2.320944959968277
Validation loss: 2.5212582882824606

Epoch: 6| Step: 4
Training loss: 2.7856882237343603
Validation loss: 2.5120855404350753

Epoch: 6| Step: 5
Training loss: 2.311153741691975
Validation loss: 2.508407968295089

Epoch: 6| Step: 6
Training loss: 2.594850789155507
Validation loss: 2.534969654968348

Epoch: 6| Step: 7
Training loss: 3.1424388297476935
Validation loss: 2.5086306236515266

Epoch: 6| Step: 8
Training loss: 1.6395445399398747
Validation loss: 2.5244255918866028

Epoch: 6| Step: 9
Training loss: 2.411383664078473
Validation loss: 2.5152917120275795

Epoch: 6| Step: 10
Training loss: 2.03779919539696
Validation loss: 2.5299995156214363

Epoch: 6| Step: 11
Training loss: 2.2317562095373664
Validation loss: 2.5054701528723657

Epoch: 6| Step: 12
Training loss: 2.3242566017466615
Validation loss: 2.5362391331137935

Epoch: 6| Step: 13
Training loss: 2.670649286396736
Validation loss: 2.505772427845213

Epoch: 189| Step: 0
Training loss: 2.2625615949307796
Validation loss: 2.5292213318750174

Epoch: 6| Step: 1
Training loss: 2.844346204028114
Validation loss: 2.525739294505462

Epoch: 6| Step: 2
Training loss: 2.287895868786141
Validation loss: 2.529878162302337

Epoch: 6| Step: 3
Training loss: 2.129515170585871
Validation loss: 2.547053461889175

Epoch: 6| Step: 4
Training loss: 2.37319054188312
Validation loss: 2.527481125325315

Epoch: 6| Step: 5
Training loss: 2.606724746606656
Validation loss: 2.5306158969250343

Epoch: 6| Step: 6
Training loss: 2.172445208667382
Validation loss: 2.5258811152875706

Epoch: 6| Step: 7
Training loss: 2.475860785100258
Validation loss: 2.5441877939104582

Epoch: 6| Step: 8
Training loss: 1.6871359397102208
Validation loss: 2.5455838913223707

Epoch: 6| Step: 9
Training loss: 2.7961227001941484
Validation loss: 2.5096972726616635

Epoch: 6| Step: 10
Training loss: 2.2998447034071754
Validation loss: 2.5189168165746376

Epoch: 6| Step: 11
Training loss: 2.430915252469975
Validation loss: 2.514037398479898

Epoch: 6| Step: 12
Training loss: 2.440129548995575
Validation loss: 2.52500819250902

Epoch: 6| Step: 13
Training loss: 2.9107519576955565
Validation loss: 2.5085330444626415

Epoch: 190| Step: 0
Training loss: 2.38883266703172
Validation loss: 2.540561956074417

Epoch: 6| Step: 1
Training loss: 2.1464283929801633
Validation loss: 2.5345751071037763

Epoch: 6| Step: 2
Training loss: 2.8403511276245834
Validation loss: 2.518153413005874

Epoch: 6| Step: 3
Training loss: 2.8673365083895805
Validation loss: 2.533222147782507

Epoch: 6| Step: 4
Training loss: 2.5685728731368043
Validation loss: 2.524948656649972

Epoch: 6| Step: 5
Training loss: 1.9170605282448616
Validation loss: 2.5237862072278503

Epoch: 6| Step: 6
Training loss: 2.937740397254767
Validation loss: 2.500137887249011

Epoch: 6| Step: 7
Training loss: 2.330276416869062
Validation loss: 2.5212075133639305

Epoch: 6| Step: 8
Training loss: 2.4262777364050483
Validation loss: 2.5174011755331613

Epoch: 6| Step: 9
Training loss: 2.112114377912745
Validation loss: 2.5205945178364817

Epoch: 6| Step: 10
Training loss: 2.068851516860482
Validation loss: 2.500493529017375

Epoch: 6| Step: 11
Training loss: 2.524992283724335
Validation loss: 2.536677430392161

Epoch: 6| Step: 12
Training loss: 1.9608475257931657
Validation loss: 2.5294671271259537

Epoch: 6| Step: 13
Training loss: 2.190736175197472
Validation loss: 2.5195308165419887

Epoch: 191| Step: 0
Training loss: 2.051217169071774
Validation loss: 2.5167392725808178

Epoch: 6| Step: 1
Training loss: 3.209182890999025
Validation loss: 2.523733049789733

Epoch: 6| Step: 2
Training loss: 2.0871081549819217
Validation loss: 2.5113968686710995

Epoch: 6| Step: 3
Training loss: 2.6475784573983514
Validation loss: 2.5521415564847927

Epoch: 6| Step: 4
Training loss: 2.4612961280727514
Validation loss: 2.518517073722292

Epoch: 6| Step: 5
Training loss: 2.293468102535418
Validation loss: 2.5222377649711087

Epoch: 6| Step: 6
Training loss: 2.0054368982880355
Validation loss: 2.5158951841693704

Epoch: 6| Step: 7
Training loss: 2.789521593621917
Validation loss: 2.512287521336503

Epoch: 6| Step: 8
Training loss: 1.848942250642991
Validation loss: 2.5252412905519273

Epoch: 6| Step: 9
Training loss: 2.4083109365123616
Validation loss: 2.5219192044165983

Epoch: 6| Step: 10
Training loss: 2.1718473364076796
Validation loss: 2.5337886145236292

Epoch: 6| Step: 11
Training loss: 2.097168707708688
Validation loss: 2.5192056206185622

Epoch: 6| Step: 12
Training loss: 2.40064627370071
Validation loss: 2.5226741840044413

Epoch: 6| Step: 13
Training loss: 2.8088068131870787
Validation loss: 2.5262793093096163

Epoch: 192| Step: 0
Training loss: 2.212463283772966
Validation loss: 2.5196061374008654

Epoch: 6| Step: 1
Training loss: 2.4359697282285144
Validation loss: 2.5274141913647488

Epoch: 6| Step: 2
Training loss: 2.624698621615267
Validation loss: 2.5167059385232737

Epoch: 6| Step: 3
Training loss: 3.186269036255245
Validation loss: 2.5233817044036058

Epoch: 6| Step: 4
Training loss: 2.1841720333952783
Validation loss: 2.515814153772087

Epoch: 6| Step: 5
Training loss: 1.8651148573046972
Validation loss: 2.523503784621703

Epoch: 6| Step: 6
Training loss: 2.306000002825457
Validation loss: 2.5102479834023677

Epoch: 6| Step: 7
Training loss: 2.541365579583984
Validation loss: 2.507788732303162

Epoch: 6| Step: 8
Training loss: 2.364084558075174
Validation loss: 2.5037695194487957

Epoch: 6| Step: 9
Training loss: 1.398383027619473
Validation loss: 2.5142732408870647

Epoch: 6| Step: 10
Training loss: 2.694179130766859
Validation loss: 2.518975226902641

Epoch: 6| Step: 11
Training loss: 3.0496894553258667
Validation loss: 2.509407044335353

Epoch: 6| Step: 12
Training loss: 2.2675008440278996
Validation loss: 2.516991177766516

Epoch: 6| Step: 13
Training loss: 1.5005928298571458
Validation loss: 2.5420346608104625

Epoch: 193| Step: 0
Training loss: 2.1126997001202477
Validation loss: 2.510229777158345

Epoch: 6| Step: 1
Training loss: 2.092228350764018
Validation loss: 2.5308280105915992

Epoch: 6| Step: 2
Training loss: 2.726245763356495
Validation loss: 2.5140349796779677

Epoch: 6| Step: 3
Training loss: 2.183230347667548
Validation loss: 2.5177538462700144

Epoch: 6| Step: 4
Training loss: 2.3096111914986897
Validation loss: 2.515556012981353

Epoch: 6| Step: 5
Training loss: 2.172623210437666
Validation loss: 2.507738761135938

Epoch: 6| Step: 6
Training loss: 3.509252036191705
Validation loss: 2.502145985443108

Epoch: 6| Step: 7
Training loss: 2.518457370163249
Validation loss: 2.5151174251436013

Epoch: 6| Step: 8
Training loss: 1.9557417163539352
Validation loss: 2.5165803624217746

Epoch: 6| Step: 9
Training loss: 2.239161772567044
Validation loss: 2.5129650873403317

Epoch: 6| Step: 10
Training loss: 2.227173624328663
Validation loss: 2.530284197525085

Epoch: 6| Step: 11
Training loss: 2.139259738341368
Validation loss: 2.5143705713073223

Epoch: 6| Step: 12
Training loss: 2.553377521404774
Validation loss: 2.503675369958187

Epoch: 6| Step: 13
Training loss: 1.9261980514898338
Validation loss: 2.507245295295199

Epoch: 194| Step: 0
Training loss: 1.8586243468592671
Validation loss: 2.5020646798576336

Epoch: 6| Step: 1
Training loss: 2.170925673890098
Validation loss: 2.49836889195842

Epoch: 6| Step: 2
Training loss: 2.2837168276360633
Validation loss: 2.535999879181097

Epoch: 6| Step: 3
Training loss: 2.290655421618363
Validation loss: 2.546026222678658

Epoch: 6| Step: 4
Training loss: 3.035584487063502
Validation loss: 2.5303373981857487

Epoch: 6| Step: 5
Training loss: 2.6614867704680067
Validation loss: 2.536377395201334

Epoch: 6| Step: 6
Training loss: 2.450785304738935
Validation loss: 2.5589237824716187

Epoch: 6| Step: 7
Training loss: 2.3325810127867754
Validation loss: 2.5278375123027845

Epoch: 6| Step: 8
Training loss: 2.0206486987946297
Validation loss: 2.5408281960232943

Epoch: 6| Step: 9
Training loss: 2.253043341777241
Validation loss: 2.5180512568928135

Epoch: 6| Step: 10
Training loss: 3.0729261150322613
Validation loss: 2.535518176788854

Epoch: 6| Step: 11
Training loss: 2.0173618610648423
Validation loss: 2.540809021326419

Epoch: 6| Step: 12
Training loss: 2.496341698977077
Validation loss: 2.521766667447751

Epoch: 6| Step: 13
Training loss: 2.0564028465718764
Validation loss: 2.5147547693388157

Epoch: 195| Step: 0
Training loss: 2.324715902547529
Validation loss: 2.5477013650569273

Epoch: 6| Step: 1
Training loss: 2.8313549839117447
Validation loss: 2.5278103954526547

Epoch: 6| Step: 2
Training loss: 1.675123534700157
Validation loss: 2.5403040039326035

Epoch: 6| Step: 3
Training loss: 2.2753520651239167
Validation loss: 2.530284500466749

Epoch: 6| Step: 4
Training loss: 2.113347360983582
Validation loss: 2.5304239055084716

Epoch: 6| Step: 5
Training loss: 3.2617058850794196
Validation loss: 2.51314625814655

Epoch: 6| Step: 6
Training loss: 2.479979843857595
Validation loss: 2.5257212933092217

Epoch: 6| Step: 7
Training loss: 1.7430450655286762
Validation loss: 2.5207001737284984

Epoch: 6| Step: 8
Training loss: 2.2125514310042305
Validation loss: 2.5319130435634536

Epoch: 6| Step: 9
Training loss: 2.0672327707052216
Validation loss: 2.54378711425138

Epoch: 6| Step: 10
Training loss: 2.9384178188711143
Validation loss: 2.510979488002418

Epoch: 6| Step: 11
Training loss: 2.502423828063262
Validation loss: 2.515546476085963

Epoch: 6| Step: 12
Training loss: 2.104551324212626
Validation loss: 2.502833837841032

Epoch: 6| Step: 13
Training loss: 1.7645410907227406
Validation loss: 2.521709403470412

Epoch: 196| Step: 0
Training loss: 2.644503391857284
Validation loss: 2.5115485040751233

Epoch: 6| Step: 1
Training loss: 2.431174458014129
Validation loss: 2.526931833860322

Epoch: 6| Step: 2
Training loss: 2.8845467661985857
Validation loss: 2.5257539694201343

Epoch: 6| Step: 3
Training loss: 2.2238453129824967
Validation loss: 2.510141242091037

Epoch: 6| Step: 4
Training loss: 1.9093322849022174
Validation loss: 2.499322155354151

Epoch: 6| Step: 5
Training loss: 2.839786995972606
Validation loss: 2.535534337011279

Epoch: 6| Step: 6
Training loss: 2.620887077358661
Validation loss: 2.5267061630445324

Epoch: 6| Step: 7
Training loss: 1.991468232403572
Validation loss: 2.5092736897627548

Epoch: 6| Step: 8
Training loss: 2.0165545072445914
Validation loss: 2.5036610284608782

Epoch: 6| Step: 9
Training loss: 2.5961443409107234
Validation loss: 2.5067899674925083

Epoch: 6| Step: 10
Training loss: 1.988290663061737
Validation loss: 2.5335617679987634

Epoch: 6| Step: 11
Training loss: 2.4420040283794746
Validation loss: 2.5023772022685913

Epoch: 6| Step: 12
Training loss: 2.4354147183095307
Validation loss: 2.5051528985589164

Epoch: 6| Step: 13
Training loss: 1.8688803943063494
Validation loss: 2.521937609886482

Epoch: 197| Step: 0
Training loss: 2.5672329249109964
Validation loss: 2.510828534744563

Epoch: 6| Step: 1
Training loss: 2.759317219907955
Validation loss: 2.5177143041986665

Epoch: 6| Step: 2
Training loss: 2.736479379964822
Validation loss: 2.5179319041575132

Epoch: 6| Step: 3
Training loss: 1.855977520707901
Validation loss: 2.500697819932427

Epoch: 6| Step: 4
Training loss: 1.8484861675443458
Validation loss: 2.497835303976331

Epoch: 6| Step: 5
Training loss: 2.7549801727799945
Validation loss: 2.5206136856111367

Epoch: 6| Step: 6
Training loss: 1.93965803986553
Validation loss: 2.5149141801756083

Epoch: 6| Step: 7
Training loss: 2.169395843115589
Validation loss: 2.514968134096086

Epoch: 6| Step: 8
Training loss: 2.3356178090446984
Validation loss: 2.5103445201445234

Epoch: 6| Step: 9
Training loss: 2.5024196359571325
Validation loss: 2.50437913489171

Epoch: 6| Step: 10
Training loss: 2.686880084554507
Validation loss: 2.5102839298019317

Epoch: 6| Step: 11
Training loss: 2.223127318545407
Validation loss: 2.5136493712737207

Epoch: 6| Step: 12
Training loss: 2.3147532851907284
Validation loss: 2.5237195678846644

Epoch: 6| Step: 13
Training loss: 1.633546946952909
Validation loss: 2.509267519911736

Epoch: 198| Step: 0
Training loss: 2.1284860178707974
Validation loss: 2.516144610369365

Epoch: 6| Step: 1
Training loss: 2.5351030200136875
Validation loss: 2.5055435308099008

Epoch: 6| Step: 2
Training loss: 2.0569376065402927
Validation loss: 2.5200145703337413

Epoch: 6| Step: 3
Training loss: 2.8995596058009867
Validation loss: 2.5122144618166087

Epoch: 6| Step: 4
Training loss: 2.2882855760110825
Validation loss: 2.5367244060301495

Epoch: 6| Step: 5
Training loss: 3.1454668821071867
Validation loss: 2.5103519597984056

Epoch: 6| Step: 6
Training loss: 1.9832475718487332
Validation loss: 2.4916829331894865

Epoch: 6| Step: 7
Training loss: 2.3695189825659204
Validation loss: 2.515885454953197

Epoch: 6| Step: 8
Training loss: 3.1375393868819943
Validation loss: 2.511979494649356

Epoch: 6| Step: 9
Training loss: 2.3826844227874053
Validation loss: 2.508239501199962

Epoch: 6| Step: 10
Training loss: 1.4118525903416947
Validation loss: 2.520695363147731

Epoch: 6| Step: 11
Training loss: 2.301238398318078
Validation loss: 2.5245280379179635

Epoch: 6| Step: 12
Training loss: 1.8071935518952698
Validation loss: 2.507531442023143

Epoch: 6| Step: 13
Training loss: 1.66871787051013
Validation loss: 2.5296175427642535

Epoch: 199| Step: 0
Training loss: 2.341012602265798
Validation loss: 2.5371578805275448

Epoch: 6| Step: 1
Training loss: 2.2460020361710216
Validation loss: 2.525394105933838

Epoch: 6| Step: 2
Training loss: 1.9025931380904555
Validation loss: 2.5166281145540297

Epoch: 6| Step: 3
Training loss: 1.8570977378436637
Validation loss: 2.5242949816641955

Epoch: 6| Step: 4
Training loss: 1.7142428863943018
Validation loss: 2.5219727777243737

Epoch: 6| Step: 5
Training loss: 2.996147065763805
Validation loss: 2.521454240798986

Epoch: 6| Step: 6
Training loss: 2.4011520283147076
Validation loss: 2.5456914949595104

Epoch: 6| Step: 7
Training loss: 2.5533576327064895
Validation loss: 2.5293186871127404

Epoch: 6| Step: 8
Training loss: 2.770005114306194
Validation loss: 2.50110430630933

Epoch: 6| Step: 9
Training loss: 2.2909823233939446
Validation loss: 2.558433431377542

Epoch: 6| Step: 10
Training loss: 1.8460594842404856
Validation loss: 2.5125158784613864

Epoch: 6| Step: 11
Training loss: 2.5389239933676433
Validation loss: 2.5072493770837285

Epoch: 6| Step: 12
Training loss: 2.40390613891879
Validation loss: 2.490380896243573

Epoch: 6| Step: 13
Training loss: 2.872521700598649
Validation loss: 2.509730909211257

Epoch: 200| Step: 0
Training loss: 2.548685658883628
Validation loss: 2.495737534679453

Epoch: 6| Step: 1
Training loss: 2.0502096487632273
Validation loss: 2.502306979182639

Epoch: 6| Step: 2
Training loss: 2.1230587787873505
Validation loss: 2.5173868755700095

Epoch: 6| Step: 3
Training loss: 1.7402573914723702
Validation loss: 2.5031709537013587

Epoch: 6| Step: 4
Training loss: 2.2557684809880945
Validation loss: 2.50726667041918

Epoch: 6| Step: 5
Training loss: 2.641382052455436
Validation loss: 2.4891637042667294

Epoch: 6| Step: 6
Training loss: 3.2457347170956172
Validation loss: 2.5066233573732677

Epoch: 6| Step: 7
Training loss: 2.4697113096973644
Validation loss: 2.5095350551978424

Epoch: 6| Step: 8
Training loss: 1.579461164701678
Validation loss: 2.5197924233828983

Epoch: 6| Step: 9
Training loss: 2.179383396824993
Validation loss: 2.505489539697286

Epoch: 6| Step: 10
Training loss: 2.5633149130580617
Validation loss: 2.4876150893532767

Epoch: 6| Step: 11
Training loss: 2.4636916477177455
Validation loss: 2.5253562894774793

Epoch: 6| Step: 12
Training loss: 2.5464177569566893
Validation loss: 2.507851376310603

Epoch: 6| Step: 13
Training loss: 1.9609137301885111
Validation loss: 2.5038328261276863

Epoch: 201| Step: 0
Training loss: 2.618903938084416
Validation loss: 2.489987026592138

Epoch: 6| Step: 1
Training loss: 2.64887569257079
Validation loss: 2.514158475305773

Epoch: 6| Step: 2
Training loss: 2.011015478369558
Validation loss: 2.5231510356473317

Epoch: 6| Step: 3
Training loss: 2.7309665908250573
Validation loss: 2.4940880979597013

Epoch: 6| Step: 4
Training loss: 2.2163868529123465
Validation loss: 2.502581420342969

Epoch: 6| Step: 5
Training loss: 2.33224716337156
Validation loss: 2.5063582320798776

Epoch: 6| Step: 6
Training loss: 2.5640339795745857
Validation loss: 2.5182529186241642

Epoch: 6| Step: 7
Training loss: 2.24200204753527
Validation loss: 2.510295801866108

Epoch: 6| Step: 8
Training loss: 1.9785275548366272
Validation loss: 2.4629510124920935

Epoch: 6| Step: 9
Training loss: 2.2976268134749436
Validation loss: 2.5100070195511925

Epoch: 6| Step: 10
Training loss: 2.3208871251920202
Validation loss: 2.4955927383733423

Epoch: 6| Step: 11
Training loss: 2.714349451965921
Validation loss: 2.4725692379388686

Epoch: 6| Step: 12
Training loss: 1.9224583430545457
Validation loss: 2.5053369673566954

Epoch: 6| Step: 13
Training loss: 2.032054448389482
Validation loss: 2.50166002042622

Epoch: 202| Step: 0
Training loss: 2.49811740563913
Validation loss: 2.4915054884295014

Epoch: 6| Step: 1
Training loss: 2.1362011716741045
Validation loss: 2.4975071332548535

Epoch: 6| Step: 2
Training loss: 2.1087910161667804
Validation loss: 2.5134677848889497

Epoch: 6| Step: 3
Training loss: 2.3245997012511914
Validation loss: 2.504826357958372

Epoch: 6| Step: 4
Training loss: 2.4930192761156067
Validation loss: 2.490789526888531

Epoch: 6| Step: 5
Training loss: 2.0252919775428224
Validation loss: 2.4956580521963034

Epoch: 6| Step: 6
Training loss: 3.0027551715041834
Validation loss: 2.512276642393803

Epoch: 6| Step: 7
Training loss: 2.337760494629213
Validation loss: 2.5170726713751295

Epoch: 6| Step: 8
Training loss: 2.1339912929768428
Validation loss: 2.506779320362241

Epoch: 6| Step: 9
Training loss: 2.509787094083758
Validation loss: 2.485879970699639

Epoch: 6| Step: 10
Training loss: 2.5191524250394766
Validation loss: 2.5022310289921195

Epoch: 6| Step: 11
Training loss: 2.31658399649382
Validation loss: 2.4857267196905073

Epoch: 6| Step: 12
Training loss: 1.8927849025770747
Validation loss: 2.4907352128688673

Epoch: 6| Step: 13
Training loss: 2.220069278117215
Validation loss: 2.5155577413996437

Epoch: 203| Step: 0
Training loss: 2.0516793745790296
Validation loss: 2.5010004005725217

Epoch: 6| Step: 1
Training loss: 2.372483275247036
Validation loss: 2.543020267896297

Epoch: 6| Step: 2
Training loss: 2.025857192976101
Validation loss: 2.530373765359309

Epoch: 6| Step: 3
Training loss: 2.11901236290991
Validation loss: 2.47579545535719

Epoch: 6| Step: 4
Training loss: 2.0334355260881334
Validation loss: 2.508232178953298

Epoch: 6| Step: 5
Training loss: 2.6329930636919094
Validation loss: 2.4787652785234044

Epoch: 6| Step: 6
Training loss: 2.7435412420917067
Validation loss: 2.519102358723358

Epoch: 6| Step: 7
Training loss: 2.4594379034080562
Validation loss: 2.524726532599737

Epoch: 6| Step: 8
Training loss: 2.588755935816865
Validation loss: 2.4878349448066026

Epoch: 6| Step: 9
Training loss: 2.3676723071903005
Validation loss: 2.5106840124494263

Epoch: 6| Step: 10
Training loss: 2.3543528480388933
Validation loss: 2.501075133514949

Epoch: 6| Step: 11
Training loss: 2.6599101262218685
Validation loss: 2.4977812365658556

Epoch: 6| Step: 12
Training loss: 2.236624485685029
Validation loss: 2.4949220204590468

Epoch: 6| Step: 13
Training loss: 1.5057688090875367
Validation loss: 2.523384341819737

Epoch: 204| Step: 0
Training loss: 2.129183745891155
Validation loss: 2.494363531273354

Epoch: 6| Step: 1
Training loss: 1.5579089809220321
Validation loss: 2.487707823742684

Epoch: 6| Step: 2
Training loss: 2.59811200037483
Validation loss: 2.4883516607903684

Epoch: 6| Step: 3
Training loss: 2.3366223610320414
Validation loss: 2.5008397824835726

Epoch: 6| Step: 4
Training loss: 2.417307034417643
Validation loss: 2.516768542909329

Epoch: 6| Step: 5
Training loss: 3.2804046995265357
Validation loss: 2.499405724639038

Epoch: 6| Step: 6
Training loss: 1.5962713156810127
Validation loss: 2.511071140038821

Epoch: 6| Step: 7
Training loss: 2.217208971883345
Validation loss: 2.5104730775302655

Epoch: 6| Step: 8
Training loss: 2.368520531321969
Validation loss: 2.549711023283935

Epoch: 6| Step: 9
Training loss: 2.7019927900600735
Validation loss: 2.5201351809554033

Epoch: 6| Step: 10
Training loss: 2.781991495449908
Validation loss: 2.534446415823639

Epoch: 6| Step: 11
Training loss: 1.934533832789574
Validation loss: 2.5299068661639565

Epoch: 6| Step: 12
Training loss: 2.0008062883185977
Validation loss: 2.51260005882498

Epoch: 6| Step: 13
Training loss: 1.8043651870973385
Validation loss: 2.5107221622178746

Epoch: 205| Step: 0
Training loss: 1.836990898346508
Validation loss: 2.524273568941513

Epoch: 6| Step: 1
Training loss: 2.4344756119079043
Validation loss: 2.5251123682549896

Epoch: 6| Step: 2
Training loss: 2.4574496302676754
Validation loss: 2.510782702163976

Epoch: 6| Step: 3
Training loss: 1.913297539264315
Validation loss: 2.503897996679325

Epoch: 6| Step: 4
Training loss: 2.494221876429574
Validation loss: 2.520106829672127

Epoch: 6| Step: 5
Training loss: 2.1847341217710703
Validation loss: 2.4967931463140105

Epoch: 6| Step: 6
Training loss: 2.522520010710967
Validation loss: 2.465345132618146

Epoch: 6| Step: 7
Training loss: 1.7815530753375692
Validation loss: 2.489184168702212

Epoch: 6| Step: 8
Training loss: 2.3110532616849673
Validation loss: 2.503160543633526

Epoch: 6| Step: 9
Training loss: 2.4701292796414704
Validation loss: 2.502895495554191

Epoch: 6| Step: 10
Training loss: 2.103670219046448
Validation loss: 2.4879552441820283

Epoch: 6| Step: 11
Training loss: 2.604202534746478
Validation loss: 2.5206307255448137

Epoch: 6| Step: 12
Training loss: 2.134470871298351
Validation loss: 2.503304438795855

Epoch: 6| Step: 13
Training loss: 3.2741571695939724
Validation loss: 2.509299897923402

Epoch: 206| Step: 0
Training loss: 2.195069431953393
Validation loss: 2.514697396661664

Epoch: 6| Step: 1
Training loss: 2.3458283428276827
Validation loss: 2.4936595314671317

Epoch: 6| Step: 2
Training loss: 1.7760149673140526
Validation loss: 2.507164382077564

Epoch: 6| Step: 3
Training loss: 2.3339218578185776
Validation loss: 2.4890431949908205

Epoch: 6| Step: 4
Training loss: 2.526126149655755
Validation loss: 2.513392924712123

Epoch: 6| Step: 5
Training loss: 2.4707858226340353
Validation loss: 2.5027855254683016

Epoch: 6| Step: 6
Training loss: 1.9025343656506417
Validation loss: 2.504348926409945

Epoch: 6| Step: 7
Training loss: 2.089663260678568
Validation loss: 2.5044851462748228

Epoch: 6| Step: 8
Training loss: 2.4756988078312694
Validation loss: 2.5137035073615817

Epoch: 6| Step: 9
Training loss: 2.9475519788201665
Validation loss: 2.4772271398961507

Epoch: 6| Step: 10
Training loss: 2.188420456282417
Validation loss: 2.4887428102233735

Epoch: 6| Step: 11
Training loss: 2.5571082542099735
Validation loss: 2.5132595949635173

Epoch: 6| Step: 12
Training loss: 1.8621424747867787
Validation loss: 2.489537484804938

Epoch: 6| Step: 13
Training loss: 2.570181335998406
Validation loss: 2.5103176442750086

Epoch: 207| Step: 0
Training loss: 2.153312229824683
Validation loss: 2.515399272301772

Epoch: 6| Step: 1
Training loss: 1.7242306804373864
Validation loss: 2.500269693778839

Epoch: 6| Step: 2
Training loss: 1.9001949636917979
Validation loss: 2.484763368101468

Epoch: 6| Step: 3
Training loss: 2.0247090589833032
Validation loss: 2.4933004127537632

Epoch: 6| Step: 4
Training loss: 2.379122318671772
Validation loss: 2.476824572825296

Epoch: 6| Step: 5
Training loss: 2.446967883923116
Validation loss: 2.5071108890844784

Epoch: 6| Step: 6
Training loss: 2.5077547916415632
Validation loss: 2.499734305547672

Epoch: 6| Step: 7
Training loss: 1.877038864416252
Validation loss: 2.5021948808422496

Epoch: 6| Step: 8
Training loss: 2.906311362654445
Validation loss: 2.4906858897312634

Epoch: 6| Step: 9
Training loss: 2.4646748577116293
Validation loss: 2.4869300301831525

Epoch: 6| Step: 10
Training loss: 2.0102196895049165
Validation loss: 2.5036863128974858

Epoch: 6| Step: 11
Training loss: 2.4984131545263786
Validation loss: 2.5015393952583738

Epoch: 6| Step: 12
Training loss: 2.0739950573088883
Validation loss: 2.4916820606998087

Epoch: 6| Step: 13
Training loss: 3.428719142729074
Validation loss: 2.491158781420858

Epoch: 208| Step: 0
Training loss: 1.5516840615340637
Validation loss: 2.4904428931450666

Epoch: 6| Step: 1
Training loss: 2.095359183864551
Validation loss: 2.483058116842129

Epoch: 6| Step: 2
Training loss: 2.0045099668913955
Validation loss: 2.482696918918747

Epoch: 6| Step: 3
Training loss: 2.336031398353155
Validation loss: 2.4843342249449565

Epoch: 6| Step: 4
Training loss: 3.0415214260035826
Validation loss: 2.504496597483574

Epoch: 6| Step: 5
Training loss: 2.440464076013215
Validation loss: 2.5200097035092446

Epoch: 6| Step: 6
Training loss: 2.1395094812035564
Validation loss: 2.5216731644848256

Epoch: 6| Step: 7
Training loss: 2.093009134424857
Validation loss: 2.506785889046646

Epoch: 6| Step: 8
Training loss: 1.8776185506480465
Validation loss: 2.5078135917752435

Epoch: 6| Step: 9
Training loss: 2.503934624997667
Validation loss: 2.513541049703152

Epoch: 6| Step: 10
Training loss: 3.038915164778896
Validation loss: 2.52243801722979

Epoch: 6| Step: 11
Training loss: 2.625207257036103
Validation loss: 2.5097457431040664

Epoch: 6| Step: 12
Training loss: 2.1847714436844226
Validation loss: 2.5383702901942033

Epoch: 6| Step: 13
Training loss: 1.9560083697087305
Validation loss: 2.5340340284717797

Epoch: 209| Step: 0
Training loss: 2.601684200888406
Validation loss: 2.5119663313557767

Epoch: 6| Step: 1
Training loss: 2.2549238370564297
Validation loss: 2.511209955808579

Epoch: 6| Step: 2
Training loss: 2.499130288478675
Validation loss: 2.5238321901675147

Epoch: 6| Step: 3
Training loss: 1.5840378080826552
Validation loss: 2.5006785917680974

Epoch: 6| Step: 4
Training loss: 2.6189009338437836
Validation loss: 2.5208112305014816

Epoch: 6| Step: 5
Training loss: 2.5758881083645626
Validation loss: 2.5363598429807612

Epoch: 6| Step: 6
Training loss: 2.3561316422502356
Validation loss: 2.5334274930515543

Epoch: 6| Step: 7
Training loss: 2.64867181782286
Validation loss: 2.5342946166714864

Epoch: 6| Step: 8
Training loss: 2.136438661729953
Validation loss: 2.5248345631445552

Epoch: 6| Step: 9
Training loss: 2.1052923181672614
Validation loss: 2.522775470541672

Epoch: 6| Step: 10
Training loss: 1.5469059796554536
Validation loss: 2.5012792892960394

Epoch: 6| Step: 11
Training loss: 2.2284691928636753
Validation loss: 2.504958787701519

Epoch: 6| Step: 12
Training loss: 2.490290574580305
Validation loss: 2.5130136120706426

Epoch: 6| Step: 13
Training loss: 2.244241444951618
Validation loss: 2.5031386771780975

Epoch: 210| Step: 0
Training loss: 2.26548398335389
Validation loss: 2.492029863550765

Epoch: 6| Step: 1
Training loss: 1.949214835917914
Validation loss: 2.469064848472657

Epoch: 6| Step: 2
Training loss: 2.5539520791680426
Validation loss: 2.5021131116817004

Epoch: 6| Step: 3
Training loss: 2.078807862027605
Validation loss: 2.4729146455131614

Epoch: 6| Step: 4
Training loss: 2.685588334197024
Validation loss: 2.4958998610765

Epoch: 6| Step: 5
Training loss: 2.245760207911341
Validation loss: 2.4781256446433564

Epoch: 6| Step: 6
Training loss: 2.6801131997470278
Validation loss: 2.458308362825306

Epoch: 6| Step: 7
Training loss: 1.9871258029517387
Validation loss: 2.4975084656252853

Epoch: 6| Step: 8
Training loss: 2.0644545108498185
Validation loss: 2.489122754292269

Epoch: 6| Step: 9
Training loss: 1.9669503357614424
Validation loss: 2.493594244974647

Epoch: 6| Step: 10
Training loss: 1.9797890002598577
Validation loss: 2.478531607649848

Epoch: 6| Step: 11
Training loss: 2.3683368171524886
Validation loss: 2.4790221758421875

Epoch: 6| Step: 12
Training loss: 2.2362039190057574
Validation loss: 2.464989629722546

Epoch: 6| Step: 13
Training loss: 3.1529318108557707
Validation loss: 2.48371828479861

Epoch: 211| Step: 0
Training loss: 2.1882800210161446
Validation loss: 2.4608450433877724

Epoch: 6| Step: 1
Training loss: 2.8347395791766283
Validation loss: 2.476946274796556

Epoch: 6| Step: 2
Training loss: 2.94799924988653
Validation loss: 2.4668915101797375

Epoch: 6| Step: 3
Training loss: 2.0542885280569396
Validation loss: 2.483467847087121

Epoch: 6| Step: 4
Training loss: 2.1057229534406297
Validation loss: 2.4757149329276826

Epoch: 6| Step: 5
Training loss: 2.3496131294455145
Validation loss: 2.4980822411403487

Epoch: 6| Step: 6
Training loss: 2.3785881243184845
Validation loss: 2.496822421503823

Epoch: 6| Step: 7
Training loss: 1.848311713252479
Validation loss: 2.4830303860339535

Epoch: 6| Step: 8
Training loss: 2.204604281254636
Validation loss: 2.480792187852409

Epoch: 6| Step: 9
Training loss: 2.551082482302846
Validation loss: 2.5008152924402314

Epoch: 6| Step: 10
Training loss: 2.0135203174051948
Validation loss: 2.4967844002433908

Epoch: 6| Step: 11
Training loss: 1.9374714510875501
Validation loss: 2.509018686238532

Epoch: 6| Step: 12
Training loss: 2.2216629463654964
Validation loss: 2.487168442496066

Epoch: 6| Step: 13
Training loss: 2.0707645714419964
Validation loss: 2.5235346308709397

Epoch: 212| Step: 0
Training loss: 2.5970628103563995
Validation loss: 2.505102943378355

Epoch: 6| Step: 1
Training loss: 2.2355804392847722
Validation loss: 2.4914708340994887

Epoch: 6| Step: 2
Training loss: 2.027560125134433
Validation loss: 2.5168953828379395

Epoch: 6| Step: 3
Training loss: 2.3303701340887946
Validation loss: 2.4882457265251396

Epoch: 6| Step: 4
Training loss: 2.3276493687543027
Validation loss: 2.5103668727403368

Epoch: 6| Step: 5
Training loss: 2.285707899493424
Validation loss: 2.5105546213780925

Epoch: 6| Step: 6
Training loss: 2.589332679736012
Validation loss: 2.5302912219122558

Epoch: 6| Step: 7
Training loss: 2.4768713147860075
Validation loss: 2.510672182043754

Epoch: 6| Step: 8
Training loss: 2.2292270711635345
Validation loss: 2.483415687364377

Epoch: 6| Step: 9
Training loss: 1.6662138164738198
Validation loss: 2.4856666606793993

Epoch: 6| Step: 10
Training loss: 1.861757307017527
Validation loss: 2.4706119967857565

Epoch: 6| Step: 11
Training loss: 1.9554750266376368
Validation loss: 2.467355524607677

Epoch: 6| Step: 12
Training loss: 2.9301065780993354
Validation loss: 2.480467222441136

Epoch: 6| Step: 13
Training loss: 2.0038612762222994
Validation loss: 2.5025095024377997

Epoch: 213| Step: 0
Training loss: 2.609103982522308
Validation loss: 2.477731428523413

Epoch: 6| Step: 1
Training loss: 2.117341996640435
Validation loss: 2.501632577804694

Epoch: 6| Step: 2
Training loss: 2.012574600827324
Validation loss: 2.4753139189043947

Epoch: 6| Step: 3
Training loss: 1.872078208528601
Validation loss: 2.4712940896304225

Epoch: 6| Step: 4
Training loss: 2.032220696546676
Validation loss: 2.4736375228739633

Epoch: 6| Step: 5
Training loss: 2.04536335578098
Validation loss: 2.4744009730531835

Epoch: 6| Step: 6
Training loss: 2.4529629793542087
Validation loss: 2.462767071418332

Epoch: 6| Step: 7
Training loss: 2.030699670040438
Validation loss: 2.4646892856411635

Epoch: 6| Step: 8
Training loss: 2.2185888097533297
Validation loss: 2.4751163658744373

Epoch: 6| Step: 9
Training loss: 2.5880791131239738
Validation loss: 2.4713342375085587

Epoch: 6| Step: 10
Training loss: 2.2574271430914368
Validation loss: 2.4893912795079935

Epoch: 6| Step: 11
Training loss: 2.7711335404375568
Validation loss: 2.4992949270869937

Epoch: 6| Step: 12
Training loss: 2.581534795313451
Validation loss: 2.494726573536681

Epoch: 6| Step: 13
Training loss: 1.7398196838386266
Validation loss: 2.4805902189240414

Epoch: 214| Step: 0
Training loss: 2.1813510029752554
Validation loss: 2.4760807016795923

Epoch: 6| Step: 1
Training loss: 2.4386395456082766
Validation loss: 2.4902629315168343

Epoch: 6| Step: 2
Training loss: 2.250464603351655
Validation loss: 2.4803325170923904

Epoch: 6| Step: 3
Training loss: 3.2042002292127
Validation loss: 2.48902161856389

Epoch: 6| Step: 4
Training loss: 2.5202438884366227
Validation loss: 2.505914313660171

Epoch: 6| Step: 5
Training loss: 2.2031283547666725
Validation loss: 2.491891037943877

Epoch: 6| Step: 6
Training loss: 1.8262260551371152
Validation loss: 2.5092519424773703

Epoch: 6| Step: 7
Training loss: 1.8596348300475818
Validation loss: 2.5087725542365726

Epoch: 6| Step: 8
Training loss: 1.9882915024408743
Validation loss: 2.472040142110527

Epoch: 6| Step: 9
Training loss: 2.124025682470078
Validation loss: 2.484881858538696

Epoch: 6| Step: 10
Training loss: 1.8268659771942113
Validation loss: 2.479786390480812

Epoch: 6| Step: 11
Training loss: 2.286032275662059
Validation loss: 2.477210075131608

Epoch: 6| Step: 12
Training loss: 2.438780619371867
Validation loss: 2.5017512986153454

Epoch: 6| Step: 13
Training loss: 1.971168848664124
Validation loss: 2.5110887929653782

Epoch: 215| Step: 0
Training loss: 2.3177426682118543
Validation loss: 2.493548814782305

Epoch: 6| Step: 1
Training loss: 1.872722323146821
Validation loss: 2.4861633299269146

Epoch: 6| Step: 2
Training loss: 2.160399493961879
Validation loss: 2.4942155090032596

Epoch: 6| Step: 3
Training loss: 1.9757691853231454
Validation loss: 2.5231816672534624

Epoch: 6| Step: 4
Training loss: 2.3766903132492407
Validation loss: 2.4976673143976447

Epoch: 6| Step: 5
Training loss: 1.998330432687181
Validation loss: 2.480367602488038

Epoch: 6| Step: 6
Training loss: 2.0325059969017083
Validation loss: 2.499690454044124

Epoch: 6| Step: 7
Training loss: 2.814878856430485
Validation loss: 2.471499673869191

Epoch: 6| Step: 8
Training loss: 2.0165178554055587
Validation loss: 2.476262282040377

Epoch: 6| Step: 9
Training loss: 2.0969109658626146
Validation loss: 2.466364427442736

Epoch: 6| Step: 10
Training loss: 2.674366464193388
Validation loss: 2.49100660543002

Epoch: 6| Step: 11
Training loss: 2.5540061298676178
Validation loss: 2.466195989610416

Epoch: 6| Step: 12
Training loss: 2.332643157065728
Validation loss: 2.509891305091475

Epoch: 6| Step: 13
Training loss: 2.6170975854715666
Validation loss: 2.4958477182415617

Epoch: 216| Step: 0
Training loss: 1.9266497218674947
Validation loss: 2.485754258499385

Epoch: 6| Step: 1
Training loss: 2.530427869871094
Validation loss: 2.4613952179804275

Epoch: 6| Step: 2
Training loss: 2.3143356872895327
Validation loss: 2.4729207630007606

Epoch: 6| Step: 3
Training loss: 2.7126419030264897
Validation loss: 2.4840793094414555

Epoch: 6| Step: 4
Training loss: 2.348463684463972
Validation loss: 2.4736171381349052

Epoch: 6| Step: 5
Training loss: 2.0413916136563306
Validation loss: 2.4818862271690025

Epoch: 6| Step: 6
Training loss: 2.5416824673854617
Validation loss: 2.507070701612687

Epoch: 6| Step: 7
Training loss: 2.2723717567508417
Validation loss: 2.5071617460042854

Epoch: 6| Step: 8
Training loss: 2.3842538945351346
Validation loss: 2.4883006502044513

Epoch: 6| Step: 9
Training loss: 2.798254003424615
Validation loss: 2.509282098063199

Epoch: 6| Step: 10
Training loss: 1.6370245527221667
Validation loss: 2.497091366114959

Epoch: 6| Step: 11
Training loss: 2.117869362351306
Validation loss: 2.500312617455021

Epoch: 6| Step: 12
Training loss: 1.9908327769740037
Validation loss: 2.4903104959878037

Epoch: 6| Step: 13
Training loss: 1.658860650242023
Validation loss: 2.5004849086680845

Epoch: 217| Step: 0
Training loss: 2.152055502973475
Validation loss: 2.498506522413424

Epoch: 6| Step: 1
Training loss: 2.5925046389914406
Validation loss: 2.4839566343450645

Epoch: 6| Step: 2
Training loss: 1.7550064408491142
Validation loss: 2.517718165366639

Epoch: 6| Step: 3
Training loss: 1.8434512009396864
Validation loss: 2.452147042846427

Epoch: 6| Step: 4
Training loss: 1.8558222062602816
Validation loss: 2.477334777306851

Epoch: 6| Step: 5
Training loss: 1.2459175200495245
Validation loss: 2.506714525396997

Epoch: 6| Step: 6
Training loss: 2.3235165857683953
Validation loss: 2.493660533828956

Epoch: 6| Step: 7
Training loss: 3.328391767385887
Validation loss: 2.482867197598067

Epoch: 6| Step: 8
Training loss: 2.309767268293323
Validation loss: 2.4896648141532256

Epoch: 6| Step: 9
Training loss: 2.5960776673793715
Validation loss: 2.4905453021072668

Epoch: 6| Step: 10
Training loss: 1.8942804858808113
Validation loss: 2.4449289207075897

Epoch: 6| Step: 11
Training loss: 2.5750790259817795
Validation loss: 2.4538996721943693

Epoch: 6| Step: 12
Training loss: 1.9296730442509529
Validation loss: 2.4790171820050126

Epoch: 6| Step: 13
Training loss: 2.50428128818534
Validation loss: 2.5073577731315906

Epoch: 218| Step: 0
Training loss: 1.9808630315693856
Validation loss: 2.5068398072421445

Epoch: 6| Step: 1
Training loss: 2.5806095982223853
Validation loss: 2.477334379928954

Epoch: 6| Step: 2
Training loss: 1.9305027772319807
Validation loss: 2.4912298795948127

Epoch: 6| Step: 3
Training loss: 3.1953045907890347
Validation loss: 2.487502434050631

Epoch: 6| Step: 4
Training loss: 2.4597447971615036
Validation loss: 2.4511672616027917

Epoch: 6| Step: 5
Training loss: 2.331700082648097
Validation loss: 2.4893465146154634

Epoch: 6| Step: 6
Training loss: 2.309312840762115
Validation loss: 2.474001536140519

Epoch: 6| Step: 7
Training loss: 1.6516175173398908
Validation loss: 2.475121885463699

Epoch: 6| Step: 8
Training loss: 1.7195451457715665
Validation loss: 2.4768657214677137

Epoch: 6| Step: 9
Training loss: 2.26056099942127
Validation loss: 2.4937023468649917

Epoch: 6| Step: 10
Training loss: 2.2186242726124004
Validation loss: 2.483391995868214

Epoch: 6| Step: 11
Training loss: 1.9821158337315878
Validation loss: 2.4583124945834762

Epoch: 6| Step: 12
Training loss: 1.8251770247211156
Validation loss: 2.4739126916031124

Epoch: 6| Step: 13
Training loss: 2.4211264160946206
Validation loss: 2.492038965789566

Epoch: 219| Step: 0
Training loss: 2.4741638312404373
Validation loss: 2.465983192297613

Epoch: 6| Step: 1
Training loss: 1.8449304971810485
Validation loss: 2.4512013582833307

Epoch: 6| Step: 2
Training loss: 2.343807067176339
Validation loss: 2.48096123792188

Epoch: 6| Step: 3
Training loss: 2.5089422515511695
Validation loss: 2.5099334575132786

Epoch: 6| Step: 4
Training loss: 2.5431464114146785
Validation loss: 2.4851649395715136

Epoch: 6| Step: 5
Training loss: 2.5246182445834835
Validation loss: 2.518540561023138

Epoch: 6| Step: 6
Training loss: 2.3341130815715583
Validation loss: 2.5098756988431217

Epoch: 6| Step: 7
Training loss: 2.389736234722445
Validation loss: 2.4661999355952884

Epoch: 6| Step: 8
Training loss: 1.7630521545182354
Validation loss: 2.513920245030466

Epoch: 6| Step: 9
Training loss: 2.864793323565099
Validation loss: 2.500028239880286

Epoch: 6| Step: 10
Training loss: 1.871447567546949
Validation loss: 2.468262329990824

Epoch: 6| Step: 11
Training loss: 1.9511709585559973
Validation loss: 2.4857386760387956

Epoch: 6| Step: 12
Training loss: 1.5837929041951495
Validation loss: 2.4629925297905157

Epoch: 6| Step: 13
Training loss: 1.8570390661810952
Validation loss: 2.5167671789715325

Epoch: 220| Step: 0
Training loss: 2.7764152766895758
Validation loss: 2.471620310900616

Epoch: 6| Step: 1
Training loss: 2.126265429531047
Validation loss: 2.437480292228748

Epoch: 6| Step: 2
Training loss: 2.272165473513291
Validation loss: 2.470432014316859

Epoch: 6| Step: 3
Training loss: 1.7511571056007778
Validation loss: 2.4940910043083897

Epoch: 6| Step: 4
Training loss: 1.9490675628679535
Validation loss: 2.4614279679343047

Epoch: 6| Step: 5
Training loss: 1.9118307376263428
Validation loss: 2.4457403995440425

Epoch: 6| Step: 6
Training loss: 2.348740922180466
Validation loss: 2.4405814046790817

Epoch: 6| Step: 7
Training loss: 2.0814913681331455
Validation loss: 2.4747547049648286

Epoch: 6| Step: 8
Training loss: 2.2088711521533315
Validation loss: 2.4661811973085053

Epoch: 6| Step: 9
Training loss: 2.6035877855950633
Validation loss: 2.4658049060945766

Epoch: 6| Step: 10
Training loss: 2.9530003435578425
Validation loss: 2.4541150298987793

Epoch: 6| Step: 11
Training loss: 1.8453369423251242
Validation loss: 2.479811390071743

Epoch: 6| Step: 12
Training loss: 2.0035664231228356
Validation loss: 2.5313602868101306

Epoch: 6| Step: 13
Training loss: 1.8910866796315182
Validation loss: 2.450362072480235

Epoch: 221| Step: 0
Training loss: 2.159528368569907
Validation loss: 2.474310151986789

Epoch: 6| Step: 1
Training loss: 1.9302344531621527
Validation loss: 2.4564267192185167

Epoch: 6| Step: 2
Training loss: 2.055765543627831
Validation loss: 2.4781492111392414

Epoch: 6| Step: 3
Training loss: 2.240752395562208
Validation loss: 2.446524203374446

Epoch: 6| Step: 4
Training loss: 2.2485199404852985
Validation loss: 2.487204596188767

Epoch: 6| Step: 5
Training loss: 3.206812378341273
Validation loss: 2.486206487865318

Epoch: 6| Step: 6
Training loss: 2.41924137772339
Validation loss: 2.4787390603758577

Epoch: 6| Step: 7
Training loss: 2.2960904396866555
Validation loss: 2.477924459857363

Epoch: 6| Step: 8
Training loss: 2.297883000707962
Validation loss: 2.477442657873995

Epoch: 6| Step: 9
Training loss: 1.7386589411483937
Validation loss: 2.4747388108382298

Epoch: 6| Step: 10
Training loss: 1.8651824145044986
Validation loss: 2.496898866819392

Epoch: 6| Step: 11
Training loss: 2.131702064158623
Validation loss: 2.486755654491455

Epoch: 6| Step: 12
Training loss: 1.8350170668969874
Validation loss: 2.4816256026134385

Epoch: 6| Step: 13
Training loss: 2.0803978902543867
Validation loss: 2.473941661387788

Epoch: 222| Step: 0
Training loss: 2.191477075748011
Validation loss: 2.4913574558478833

Epoch: 6| Step: 1
Training loss: 2.394494210434369
Validation loss: 2.4771420958783

Epoch: 6| Step: 2
Training loss: 2.091094881405325
Validation loss: 2.468025601766979

Epoch: 6| Step: 3
Training loss: 1.6329932591894265
Validation loss: 2.4568170912299063

Epoch: 6| Step: 4
Training loss: 2.2802371559279027
Validation loss: 2.506659448819884

Epoch: 6| Step: 5
Training loss: 1.7939446479908268
Validation loss: 2.5034548211884062

Epoch: 6| Step: 6
Training loss: 2.832821481882996
Validation loss: 2.5002323647667186

Epoch: 6| Step: 7
Training loss: 2.2818271481698074
Validation loss: 2.4940319526001056

Epoch: 6| Step: 8
Training loss: 2.146100802248549
Validation loss: 2.466460058330763

Epoch: 6| Step: 9
Training loss: 3.172640102169723
Validation loss: 2.468763044807526

Epoch: 6| Step: 10
Training loss: 2.019651191735666
Validation loss: 2.4864945866310215

Epoch: 6| Step: 11
Training loss: 1.610337645387861
Validation loss: 2.4829836490252264

Epoch: 6| Step: 12
Training loss: 2.0031819066193366
Validation loss: 2.474596467717623

Epoch: 6| Step: 13
Training loss: 1.8001359623316342
Validation loss: 2.46577779376868

Epoch: 223| Step: 0
Training loss: 2.386249502350809
Validation loss: 2.491145918721271

Epoch: 6| Step: 1
Training loss: 1.8466800748198298
Validation loss: 2.4733531504873842

Epoch: 6| Step: 2
Training loss: 2.5095583343991907
Validation loss: 2.467476950230661

Epoch: 6| Step: 3
Training loss: 2.222114376259237
Validation loss: 2.4883402491273547

Epoch: 6| Step: 4
Training loss: 1.7161641870037232
Validation loss: 2.4681595116506214

Epoch: 6| Step: 5
Training loss: 2.391490605040162
Validation loss: 2.491053335991958

Epoch: 6| Step: 6
Training loss: 2.3011037085685406
Validation loss: 2.4322765926326033

Epoch: 6| Step: 7
Training loss: 2.4441878685051712
Validation loss: 2.4506275482042716

Epoch: 6| Step: 8
Training loss: 2.139757189300365
Validation loss: 2.4851136170213572

Epoch: 6| Step: 9
Training loss: 2.1500391313407268
Validation loss: 2.455826109799797

Epoch: 6| Step: 10
Training loss: 1.9787305920360596
Validation loss: 2.460135065744971

Epoch: 6| Step: 11
Training loss: 2.5234445861150023
Validation loss: 2.4746998660154556

Epoch: 6| Step: 12
Training loss: 2.4967097565515046
Validation loss: 2.483330404146786

Epoch: 6| Step: 13
Training loss: 1.6518610255920056
Validation loss: 2.4982006652926296

Epoch: 224| Step: 0
Training loss: 2.648079276825707
Validation loss: 2.472602371261003

Epoch: 6| Step: 1
Training loss: 2.563558685440517
Validation loss: 2.4577253315278202

Epoch: 6| Step: 2
Training loss: 2.0377680736718826
Validation loss: 2.465702921809193

Epoch: 6| Step: 3
Training loss: 2.3995736379196257
Validation loss: 2.462795250029209

Epoch: 6| Step: 4
Training loss: 1.613455035660929
Validation loss: 2.4459850575384894

Epoch: 6| Step: 5
Training loss: 1.9428666146632525
Validation loss: 2.445133884551624

Epoch: 6| Step: 6
Training loss: 2.2776815644803343
Validation loss: 2.4661560803379707

Epoch: 6| Step: 7
Training loss: 2.6157412048559485
Validation loss: 2.477839510644797

Epoch: 6| Step: 8
Training loss: 2.531020354226394
Validation loss: 2.464895701569044

Epoch: 6| Step: 9
Training loss: 1.856846797578719
Validation loss: 2.46906408687634

Epoch: 6| Step: 10
Training loss: 1.9819415332666177
Validation loss: 2.475102133377032

Epoch: 6| Step: 11
Training loss: 2.060638975281744
Validation loss: 2.4637630525944574

Epoch: 6| Step: 12
Training loss: 2.376795642058628
Validation loss: 2.4399540518884706

Epoch: 6| Step: 13
Training loss: 1.2016257816313345
Validation loss: 2.4786565329384653

Epoch: 225| Step: 0
Training loss: 2.0725247062066385
Validation loss: 2.4741887467256416

Epoch: 6| Step: 1
Training loss: 2.2098034218058635
Validation loss: 2.4726730781820656

Epoch: 6| Step: 2
Training loss: 2.453531510997518
Validation loss: 2.4817856125995785

Epoch: 6| Step: 3
Training loss: 2.8749129240698554
Validation loss: 2.4601768483541697

Epoch: 6| Step: 4
Training loss: 2.027126881313633
Validation loss: 2.464701621760781

Epoch: 6| Step: 5
Training loss: 1.6579784515186178
Validation loss: 2.4415398505951726

Epoch: 6| Step: 6
Training loss: 2.579393386941664
Validation loss: 2.4894089821593184

Epoch: 6| Step: 7
Training loss: 2.202276945910863
Validation loss: 2.436708901980879

Epoch: 6| Step: 8
Training loss: 2.670235649596762
Validation loss: 2.488291088178877

Epoch: 6| Step: 9
Training loss: 1.5844261597569151
Validation loss: 2.4922162717576097

Epoch: 6| Step: 10
Training loss: 2.2817428265556323
Validation loss: 2.4684222278841457

Epoch: 6| Step: 11
Training loss: 2.1180104137953517
Validation loss: 2.459458655835271

Epoch: 6| Step: 12
Training loss: 1.8701118967165693
Validation loss: 2.4621410431605724

Epoch: 6| Step: 13
Training loss: 2.1578868237180164
Validation loss: 2.4623185904604807

Epoch: 226| Step: 0
Training loss: 1.618966124257367
Validation loss: 2.489676050357927

Epoch: 6| Step: 1
Training loss: 1.42105623922392
Validation loss: 2.4973322421742874

Epoch: 6| Step: 2
Training loss: 2.7759390711240437
Validation loss: 2.4722158606214144

Epoch: 6| Step: 3
Training loss: 1.930864106669678
Validation loss: 2.4756201959643893

Epoch: 6| Step: 4
Training loss: 2.1370079500356627
Validation loss: 2.4650524617820375

Epoch: 6| Step: 5
Training loss: 2.1331406784487363
Validation loss: 2.4963895825362634

Epoch: 6| Step: 6
Training loss: 3.2662288709760765
Validation loss: 2.4993172031037085

Epoch: 6| Step: 7
Training loss: 2.4366637531616213
Validation loss: 2.5022633848419678

Epoch: 6| Step: 8
Training loss: 2.366413354973188
Validation loss: 2.4963028981096778

Epoch: 6| Step: 9
Training loss: 1.5322290521410622
Validation loss: 2.464192332590961

Epoch: 6| Step: 10
Training loss: 2.2311948539693693
Validation loss: 2.45515872907423

Epoch: 6| Step: 11
Training loss: 2.1326036735279077
Validation loss: 2.457985889068267

Epoch: 6| Step: 12
Training loss: 2.229761549342227
Validation loss: 2.4446496443496266

Epoch: 6| Step: 13
Training loss: 2.342068081407801
Validation loss: 2.455605030733787

Epoch: 227| Step: 0
Training loss: 2.2010104806486708
Validation loss: 2.450226234670516

Epoch: 6| Step: 1
Training loss: 1.7805991071088452
Validation loss: 2.4572940574156927

Epoch: 6| Step: 2
Training loss: 2.471829003293107
Validation loss: 2.4702209025410857

Epoch: 6| Step: 3
Training loss: 2.3839007784721957
Validation loss: 2.4802539606159435

Epoch: 6| Step: 4
Training loss: 1.8243989712485382
Validation loss: 2.519008613365843

Epoch: 6| Step: 5
Training loss: 2.166139673063913
Validation loss: 2.431660503977148

Epoch: 6| Step: 6
Training loss: 1.596274078832773
Validation loss: 2.4561848850757597

Epoch: 6| Step: 7
Training loss: 2.391061979759673
Validation loss: 2.464945850695685

Epoch: 6| Step: 8
Training loss: 2.061349258762707
Validation loss: 2.485704463176084

Epoch: 6| Step: 9
Training loss: 2.927718739534634
Validation loss: 2.4799490735266376

Epoch: 6| Step: 10
Training loss: 2.097353211860199
Validation loss: 2.459073339271141

Epoch: 6| Step: 11
Training loss: 2.0065867916740485
Validation loss: 2.4527021030107576

Epoch: 6| Step: 12
Training loss: 2.5246839722123435
Validation loss: 2.430383016162782

Epoch: 6| Step: 13
Training loss: 2.0207709338854634
Validation loss: 2.45177400830898

Epoch: 228| Step: 0
Training loss: 1.9549174514279581
Validation loss: 2.4501431172424946

Epoch: 6| Step: 1
Training loss: 1.9017958586413939
Validation loss: 2.4803989856958033

Epoch: 6| Step: 2
Training loss: 1.7790236362733323
Validation loss: 2.472177123896304

Epoch: 6| Step: 3
Training loss: 1.5633246725095993
Validation loss: 2.487482986396134

Epoch: 6| Step: 4
Training loss: 1.718602954469794
Validation loss: 2.468970854706448

Epoch: 6| Step: 5
Training loss: 1.9493571444443087
Validation loss: 2.4438474165493327

Epoch: 6| Step: 6
Training loss: 2.295950463475029
Validation loss: 2.440785662262985

Epoch: 6| Step: 7
Training loss: 2.0364071448511543
Validation loss: 2.467048044856297

Epoch: 6| Step: 8
Training loss: 1.903759439386121
Validation loss: 2.4394753726194436

Epoch: 6| Step: 9
Training loss: 1.8066679421498957
Validation loss: 2.439920889716609

Epoch: 6| Step: 10
Training loss: 3.6310035713869526
Validation loss: 2.457724688981309

Epoch: 6| Step: 11
Training loss: 2.317851807228982
Validation loss: 2.4504732056691916

Epoch: 6| Step: 12
Training loss: 2.7823380474384107
Validation loss: 2.483658669581201

Epoch: 6| Step: 13
Training loss: 1.702505576506905
Validation loss: 2.5021875450052216

Epoch: 229| Step: 0
Training loss: 2.1185785769992496
Validation loss: 2.4423215417166224

Epoch: 6| Step: 1
Training loss: 2.604124806385567
Validation loss: 2.481436342901471

Epoch: 6| Step: 2
Training loss: 1.6274913616507845
Validation loss: 2.46211677002429

Epoch: 6| Step: 3
Training loss: 1.853517618771155
Validation loss: 2.473453003201992

Epoch: 6| Step: 4
Training loss: 2.721653057032436
Validation loss: 2.459348229937012

Epoch: 6| Step: 5
Training loss: 2.0215983040811953
Validation loss: 2.4525262496312985

Epoch: 6| Step: 6
Training loss: 1.8816153491545695
Validation loss: 2.4671209497217546

Epoch: 6| Step: 7
Training loss: 1.8328503564955951
Validation loss: 2.467544287195944

Epoch: 6| Step: 8
Training loss: 3.1519955202835703
Validation loss: 2.4788564669077062

Epoch: 6| Step: 9
Training loss: 2.142492662949168
Validation loss: 2.450245364913158

Epoch: 6| Step: 10
Training loss: 1.8331945829194496
Validation loss: 2.415512079307626

Epoch: 6| Step: 11
Training loss: 2.2664070621187897
Validation loss: 2.4514990024453898

Epoch: 6| Step: 12
Training loss: 2.1052646856553405
Validation loss: 2.437630791595647

Epoch: 6| Step: 13
Training loss: 2.078456536714734
Validation loss: 2.4679284910290806

Epoch: 230| Step: 0
Training loss: 3.1483866117165373
Validation loss: 2.452929989920005

Epoch: 6| Step: 1
Training loss: 1.6996926534735546
Validation loss: 2.4657265844231424

Epoch: 6| Step: 2
Training loss: 2.009690768049855
Validation loss: 2.4573958875770865

Epoch: 6| Step: 3
Training loss: 1.7577377642532688
Validation loss: 2.4435138689124614

Epoch: 6| Step: 4
Training loss: 1.8928643198211417
Validation loss: 2.44576518740237

Epoch: 6| Step: 5
Training loss: 1.7239624054122116
Validation loss: 2.4391858634220083

Epoch: 6| Step: 6
Training loss: 2.348553427387579
Validation loss: 2.451383927108718

Epoch: 6| Step: 7
Training loss: 2.2522454183749745
Validation loss: 2.4478408944876913

Epoch: 6| Step: 8
Training loss: 2.157714125526725
Validation loss: 2.4366002406037954

Epoch: 6| Step: 9
Training loss: 2.179998013381753
Validation loss: 2.465188123232165

Epoch: 6| Step: 10
Training loss: 2.421806679038855
Validation loss: 2.466648360430838

Epoch: 6| Step: 11
Training loss: 2.2530219658984243
Validation loss: 2.4532792749770165

Epoch: 6| Step: 12
Training loss: 2.0428694341672773
Validation loss: 2.4560076975869

Epoch: 6| Step: 13
Training loss: 2.5423854270183703
Validation loss: 2.4604081263743054

Epoch: 231| Step: 0
Training loss: 2.47585423687876
Validation loss: 2.474842179363751

Epoch: 6| Step: 1
Training loss: 2.308899628438114
Validation loss: 2.483625752400335

Epoch: 6| Step: 2
Training loss: 2.0216572710632894
Validation loss: 2.440970781895797

Epoch: 6| Step: 3
Training loss: 2.1285205176639033
Validation loss: 2.4568544308510383

Epoch: 6| Step: 4
Training loss: 2.3216456427059255
Validation loss: 2.4566684158089

Epoch: 6| Step: 5
Training loss: 1.8843244125129852
Validation loss: 2.4519263409466148

Epoch: 6| Step: 6
Training loss: 2.2689493979691204
Validation loss: 2.4763819240921747

Epoch: 6| Step: 7
Training loss: 1.8297647800299461
Validation loss: 2.47026013747196

Epoch: 6| Step: 8
Training loss: 2.2445183843555303
Validation loss: 2.4551543309618387

Epoch: 6| Step: 9
Training loss: 1.981280459582006
Validation loss: 2.478781915268008

Epoch: 6| Step: 10
Training loss: 1.5285351099555886
Validation loss: 2.450281526146272

Epoch: 6| Step: 11
Training loss: 3.255139615160089
Validation loss: 2.433505191632567

Epoch: 6| Step: 12
Training loss: 1.939599837394451
Validation loss: 2.4434659532377156

Epoch: 6| Step: 13
Training loss: 1.9360861387912105
Validation loss: 2.4728483536182746

Epoch: 232| Step: 0
Training loss: 2.348365613049056
Validation loss: 2.474963917183848

Epoch: 6| Step: 1
Training loss: 2.0251026739770324
Validation loss: 2.472697476820916

Epoch: 6| Step: 2
Training loss: 1.7456660418904786
Validation loss: 2.462994144170289

Epoch: 6| Step: 3
Training loss: 1.6100575009141753
Validation loss: 2.466767944980035

Epoch: 6| Step: 4
Training loss: 2.939575598310265
Validation loss: 2.454451285591873

Epoch: 6| Step: 5
Training loss: 1.7746013569802908
Validation loss: 2.4780980401972106

Epoch: 6| Step: 6
Training loss: 2.034219185623789
Validation loss: 2.4551661114531482

Epoch: 6| Step: 7
Training loss: 2.4564588695757723
Validation loss: 2.4763301555211137

Epoch: 6| Step: 8
Training loss: 2.2403265377865442
Validation loss: 2.446423977743801

Epoch: 6| Step: 9
Training loss: 1.556036742279164
Validation loss: 2.4704772692939074

Epoch: 6| Step: 10
Training loss: 1.9665039814186869
Validation loss: 2.434827761213739

Epoch: 6| Step: 11
Training loss: 2.6505347306185842
Validation loss: 2.4676147193296902

Epoch: 6| Step: 12
Training loss: 2.288359237805817
Validation loss: 2.4673998775292345

Epoch: 6| Step: 13
Training loss: 2.1019880012946484
Validation loss: 2.440197855979663

Epoch: 233| Step: 0
Training loss: 1.9635502404414487
Validation loss: 2.487071152020911

Epoch: 6| Step: 1
Training loss: 2.0888057804934967
Validation loss: 2.420916715123566

Epoch: 6| Step: 2
Training loss: 1.8245067818312548
Validation loss: 2.4431127961181547

Epoch: 6| Step: 3
Training loss: 2.407277767108806
Validation loss: 2.445760898181666

Epoch: 6| Step: 4
Training loss: 2.6681142295393045
Validation loss: 2.4589929260685413

Epoch: 6| Step: 5
Training loss: 1.8721151411234127
Validation loss: 2.430871621211293

Epoch: 6| Step: 6
Training loss: 2.025777752185866
Validation loss: 2.4637570164224605

Epoch: 6| Step: 7
Training loss: 2.5609442477460296
Validation loss: 2.4849836940514725

Epoch: 6| Step: 8
Training loss: 1.8120458625900955
Validation loss: 2.4635194754332197

Epoch: 6| Step: 9
Training loss: 2.4109067567557454
Validation loss: 2.462440707967745

Epoch: 6| Step: 10
Training loss: 1.8232774940508918
Validation loss: 2.4909053321160886

Epoch: 6| Step: 11
Training loss: 1.7392201149146647
Validation loss: 2.4621842202637025

Epoch: 6| Step: 12
Training loss: 2.5328289805681528
Validation loss: 2.474676366640406

Epoch: 6| Step: 13
Training loss: 2.1639898955907797
Validation loss: 2.463503382900294

Epoch: 234| Step: 0
Training loss: 2.0482943906048994
Validation loss: 2.4428424607283055

Epoch: 6| Step: 1
Training loss: 2.805811239831007
Validation loss: 2.48542075457031

Epoch: 6| Step: 2
Training loss: 2.0384476125543225
Validation loss: 2.459998642085451

Epoch: 6| Step: 3
Training loss: 2.684417642558884
Validation loss: 2.5000184878824467

Epoch: 6| Step: 4
Training loss: 2.9040489475759514
Validation loss: 2.443635415443948

Epoch: 6| Step: 5
Training loss: 1.6778483413161989
Validation loss: 2.46671900210059

Epoch: 6| Step: 6
Training loss: 1.6987174160536183
Validation loss: 2.455485496602096

Epoch: 6| Step: 7
Training loss: 2.0631132659069946
Validation loss: 2.454751123614629

Epoch: 6| Step: 8
Training loss: 1.3893646357909515
Validation loss: 2.446532391421135

Epoch: 6| Step: 9
Training loss: 1.8532785438882555
Validation loss: 2.4296764105390847

Epoch: 6| Step: 10
Training loss: 1.903386513667996
Validation loss: 2.4488551382862793

Epoch: 6| Step: 11
Training loss: 1.8949425948816307
Validation loss: 2.4303438194230367

Epoch: 6| Step: 12
Training loss: 2.08349775301302
Validation loss: 2.4346930120564383

Epoch: 6| Step: 13
Training loss: 2.5221418237219106
Validation loss: 2.477197426670279

Epoch: 235| Step: 0
Training loss: 2.0283849611296936
Validation loss: 2.412119501537774

Epoch: 6| Step: 1
Training loss: 2.9126244645271906
Validation loss: 2.459257316856621

Epoch: 6| Step: 2
Training loss: 1.501038986228369
Validation loss: 2.4362568647255443

Epoch: 6| Step: 3
Training loss: 2.107912248721309
Validation loss: 2.466510679749985

Epoch: 6| Step: 4
Training loss: 1.560785344586571
Validation loss: 2.4585286284123895

Epoch: 6| Step: 5
Training loss: 2.1255032560529514
Validation loss: 2.4700254845090206

Epoch: 6| Step: 6
Training loss: 2.2657476983882088
Validation loss: 2.4543838327870393

Epoch: 6| Step: 7
Training loss: 2.3730534055015595
Validation loss: 2.4664124922915525

Epoch: 6| Step: 8
Training loss: 2.425743999594476
Validation loss: 2.464943781016546

Epoch: 6| Step: 9
Training loss: 1.7649482848071847
Validation loss: 2.4604037923483766

Epoch: 6| Step: 10
Training loss: 2.280357081576179
Validation loss: 2.4613109070289907

Epoch: 6| Step: 11
Training loss: 2.323414588102082
Validation loss: 2.4729604770595253

Epoch: 6| Step: 12
Training loss: 2.1321192023285733
Validation loss: 2.4082069392617735

Epoch: 6| Step: 13
Training loss: 2.099220644428632
Validation loss: 2.438297270705955

Epoch: 236| Step: 0
Training loss: 1.7619308716141635
Validation loss: 2.435368127550666

Epoch: 6| Step: 1
Training loss: 2.4803368721094134
Validation loss: 2.426641256995108

Epoch: 6| Step: 2
Training loss: 2.1360276131363123
Validation loss: 2.4395559962083024

Epoch: 6| Step: 3
Training loss: 2.0460732323898494
Validation loss: 2.471554160623109

Epoch: 6| Step: 4
Training loss: 1.6197660225395016
Validation loss: 2.46192206815603

Epoch: 6| Step: 5
Training loss: 2.042866749888571
Validation loss: 2.4722280492649014

Epoch: 6| Step: 6
Training loss: 2.133467018389243
Validation loss: 2.447736300855876

Epoch: 6| Step: 7
Training loss: 2.354804456169224
Validation loss: 2.449992424336035

Epoch: 6| Step: 8
Training loss: 1.9974469937201231
Validation loss: 2.4472458869253275

Epoch: 6| Step: 9
Training loss: 1.990704871091911
Validation loss: 2.441581038980012

Epoch: 6| Step: 10
Training loss: 2.0960198240434664
Validation loss: 2.424049683496209

Epoch: 6| Step: 11
Training loss: 2.7827634658220357
Validation loss: 2.480682120473304

Epoch: 6| Step: 12
Training loss: 1.8810113546382639
Validation loss: 2.4775445777266154

Epoch: 6| Step: 13
Training loss: 2.4804579847207338
Validation loss: 2.445030983800413

Epoch: 237| Step: 0
Training loss: 1.7495241199323248
Validation loss: 2.4356869527367455

Epoch: 6| Step: 1
Training loss: 1.7647467935719172
Validation loss: 2.480263529853447

Epoch: 6| Step: 2
Training loss: 1.8673965145582307
Validation loss: 2.4514091567397767

Epoch: 6| Step: 3
Training loss: 2.21121235679039
Validation loss: 2.4466796248832354

Epoch: 6| Step: 4
Training loss: 2.1427245598603455
Validation loss: 2.41274336647312

Epoch: 6| Step: 5
Training loss: 1.824445885969907
Validation loss: 2.446376895586528

Epoch: 6| Step: 6
Training loss: 2.617857707738583
Validation loss: 2.4243271696793176

Epoch: 6| Step: 7
Training loss: 1.556663828907789
Validation loss: 2.4553584208682904

Epoch: 6| Step: 8
Training loss: 1.9124513033981447
Validation loss: 2.448244483342906

Epoch: 6| Step: 9
Training loss: 2.6387787634195803
Validation loss: 2.4470414918031103

Epoch: 6| Step: 10
Training loss: 2.539365591885684
Validation loss: 2.468611050142184

Epoch: 6| Step: 11
Training loss: 2.085498092032241
Validation loss: 2.4577135080192583

Epoch: 6| Step: 12
Training loss: 1.9268835290651378
Validation loss: 2.4587138719008164

Epoch: 6| Step: 13
Training loss: 2.7721613997279015
Validation loss: 2.431379017679536

Epoch: 238| Step: 0
Training loss: 1.5196718283301538
Validation loss: 2.459118350834355

Epoch: 6| Step: 1
Training loss: 1.7976278303636164
Validation loss: 2.4773138838357003

Epoch: 6| Step: 2
Training loss: 2.3537526624667544
Validation loss: 2.482473766449068

Epoch: 6| Step: 3
Training loss: 2.6548826400766883
Validation loss: 2.4411701614259576

Epoch: 6| Step: 4
Training loss: 1.9370413821934616
Validation loss: 2.423445909747521

Epoch: 6| Step: 5
Training loss: 2.347334295402459
Validation loss: 2.441118240530433

Epoch: 6| Step: 6
Training loss: 2.126401439120033
Validation loss: 2.4244979738359187

Epoch: 6| Step: 7
Training loss: 2.531930902523568
Validation loss: 2.4277065581971393

Epoch: 6| Step: 8
Training loss: 1.7569620067068823
Validation loss: 2.4754596403967217

Epoch: 6| Step: 9
Training loss: 2.734884596068854
Validation loss: 2.4410256560282417

Epoch: 6| Step: 10
Training loss: 2.1577196503149962
Validation loss: 2.480322308844639

Epoch: 6| Step: 11
Training loss: 1.7543624590461833
Validation loss: 2.4600847007932276

Epoch: 6| Step: 12
Training loss: 2.0321615667916078
Validation loss: 2.440456612919239

Epoch: 6| Step: 13
Training loss: 2.118156858707206
Validation loss: 2.469316110518719

Epoch: 239| Step: 0
Training loss: 2.4147732870335874
Validation loss: 2.4464292634136253

Epoch: 6| Step: 1
Training loss: 2.1202615752883047
Validation loss: 2.4208501779804257

Epoch: 6| Step: 2
Training loss: 2.079368162106644
Validation loss: 2.4485698157609073

Epoch: 6| Step: 3
Training loss: 2.000819991815465
Validation loss: 2.4672419317761185

Epoch: 6| Step: 4
Training loss: 2.28470151892509
Validation loss: 2.448717860059139

Epoch: 6| Step: 5
Training loss: 1.5688561665755014
Validation loss: 2.421599933989077

Epoch: 6| Step: 6
Training loss: 2.1857273003469424
Validation loss: 2.446279331019507

Epoch: 6| Step: 7
Training loss: 1.963350794357779
Validation loss: 2.4562788478302555

Epoch: 6| Step: 8
Training loss: 1.645743677457729
Validation loss: 2.4263955080436483

Epoch: 6| Step: 9
Training loss: 2.108328326474403
Validation loss: 2.4181248629386105

Epoch: 6| Step: 10
Training loss: 2.3440811940474906
Validation loss: 2.4672664527012618

Epoch: 6| Step: 11
Training loss: 2.668950940324061
Validation loss: 2.410702843092824

Epoch: 6| Step: 12
Training loss: 2.544891708558259
Validation loss: 2.4296997532151274

Epoch: 6| Step: 13
Training loss: 1.3495765604758236
Validation loss: 2.434568558175298

Epoch: 240| Step: 0
Training loss: 1.7189966198242757
Validation loss: 2.4465816176233255

Epoch: 6| Step: 1
Training loss: 1.800591183642462
Validation loss: 2.4629257907584936

Epoch: 6| Step: 2
Training loss: 1.961069596541295
Validation loss: 2.45491202059425

Epoch: 6| Step: 3
Training loss: 1.991628531033697
Validation loss: 2.4275894119779493

Epoch: 6| Step: 4
Training loss: 3.2510752733117787
Validation loss: 2.448490127142486

Epoch: 6| Step: 5
Training loss: 2.404291817654358
Validation loss: 2.4497248391069224

Epoch: 6| Step: 6
Training loss: 1.4409215261996495
Validation loss: 2.4350058139830075

Epoch: 6| Step: 7
Training loss: 2.0250861914858778
Validation loss: 2.4521144972195956

Epoch: 6| Step: 8
Training loss: 2.475335813146956
Validation loss: 2.4429221089998157

Epoch: 6| Step: 9
Training loss: 2.2786840352080433
Validation loss: 2.4495829440496655

Epoch: 6| Step: 10
Training loss: 2.080672803233952
Validation loss: 2.4587471768150264

Epoch: 6| Step: 11
Training loss: 1.9331215638340757
Validation loss: 2.445467089622183

Epoch: 6| Step: 12
Training loss: 1.7570673062367987
Validation loss: 2.442898909458402

Epoch: 6| Step: 13
Training loss: 1.9676167087282093
Validation loss: 2.4265304538486085

Epoch: 241| Step: 0
Training loss: 1.2983653685437564
Validation loss: 2.4449267617334147

Epoch: 6| Step: 1
Training loss: 2.5528501850642966
Validation loss: 2.455787379703701

Epoch: 6| Step: 2
Training loss: 1.671274736973159
Validation loss: 2.417251868958307

Epoch: 6| Step: 3
Training loss: 2.303594401129893
Validation loss: 2.456826557666427

Epoch: 6| Step: 4
Training loss: 2.4171811794797575
Validation loss: 2.4453679266911488

Epoch: 6| Step: 5
Training loss: 1.868712309390272
Validation loss: 2.4472855127143567

Epoch: 6| Step: 6
Training loss: 2.419761670885023
Validation loss: 2.475501091340818

Epoch: 6| Step: 7
Training loss: 2.2604715601383565
Validation loss: 2.459410657828894

Epoch: 6| Step: 8
Training loss: 2.5495576362626124
Validation loss: 2.464616373336649

Epoch: 6| Step: 9
Training loss: 2.486055297745995
Validation loss: 2.4359136546142075

Epoch: 6| Step: 10
Training loss: 1.7004671969481588
Validation loss: 2.4177255031195535

Epoch: 6| Step: 11
Training loss: 1.6065854831751547
Validation loss: 2.4306082419697703

Epoch: 6| Step: 12
Training loss: 2.0148581295380397
Validation loss: 2.428286528867436

Epoch: 6| Step: 13
Training loss: 1.8143137045719002
Validation loss: 2.468676031044792

Epoch: 242| Step: 0
Training loss: 2.216469680905767
Validation loss: 2.4281706100075895

Epoch: 6| Step: 1
Training loss: 2.1573532157110638
Validation loss: 2.427879196321019

Epoch: 6| Step: 2
Training loss: 2.6293538634999196
Validation loss: 2.4641776057683122

Epoch: 6| Step: 3
Training loss: 2.3089365954708017
Validation loss: 2.4302379758903414

Epoch: 6| Step: 4
Training loss: 1.918057441603077
Validation loss: 2.458579430863853

Epoch: 6| Step: 5
Training loss: 2.2768455732581714
Validation loss: 2.428459047642196

Epoch: 6| Step: 6
Training loss: 2.1236635381152347
Validation loss: 2.438032044348045

Epoch: 6| Step: 7
Training loss: 1.9189040628518141
Validation loss: 2.4217043728882457

Epoch: 6| Step: 8
Training loss: 2.2495293654852384
Validation loss: 2.4278497085840427

Epoch: 6| Step: 9
Training loss: 1.732074345735209
Validation loss: 2.4419745532066823

Epoch: 6| Step: 10
Training loss: 2.0971230054660435
Validation loss: 2.3865396502152993

Epoch: 6| Step: 11
Training loss: 2.2473463728594423
Validation loss: 2.4706125156127454

Epoch: 6| Step: 12
Training loss: 1.8290328681457773
Validation loss: 2.4192008167721495

Epoch: 6| Step: 13
Training loss: 1.545207039500492
Validation loss: 2.4446586912438883

Epoch: 243| Step: 0
Training loss: 2.6873168882931298
Validation loss: 2.4453785120199205

Epoch: 6| Step: 1
Training loss: 2.165674153440308
Validation loss: 2.449641547685775

Epoch: 6| Step: 2
Training loss: 2.419562336934767
Validation loss: 2.4511033749377957

Epoch: 6| Step: 3
Training loss: 2.266410112821488
Validation loss: 2.42202038548555

Epoch: 6| Step: 4
Training loss: 1.6511162421134082
Validation loss: 2.4804267133658815

Epoch: 6| Step: 5
Training loss: 2.1563622265787297
Validation loss: 2.4446864661641223

Epoch: 6| Step: 6
Training loss: 2.4427188854084507
Validation loss: 2.416032048691336

Epoch: 6| Step: 7
Training loss: 1.5778286344020964
Validation loss: 2.4815439506335113

Epoch: 6| Step: 8
Training loss: 2.334130037622527
Validation loss: 2.4844167066971217

Epoch: 6| Step: 9
Training loss: 1.6684511009872294
Validation loss: 2.4717823625234967

Epoch: 6| Step: 10
Training loss: 1.9745829322923472
Validation loss: 2.4489207135409523

Epoch: 6| Step: 11
Training loss: 2.1193111790525774
Validation loss: 2.474579689911067

Epoch: 6| Step: 12
Training loss: 1.3150520490636564
Validation loss: 2.4488468041151354

Epoch: 6| Step: 13
Training loss: 2.9202616924440106
Validation loss: 2.400397978235993

Epoch: 244| Step: 0
Training loss: 2.0535421333829755
Validation loss: 2.4298691299364106

Epoch: 6| Step: 1
Training loss: 2.2196427819098883
Validation loss: 2.453357554617559

Epoch: 6| Step: 2
Training loss: 2.023570641809922
Validation loss: 2.4590048528933135

Epoch: 6| Step: 3
Training loss: 1.7364589783458126
Validation loss: 2.4677188776571564

Epoch: 6| Step: 4
Training loss: 2.804919730005203
Validation loss: 2.4801180833820946

Epoch: 6| Step: 5
Training loss: 2.218451036540108
Validation loss: 2.4436702603117406

Epoch: 6| Step: 6
Training loss: 1.8948504306879592
Validation loss: 2.4145989453031165

Epoch: 6| Step: 7
Training loss: 1.5278676883173328
Validation loss: 2.4141975861768588

Epoch: 6| Step: 8
Training loss: 1.7885794841283744
Validation loss: 2.421534231335436

Epoch: 6| Step: 9
Training loss: 1.6888843791815016
Validation loss: 2.4160480563243993

Epoch: 6| Step: 10
Training loss: 2.557846402809878
Validation loss: 2.472983727355039

Epoch: 6| Step: 11
Training loss: 2.307129474619639
Validation loss: 2.4456962591760107

Epoch: 6| Step: 12
Training loss: 1.7733045351706478
Validation loss: 2.4130839657016114

Epoch: 6| Step: 13
Training loss: 2.6149377063457644
Validation loss: 2.4401367551642643

Epoch: 245| Step: 0
Training loss: 1.7292776033901531
Validation loss: 2.4360688022630064

Epoch: 6| Step: 1
Training loss: 2.347386806468706
Validation loss: 2.4229051313126644

Epoch: 6| Step: 2
Training loss: 2.1775629224127817
Validation loss: 2.443229723724345

Epoch: 6| Step: 3
Training loss: 2.352382884338259
Validation loss: 2.442087876327135

Epoch: 6| Step: 4
Training loss: 2.5463605489876477
Validation loss: 2.4154888287736394

Epoch: 6| Step: 5
Training loss: 1.760059395676522
Validation loss: 2.4154487715703095

Epoch: 6| Step: 6
Training loss: 2.078611388686154
Validation loss: 2.4454794839195966

Epoch: 6| Step: 7
Training loss: 1.4173432959538084
Validation loss: 2.4079288879119254

Epoch: 6| Step: 8
Training loss: 2.2431171895611555
Validation loss: 2.4426450087303224

Epoch: 6| Step: 9
Training loss: 1.214477582006121
Validation loss: 2.446294422867131

Epoch: 6| Step: 10
Training loss: 1.831838829492966
Validation loss: 2.4489018367574573

Epoch: 6| Step: 11
Training loss: 2.7159932509101083
Validation loss: 2.434848893964366

Epoch: 6| Step: 12
Training loss: 2.2822545596271606
Validation loss: 2.4399616904086434

Epoch: 6| Step: 13
Training loss: 1.9063331710931868
Validation loss: 2.4405519149509844

Epoch: 246| Step: 0
Training loss: 2.2281077594277323
Validation loss: 2.4473707698338103

Epoch: 6| Step: 1
Training loss: 1.6648101559798016
Validation loss: 2.4489983578575707

Epoch: 6| Step: 2
Training loss: 2.2778794981824095
Validation loss: 2.420529843899318

Epoch: 6| Step: 3
Training loss: 1.8447136381230682
Validation loss: 2.4444176666440636

Epoch: 6| Step: 4
Training loss: 1.963387710107562
Validation loss: 2.47297496135169

Epoch: 6| Step: 5
Training loss: 2.273678167130152
Validation loss: 2.435504514061675

Epoch: 6| Step: 6
Training loss: 1.9178394654746345
Validation loss: 2.450441620711955

Epoch: 6| Step: 7
Training loss: 1.7287499565295519
Validation loss: 2.4205504829557647

Epoch: 6| Step: 8
Training loss: 2.175664984235098
Validation loss: 2.441369150843796

Epoch: 6| Step: 9
Training loss: 1.9724832893311603
Validation loss: 2.4579368891785256

Epoch: 6| Step: 10
Training loss: 1.8483626001424138
Validation loss: 2.418253402816615

Epoch: 6| Step: 11
Training loss: 2.191346193194433
Validation loss: 2.4086780275946027

Epoch: 6| Step: 12
Training loss: 3.074398050084167
Validation loss: 2.3966872381995317

Epoch: 6| Step: 13
Training loss: 1.4641201012027154
Validation loss: 2.4343742351964397

Epoch: 247| Step: 0
Training loss: 2.2017571281351502
Validation loss: 2.3822037931857394

Epoch: 6| Step: 1
Training loss: 1.473505802128879
Validation loss: 2.4120567711610073

Epoch: 6| Step: 2
Training loss: 1.855074099682738
Validation loss: 2.412306523969155

Epoch: 6| Step: 3
Training loss: 2.65124992546862
Validation loss: 2.4571047337810406

Epoch: 6| Step: 4
Training loss: 1.9064275940262323
Validation loss: 2.444666725617162

Epoch: 6| Step: 5
Training loss: 1.9634215894118499
Validation loss: 2.437922197940651

Epoch: 6| Step: 6
Training loss: 2.012486816742171
Validation loss: 2.453915230130886

Epoch: 6| Step: 7
Training loss: 1.572692509861849
Validation loss: 2.4496956153791727

Epoch: 6| Step: 8
Training loss: 2.738913295792716
Validation loss: 2.4154455471817236

Epoch: 6| Step: 9
Training loss: 2.131603303414461
Validation loss: 2.4280895017338446

Epoch: 6| Step: 10
Training loss: 1.8279901438474493
Validation loss: 2.4603145328480087

Epoch: 6| Step: 11
Training loss: 2.6133832469701863
Validation loss: 2.4682534859393415

Epoch: 6| Step: 12
Training loss: 1.8368573420851493
Validation loss: 2.4555169514286344

Epoch: 6| Step: 13
Training loss: 1.7542750049519795
Validation loss: 2.412542043595103

Epoch: 248| Step: 0
Training loss: 1.8911454296260464
Validation loss: 2.4206741822755236

Epoch: 6| Step: 1
Training loss: 2.0008371508444207
Validation loss: 2.3967902121621862

Epoch: 6| Step: 2
Training loss: 2.490522157084574
Validation loss: 2.4525600263745377

Epoch: 6| Step: 3
Training loss: 2.143481054757539
Validation loss: 2.448550126415112

Epoch: 6| Step: 4
Training loss: 1.5842739456724406
Validation loss: 2.4607142214152224

Epoch: 6| Step: 5
Training loss: 2.1882539812136996
Validation loss: 2.4952588819289425

Epoch: 6| Step: 6
Training loss: 2.1508079075434345
Validation loss: 2.4557313749525504

Epoch: 6| Step: 7
Training loss: 1.7551212987252862
Validation loss: 2.4746618146099375

Epoch: 6| Step: 8
Training loss: 2.403052943306439
Validation loss: 2.4223161320116753

Epoch: 6| Step: 9
Training loss: 1.3545898314294436
Validation loss: 2.430537280137539

Epoch: 6| Step: 10
Training loss: 2.0108364503691134
Validation loss: 2.437827706427566

Epoch: 6| Step: 11
Training loss: 2.3501244897537
Validation loss: 2.4363308004222834

Epoch: 6| Step: 12
Training loss: 2.5873344773871
Validation loss: 2.4289732786323923

Epoch: 6| Step: 13
Training loss: 1.764516634470575
Validation loss: 2.4433116420124406

Epoch: 249| Step: 0
Training loss: 1.6950492127062546
Validation loss: 2.415072010097622

Epoch: 6| Step: 1
Training loss: 2.3809638184318125
Validation loss: 2.46472772295571

Epoch: 6| Step: 2
Training loss: 2.702358776711347
Validation loss: 2.454480441208077

Epoch: 6| Step: 3
Training loss: 1.9025450801646504
Validation loss: 2.4469422177106255

Epoch: 6| Step: 4
Training loss: 1.9899047338982951
Validation loss: 2.401050073168818

Epoch: 6| Step: 5
Training loss: 2.3078701996095554
Validation loss: 2.4594239210370477

Epoch: 6| Step: 6
Training loss: 1.9814756944789076
Validation loss: 2.450381204801048

Epoch: 6| Step: 7
Training loss: 2.7149659932010715
Validation loss: 2.42777406054216

Epoch: 6| Step: 8
Training loss: 1.3601774280877905
Validation loss: 2.414046411234671

Epoch: 6| Step: 9
Training loss: 1.9037040844174895
Validation loss: 2.422107726898928

Epoch: 6| Step: 10
Training loss: 2.49246472577662
Validation loss: 2.4244120308014088

Epoch: 6| Step: 11
Training loss: 1.6279454313453983
Validation loss: 2.3828570994656935

Epoch: 6| Step: 12
Training loss: 1.825238483994012
Validation loss: 2.4739447660133513

Epoch: 6| Step: 13
Training loss: 2.2124630682497597
Validation loss: 2.3781099957462577

Epoch: 250| Step: 0
Training loss: 2.3162460915068803
Validation loss: 2.4552905810757233

Epoch: 6| Step: 1
Training loss: 2.2370383654848487
Validation loss: 2.428568026833355

Epoch: 6| Step: 2
Training loss: 2.2354388072068985
Validation loss: 2.4574814480238705

Epoch: 6| Step: 3
Training loss: 1.4226180430209423
Validation loss: 2.456795284478415

Epoch: 6| Step: 4
Training loss: 1.710032881481965
Validation loss: 2.440586221384851

Epoch: 6| Step: 5
Training loss: 2.1141597029055417
Validation loss: 2.42155977302177

Epoch: 6| Step: 6
Training loss: 1.255649768666699
Validation loss: 2.413626582928207

Epoch: 6| Step: 7
Training loss: 2.9547532855476426
Validation loss: 2.441952738315753

Epoch: 6| Step: 8
Training loss: 1.909285395590983
Validation loss: 2.437360545529438

Epoch: 6| Step: 9
Training loss: 2.2451140016696622
Validation loss: 2.4422614345628353

Epoch: 6| Step: 10
Training loss: 1.9596857581954366
Validation loss: 2.442471462006669

Epoch: 6| Step: 11
Training loss: 2.2112156992872527
Validation loss: 2.44365969171252

Epoch: 6| Step: 12
Training loss: 1.7781741707008503
Validation loss: 2.433935787883602

Epoch: 6| Step: 13
Training loss: 2.067404839241126
Validation loss: 2.4287304620426284

Epoch: 251| Step: 0
Training loss: 1.9404156803879196
Validation loss: 2.420898484094349

Epoch: 6| Step: 1
Training loss: 2.398817796410043
Validation loss: 2.471774185518713

Epoch: 6| Step: 2
Training loss: 2.51797735512802
Validation loss: 2.4770718047564415

Epoch: 6| Step: 3
Training loss: 2.1071343848956388
Validation loss: 2.4432402275542415

Epoch: 6| Step: 4
Training loss: 1.9938005686119815
Validation loss: 2.4286370970619258

Epoch: 6| Step: 5
Training loss: 1.7825094756186195
Validation loss: 2.4370181677867446

Epoch: 6| Step: 6
Training loss: 1.87836066114736
Validation loss: 2.3973102149696426

Epoch: 6| Step: 7
Training loss: 2.031781875227008
Validation loss: 2.4516468782282237

Epoch: 6| Step: 8
Training loss: 2.6183502802633245
Validation loss: 2.459346452633249

Epoch: 6| Step: 9
Training loss: 1.940360511042028
Validation loss: 2.4299001451305466

Epoch: 6| Step: 10
Training loss: 2.253088632573177
Validation loss: 2.435679583679679

Epoch: 6| Step: 11
Training loss: 1.5609645928980491
Validation loss: 2.4444164311884897

Epoch: 6| Step: 12
Training loss: 1.805322378539953
Validation loss: 2.408992521818632

Epoch: 6| Step: 13
Training loss: 2.266271669901761
Validation loss: 2.4363984384181467

Epoch: 252| Step: 0
Training loss: 1.3380590179724483
Validation loss: 2.4763922101793914

Epoch: 6| Step: 1
Training loss: 2.288810742174825
Validation loss: 2.397184741084063

Epoch: 6| Step: 2
Training loss: 2.0970730956603494
Validation loss: 2.4326055538994518

Epoch: 6| Step: 3
Training loss: 2.8182021934578168
Validation loss: 2.446354494854564

Epoch: 6| Step: 4
Training loss: 2.1398512284091438
Validation loss: 2.4767874012645015

Epoch: 6| Step: 5
Training loss: 2.1533172122993554
Validation loss: 2.4945913104161357

Epoch: 6| Step: 6
Training loss: 1.7460491678234349
Validation loss: 2.4546726850197285

Epoch: 6| Step: 7
Training loss: 1.6643066227182501
Validation loss: 2.4163629328967

Epoch: 6| Step: 8
Training loss: 2.5068730291008365
Validation loss: 2.4477293066316137

Epoch: 6| Step: 9
Training loss: 1.749929017943464
Validation loss: 2.458513021463283

Epoch: 6| Step: 10
Training loss: 2.26656716586487
Validation loss: 2.4510909578284124

Epoch: 6| Step: 11
Training loss: 1.8208890992215365
Validation loss: 2.481148614617873

Epoch: 6| Step: 12
Training loss: 1.5331265375726006
Validation loss: 2.4238536710712455

Epoch: 6| Step: 13
Training loss: 1.5604846927633982
Validation loss: 2.457922508182559

Epoch: 253| Step: 0
Training loss: 1.9317697881053142
Validation loss: 2.46426405118297

Epoch: 6| Step: 1
Training loss: 1.5945253169291873
Validation loss: 2.4678044469075147

Epoch: 6| Step: 2
Training loss: 1.8972818130075881
Validation loss: 2.42632859549055

Epoch: 6| Step: 3
Training loss: 2.240566824313407
Validation loss: 2.4370056515589162

Epoch: 6| Step: 4
Training loss: 1.7747723769257515
Validation loss: 2.433987676617346

Epoch: 6| Step: 5
Training loss: 2.769573862369421
Validation loss: 2.4753191159564154

Epoch: 6| Step: 6
Training loss: 1.8734066232868205
Validation loss: 2.447422444956448

Epoch: 6| Step: 7
Training loss: 1.9348331063030257
Validation loss: 2.4484131069873754

Epoch: 6| Step: 8
Training loss: 2.232712560703492
Validation loss: 2.399650823450948

Epoch: 6| Step: 9
Training loss: 2.755974781369458
Validation loss: 2.4571563048759235

Epoch: 6| Step: 10
Training loss: 1.8876571690888935
Validation loss: 2.4441312182627195

Epoch: 6| Step: 11
Training loss: 2.1066199501306184
Validation loss: 2.4439679247991903

Epoch: 6| Step: 12
Training loss: 0.8243858204233437
Validation loss: 2.4274802283270365

Epoch: 6| Step: 13
Training loss: 2.2413412484243507
Validation loss: 2.415024194640583

Epoch: 254| Step: 0
Training loss: 1.9566267436870344
Validation loss: 2.396129072714771

Epoch: 6| Step: 1
Training loss: 2.0260858473745373
Validation loss: 2.4260057115598066

Epoch: 6| Step: 2
Training loss: 1.5851155673954855
Validation loss: 2.4667693635846786

Epoch: 6| Step: 3
Training loss: 2.0189518641590394
Validation loss: 2.4252625510699524

Epoch: 6| Step: 4
Training loss: 2.057391921550161
Validation loss: 2.4437102136939184

Epoch: 6| Step: 5
Training loss: 2.9979697351130494
Validation loss: 2.4364976249647845

Epoch: 6| Step: 6
Training loss: 1.753217872158814
Validation loss: 2.410997021887485

Epoch: 6| Step: 7
Training loss: 1.6931775973385517
Validation loss: 2.4243687419651283

Epoch: 6| Step: 8
Training loss: 2.012359457854378
Validation loss: 2.415717330624356

Epoch: 6| Step: 9
Training loss: 2.3969146168206263
Validation loss: 2.425340256459895

Epoch: 6| Step: 10
Training loss: 2.287262192335373
Validation loss: 2.4207590719070153

Epoch: 6| Step: 11
Training loss: 1.4492660473614034
Validation loss: 2.3977743888025693

Epoch: 6| Step: 12
Training loss: 2.127757359144724
Validation loss: 2.4382934966808216

Epoch: 6| Step: 13
Training loss: 1.5479305788683966
Validation loss: 2.4464217614058117

Epoch: 255| Step: 0
Training loss: 2.1581244683064797
Validation loss: 2.404615715274324

Epoch: 6| Step: 1
Training loss: 1.5235984521597092
Validation loss: 2.4310019600480093

Epoch: 6| Step: 2
Training loss: 2.872638229882119
Validation loss: 2.4300158675476804

Epoch: 6| Step: 3
Training loss: 1.9303149234212442
Validation loss: 2.415061392778597

Epoch: 6| Step: 4
Training loss: 2.3913639896102064
Validation loss: 2.4334090247064415

Epoch: 6| Step: 5
Training loss: 1.6420027261402392
Validation loss: 2.4546913688612833

Epoch: 6| Step: 6
Training loss: 1.882225863290443
Validation loss: 2.416226463267956

Epoch: 6| Step: 7
Training loss: 2.2719394428080846
Validation loss: 2.4444102675353503

Epoch: 6| Step: 8
Training loss: 1.8175980134585432
Validation loss: 2.463752435955924

Epoch: 6| Step: 9
Training loss: 1.79594005642283
Validation loss: 2.4623354726342828

Epoch: 6| Step: 10
Training loss: 1.7305387392378506
Validation loss: 2.4759333372828607

Epoch: 6| Step: 11
Training loss: 2.257079748026781
Validation loss: 2.409166936194154

Epoch: 6| Step: 12
Training loss: 1.801274230074008
Validation loss: 2.4603868865005056

Epoch: 6| Step: 13
Training loss: 2.404504811942683
Validation loss: 2.4582311199860065

Epoch: 256| Step: 0
Training loss: 1.8821679749316091
Validation loss: 2.420302305886794

Epoch: 6| Step: 1
Training loss: 2.9148507777865227
Validation loss: 2.428973417950744

Epoch: 6| Step: 2
Training loss: 1.8813921370942044
Validation loss: 2.4169497431987894

Epoch: 6| Step: 3
Training loss: 2.0135765608125413
Validation loss: 2.4285480270083797

Epoch: 6| Step: 4
Training loss: 2.267102200607747
Validation loss: 2.393600940778331

Epoch: 6| Step: 5
Training loss: 2.599752627122243
Validation loss: 2.4512327812788066

Epoch: 6| Step: 6
Training loss: 1.830055000541769
Validation loss: 2.371431979531307

Epoch: 6| Step: 7
Training loss: 1.8394912414425217
Validation loss: 2.424586909302733

Epoch: 6| Step: 8
Training loss: 1.7337542273504953
Validation loss: 2.4477317480140517

Epoch: 6| Step: 9
Training loss: 1.851328130769454
Validation loss: 2.4250591806417865

Epoch: 6| Step: 10
Training loss: 1.495382194529159
Validation loss: 2.4445073854786736

Epoch: 6| Step: 11
Training loss: 2.1467693719324137
Validation loss: 2.4136708227870574

Epoch: 6| Step: 12
Training loss: 1.6448868392006895
Validation loss: 2.4270187781991677

Epoch: 6| Step: 13
Training loss: 1.8067500230813727
Validation loss: 2.453091620845256

Epoch: 257| Step: 0
Training loss: 2.187977656939029
Validation loss: 2.4813835443483687

Epoch: 6| Step: 1
Training loss: 1.8555221389317336
Validation loss: 2.4431052954692194

Epoch: 6| Step: 2
Training loss: 1.9433003018856132
Validation loss: 2.4268432921695604

Epoch: 6| Step: 3
Training loss: 2.4844029263060445
Validation loss: 2.4462811607839243

Epoch: 6| Step: 4
Training loss: 1.9438810788816863
Validation loss: 2.4041986723046724

Epoch: 6| Step: 5
Training loss: 1.945151081052291
Validation loss: 2.3994258078810784

Epoch: 6| Step: 6
Training loss: 1.9035489692170773
Validation loss: 2.4571167125485656

Epoch: 6| Step: 7
Training loss: 2.1072948230135844
Validation loss: 2.370431920677977

Epoch: 6| Step: 8
Training loss: 2.563890870537709
Validation loss: 2.412796792607474

Epoch: 6| Step: 9
Training loss: 2.3337431842886276
Validation loss: 2.369446121404241

Epoch: 6| Step: 10
Training loss: 1.2973291452186027
Validation loss: 2.4466624785589146

Epoch: 6| Step: 11
Training loss: 1.9622405081082102
Validation loss: 2.4153592289752863

Epoch: 6| Step: 12
Training loss: 1.9578014084242255
Validation loss: 2.4014667443192192

Epoch: 6| Step: 13
Training loss: 1.8452452722459671
Validation loss: 2.411315745427754

Epoch: 258| Step: 0
Training loss: 1.8142155388046466
Validation loss: 2.4599589563779682

Epoch: 6| Step: 1
Training loss: 2.1496141575422674
Validation loss: 2.395017002417095

Epoch: 6| Step: 2
Training loss: 1.7519809546328173
Validation loss: 2.446952163426106

Epoch: 6| Step: 3
Training loss: 1.630636124549194
Validation loss: 2.45161695222299

Epoch: 6| Step: 4
Training loss: 2.3563077074669314
Validation loss: 2.42188723240521

Epoch: 6| Step: 5
Training loss: 2.016081056085551
Validation loss: 2.420938822815598

Epoch: 6| Step: 6
Training loss: 2.507725414059389
Validation loss: 2.4360244666518542

Epoch: 6| Step: 7
Training loss: 2.244689183798138
Validation loss: 2.4144488174653795

Epoch: 6| Step: 8
Training loss: 2.207774349458069
Validation loss: 2.434226617628789

Epoch: 6| Step: 9
Training loss: 1.8568892331959737
Validation loss: 2.4511031045692966

Epoch: 6| Step: 10
Training loss: 2.404925192226631
Validation loss: 2.4495824594913715

Epoch: 6| Step: 11
Training loss: 1.710810547739032
Validation loss: 2.4416527434579294

Epoch: 6| Step: 12
Training loss: 1.9172904685675527
Validation loss: 2.4604706143753767

Epoch: 6| Step: 13
Training loss: 1.271023246249418
Validation loss: 2.4001051226020214

Epoch: 259| Step: 0
Training loss: 1.6552937464185542
Validation loss: 2.454455689664223

Epoch: 6| Step: 1
Training loss: 1.4031737695047422
Validation loss: 2.458496766856542

Epoch: 6| Step: 2
Training loss: 1.91645395784832
Validation loss: 2.4167925943642397

Epoch: 6| Step: 3
Training loss: 1.8437407541851398
Validation loss: 2.4275007047939745

Epoch: 6| Step: 4
Training loss: 2.3908958530949604
Validation loss: 2.4218445129275152

Epoch: 6| Step: 5
Training loss: 2.378506832072093
Validation loss: 2.403784279228129

Epoch: 6| Step: 6
Training loss: 1.9286004220710664
Validation loss: 2.430831728117683

Epoch: 6| Step: 7
Training loss: 1.8719769585405919
Validation loss: 2.4317801470956124

Epoch: 6| Step: 8
Training loss: 2.383970885822275
Validation loss: 2.423499929279424

Epoch: 6| Step: 9
Training loss: 1.941859294139061
Validation loss: 2.3855816438868658

Epoch: 6| Step: 10
Training loss: 2.328077891852467
Validation loss: 2.4281294338101214

Epoch: 6| Step: 11
Training loss: 2.432986359701871
Validation loss: 2.404793952812121

Epoch: 6| Step: 12
Training loss: 1.6072022669271582
Validation loss: 2.420265318585182

Epoch: 6| Step: 13
Training loss: 1.4024315596692318
Validation loss: 2.4286934046499606

Epoch: 260| Step: 0
Training loss: 2.489589568786048
Validation loss: 2.4275884541460755

Epoch: 6| Step: 1
Training loss: 1.909207660440853
Validation loss: 2.42778972676513

Epoch: 6| Step: 2
Training loss: 1.5935555133707566
Validation loss: 2.437843338539616

Epoch: 6| Step: 3
Training loss: 1.7003198322796382
Validation loss: 2.3774492936024596

Epoch: 6| Step: 4
Training loss: 2.518433608257895
Validation loss: 2.4097452549037883

Epoch: 6| Step: 5
Training loss: 1.8142247379642107
Validation loss: 2.389260965296159

Epoch: 6| Step: 6
Training loss: 1.8989636355389012
Validation loss: 2.4170647184780116

Epoch: 6| Step: 7
Training loss: 1.8814473881883793
Validation loss: 2.426683113964078

Epoch: 6| Step: 8
Training loss: 2.04505863114975
Validation loss: 2.3838645179477895

Epoch: 6| Step: 9
Training loss: 1.436571401784658
Validation loss: 2.41417227853629

Epoch: 6| Step: 10
Training loss: 2.6472837022240427
Validation loss: 2.401188727093096

Epoch: 6| Step: 11
Training loss: 2.2491034734931072
Validation loss: 2.3798912206709932

Epoch: 6| Step: 12
Training loss: 2.1022032714542473
Validation loss: 2.4006019310441475

Epoch: 6| Step: 13
Training loss: 1.9371631698692804
Validation loss: 2.426562487121379

Epoch: 261| Step: 0
Training loss: 1.7373298012782212
Validation loss: 2.4087235918826133

Epoch: 6| Step: 1
Training loss: 2.192238824614679
Validation loss: 2.4170399046283566

Epoch: 6| Step: 2
Training loss: 1.782347090316616
Validation loss: 2.4573248860848733

Epoch: 6| Step: 3
Training loss: 2.4658925383914796
Validation loss: 2.457388014272273

Epoch: 6| Step: 4
Training loss: 1.81919230428056
Validation loss: 2.3953510678256715

Epoch: 6| Step: 5
Training loss: 1.936182866468771
Validation loss: 2.4263618763416677

Epoch: 6| Step: 6
Training loss: 1.6843950882600234
Validation loss: 2.4354138982946165

Epoch: 6| Step: 7
Training loss: 1.4667792389034215
Validation loss: 2.4599499376150042

Epoch: 6| Step: 8
Training loss: 2.133081887248476
Validation loss: 2.4246365102121765

Epoch: 6| Step: 9
Training loss: 1.676188315011103
Validation loss: 2.383224574862566

Epoch: 6| Step: 10
Training loss: 2.793565379620173
Validation loss: 2.4284721019677042

Epoch: 6| Step: 11
Training loss: 1.847730316548622
Validation loss: 2.4050428145468814

Epoch: 6| Step: 12
Training loss: 2.301849479937773
Validation loss: 2.3874702074214733

Epoch: 6| Step: 13
Training loss: 1.7319530725795302
Validation loss: 2.401153777159338

Epoch: 262| Step: 0
Training loss: 1.697484677207679
Validation loss: 2.405305942253498

Epoch: 6| Step: 1
Training loss: 2.0383628141694308
Validation loss: 2.397949516493533

Epoch: 6| Step: 2
Training loss: 1.920620144193341
Validation loss: 2.461432801650612

Epoch: 6| Step: 3
Training loss: 1.9150256166662087
Validation loss: 2.408620771538079

Epoch: 6| Step: 4
Training loss: 1.8696780015263268
Validation loss: 2.420215248345525

Epoch: 6| Step: 5
Training loss: 1.5648092371790838
Validation loss: 2.428426757784349

Epoch: 6| Step: 6
Training loss: 1.6171185022645096
Validation loss: 2.44517002072633

Epoch: 6| Step: 7
Training loss: 2.618297739966703
Validation loss: 2.419422874246059

Epoch: 6| Step: 8
Training loss: 2.0132420374315996
Validation loss: 2.406561115034284

Epoch: 6| Step: 9
Training loss: 2.020495658531896
Validation loss: 2.405719693849454

Epoch: 6| Step: 10
Training loss: 1.6798823753687229
Validation loss: 2.3961322032671624

Epoch: 6| Step: 11
Training loss: 2.849611717678098
Validation loss: 2.4204175847703104

Epoch: 6| Step: 12
Training loss: 1.8129031292073752
Validation loss: 2.4162180918839153

Epoch: 6| Step: 13
Training loss: 2.271114460286763
Validation loss: 2.4593720415139284

Epoch: 263| Step: 0
Training loss: 2.662802389819835
Validation loss: 2.4094140955123993

Epoch: 6| Step: 1
Training loss: 1.9085448163162035
Validation loss: 2.4321451721181764

Epoch: 6| Step: 2
Training loss: 1.621609231272178
Validation loss: 2.418132161186841

Epoch: 6| Step: 3
Training loss: 1.4286376767465143
Validation loss: 2.4427679040501227

Epoch: 6| Step: 4
Training loss: 2.5849019077364677
Validation loss: 2.4324988613128737

Epoch: 6| Step: 5
Training loss: 1.861230453378325
Validation loss: 2.4062583613160524

Epoch: 6| Step: 6
Training loss: 2.6366784212772334
Validation loss: 2.4620872685537756

Epoch: 6| Step: 7
Training loss: 1.5430449261753711
Validation loss: 2.4313564476631266

Epoch: 6| Step: 8
Training loss: 2.3228534182389797
Validation loss: 2.4689787414343574

Epoch: 6| Step: 9
Training loss: 1.6898016597675087
Validation loss: 2.403379842594231

Epoch: 6| Step: 10
Training loss: 1.7796586272967954
Validation loss: 2.4117096722760922

Epoch: 6| Step: 11
Training loss: 1.9199437308013376
Validation loss: 2.460680795183078

Epoch: 6| Step: 12
Training loss: 1.6194356136542911
Validation loss: 2.4863654338635595

Epoch: 6| Step: 13
Training loss: 2.0137864828564016
Validation loss: 2.412735520651847

Epoch: 264| Step: 0
Training loss: 1.5524593469576904
Validation loss: 2.467306164258494

Epoch: 6| Step: 1
Training loss: 2.1931106548650074
Validation loss: 2.397603409849554

Epoch: 6| Step: 2
Training loss: 2.3013395140569677
Validation loss: 2.345521695048626

Epoch: 6| Step: 3
Training loss: 2.001376155424794
Validation loss: 2.479016157693204

Epoch: 6| Step: 4
Training loss: 1.8845718205086464
Validation loss: 2.431152359040193

Epoch: 6| Step: 5
Training loss: 2.194433070071502
Validation loss: 2.399612849039619

Epoch: 6| Step: 6
Training loss: 1.5535979166889071
Validation loss: 2.4446270925102302

Epoch: 6| Step: 7
Training loss: 2.355053006201309
Validation loss: 2.423494452380404

Epoch: 6| Step: 8
Training loss: 1.626797342341109
Validation loss: 2.4605563382769673

Epoch: 6| Step: 9
Training loss: 2.0160196790264533
Validation loss: 2.4130075179633814

Epoch: 6| Step: 10
Training loss: 1.6522336521849303
Validation loss: 2.448994618119186

Epoch: 6| Step: 11
Training loss: 1.6381207927371841
Validation loss: 2.4525509124592846

Epoch: 6| Step: 12
Training loss: 2.043776868357766
Validation loss: 2.4308497768133375

Epoch: 6| Step: 13
Training loss: 2.8918698491400394
Validation loss: 2.4282534480666786

Epoch: 265| Step: 0
Training loss: 1.891974731881449
Validation loss: 2.4427926528062835

Epoch: 6| Step: 1
Training loss: 2.2969311558093306
Validation loss: 2.3829758218127512

Epoch: 6| Step: 2
Training loss: 1.7359106465210352
Validation loss: 2.3796358701589533

Epoch: 6| Step: 3
Training loss: 2.1466103292066174
Validation loss: 2.4643871822607784

Epoch: 6| Step: 4
Training loss: 1.9029900238328878
Validation loss: 2.4292620905783244

Epoch: 6| Step: 5
Training loss: 1.8704615661824746
Validation loss: 2.424971455527719

Epoch: 6| Step: 6
Training loss: 1.3526416946197328
Validation loss: 2.4003177044574393

Epoch: 6| Step: 7
Training loss: 1.984874031816673
Validation loss: 2.4179256967553058

Epoch: 6| Step: 8
Training loss: 2.6191606513729155
Validation loss: 2.431613797532653

Epoch: 6| Step: 9
Training loss: 1.6809961233644644
Validation loss: 2.4541642418949396

Epoch: 6| Step: 10
Training loss: 2.486206627069957
Validation loss: 2.4300875772743953

Epoch: 6| Step: 11
Training loss: 1.6399357392351692
Validation loss: 2.3960991268379224

Epoch: 6| Step: 12
Training loss: 1.926150149283022
Validation loss: 2.439917107695783

Epoch: 6| Step: 13
Training loss: 1.9406074707418983
Validation loss: 2.3961001325649662

Epoch: 266| Step: 0
Training loss: 1.7980602833249788
Validation loss: 2.4205497182748195

Epoch: 6| Step: 1
Training loss: 1.1745676767136413
Validation loss: 2.3829209094415034

Epoch: 6| Step: 2
Training loss: 1.7814217200241986
Validation loss: 2.462248155720561

Epoch: 6| Step: 3
Training loss: 1.9643746454989253
Validation loss: 2.4490324596115594

Epoch: 6| Step: 4
Training loss: 2.219831820810555
Validation loss: 2.4170058669731413

Epoch: 6| Step: 5
Training loss: 1.9176602552507787
Validation loss: 2.4580721752074717

Epoch: 6| Step: 6
Training loss: 1.9298849275112386
Validation loss: 2.466806822766244

Epoch: 6| Step: 7
Training loss: 2.5923846224471947
Validation loss: 2.4279149050834583

Epoch: 6| Step: 8
Training loss: 2.30907475193463
Validation loss: 2.4212598788922985

Epoch: 6| Step: 9
Training loss: 1.9981244352767666
Validation loss: 2.4141655568838845

Epoch: 6| Step: 10
Training loss: 1.8272991434290162
Validation loss: 2.419799099197497

Epoch: 6| Step: 11
Training loss: 1.9044252010047347
Validation loss: 2.475364086882291

Epoch: 6| Step: 12
Training loss: 1.9746716769659516
Validation loss: 2.4296614064495525

Epoch: 6| Step: 13
Training loss: 2.392199029278022
Validation loss: 2.420814053662351

Epoch: 267| Step: 0
Training loss: 1.7206422966067976
Validation loss: 2.42922219506158

Epoch: 6| Step: 1
Training loss: 2.3875067825620486
Validation loss: 2.4502199412442165

Epoch: 6| Step: 2
Training loss: 1.9954911309611243
Validation loss: 2.397452178725884

Epoch: 6| Step: 3
Training loss: 2.072593842741263
Validation loss: 2.3927220682755164

Epoch: 6| Step: 4
Training loss: 1.437649843450218
Validation loss: 2.3951234519308953

Epoch: 6| Step: 5
Training loss: 2.1202451578576818
Validation loss: 2.3861013840231213

Epoch: 6| Step: 6
Training loss: 2.0084119562400584
Validation loss: 2.4069885614159485

Epoch: 6| Step: 7
Training loss: 1.8283985291955174
Validation loss: 2.442198527360319

Epoch: 6| Step: 8
Training loss: 1.5881645463735905
Validation loss: 2.378845292731591

Epoch: 6| Step: 9
Training loss: 2.144474438746874
Validation loss: 2.3896869403691787

Epoch: 6| Step: 10
Training loss: 1.8315511696697229
Validation loss: 2.4388300125503193

Epoch: 6| Step: 11
Training loss: 2.5393391150404305
Validation loss: 2.4255415742703836

Epoch: 6| Step: 12
Training loss: 2.2949985442645207
Validation loss: 2.452185304576396

Epoch: 6| Step: 13
Training loss: 1.5491007195783602
Validation loss: 2.4139589639994496

Epoch: 268| Step: 0
Training loss: 2.1341611070819946
Validation loss: 2.3849130147065547

Epoch: 6| Step: 1
Training loss: 1.8516054430138487
Validation loss: 2.4337326081559665

Epoch: 6| Step: 2
Training loss: 2.244882061075737
Validation loss: 2.382346698023801

Epoch: 6| Step: 3
Training loss: 1.9264346362623201
Validation loss: 2.3546545024346677

Epoch: 6| Step: 4
Training loss: 1.855339415208665
Validation loss: 2.420954644458513

Epoch: 6| Step: 5
Training loss: 1.8042995812114366
Validation loss: 2.472501365420443

Epoch: 6| Step: 6
Training loss: 2.0743325412378275
Validation loss: 2.404879492543901

Epoch: 6| Step: 7
Training loss: 1.9651656446454522
Validation loss: 2.4436277317553685

Epoch: 6| Step: 8
Training loss: 1.7975702018982633
Validation loss: 2.4200259662876844

Epoch: 6| Step: 9
Training loss: 2.760085771029578
Validation loss: 2.4399252953248096

Epoch: 6| Step: 10
Training loss: 1.594044676821092
Validation loss: 2.3702603505589717

Epoch: 6| Step: 11
Training loss: 1.4196015512193
Validation loss: 2.4104901651523756

Epoch: 6| Step: 12
Training loss: 2.31941776171455
Validation loss: 2.381027286690944

Epoch: 6| Step: 13
Training loss: 1.93723350661037
Validation loss: 2.4405820139238212

Epoch: 269| Step: 0
Training loss: 1.881811105181255
Validation loss: 2.4153208869811595

Epoch: 6| Step: 1
Training loss: 1.6261652656547316
Validation loss: 2.4263325339359567

Epoch: 6| Step: 2
Training loss: 1.2378620677674246
Validation loss: 2.4412609993334136

Epoch: 6| Step: 3
Training loss: 1.735282179562246
Validation loss: 2.3667486734306133

Epoch: 6| Step: 4
Training loss: 1.9357735725316478
Validation loss: 2.427459853072985

Epoch: 6| Step: 5
Training loss: 2.314842481094615
Validation loss: 2.409593450594645

Epoch: 6| Step: 6
Training loss: 2.2155384945358687
Validation loss: 2.416022820326505

Epoch: 6| Step: 7
Training loss: 1.606960819167916
Validation loss: 2.3937575762194623

Epoch: 6| Step: 8
Training loss: 2.5529803717187773
Validation loss: 2.413726924557525

Epoch: 6| Step: 9
Training loss: 1.9971580579363584
Validation loss: 2.3893525583492266

Epoch: 6| Step: 10
Training loss: 1.8209646472966194
Validation loss: 2.4316763639222625

Epoch: 6| Step: 11
Training loss: 2.116261973203529
Validation loss: 2.4140215791034336

Epoch: 6| Step: 12
Training loss: 2.3998114909208113
Validation loss: 2.417134518327773

Epoch: 6| Step: 13
Training loss: 1.2444357529452106
Validation loss: 2.3997870787476043

Epoch: 270| Step: 0
Training loss: 1.8682883620599346
Validation loss: 2.4176467871203156

Epoch: 6| Step: 1
Training loss: 1.8755494902022058
Validation loss: 2.3922297709185987

Epoch: 6| Step: 2
Training loss: 1.8524495506881824
Validation loss: 2.394589878748243

Epoch: 6| Step: 3
Training loss: 2.03688453318591
Validation loss: 2.435915344824131

Epoch: 6| Step: 4
Training loss: 1.5002736795619744
Validation loss: 2.3931162817799025

Epoch: 6| Step: 5
Training loss: 1.794668152718309
Validation loss: 2.4478505412124507

Epoch: 6| Step: 6
Training loss: 2.1357635092314182
Validation loss: 2.3908900012775876

Epoch: 6| Step: 7
Training loss: 1.6274712185285096
Validation loss: 2.427920530923743

Epoch: 6| Step: 8
Training loss: 2.078615059111437
Validation loss: 2.4207446151346668

Epoch: 6| Step: 9
Training loss: 2.174192660220083
Validation loss: 2.4050139624712

Epoch: 6| Step: 10
Training loss: 2.2684794367093013
Validation loss: 2.4203456637456724

Epoch: 6| Step: 11
Training loss: 1.8059851534751756
Validation loss: 2.4342667576029657

Epoch: 6| Step: 12
Training loss: 2.2256402498240733
Validation loss: 2.4377288269215636

Epoch: 6| Step: 13
Training loss: 1.6468409902111967
Validation loss: 2.3879981968775104

Epoch: 271| Step: 0
Training loss: 1.7500478193016695
Validation loss: 2.439055821074055

Epoch: 6| Step: 1
Training loss: 2.044131238184305
Validation loss: 2.3988288607394512

Epoch: 6| Step: 2
Training loss: 1.405316869768369
Validation loss: 2.434469136654197

Epoch: 6| Step: 3
Training loss: 1.9194179428498908
Validation loss: 2.4032218618829253

Epoch: 6| Step: 4
Training loss: 1.8402200301924454
Validation loss: 2.3930778426565023

Epoch: 6| Step: 5
Training loss: 1.2758386826771608
Validation loss: 2.4587430030381245

Epoch: 6| Step: 6
Training loss: 2.279925654353642
Validation loss: 2.383751568869474

Epoch: 6| Step: 7
Training loss: 3.0312651014443417
Validation loss: 2.3873816782718316

Epoch: 6| Step: 8
Training loss: 1.6322091918181667
Validation loss: 2.3886084633645344

Epoch: 6| Step: 9
Training loss: 1.8693322030706612
Validation loss: 2.4139892086992876

Epoch: 6| Step: 10
Training loss: 2.3206659426725915
Validation loss: 2.4273265209958423

Epoch: 6| Step: 11
Training loss: 1.9124583470414986
Validation loss: 2.400765067787937

Epoch: 6| Step: 12
Training loss: 1.6953456892992609
Validation loss: 2.3778993922213134

Epoch: 6| Step: 13
Training loss: 1.856041877972937
Validation loss: 2.380581142618455

Epoch: 272| Step: 0
Training loss: 2.082701727174345
Validation loss: 2.414240905008102

Epoch: 6| Step: 1
Training loss: 1.8953971850163478
Validation loss: 2.394696921063016

Epoch: 6| Step: 2
Training loss: 2.4146211341968753
Validation loss: 2.416702111832565

Epoch: 6| Step: 3
Training loss: 1.6403830940287
Validation loss: 2.4072704732262498

Epoch: 6| Step: 4
Training loss: 2.1002754893573052
Validation loss: 2.410842164747469

Epoch: 6| Step: 5
Training loss: 1.2540468511453444
Validation loss: 2.3940478025237866

Epoch: 6| Step: 6
Training loss: 1.7498360284552672
Validation loss: 2.4058879158499793

Epoch: 6| Step: 7
Training loss: 2.1270611808238553
Validation loss: 2.3762554715797037

Epoch: 6| Step: 8
Training loss: 1.2431255613299868
Validation loss: 2.458042215831746

Epoch: 6| Step: 9
Training loss: 2.091284709672014
Validation loss: 2.4263402565458314

Epoch: 6| Step: 10
Training loss: 2.4873957473148027
Validation loss: 2.416512173207661

Epoch: 6| Step: 11
Training loss: 2.106808153221935
Validation loss: 2.4358653899960268

Epoch: 6| Step: 12
Training loss: 1.9685893523052602
Validation loss: 2.4437709314290035

Epoch: 6| Step: 13
Training loss: 2.221337864328887
Validation loss: 2.400613766725338

Epoch: 273| Step: 0
Training loss: 1.9595413405098745
Validation loss: 2.420811628552505

Epoch: 6| Step: 1
Training loss: 1.562483825599878
Validation loss: 2.416060668388543

Epoch: 6| Step: 2
Training loss: 1.737181171831853
Validation loss: 2.4505669501408804

Epoch: 6| Step: 3
Training loss: 2.849161051361302
Validation loss: 2.3633540745098713

Epoch: 6| Step: 4
Training loss: 1.710818351881925
Validation loss: 2.4151830183681913

Epoch: 6| Step: 5
Training loss: 1.9516051826054837
Validation loss: 2.424331504223641

Epoch: 6| Step: 6
Training loss: 2.2007422582214353
Validation loss: 2.392374083955821

Epoch: 6| Step: 7
Training loss: 1.2887971547155153
Validation loss: 2.4103663478875905

Epoch: 6| Step: 8
Training loss: 1.688585144399439
Validation loss: 2.3929755188614403

Epoch: 6| Step: 9
Training loss: 2.313470894390745
Validation loss: 2.418169039055201

Epoch: 6| Step: 10
Training loss: 1.9861685389624377
Validation loss: 2.404799065602513

Epoch: 6| Step: 11
Training loss: 1.9970810570462798
Validation loss: 2.410348511423617

Epoch: 6| Step: 12
Training loss: 1.970670217762915
Validation loss: 2.407634052063712

Epoch: 6| Step: 13
Training loss: 2.109074210867655
Validation loss: 2.3881227713053472

Epoch: 274| Step: 0
Training loss: 1.8195300078070442
Validation loss: 2.4659483217265388

Epoch: 6| Step: 1
Training loss: 1.9544454154811632
Validation loss: 2.433165415933062

Epoch: 6| Step: 2
Training loss: 1.4456341359814198
Validation loss: 2.3948835147838294

Epoch: 6| Step: 3
Training loss: 1.9707898063234999
Validation loss: 2.3971837935617413

Epoch: 6| Step: 4
Training loss: 1.810512637048174
Validation loss: 2.3936305708967023

Epoch: 6| Step: 5
Training loss: 1.5966593796491417
Validation loss: 2.451752871917533

Epoch: 6| Step: 6
Training loss: 2.0687474507203776
Validation loss: 2.4748497143466888

Epoch: 6| Step: 7
Training loss: 2.9616992946781697
Validation loss: 2.4716974620327705

Epoch: 6| Step: 8
Training loss: 1.913518587020658
Validation loss: 2.427167820127855

Epoch: 6| Step: 9
Training loss: 2.1904648443386274
Validation loss: 2.4159006263221334

Epoch: 6| Step: 10
Training loss: 1.8789679820493292
Validation loss: 2.4469496343077255

Epoch: 6| Step: 11
Training loss: 2.0867616546915966
Validation loss: 2.465140470772918

Epoch: 6| Step: 12
Training loss: 1.7082100645422014
Validation loss: 2.4073458657086464

Epoch: 6| Step: 13
Training loss: 1.6884406258601614
Validation loss: 2.466511916611279

Epoch: 275| Step: 0
Training loss: 1.7491401194677738
Validation loss: 2.3744173765536627

Epoch: 6| Step: 1
Training loss: 2.1533607254215075
Validation loss: 2.4829326789019883

Epoch: 6| Step: 2
Training loss: 2.1847544197328532
Validation loss: 2.3929464570088363

Epoch: 6| Step: 3
Training loss: 2.0702946500188637
Validation loss: 2.421340047058559

Epoch: 6| Step: 4
Training loss: 1.7898107571435362
Validation loss: 2.3594558415114455

Epoch: 6| Step: 5
Training loss: 2.1077638477679996
Validation loss: 2.4015701314213094

Epoch: 6| Step: 6
Training loss: 1.6563855961408949
Validation loss: 2.3490389132586302

Epoch: 6| Step: 7
Training loss: 1.7576392872558422
Validation loss: 2.369939952827982

Epoch: 6| Step: 8
Training loss: 1.5948339030202037
Validation loss: 2.3972960819741305

Epoch: 6| Step: 9
Training loss: 2.4489229988027272
Validation loss: 2.41372913480495

Epoch: 6| Step: 10
Training loss: 1.6020413310973565
Validation loss: 2.3854204215352324

Epoch: 6| Step: 11
Training loss: 2.1978315243493594
Validation loss: 2.3849572481159926

Epoch: 6| Step: 12
Training loss: 1.7763512827206822
Validation loss: 2.3883911732034457

Epoch: 6| Step: 13
Training loss: 1.2583656279522877
Validation loss: 2.4311008073437024

Epoch: 276| Step: 0
Training loss: 2.2316245910613386
Validation loss: 2.3791691725571713

Epoch: 6| Step: 1
Training loss: 2.381364125798466
Validation loss: 2.4090380077943596

Epoch: 6| Step: 2
Training loss: 1.8838685425819872
Validation loss: 2.396746121193312

Epoch: 6| Step: 3
Training loss: 1.9340761758108473
Validation loss: 2.3865006094076096

Epoch: 6| Step: 4
Training loss: 1.8190258537917199
Validation loss: 2.373869088585513

Epoch: 6| Step: 5
Training loss: 1.395232037897351
Validation loss: 2.4037447010147166

Epoch: 6| Step: 6
Training loss: 2.035109858066491
Validation loss: 2.404610526931533

Epoch: 6| Step: 7
Training loss: 2.243411803193358
Validation loss: 2.41493406198923

Epoch: 6| Step: 8
Training loss: 1.8010252416982198
Validation loss: 2.38099907011116

Epoch: 6| Step: 9
Training loss: 1.9210259027278669
Validation loss: 2.36887867967354

Epoch: 6| Step: 10
Training loss: 2.0568810419337584
Validation loss: 2.4321207577274935

Epoch: 6| Step: 11
Training loss: 1.5042554573770321
Validation loss: 2.383618735600385

Epoch: 6| Step: 12
Training loss: 2.0079890667059166
Validation loss: 2.4465018563852716

Epoch: 6| Step: 13
Training loss: 1.7449827478643558
Validation loss: 2.420420798298659

Epoch: 277| Step: 0
Training loss: 1.6645728389837282
Validation loss: 2.368336525969508

Epoch: 6| Step: 1
Training loss: 1.8048019042640813
Validation loss: 2.3613594411576306

Epoch: 6| Step: 2
Training loss: 2.0436282433688193
Validation loss: 2.450866106480192

Epoch: 6| Step: 3
Training loss: 1.9685376976226974
Validation loss: 2.4281800023060103

Epoch: 6| Step: 4
Training loss: 1.7682672495572986
Validation loss: 2.4628223676040513

Epoch: 6| Step: 5
Training loss: 1.3176966831260195
Validation loss: 2.4459792122693766

Epoch: 6| Step: 6
Training loss: 2.0805608484766474
Validation loss: 2.4907289960664216

Epoch: 6| Step: 7
Training loss: 1.9123641595406662
Validation loss: 2.430235939946311

Epoch: 6| Step: 8
Training loss: 2.1632620642883427
Validation loss: 2.4606557877221427

Epoch: 6| Step: 9
Training loss: 2.3122155298069678
Validation loss: 2.432268714958988

Epoch: 6| Step: 10
Training loss: 2.2318252206686777
Validation loss: 2.4594254845982126

Epoch: 6| Step: 11
Training loss: 2.341632242277799
Validation loss: 2.3948921384399062

Epoch: 6| Step: 12
Training loss: 1.4785278803570678
Validation loss: 2.4330355196344873

Epoch: 6| Step: 13
Training loss: 1.8684289867043204
Validation loss: 2.443210932033879

Epoch: 278| Step: 0
Training loss: 1.4433412047443903
Validation loss: 2.4168295170698975

Epoch: 6| Step: 1
Training loss: 1.8390733924355174
Validation loss: 2.387232345274242

Epoch: 6| Step: 2
Training loss: 1.4593685926014905
Validation loss: 2.3783618729745797

Epoch: 6| Step: 3
Training loss: 1.8661391375676464
Validation loss: 2.4316419180794013

Epoch: 6| Step: 4
Training loss: 2.083584605004889
Validation loss: 2.422187425651285

Epoch: 6| Step: 5
Training loss: 1.8611598704326062
Validation loss: 2.4091089633503016

Epoch: 6| Step: 6
Training loss: 2.046020329379066
Validation loss: 2.3682839695613045

Epoch: 6| Step: 7
Training loss: 1.5714545959943382
Validation loss: 2.4273010590021378

Epoch: 6| Step: 8
Training loss: 1.522515277002919
Validation loss: 2.453807378756709

Epoch: 6| Step: 9
Training loss: 2.389558242448837
Validation loss: 2.3874826161016336

Epoch: 6| Step: 10
Training loss: 2.4564077195643046
Validation loss: 2.399847848061694

Epoch: 6| Step: 11
Training loss: 1.954398998555986
Validation loss: 2.410119010991413

Epoch: 6| Step: 12
Training loss: 2.2482227087647626
Validation loss: 2.379097142220282

Epoch: 6| Step: 13
Training loss: 2.026428604114451
Validation loss: 2.4105983758135094

Epoch: 279| Step: 0
Training loss: 1.7759206587063223
Validation loss: 2.415855366653846

Epoch: 6| Step: 1
Training loss: 2.3507882804930285
Validation loss: 2.4007093107759907

Epoch: 6| Step: 2
Training loss: 2.248154413085472
Validation loss: 2.381922194072435

Epoch: 6| Step: 3
Training loss: 1.961232318980822
Validation loss: 2.4228961444473356

Epoch: 6| Step: 4
Training loss: 1.9968111723487947
Validation loss: 2.4333430156298803

Epoch: 6| Step: 5
Training loss: 1.7084717423109175
Validation loss: 2.4306743827950794

Epoch: 6| Step: 6
Training loss: 1.6386413207632697
Validation loss: 2.4149437085283605

Epoch: 6| Step: 7
Training loss: 1.9902543805345738
Validation loss: 2.458788624339422

Epoch: 6| Step: 8
Training loss: 1.853823026323507
Validation loss: 2.4508795806744708

Epoch: 6| Step: 9
Training loss: 2.0173537063973406
Validation loss: 2.470463703265002

Epoch: 6| Step: 10
Training loss: 1.729288288419994
Validation loss: 2.480536212799871

Epoch: 6| Step: 11
Training loss: 1.994401188041587
Validation loss: 2.478297605447814

Epoch: 6| Step: 12
Training loss: 1.8925378753822788
Validation loss: 2.4179837688618604

Epoch: 6| Step: 13
Training loss: 2.081172687366109
Validation loss: 2.451197877621873

Epoch: 280| Step: 0
Training loss: 1.5318149380872088
Validation loss: 2.4116510844736236

Epoch: 6| Step: 1
Training loss: 1.755987007840349
Validation loss: 2.4104547773611014

Epoch: 6| Step: 2
Training loss: 2.1831757447345965
Validation loss: 2.3833430432028555

Epoch: 6| Step: 3
Training loss: 1.7983715956715298
Validation loss: 2.440391943195863

Epoch: 6| Step: 4
Training loss: 1.8253010514574133
Validation loss: 2.4208770294196618

Epoch: 6| Step: 5
Training loss: 1.8450828519170168
Validation loss: 2.4237332405594385

Epoch: 6| Step: 6
Training loss: 1.554190321359625
Validation loss: 2.382418343610528

Epoch: 6| Step: 7
Training loss: 2.041775239925074
Validation loss: 2.4245143728465925

Epoch: 6| Step: 8
Training loss: 1.7058984415251253
Validation loss: 2.421167843746259

Epoch: 6| Step: 9
Training loss: 2.1323203612463675
Validation loss: 2.4142738380133433

Epoch: 6| Step: 10
Training loss: 1.9022031258182073
Validation loss: 2.404407705823378

Epoch: 6| Step: 11
Training loss: 2.4224062429261988
Validation loss: 2.3965940818330433

Epoch: 6| Step: 12
Training loss: 1.5398384113499857
Validation loss: 2.3940876979182786

Epoch: 6| Step: 13
Training loss: 2.5282222394314084
Validation loss: 2.3960783718542507

Epoch: 281| Step: 0
Training loss: 1.5529540860180089
Validation loss: 2.378878879556364

Epoch: 6| Step: 1
Training loss: 2.24964181380176
Validation loss: 2.3928877301413434

Epoch: 6| Step: 2
Training loss: 2.2010365861748915
Validation loss: 2.391987003435976

Epoch: 6| Step: 3
Training loss: 1.7664344754973467
Validation loss: 2.404446406829392

Epoch: 6| Step: 4
Training loss: 1.6656601091588776
Validation loss: 2.3634708814916245

Epoch: 6| Step: 5
Training loss: 1.2119250792710385
Validation loss: 2.406162882052051

Epoch: 6| Step: 6
Training loss: 2.1914826242122296
Validation loss: 2.38605498751599

Epoch: 6| Step: 7
Training loss: 1.6533038729432235
Validation loss: 2.3925510041819935

Epoch: 6| Step: 8
Training loss: 2.734642320917317
Validation loss: 2.4263999318704816

Epoch: 6| Step: 9
Training loss: 1.6289183252559394
Validation loss: 2.398747144018308

Epoch: 6| Step: 10
Training loss: 1.8781919648328536
Validation loss: 2.423976028926135

Epoch: 6| Step: 11
Training loss: 1.835445062054684
Validation loss: 2.4209760264382356

Epoch: 6| Step: 12
Training loss: 1.8029656721624896
Validation loss: 2.434617883070164

Epoch: 6| Step: 13
Training loss: 2.303877866097357
Validation loss: 2.4426160351042463

Epoch: 282| Step: 0
Training loss: 1.851386983415304
Validation loss: 2.426912982963271

Epoch: 6| Step: 1
Training loss: 1.964373006986553
Validation loss: 2.425228578607222

Epoch: 6| Step: 2
Training loss: 1.3614821490554532
Validation loss: 2.4144183497040315

Epoch: 6| Step: 3
Training loss: 1.344063788747979
Validation loss: 2.419080327365151

Epoch: 6| Step: 4
Training loss: 1.4321109264661502
Validation loss: 2.4494413521427276

Epoch: 6| Step: 5
Training loss: 2.7259072989404816
Validation loss: 2.3677509029574924

Epoch: 6| Step: 6
Training loss: 1.788077937243162
Validation loss: 2.4001741819940987

Epoch: 6| Step: 7
Training loss: 2.021460550508761
Validation loss: 2.4238917099236232

Epoch: 6| Step: 8
Training loss: 1.945617468035389
Validation loss: 2.4012915218984925

Epoch: 6| Step: 9
Training loss: 2.233270545570311
Validation loss: 2.387555583978365

Epoch: 6| Step: 10
Training loss: 2.080034225072252
Validation loss: 2.4508432729308725

Epoch: 6| Step: 11
Training loss: 1.6734436376977342
Validation loss: 2.4417066053482337

Epoch: 6| Step: 12
Training loss: 2.121660638018022
Validation loss: 2.411055593684877

Epoch: 6| Step: 13
Training loss: 1.353668292354524
Validation loss: 2.414383111335895

Epoch: 283| Step: 0
Training loss: 1.719483513799925
Validation loss: 2.3525575345001033

Epoch: 6| Step: 1
Training loss: 1.930888122924931
Validation loss: 2.3907941929542864

Epoch: 6| Step: 2
Training loss: 1.3422725450708044
Validation loss: 2.395148437177971

Epoch: 6| Step: 3
Training loss: 1.9394627135809044
Validation loss: 2.4331269120056076

Epoch: 6| Step: 4
Training loss: 1.955882696702565
Validation loss: 2.4113205998610154

Epoch: 6| Step: 5
Training loss: 2.1935622001752306
Validation loss: 2.4311341309525987

Epoch: 6| Step: 6
Training loss: 2.1756830655584496
Validation loss: 2.363022626425976

Epoch: 6| Step: 7
Training loss: 1.702113419838449
Validation loss: 2.4071926800220895

Epoch: 6| Step: 8
Training loss: 2.5715609130409454
Validation loss: 2.432578728642711

Epoch: 6| Step: 9
Training loss: 1.686837949511991
Validation loss: 2.419762583079888

Epoch: 6| Step: 10
Training loss: 1.7262579878084308
Validation loss: 2.447362289193769

Epoch: 6| Step: 11
Training loss: 1.8046361081951423
Validation loss: 2.429453118590933

Epoch: 6| Step: 12
Training loss: 1.699918195214806
Validation loss: 2.46644717180559

Epoch: 6| Step: 13
Training loss: 2.6464112218902565
Validation loss: 2.4373658550614463

Epoch: 284| Step: 0
Training loss: 1.578564724232912
Validation loss: 2.429595410568608

Epoch: 6| Step: 1
Training loss: 2.1945580105696387
Validation loss: 2.416692893452069

Epoch: 6| Step: 2
Training loss: 1.976700005252846
Validation loss: 2.4336364749717347

Epoch: 6| Step: 3
Training loss: 2.0124831441801274
Validation loss: 2.3815409467874074

Epoch: 6| Step: 4
Training loss: 1.7518784114764963
Validation loss: 2.413244852140731

Epoch: 6| Step: 5
Training loss: 1.611900644028118
Validation loss: 2.402416900366776

Epoch: 6| Step: 6
Training loss: 1.689481772472074
Validation loss: 2.379743287786036

Epoch: 6| Step: 7
Training loss: 1.0469075667596557
Validation loss: 2.391456181229166

Epoch: 6| Step: 8
Training loss: 2.6667434760793762
Validation loss: 2.4221224136815236

Epoch: 6| Step: 9
Training loss: 1.8412401605927164
Validation loss: 2.3688967666962055

Epoch: 6| Step: 10
Training loss: 2.0843878429652007
Validation loss: 2.428614297833406

Epoch: 6| Step: 11
Training loss: 2.002642316583005
Validation loss: 2.37971432396379

Epoch: 6| Step: 12
Training loss: 1.7969309922492187
Validation loss: 2.393224688308669

Epoch: 6| Step: 13
Training loss: 1.234100890809787
Validation loss: 2.3767979373441555

Epoch: 285| Step: 0
Training loss: 1.851329740549424
Validation loss: 2.4047356282808736

Epoch: 6| Step: 1
Training loss: 1.988615116649921
Validation loss: 2.417962578302709

Epoch: 6| Step: 2
Training loss: 1.8115910849060648
Validation loss: 2.400620172043941

Epoch: 6| Step: 3
Training loss: 2.422310476221595
Validation loss: 2.3838952536117883

Epoch: 6| Step: 4
Training loss: 1.8146087612585136
Validation loss: 2.4227929002362187

Epoch: 6| Step: 5
Training loss: 1.6305970854762295
Validation loss: 2.3863015287929548

Epoch: 6| Step: 6
Training loss: 2.0399713938708257
Validation loss: 2.3767583465940283

Epoch: 6| Step: 7
Training loss: 1.2981933878413907
Validation loss: 2.4090620287892768

Epoch: 6| Step: 8
Training loss: 2.0461904531307438
Validation loss: 2.356641630552704

Epoch: 6| Step: 9
Training loss: 2.0418455343978232
Validation loss: 2.4261871786118965

Epoch: 6| Step: 10
Training loss: 1.9443262503290197
Validation loss: 2.4682976903004636

Epoch: 6| Step: 11
Training loss: 1.2721171642960625
Validation loss: 2.417942101641207

Epoch: 6| Step: 12
Training loss: 1.941867397503417
Validation loss: 2.4243224597265423

Epoch: 6| Step: 13
Training loss: 1.9722810596172646
Validation loss: 2.4649243602692907

Epoch: 286| Step: 0
Training loss: 1.7964000571798564
Validation loss: 2.3857308454147694

Epoch: 6| Step: 1
Training loss: 1.6635569489536899
Validation loss: 2.39175028881127

Epoch: 6| Step: 2
Training loss: 2.0495287749035667
Validation loss: 2.4132645974200018

Epoch: 6| Step: 3
Training loss: 1.4453382335124638
Validation loss: 2.415405598051105

Epoch: 6| Step: 4
Training loss: 2.3525826405392025
Validation loss: 2.3780843571534205

Epoch: 6| Step: 5
Training loss: 2.14957422875536
Validation loss: 2.4053140137497753

Epoch: 6| Step: 6
Training loss: 1.4032099606761794
Validation loss: 2.4771939732213646

Epoch: 6| Step: 7
Training loss: 2.691847190669002
Validation loss: 2.410393259745588

Epoch: 6| Step: 8
Training loss: 1.7958876841286948
Validation loss: 2.4347566970327703

Epoch: 6| Step: 9
Training loss: 1.70534643485132
Validation loss: 2.407846538827501

Epoch: 6| Step: 10
Training loss: 2.184693852675801
Validation loss: 2.4302051305249788

Epoch: 6| Step: 11
Training loss: 1.3241716224588875
Validation loss: 2.413340473475806

Epoch: 6| Step: 12
Training loss: 1.231457364585279
Validation loss: 2.4332042142611527

Epoch: 6| Step: 13
Training loss: 1.7768457406687876
Validation loss: 2.382148009600546

Epoch: 287| Step: 0
Training loss: 2.4701752230619984
Validation loss: 2.397350635133558

Epoch: 6| Step: 1
Training loss: 1.7696211162593771
Validation loss: 2.4241965110955617

Epoch: 6| Step: 2
Training loss: 1.7468948062872585
Validation loss: 2.3957558871285145

Epoch: 6| Step: 3
Training loss: 1.745231535014574
Validation loss: 2.4211805562018394

Epoch: 6| Step: 4
Training loss: 1.8447626210329082
Validation loss: 2.427572547956668

Epoch: 6| Step: 5
Training loss: 2.0804757038248063
Validation loss: 2.434782929188528

Epoch: 6| Step: 6
Training loss: 2.7899076319345344
Validation loss: 2.4437826503509794

Epoch: 6| Step: 7
Training loss: 1.4783035589844542
Validation loss: 2.441840871932333

Epoch: 6| Step: 8
Training loss: 1.7199031082851841
Validation loss: 2.3735972386903654

Epoch: 6| Step: 9
Training loss: 1.8101894515560801
Validation loss: 2.4309161678616777

Epoch: 6| Step: 10
Training loss: 1.8335570791289009
Validation loss: 2.4297273192941087

Epoch: 6| Step: 11
Training loss: 1.5886682762178397
Validation loss: 2.390790201862775

Epoch: 6| Step: 12
Training loss: 1.7584006448791405
Validation loss: 2.423246437699776

Epoch: 6| Step: 13
Training loss: 1.2935970197521787
Validation loss: 2.4226574891026877

Epoch: 288| Step: 0
Training loss: 1.9913085195176474
Validation loss: 2.3961475007606605

Epoch: 6| Step: 1
Training loss: 2.2892243520131657
Validation loss: 2.4099941643579705

Epoch: 6| Step: 2
Training loss: 1.9444515054059874
Validation loss: 2.406524730948528

Epoch: 6| Step: 3
Training loss: 1.7383332319738127
Validation loss: 2.4060643037488747

Epoch: 6| Step: 4
Training loss: 1.9065664060059
Validation loss: 2.4442221695310877

Epoch: 6| Step: 5
Training loss: 1.6255450435042715
Validation loss: 2.4331610265329617

Epoch: 6| Step: 6
Training loss: 1.4442443199580883
Validation loss: 2.4151067480002952

Epoch: 6| Step: 7
Training loss: 1.5320625484835206
Validation loss: 2.344921287540415

Epoch: 6| Step: 8
Training loss: 1.841656029211655
Validation loss: 2.3797962240075736

Epoch: 6| Step: 9
Training loss: 1.980443228231757
Validation loss: 2.3867042094895203

Epoch: 6| Step: 10
Training loss: 2.5631080464284013
Validation loss: 2.359548135212844

Epoch: 6| Step: 11
Training loss: 1.900954222736491
Validation loss: 2.4063225053236104

Epoch: 6| Step: 12
Training loss: 1.4450573670242608
Validation loss: 2.410923454502093

Epoch: 6| Step: 13
Training loss: 1.053529456828925
Validation loss: 2.382763700424287

Epoch: 289| Step: 0
Training loss: 1.465205033572187
Validation loss: 2.3928102996662677

Epoch: 6| Step: 1
Training loss: 1.2629609503429093
Validation loss: 2.3847594162868213

Epoch: 6| Step: 2
Training loss: 1.5778695079094718
Validation loss: 2.387148070290039

Epoch: 6| Step: 3
Training loss: 1.24735824857512
Validation loss: 2.413155070537673

Epoch: 6| Step: 4
Training loss: 1.896138372788169
Validation loss: 2.3964857528383967

Epoch: 6| Step: 5
Training loss: 1.9715800456186754
Validation loss: 2.3811749594709344

Epoch: 6| Step: 6
Training loss: 2.099211104123183
Validation loss: 2.407949121809121

Epoch: 6| Step: 7
Training loss: 1.9145793606201842
Validation loss: 2.4353972853014274

Epoch: 6| Step: 8
Training loss: 2.01114078848751
Validation loss: 2.432706589110112

Epoch: 6| Step: 9
Training loss: 1.7076049120105214
Validation loss: 2.4073322516804248

Epoch: 6| Step: 10
Training loss: 2.9089284060346943
Validation loss: 2.4417726056609883

Epoch: 6| Step: 11
Training loss: 2.3178325719788466
Validation loss: 2.389135390051629

Epoch: 6| Step: 12
Training loss: 1.5338585102773237
Validation loss: 2.427425115579377

Epoch: 6| Step: 13
Training loss: 1.2906902786261178
Validation loss: 2.3566753652070114

Epoch: 290| Step: 0
Training loss: 1.583169560579013
Validation loss: 2.4069220652864742

Epoch: 6| Step: 1
Training loss: 1.4569008285609129
Validation loss: 2.4105677705831696

Epoch: 6| Step: 2
Training loss: 2.519490370307896
Validation loss: 2.40737419571785

Epoch: 6| Step: 3
Training loss: 1.2872491740366527
Validation loss: 2.4163840732970714

Epoch: 6| Step: 4
Training loss: 1.6516359224483026
Validation loss: 2.419996159334456

Epoch: 6| Step: 5
Training loss: 1.9635651146039315
Validation loss: 2.370671758857746

Epoch: 6| Step: 6
Training loss: 1.5277138186081063
Validation loss: 2.419991040514493

Epoch: 6| Step: 7
Training loss: 1.8995882792853667
Validation loss: 2.4447732662613006

Epoch: 6| Step: 8
Training loss: 2.280939159379641
Validation loss: 2.4260226541030945

Epoch: 6| Step: 9
Training loss: 1.5731367079398013
Validation loss: 2.429434204509706

Epoch: 6| Step: 10
Training loss: 1.643648395371535
Validation loss: 2.416453431841896

Epoch: 6| Step: 11
Training loss: 2.1462728797079653
Validation loss: 2.4606909833350414

Epoch: 6| Step: 12
Training loss: 2.034296187179451
Validation loss: 2.3611334083255504

Epoch: 6| Step: 13
Training loss: 2.2663601438980003
Validation loss: 2.389243089839458

Epoch: 291| Step: 0
Training loss: 2.1063601954580924
Validation loss: 2.414373204533578

Epoch: 6| Step: 1
Training loss: 1.5204270573549592
Validation loss: 2.410075293904962

Epoch: 6| Step: 2
Training loss: 1.4504263645641675
Validation loss: 2.412866813669423

Epoch: 6| Step: 3
Training loss: 1.875622264602024
Validation loss: 2.4166722972989567

Epoch: 6| Step: 4
Training loss: 1.8634989549302798
Validation loss: 2.425388660499181

Epoch: 6| Step: 5
Training loss: 1.821469050045775
Validation loss: 2.3956298524140576

Epoch: 6| Step: 6
Training loss: 1.7145808893914802
Validation loss: 2.3614919230715867

Epoch: 6| Step: 7
Training loss: 2.6079921141721707
Validation loss: 2.375356268054064

Epoch: 6| Step: 8
Training loss: 1.4684620027026056
Validation loss: 2.3840645838246974

Epoch: 6| Step: 9
Training loss: 2.1334389685266317
Validation loss: 2.429360280527948

Epoch: 6| Step: 10
Training loss: 1.5052609373974137
Validation loss: 2.3556499046593067

Epoch: 6| Step: 11
Training loss: 1.620815832375362
Validation loss: 2.4033847967910034

Epoch: 6| Step: 12
Training loss: 1.7763176607564546
Validation loss: 2.390903224407606

Epoch: 6| Step: 13
Training loss: 2.0198103160367693
Validation loss: 2.3648613397744067

Epoch: 292| Step: 0
Training loss: 1.5659873192908325
Validation loss: 2.404646070027063

Epoch: 6| Step: 1
Training loss: 1.4589036462145086
Validation loss: 2.4189991082394053

Epoch: 6| Step: 2
Training loss: 1.6462515126701478
Validation loss: 2.397053190174604

Epoch: 6| Step: 3
Training loss: 1.906691328147086
Validation loss: 2.383550653919636

Epoch: 6| Step: 4
Training loss: 1.7288067761060248
Validation loss: 2.4225390246080445

Epoch: 6| Step: 5
Training loss: 1.7905916567056384
Validation loss: 2.462185676910268

Epoch: 6| Step: 6
Training loss: 2.176336741463428
Validation loss: 2.398251664361312

Epoch: 6| Step: 7
Training loss: 2.3610462055136305
Validation loss: 2.37778084551843

Epoch: 6| Step: 8
Training loss: 1.7574675497041017
Validation loss: 2.3950513493594228

Epoch: 6| Step: 9
Training loss: 2.0135239880754887
Validation loss: 2.37295963139303

Epoch: 6| Step: 10
Training loss: 1.8817390135830416
Validation loss: 2.449991505607929

Epoch: 6| Step: 11
Training loss: 1.4390087502845095
Validation loss: 2.3771320309090163

Epoch: 6| Step: 12
Training loss: 2.3656756417058222
Validation loss: 2.3642149316561265

Epoch: 6| Step: 13
Training loss: 2.0075677507305185
Validation loss: 2.378204048626736

Epoch: 293| Step: 0
Training loss: 1.7120467818365892
Validation loss: 2.4333127017403067

Epoch: 6| Step: 1
Training loss: 1.6813941978814586
Validation loss: 2.4579832586605126

Epoch: 6| Step: 2
Training loss: 2.1232986371106533
Validation loss: 2.4102809103461413

Epoch: 6| Step: 3
Training loss: 1.4312034032974166
Validation loss: 2.3907709668957438

Epoch: 6| Step: 4
Training loss: 1.5328297154259896
Validation loss: 2.4142821439321835

Epoch: 6| Step: 5
Training loss: 1.8126944075932447
Validation loss: 2.445353927819643

Epoch: 6| Step: 6
Training loss: 1.5227826398258246
Validation loss: 2.4191733087779808

Epoch: 6| Step: 7
Training loss: 1.8699664261807845
Validation loss: 2.414645151143297

Epoch: 6| Step: 8
Training loss: 1.927802334933505
Validation loss: 2.4230203196909037

Epoch: 6| Step: 9
Training loss: 1.75642116160562
Validation loss: 2.419938117510438

Epoch: 6| Step: 10
Training loss: 2.4925423970342377
Validation loss: 2.434499145503282

Epoch: 6| Step: 11
Training loss: 1.7899858515729046
Validation loss: 2.3909549548434277

Epoch: 6| Step: 12
Training loss: 1.8818565886175522
Validation loss: 2.376586777976882

Epoch: 6| Step: 13
Training loss: 2.140199493664239
Validation loss: 2.3340520583190387

Epoch: 294| Step: 0
Training loss: 1.7962230660709508
Validation loss: 2.3955055158782095

Epoch: 6| Step: 1
Training loss: 1.7217975301328925
Validation loss: 2.404548240889995

Epoch: 6| Step: 2
Training loss: 1.8596369454652188
Validation loss: 2.4527154887269313

Epoch: 6| Step: 3
Training loss: 1.5453249168089997
Validation loss: 2.4307179057976205

Epoch: 6| Step: 4
Training loss: 1.640350173456521
Validation loss: 2.3834943280342586

Epoch: 6| Step: 5
Training loss: 2.1081519077731468
Validation loss: 2.4240467243692057

Epoch: 6| Step: 6
Training loss: 1.3734009721605052
Validation loss: 2.4267868317893724

Epoch: 6| Step: 7
Training loss: 1.8931186089292886
Validation loss: 2.403959710265297

Epoch: 6| Step: 8
Training loss: 1.8285713628998812
Validation loss: 2.4086438723060324

Epoch: 6| Step: 9
Training loss: 1.8774996943162447
Validation loss: 2.3709405533068306

Epoch: 6| Step: 10
Training loss: 2.547887308404382
Validation loss: 2.384551566374409

Epoch: 6| Step: 11
Training loss: 1.9217582605153882
Validation loss: 2.3555209317106693

Epoch: 6| Step: 12
Training loss: 1.7499788827984406
Validation loss: 2.3955834199982124

Epoch: 6| Step: 13
Training loss: 2.1571981584467173
Validation loss: 2.4015792370530287

Epoch: 295| Step: 0
Training loss: 2.1848152033614547
Validation loss: 2.4016515460720407

Epoch: 6| Step: 1
Training loss: 2.3668941907807293
Validation loss: 2.389996372986795

Epoch: 6| Step: 2
Training loss: 1.614078204806976
Validation loss: 2.3624895554716585

Epoch: 6| Step: 3
Training loss: 1.512059530640391
Validation loss: 2.3747315376504328

Epoch: 6| Step: 4
Training loss: 2.0946059114438143
Validation loss: 2.3831465410499155

Epoch: 6| Step: 5
Training loss: 2.0021293748635243
Validation loss: 2.438792640839406

Epoch: 6| Step: 6
Training loss: 1.7615947806645682
Validation loss: 2.400768215787606

Epoch: 6| Step: 7
Training loss: 2.266407272512211
Validation loss: 2.379679970039246

Epoch: 6| Step: 8
Training loss: 1.5192429923705237
Validation loss: 2.4583455504845046

Epoch: 6| Step: 9
Training loss: 1.7202174078136936
Validation loss: 2.400921088490658

Epoch: 6| Step: 10
Training loss: 1.81472352541478
Validation loss: 2.407033279274892

Epoch: 6| Step: 11
Training loss: 1.4365820234165754
Validation loss: 2.384588550736091

Epoch: 6| Step: 12
Training loss: 1.7074471322807308
Validation loss: 2.381077187221839

Epoch: 6| Step: 13
Training loss: 1.4330845066077658
Validation loss: 2.3672623832492703

Epoch: 296| Step: 0
Training loss: 2.0650728535212366
Validation loss: 2.39245920729133

Epoch: 6| Step: 1
Training loss: 1.7411621908487758
Validation loss: 2.3724576839059877

Epoch: 6| Step: 2
Training loss: 2.1501934851590927
Validation loss: 2.4288056032035414

Epoch: 6| Step: 3
Training loss: 2.5238422270007277
Validation loss: 2.4575754801257412

Epoch: 6| Step: 4
Training loss: 1.8472723854475244
Validation loss: 2.3986070439466696

Epoch: 6| Step: 5
Training loss: 1.4956269096110453
Validation loss: 2.4801213518661247

Epoch: 6| Step: 6
Training loss: 1.241509978544253
Validation loss: 2.453910064012623

Epoch: 6| Step: 7
Training loss: 1.5231398854175957
Validation loss: 2.406282730210215

Epoch: 6| Step: 8
Training loss: 1.7182482593959927
Validation loss: 2.3881418864383

Epoch: 6| Step: 9
Training loss: 2.1043675644655124
Validation loss: 2.39849223883145

Epoch: 6| Step: 10
Training loss: 1.978115994160236
Validation loss: 2.4279929592854703

Epoch: 6| Step: 11
Training loss: 1.865808975630925
Validation loss: 2.3828669393376884

Epoch: 6| Step: 12
Training loss: 1.6559162883332252
Validation loss: 2.373789146702017

Epoch: 6| Step: 13
Training loss: 1.2379894213555727
Validation loss: 2.393551897387126

Epoch: 297| Step: 0
Training loss: 1.5360377452653176
Validation loss: 2.421428758658813

Epoch: 6| Step: 1
Training loss: 2.283714113251046
Validation loss: 2.4108888296509154

Epoch: 6| Step: 2
Training loss: 1.2008954482169618
Validation loss: 2.3866822025264103

Epoch: 6| Step: 3
Training loss: 1.7752635813834041
Validation loss: 2.4218716185060223

Epoch: 6| Step: 4
Training loss: 2.091832435797171
Validation loss: 2.4350553590060375

Epoch: 6| Step: 5
Training loss: 2.0786290525483726
Validation loss: 2.4486013463392773

Epoch: 6| Step: 6
Training loss: 1.7656434994969041
Validation loss: 2.4066767597126035

Epoch: 6| Step: 7
Training loss: 1.6055981660458936
Validation loss: 2.4199082109513332

Epoch: 6| Step: 8
Training loss: 2.5011538703743468
Validation loss: 2.41127104186821

Epoch: 6| Step: 9
Training loss: 1.7666620230463768
Validation loss: 2.443312178178273

Epoch: 6| Step: 10
Training loss: 1.9943383667108896
Validation loss: 2.391872640487607

Epoch: 6| Step: 11
Training loss: 1.749014781459771
Validation loss: 2.375530375837298

Epoch: 6| Step: 12
Training loss: 1.5666823298435593
Validation loss: 2.4378668669665164

Epoch: 6| Step: 13
Training loss: 1.560585603961497
Validation loss: 2.424179878335777

Epoch: 298| Step: 0
Training loss: 1.7159830883544374
Validation loss: 2.3736044729584753

Epoch: 6| Step: 1
Training loss: 1.7489265146668782
Validation loss: 2.402747979059267

Epoch: 6| Step: 2
Training loss: 1.289664018332637
Validation loss: 2.330629094836987

Epoch: 6| Step: 3
Training loss: 1.8421517896871469
Validation loss: 2.409385703834909

Epoch: 6| Step: 4
Training loss: 1.6534445412341139
Validation loss: 2.424117234793312

Epoch: 6| Step: 5
Training loss: 1.8502202701888695
Validation loss: 2.4406773399444592

Epoch: 6| Step: 6
Training loss: 2.6551297686629067
Validation loss: 2.371358747416096

Epoch: 6| Step: 7
Training loss: 1.9052885163461806
Validation loss: 2.3343285937198646

Epoch: 6| Step: 8
Training loss: 1.5743663330566464
Validation loss: 2.382750123470206

Epoch: 6| Step: 9
Training loss: 1.5523112938247248
Validation loss: 2.4162282362151513

Epoch: 6| Step: 10
Training loss: 2.08719874052724
Validation loss: 2.3762318644457547

Epoch: 6| Step: 11
Training loss: 2.0012826382931874
Validation loss: 2.4109642982568626

Epoch: 6| Step: 12
Training loss: 1.994125321317379
Validation loss: 2.4056890819666035

Epoch: 6| Step: 13
Training loss: 1.2866641766683833
Validation loss: 2.401910905105053

Epoch: 299| Step: 0
Training loss: 2.5662949536488466
Validation loss: 2.3892418043937367

Epoch: 6| Step: 1
Training loss: 1.7448588875494566
Validation loss: 2.419674452449231

Epoch: 6| Step: 2
Training loss: 1.8509953269961337
Validation loss: 2.3967976342030206

Epoch: 6| Step: 3
Training loss: 1.6725014912095428
Validation loss: 2.435213765345405

Epoch: 6| Step: 4
Training loss: 1.6343076148647422
Validation loss: 2.402345141552071

Epoch: 6| Step: 5
Training loss: 1.3896085045787607
Validation loss: 2.3710642912800894

Epoch: 6| Step: 6
Training loss: 2.031558673586878
Validation loss: 2.421160407468812

Epoch: 6| Step: 7
Training loss: 1.8231184130246576
Validation loss: 2.369473136653728

Epoch: 6| Step: 8
Training loss: 1.5610796767237982
Validation loss: 2.371891707890403

Epoch: 6| Step: 9
Training loss: 2.3666604843417085
Validation loss: 2.4123937787136955

Epoch: 6| Step: 10
Training loss: 1.4215813637498862
Validation loss: 2.4357387825888233

Epoch: 6| Step: 11
Training loss: 1.3028868624591752
Validation loss: 2.342560043970639

Epoch: 6| Step: 12
Training loss: 1.888097034538934
Validation loss: 2.4270910507375913

Epoch: 6| Step: 13
Training loss: 1.324806915465794
Validation loss: 2.368110388301991

Epoch: 300| Step: 0
Training loss: 1.6904178400798007
Validation loss: 2.426406972785783

Epoch: 6| Step: 1
Training loss: 1.8739670769355135
Validation loss: 2.3791527842544125

Epoch: 6| Step: 2
Training loss: 1.7134912670882496
Validation loss: 2.4073827373584034

Epoch: 6| Step: 3
Training loss: 1.816732069757206
Validation loss: 2.416553749979732

Epoch: 6| Step: 4
Training loss: 1.280764138746284
Validation loss: 2.3776135962629636

Epoch: 6| Step: 5
Training loss: 1.788935227843693
Validation loss: 2.415416110373938

Epoch: 6| Step: 6
Training loss: 1.8200344151607093
Validation loss: 2.4192226434297806

Epoch: 6| Step: 7
Training loss: 1.3136333839932297
Validation loss: 2.375236122232887

Epoch: 6| Step: 8
Training loss: 1.6096301570951026
Validation loss: 2.3499062839097262

Epoch: 6| Step: 9
Training loss: 2.024428430589991
Validation loss: 2.3743994892206244

Epoch: 6| Step: 10
Training loss: 1.5367749248994806
Validation loss: 2.4252862792397654

Epoch: 6| Step: 11
Training loss: 2.720633019107539
Validation loss: 2.3682089811343854

Epoch: 6| Step: 12
Training loss: 1.4104478698314102
Validation loss: 2.366473413740759

Epoch: 6| Step: 13
Training loss: 2.3973233993453165
Validation loss: 2.4190932373072207

Epoch: 301| Step: 0
Training loss: 1.9875792217660206
Validation loss: 2.4011225871035378

Epoch: 6| Step: 1
Training loss: 1.1975875347055702
Validation loss: 2.3870031470235196

Epoch: 6| Step: 2
Training loss: 1.5939010847696242
Validation loss: 2.4107694189075395

Epoch: 6| Step: 3
Training loss: 1.5565960541474315
Validation loss: 2.4491539096899544

Epoch: 6| Step: 4
Training loss: 1.4944666687511565
Validation loss: 2.402978622220272

Epoch: 6| Step: 5
Training loss: 1.8581529977423277
Validation loss: 2.432899152774338

Epoch: 6| Step: 6
Training loss: 1.412960909022619
Validation loss: 2.386274829755669

Epoch: 6| Step: 7
Training loss: 2.1402874979861104
Validation loss: 2.384697087994928

Epoch: 6| Step: 8
Training loss: 1.5190502670539476
Validation loss: 2.3915522315576445

Epoch: 6| Step: 9
Training loss: 1.907029289672794
Validation loss: 2.3695410818526605

Epoch: 6| Step: 10
Training loss: 2.3057740834349603
Validation loss: 2.4021754516268166

Epoch: 6| Step: 11
Training loss: 2.0462040857233443
Validation loss: 2.382867595614607

Epoch: 6| Step: 12
Training loss: 1.7304045447844962
Validation loss: 2.3919045277891535

Epoch: 6| Step: 13
Training loss: 2.7385170218799035
Validation loss: 2.3886574805357945

Epoch: 302| Step: 0
Training loss: 1.7456753974192645
Validation loss: 2.439012880172634

Epoch: 6| Step: 1
Training loss: 2.00584130803694
Validation loss: 2.390220116120815

Epoch: 6| Step: 2
Training loss: 1.9518990903669227
Validation loss: 2.387465316304918

Epoch: 6| Step: 3
Training loss: 1.6350983311893144
Validation loss: 2.392654524741293

Epoch: 6| Step: 4
Training loss: 1.9939445376780012
Validation loss: 2.403623100316091

Epoch: 6| Step: 5
Training loss: 1.1222290245538231
Validation loss: 2.4542698369993645

Epoch: 6| Step: 6
Training loss: 1.6168399750669098
Validation loss: 2.3654202430322617

Epoch: 6| Step: 7
Training loss: 2.0591120782170114
Validation loss: 2.3525838171568636

Epoch: 6| Step: 8
Training loss: 2.5227677250648557
Validation loss: 2.39043908519263

Epoch: 6| Step: 9
Training loss: 1.7961205266853935
Validation loss: 2.4007837784634516

Epoch: 6| Step: 10
Training loss: 2.2317716998377173
Validation loss: 2.3901174313295153

Epoch: 6| Step: 11
Training loss: 1.8844569452538906
Validation loss: 2.3933590171939008

Epoch: 6| Step: 12
Training loss: 1.6634519647990216
Validation loss: 2.414921097965091

Epoch: 6| Step: 13
Training loss: 1.2203087253487757
Validation loss: 2.3852028936116856

Epoch: 303| Step: 0
Training loss: 1.5398791320235024
Validation loss: 2.3827900396452133

Epoch: 6| Step: 1
Training loss: 1.5263459441499967
Validation loss: 2.4097390249095856

Epoch: 6| Step: 2
Training loss: 1.7263445824546748
Validation loss: 2.3791987141030697

Epoch: 6| Step: 3
Training loss: 1.8774372790307365
Validation loss: 2.4550669455597802

Epoch: 6| Step: 4
Training loss: 1.5159148892690408
Validation loss: 2.420586677930543

Epoch: 6| Step: 5
Training loss: 1.4666570807634998
Validation loss: 2.447974566994757

Epoch: 6| Step: 6
Training loss: 1.2931850747949516
Validation loss: 2.416187814605644

Epoch: 6| Step: 7
Training loss: 1.8189498319664943
Validation loss: 2.4820698647890223

Epoch: 6| Step: 8
Training loss: 2.4749490674875947
Validation loss: 2.4426163373737997

Epoch: 6| Step: 9
Training loss: 1.8744312695397811
Validation loss: 2.41595718512465

Epoch: 6| Step: 10
Training loss: 1.6643192290224103
Validation loss: 2.4461786289876533

Epoch: 6| Step: 11
Training loss: 2.368143625072894
Validation loss: 2.405681391104064

Epoch: 6| Step: 12
Training loss: 2.1890998439612237
Validation loss: 2.4802971448926385

Epoch: 6| Step: 13
Training loss: 1.7606679146451811
Validation loss: 2.445264609085853

Epoch: 304| Step: 0
Training loss: 1.8696095865864892
Validation loss: 2.368835813213814

Epoch: 6| Step: 1
Training loss: 1.8355835918448788
Validation loss: 2.389743126195846

Epoch: 6| Step: 2
Training loss: 1.6997528990507476
Validation loss: 2.4108832884801488

Epoch: 6| Step: 3
Training loss: 1.9182770087057046
Validation loss: 2.4252813063588987

Epoch: 6| Step: 4
Training loss: 1.4375772040823211
Validation loss: 2.3647134320545886

Epoch: 6| Step: 5
Training loss: 2.598032896801218
Validation loss: 2.335868390771324

Epoch: 6| Step: 6
Training loss: 1.6195445551972076
Validation loss: 2.4117634890980177

Epoch: 6| Step: 7
Training loss: 1.7857444678889383
Validation loss: 2.394344943614557

Epoch: 6| Step: 8
Training loss: 1.591840909571141
Validation loss: 2.395090610967654

Epoch: 6| Step: 9
Training loss: 1.5099230606485778
Validation loss: 2.366574667579986

Epoch: 6| Step: 10
Training loss: 1.4017696640026023
Validation loss: 2.418038370022532

Epoch: 6| Step: 11
Training loss: 2.4566809278649617
Validation loss: 2.4257096153571416

Epoch: 6| Step: 12
Training loss: 1.6167096155236145
Validation loss: 2.3745901167515657

Epoch: 6| Step: 13
Training loss: 1.7125388537823343
Validation loss: 2.3881309293255155

Epoch: 305| Step: 0
Training loss: 1.4138545520954042
Validation loss: 2.4232378736894087

Epoch: 6| Step: 1
Training loss: 1.3769445973666565
Validation loss: 2.361245336845288

Epoch: 6| Step: 2
Training loss: 1.8721414392338802
Validation loss: 2.3229389508737968

Epoch: 6| Step: 3
Training loss: 1.529040708560056
Validation loss: 2.333373215183631

Epoch: 6| Step: 4
Training loss: 1.9955265560653193
Validation loss: 2.386401483159028

Epoch: 6| Step: 5
Training loss: 1.7671062366476784
Validation loss: 2.4430486725917597

Epoch: 6| Step: 6
Training loss: 1.8634614677365593
Validation loss: 2.39533954648411

Epoch: 6| Step: 7
Training loss: 1.770671014265292
Validation loss: 2.4667307814048245

Epoch: 6| Step: 8
Training loss: 2.6869093667330577
Validation loss: 2.4338816518534183

Epoch: 6| Step: 9
Training loss: 1.4963000282330936
Validation loss: 2.4468951444774025

Epoch: 6| Step: 10
Training loss: 1.3565678166986308
Validation loss: 2.459557447663019

Epoch: 6| Step: 11
Training loss: 2.1664065669513835
Validation loss: 2.5211111007389233

Epoch: 6| Step: 12
Training loss: 2.0718807398743904
Validation loss: 2.4492875330415997

Epoch: 6| Step: 13
Training loss: 1.6167555522407504
Validation loss: 2.4183385438565335

Epoch: 306| Step: 0
Training loss: 1.4236047305245838
Validation loss: 2.429248724956684

Epoch: 6| Step: 1
Training loss: 2.5468118109792117
Validation loss: 2.3759136277681945

Epoch: 6| Step: 2
Training loss: 1.6850942487987415
Validation loss: 2.360391368704515

Epoch: 6| Step: 3
Training loss: 1.6446051139281632
Validation loss: 2.404749841217858

Epoch: 6| Step: 4
Training loss: 1.5319326786309182
Validation loss: 2.353526469859958

Epoch: 6| Step: 5
Training loss: 1.3094325779020342
Validation loss: 2.399135670627771

Epoch: 6| Step: 6
Training loss: 1.3832268390491818
Validation loss: 2.3652988077981516

Epoch: 6| Step: 7
Training loss: 1.9759846321311452
Validation loss: 2.378010215725674

Epoch: 6| Step: 8
Training loss: 1.9312899341590157
Validation loss: 2.4032142420645553

Epoch: 6| Step: 9
Training loss: 1.958820248666606
Validation loss: 2.389080344551541

Epoch: 6| Step: 10
Training loss: 1.6000305292077939
Validation loss: 2.3893706953197107

Epoch: 6| Step: 11
Training loss: 2.588402808985205
Validation loss: 2.348980946740416

Epoch: 6| Step: 12
Training loss: 1.6018174131403593
Validation loss: 2.352996349784934

Epoch: 6| Step: 13
Training loss: 1.3554541507341484
Validation loss: 2.3860713246517373

Epoch: 307| Step: 0
Training loss: 1.7204995700666028
Validation loss: 2.3523040846062586

Epoch: 6| Step: 1
Training loss: 1.4663143659612077
Validation loss: 2.4113537205286835

Epoch: 6| Step: 2
Training loss: 1.5070622608559718
Validation loss: 2.40726207176223

Epoch: 6| Step: 3
Training loss: 1.5222482587779627
Validation loss: 2.3976121616557196

Epoch: 6| Step: 4
Training loss: 1.79001202435424
Validation loss: 2.404168031991081

Epoch: 6| Step: 5
Training loss: 1.5628564046647289
Validation loss: 2.4085982772397543

Epoch: 6| Step: 6
Training loss: 1.3150190974252114
Validation loss: 2.3971926057187676

Epoch: 6| Step: 7
Training loss: 2.1199154329527143
Validation loss: 2.4000207639465967

Epoch: 6| Step: 8
Training loss: 1.5400958779449219
Validation loss: 2.362038592364012

Epoch: 6| Step: 9
Training loss: 1.5322576827225267
Validation loss: 2.4136104238099563

Epoch: 6| Step: 10
Training loss: 1.7882091369354518
Validation loss: 2.3528930984487877

Epoch: 6| Step: 11
Training loss: 2.4364568972627523
Validation loss: 2.3970237702770167

Epoch: 6| Step: 12
Training loss: 2.460523976293472
Validation loss: 2.4006761607209826

Epoch: 6| Step: 13
Training loss: 1.0157761681368995
Validation loss: 2.440060980589722

Epoch: 308| Step: 0
Training loss: 1.7841754781739139
Validation loss: 2.3790576158635233

Epoch: 6| Step: 1
Training loss: 1.5754839259677218
Validation loss: 2.388484911932192

Epoch: 6| Step: 2
Training loss: 1.1920919477535294
Validation loss: 2.415831247130929

Epoch: 6| Step: 3
Training loss: 1.6547956018914562
Validation loss: 2.36760636784517

Epoch: 6| Step: 4
Training loss: 1.6106784319942649
Validation loss: 2.386794158478446

Epoch: 6| Step: 5
Training loss: 2.24017711722545
Validation loss: 2.480371472181805

Epoch: 6| Step: 6
Training loss: 1.7935643754672739
Validation loss: 2.3882163198330955

Epoch: 6| Step: 7
Training loss: 1.6687506600710817
Validation loss: 2.449484720135478

Epoch: 6| Step: 8
Training loss: 2.2365431503134725
Validation loss: 2.429278309685168

Epoch: 6| Step: 9
Training loss: 2.458736149603926
Validation loss: 2.449835443442994

Epoch: 6| Step: 10
Training loss: 1.3251928836853664
Validation loss: 2.404699434591412

Epoch: 6| Step: 11
Training loss: 0.9233652774045369
Validation loss: 2.430331313126053

Epoch: 6| Step: 12
Training loss: 1.8901729831552454
Validation loss: 2.440269568008277

Epoch: 6| Step: 13
Training loss: 2.1007049966622415
Validation loss: 2.3435942807987953

Epoch: 309| Step: 0
Training loss: 1.591807359532189
Validation loss: 2.4002553267774998

Epoch: 6| Step: 1
Training loss: 2.4936309747805527
Validation loss: 2.3830711510820284

Epoch: 6| Step: 2
Training loss: 1.8226370315421496
Validation loss: 2.4002594740896113

Epoch: 6| Step: 3
Training loss: 1.6888050401868109
Validation loss: 2.388379979480526

Epoch: 6| Step: 4
Training loss: 1.717172071753798
Validation loss: 2.3464518581772364

Epoch: 6| Step: 5
Training loss: 1.4041300583018765
Validation loss: 2.3928010417398915

Epoch: 6| Step: 6
Training loss: 2.392882035864082
Validation loss: 2.4309824632401456

Epoch: 6| Step: 7
Training loss: 1.750887032904407
Validation loss: 2.3510927355163656

Epoch: 6| Step: 8
Training loss: 1.1888930532099282
Validation loss: 2.4391374370529446

Epoch: 6| Step: 9
Training loss: 1.711450787196953
Validation loss: 2.343138928892446

Epoch: 6| Step: 10
Training loss: 1.576842589587701
Validation loss: 2.3640634423188778

Epoch: 6| Step: 11
Training loss: 2.159678621932096
Validation loss: 2.3798254803806738

Epoch: 6| Step: 12
Training loss: 1.1845292023697789
Validation loss: 2.4927973798716603

Epoch: 6| Step: 13
Training loss: 2.3189063130050926
Validation loss: 2.378683125041366

Epoch: 310| Step: 0
Training loss: 2.001051983731422
Validation loss: 2.358587385502436

Epoch: 6| Step: 1
Training loss: 1.7735961305361854
Validation loss: 2.3279697696535138

Epoch: 6| Step: 2
Training loss: 1.6168713836570496
Validation loss: 2.4061407398167005

Epoch: 6| Step: 3
Training loss: 1.3526599375562274
Validation loss: 2.3654868616070583

Epoch: 6| Step: 4
Training loss: 1.9684587899047064
Validation loss: 2.4077418076041694

Epoch: 6| Step: 5
Training loss: 1.8570149935731781
Validation loss: 2.4240949699567005

Epoch: 6| Step: 6
Training loss: 1.728266983683794
Validation loss: 2.417142236385241

Epoch: 6| Step: 7
Training loss: 2.3731170016001513
Validation loss: 2.4417759937170964

Epoch: 6| Step: 8
Training loss: 1.6318067893912693
Validation loss: 2.4114349728394546

Epoch: 6| Step: 9
Training loss: 1.5787828037602178
Validation loss: 2.4528149973967452

Epoch: 6| Step: 10
Training loss: 1.7959206078277405
Validation loss: 2.4098723348658764

Epoch: 6| Step: 11
Training loss: 1.7272892453804694
Validation loss: 2.4759720400915826

Epoch: 6| Step: 12
Training loss: 1.6083767952589167
Validation loss: 2.3476674560773008

Epoch: 6| Step: 13
Training loss: 1.4069448661657122
Validation loss: 2.396523389557126

Epoch: 311| Step: 0
Training loss: 1.2857107340294358
Validation loss: 2.3903103655631064

Epoch: 6| Step: 1
Training loss: 1.664007911324034
Validation loss: 2.3764071977702126

Epoch: 6| Step: 2
Training loss: 1.8036569402405778
Validation loss: 2.3533689574128087

Epoch: 6| Step: 3
Training loss: 2.282244008511357
Validation loss: 2.3393862546833644

Epoch: 6| Step: 4
Training loss: 2.1059984096510225
Validation loss: 2.374572034768338

Epoch: 6| Step: 5
Training loss: 1.8115326503303468
Validation loss: 2.424818765887335

Epoch: 6| Step: 6
Training loss: 2.350665659675808
Validation loss: 2.415709814955617

Epoch: 6| Step: 7
Training loss: 1.7342488698374143
Validation loss: 2.4052360688010865

Epoch: 6| Step: 8
Training loss: 1.5501135630690561
Validation loss: 2.3582841948129465

Epoch: 6| Step: 9
Training loss: 1.838365288794187
Validation loss: 2.3960435180348196

Epoch: 6| Step: 10
Training loss: 1.4934576730110027
Validation loss: 2.375362206706363

Epoch: 6| Step: 11
Training loss: 1.4894781631298095
Validation loss: 2.338910675004197

Epoch: 6| Step: 12
Training loss: 1.2187978294964184
Validation loss: 2.3997288931923655

Epoch: 6| Step: 13
Training loss: 1.9154146984467246
Validation loss: 2.3580283456471993

Epoch: 312| Step: 0
Training loss: 1.4834103310706543
Validation loss: 2.333518535834818

Epoch: 6| Step: 1
Training loss: 2.1706920668117986
Validation loss: 2.3657904257931053

Epoch: 6| Step: 2
Training loss: 1.6585021631124959
Validation loss: 2.3329754619424135

Epoch: 6| Step: 3
Training loss: 1.6296807878745554
Validation loss: 2.425122559392142

Epoch: 6| Step: 4
Training loss: 1.8673528494304774
Validation loss: 2.399649587382371

Epoch: 6| Step: 5
Training loss: 2.1684047501121273
Validation loss: 2.387020789551198

Epoch: 6| Step: 6
Training loss: 1.431504559263483
Validation loss: 2.3800052399912413

Epoch: 6| Step: 7
Training loss: 2.158619339108189
Validation loss: 2.3862756376498004

Epoch: 6| Step: 8
Training loss: 1.5791246628354414
Validation loss: 2.395069312588402

Epoch: 6| Step: 9
Training loss: 1.3850245482544987
Validation loss: 2.35302262345458

Epoch: 6| Step: 10
Training loss: 1.608566970194688
Validation loss: 2.409747628382657

Epoch: 6| Step: 11
Training loss: 1.4208136988799935
Validation loss: 2.395049615325898

Epoch: 6| Step: 12
Training loss: 2.4417419691050415
Validation loss: 2.4112416705182107

Epoch: 6| Step: 13
Training loss: 1.3026293665072661
Validation loss: 2.395004842573753

Epoch: 313| Step: 0
Training loss: 1.6981700247930032
Validation loss: 2.3703933337875083

Epoch: 6| Step: 1
Training loss: 1.7520574328140697
Validation loss: 2.4250832157849738

Epoch: 6| Step: 2
Training loss: 1.7975533573258602
Validation loss: 2.411431126474398

Epoch: 6| Step: 3
Training loss: 1.391789580911414
Validation loss: 2.3865173409536182

Epoch: 6| Step: 4
Training loss: 1.6529333627311291
Validation loss: 2.4311127824256356

Epoch: 6| Step: 5
Training loss: 2.056703108284874
Validation loss: 2.408429714989008

Epoch: 6| Step: 6
Training loss: 1.3730963620727257
Validation loss: 2.374581499257313

Epoch: 6| Step: 7
Training loss: 1.822916288829946
Validation loss: 2.4144952518048473

Epoch: 6| Step: 8
Training loss: 2.2047248604661913
Validation loss: 2.389123477118853

Epoch: 6| Step: 9
Training loss: 2.395054820633873
Validation loss: 2.3999589639235235

Epoch: 6| Step: 10
Training loss: 1.6278365394016778
Validation loss: 2.401851238271214

Epoch: 6| Step: 11
Training loss: 1.775056410954227
Validation loss: 2.313501785694817

Epoch: 6| Step: 12
Training loss: 1.389246396570645
Validation loss: 2.352222675242756

Epoch: 6| Step: 13
Training loss: 1.0057875524266817
Validation loss: 2.3762169824932857

Epoch: 314| Step: 0
Training loss: 1.6570547056359042
Validation loss: 2.3360669867741666

Epoch: 6| Step: 1
Training loss: 1.0280663447475438
Validation loss: 2.4230201281865367

Epoch: 6| Step: 2
Training loss: 1.630015628950397
Validation loss: 2.397338020881787

Epoch: 6| Step: 3
Training loss: 2.856214767672814
Validation loss: 2.4052474254936116

Epoch: 6| Step: 4
Training loss: 1.479511847538517
Validation loss: 2.3873462684847615

Epoch: 6| Step: 5
Training loss: 1.5967506136292053
Validation loss: 2.3975787709645497

Epoch: 6| Step: 6
Training loss: 2.2112381262322973
Validation loss: 2.466829842150902

Epoch: 6| Step: 7
Training loss: 2.0761023982598505
Validation loss: 2.375631331601896

Epoch: 6| Step: 8
Training loss: 1.814782054310607
Validation loss: 2.3580059400475633

Epoch: 6| Step: 9
Training loss: 1.2292826430785138
Validation loss: 2.363701807886325

Epoch: 6| Step: 10
Training loss: 2.18199478594247
Validation loss: 2.3523656588038815

Epoch: 6| Step: 11
Training loss: 1.3193546861379495
Validation loss: 2.4090153146645528

Epoch: 6| Step: 12
Training loss: 1.484137666702033
Validation loss: 2.3683853327164788

Epoch: 6| Step: 13
Training loss: 1.6683877959049012
Validation loss: 2.361845447908417

Epoch: 315| Step: 0
Training loss: 1.190184520231929
Validation loss: 2.420602637703701

Epoch: 6| Step: 1
Training loss: 2.5945402113642855
Validation loss: 2.4682295502353138

Epoch: 6| Step: 2
Training loss: 1.722128166515349
Validation loss: 2.425305249981048

Epoch: 6| Step: 3
Training loss: 1.8031207793664046
Validation loss: 2.429053526262999

Epoch: 6| Step: 4
Training loss: 1.245571924084648
Validation loss: 2.399875340420234

Epoch: 6| Step: 5
Training loss: 2.010296542938817
Validation loss: 2.4380188508848324

Epoch: 6| Step: 6
Training loss: 1.2328395709992663
Validation loss: 2.4260662489326745

Epoch: 6| Step: 7
Training loss: 1.8179769964158157
Validation loss: 2.4158385485940412

Epoch: 6| Step: 8
Training loss: 1.9152333940553652
Validation loss: 2.4334904629324536

Epoch: 6| Step: 9
Training loss: 1.37438595672445
Validation loss: 2.3720693862878037

Epoch: 6| Step: 10
Training loss: 1.9450567605922608
Validation loss: 2.4036671072679803

Epoch: 6| Step: 11
Training loss: 1.8748020067582276
Validation loss: 2.4196496282799513

Epoch: 6| Step: 12
Training loss: 1.8526835850239083
Validation loss: 2.3589944698991894

Epoch: 6| Step: 13
Training loss: 1.8225600484157378
Validation loss: 2.411093932268074

Epoch: 316| Step: 0
Training loss: 1.7190792808691442
Validation loss: 2.4222313424593156

Epoch: 6| Step: 1
Training loss: 2.291943088390801
Validation loss: 2.4030454904447356

Epoch: 6| Step: 2
Training loss: 1.493869173411543
Validation loss: 2.3927692478130425

Epoch: 6| Step: 3
Training loss: 2.601443542876705
Validation loss: 2.4011429477548027

Epoch: 6| Step: 4
Training loss: 1.7865991416431168
Validation loss: 2.374005110387344

Epoch: 6| Step: 5
Training loss: 1.415910556446777
Validation loss: 2.36905282416362

Epoch: 6| Step: 6
Training loss: 1.5814720389939334
Validation loss: 2.404706523053786

Epoch: 6| Step: 7
Training loss: 1.8151126315896888
Validation loss: 2.371923039136965

Epoch: 6| Step: 8
Training loss: 1.5692668109094838
Validation loss: 2.442729928253354

Epoch: 6| Step: 9
Training loss: 1.2262007550414098
Validation loss: 2.4276212335358216

Epoch: 6| Step: 10
Training loss: 1.9912108776322637
Validation loss: 2.416875246429403

Epoch: 6| Step: 11
Training loss: 1.9080441895811877
Validation loss: 2.357046948574243

Epoch: 6| Step: 12
Training loss: 1.8030276901987765
Validation loss: 2.4410513455917466

Epoch: 6| Step: 13
Training loss: 1.1471256886422287
Validation loss: 2.39824985086607

Epoch: 317| Step: 0
Training loss: 1.6691298720363617
Validation loss: 2.392690509553308

Epoch: 6| Step: 1
Training loss: 2.10561459519218
Validation loss: 2.366090714643857

Epoch: 6| Step: 2
Training loss: 2.387514571699642
Validation loss: 2.380537247893001

Epoch: 6| Step: 3
Training loss: 1.3325022650550928
Validation loss: 2.339411713298479

Epoch: 6| Step: 4
Training loss: 1.2486633783946517
Validation loss: 2.3423434099574503

Epoch: 6| Step: 5
Training loss: 1.708218299280161
Validation loss: 2.412914395636877

Epoch: 6| Step: 6
Training loss: 1.3946996848915834
Validation loss: 2.427767310814503

Epoch: 6| Step: 7
Training loss: 1.6351389396031888
Validation loss: 2.450023730993704

Epoch: 6| Step: 8
Training loss: 2.239520889712843
Validation loss: 2.3878300297449884

Epoch: 6| Step: 9
Training loss: 1.7909179128368837
Validation loss: 2.3825322167055196

Epoch: 6| Step: 10
Training loss: 1.2399406025104212
Validation loss: 2.369018534228044

Epoch: 6| Step: 11
Training loss: 1.8134762338238462
Validation loss: 2.4545929524858807

Epoch: 6| Step: 12
Training loss: 1.8263381311142763
Validation loss: 2.4373553643069816

Epoch: 6| Step: 13
Training loss: 1.5853560561007987
Validation loss: 2.437788008930471

Epoch: 318| Step: 0
Training loss: 1.7302606255125546
Validation loss: 2.3917275468794656

Epoch: 6| Step: 1
Training loss: 2.5801294106548838
Validation loss: 2.3787684554018345

Epoch: 6| Step: 2
Training loss: 1.254642021143552
Validation loss: 2.38979218874973

Epoch: 6| Step: 3
Training loss: 2.0514349776508385
Validation loss: 2.4306822297760142

Epoch: 6| Step: 4
Training loss: 1.38159048104312
Validation loss: 2.3643533109522075

Epoch: 6| Step: 5
Training loss: 1.9609881998628194
Validation loss: 2.3929086054708724

Epoch: 6| Step: 6
Training loss: 1.3831781022556384
Validation loss: 2.39939056248349

Epoch: 6| Step: 7
Training loss: 1.4466026527697957
Validation loss: 2.348085115669548

Epoch: 6| Step: 8
Training loss: 1.8033193711582347
Validation loss: 2.412764655466337

Epoch: 6| Step: 9
Training loss: 1.5805251499432937
Validation loss: 2.3962395062016943

Epoch: 6| Step: 10
Training loss: 1.7375673349629572
Validation loss: 2.3393373598972786

Epoch: 6| Step: 11
Training loss: 1.1885667326298632
Validation loss: 2.3903604085289185

Epoch: 6| Step: 12
Training loss: 1.974566873306195
Validation loss: 2.4221794410764224

Epoch: 6| Step: 13
Training loss: 1.9407930998551373
Validation loss: 2.4317484664082514

Epoch: 319| Step: 0
Training loss: 2.096831829234947
Validation loss: 2.363035115749047

Epoch: 6| Step: 1
Training loss: 1.7861501652212017
Validation loss: 2.4185082318195392

Epoch: 6| Step: 2
Training loss: 1.180074817661675
Validation loss: 2.4001087766952756

Epoch: 6| Step: 3
Training loss: 1.5831725724907912
Validation loss: 2.3525231632344528

Epoch: 6| Step: 4
Training loss: 1.3949489876091963
Validation loss: 2.398634575109106

Epoch: 6| Step: 5
Training loss: 1.8120196133366828
Validation loss: 2.3502204032388967

Epoch: 6| Step: 6
Training loss: 1.7440793837232627
Validation loss: 2.3812540381302627

Epoch: 6| Step: 7
Training loss: 2.5240952901066986
Validation loss: 2.3933993594838836

Epoch: 6| Step: 8
Training loss: 1.7232375775167144
Validation loss: 2.386894346227514

Epoch: 6| Step: 9
Training loss: 1.7273245808242095
Validation loss: 2.427949504639482

Epoch: 6| Step: 10
Training loss: 1.9234611354835263
Validation loss: 2.393225589194148

Epoch: 6| Step: 11
Training loss: 1.547686893596884
Validation loss: 2.4242482402795607

Epoch: 6| Step: 12
Training loss: 1.6539789139719314
Validation loss: 2.400384828369983

Epoch: 6| Step: 13
Training loss: 1.053786960012452
Validation loss: 2.34675349856942

Epoch: 320| Step: 0
Training loss: 1.7270537493127238
Validation loss: 2.3565266804242477

Epoch: 6| Step: 1
Training loss: 1.441248939427749
Validation loss: 2.4177053611148143

Epoch: 6| Step: 2
Training loss: 1.3706632193591286
Validation loss: 2.382821790279337

Epoch: 6| Step: 3
Training loss: 2.202453727452594
Validation loss: 2.380746044294977

Epoch: 6| Step: 4
Training loss: 1.686272492594541
Validation loss: 2.402111464758165

Epoch: 6| Step: 5
Training loss: 1.6656868756737409
Validation loss: 2.408820638426052

Epoch: 6| Step: 6
Training loss: 1.9228241600304299
Validation loss: 2.3863698209755144

Epoch: 6| Step: 7
Training loss: 1.8418517605157163
Validation loss: 2.3688694294061863

Epoch: 6| Step: 8
Training loss: 1.4135238717556027
Validation loss: 2.4407826719597097

Epoch: 6| Step: 9
Training loss: 1.529853495396441
Validation loss: 2.418504872648498

Epoch: 6| Step: 10
Training loss: 1.8348378885781873
Validation loss: 2.3387717708354527

Epoch: 6| Step: 11
Training loss: 1.3692127595148156
Validation loss: 2.3921352674597918

Epoch: 6| Step: 12
Training loss: 1.4651488939987272
Validation loss: 2.345188869036227

Epoch: 6| Step: 13
Training loss: 2.4801907601362116
Validation loss: 2.4431669789132253

Epoch: 321| Step: 0
Training loss: 1.4601194978173855
Validation loss: 2.3768024259800056

Epoch: 6| Step: 1
Training loss: 1.4381819227111396
Validation loss: 2.3310363601919604

Epoch: 6| Step: 2
Training loss: 1.719880789795202
Validation loss: 2.3948645824527928

Epoch: 6| Step: 3
Training loss: 0.8222055299957566
Validation loss: 2.3313783932206484

Epoch: 6| Step: 4
Training loss: 1.5095686888960573
Validation loss: 2.390797864495242

Epoch: 6| Step: 5
Training loss: 2.066990212781349
Validation loss: 2.3902083962922887

Epoch: 6| Step: 6
Training loss: 1.4655520748385984
Validation loss: 2.3879993047830883

Epoch: 6| Step: 7
Training loss: 2.804753294786673
Validation loss: 2.345684687548547

Epoch: 6| Step: 8
Training loss: 2.056646421302967
Validation loss: 2.409398351837343

Epoch: 6| Step: 9
Training loss: 1.843453140929637
Validation loss: 2.3460735395285743

Epoch: 6| Step: 10
Training loss: 1.4004538719972761
Validation loss: 2.4121521999315103

Epoch: 6| Step: 11
Training loss: 1.5229307456698638
Validation loss: 2.420968031514475

Epoch: 6| Step: 12
Training loss: 1.5384719412708698
Validation loss: 2.400046192770619

Epoch: 6| Step: 13
Training loss: 1.754471108060362
Validation loss: 2.3968180198285687

Epoch: 322| Step: 0
Training loss: 1.6828049938491412
Validation loss: 2.3946903243303708

Epoch: 6| Step: 1
Training loss: 1.6549452914965739
Validation loss: 2.385899535504989

Epoch: 6| Step: 2
Training loss: 1.220794430179064
Validation loss: 2.399679209051115

Epoch: 6| Step: 3
Training loss: 1.9643682734986896
Validation loss: 2.382207066872683

Epoch: 6| Step: 4
Training loss: 1.9573566219588405
Validation loss: 2.394053882206578

Epoch: 6| Step: 5
Training loss: 1.3177226471657515
Validation loss: 2.405174363345486

Epoch: 6| Step: 6
Training loss: 1.7081014739453244
Validation loss: 2.402101701584167

Epoch: 6| Step: 7
Training loss: 2.377156633678408
Validation loss: 2.3559081590919946

Epoch: 6| Step: 8
Training loss: 1.6495218913651233
Validation loss: 2.36343467632692

Epoch: 6| Step: 9
Training loss: 1.4389249953391992
Validation loss: 2.443529515007572

Epoch: 6| Step: 10
Training loss: 1.4931883326591964
Validation loss: 2.382443495994816

Epoch: 6| Step: 11
Training loss: 1.962791326487882
Validation loss: 2.3735249423208873

Epoch: 6| Step: 12
Training loss: 2.0597871220416595
Validation loss: 2.374897962212199

Epoch: 6| Step: 13
Training loss: 1.4948546056312395
Validation loss: 2.329964649184539

Epoch: 323| Step: 0
Training loss: 2.177904938317814
Validation loss: 2.3788899126914202

Epoch: 6| Step: 1
Training loss: 0.9152050213862762
Validation loss: 2.39919115540187

Epoch: 6| Step: 2
Training loss: 2.1691356920611793
Validation loss: 2.3728079937537707

Epoch: 6| Step: 3
Training loss: 0.8341071509725767
Validation loss: 2.4095945772970757

Epoch: 6| Step: 4
Training loss: 1.9716680789962875
Validation loss: 2.374877663156356

Epoch: 6| Step: 5
Training loss: 1.7761721595711917
Validation loss: 2.3919832254721474

Epoch: 6| Step: 6
Training loss: 1.889141982861993
Validation loss: 2.361213446451736

Epoch: 6| Step: 7
Training loss: 1.7745141613637845
Validation loss: 2.3866667487650366

Epoch: 6| Step: 8
Training loss: 1.7678404555420777
Validation loss: 2.3606991674740248

Epoch: 6| Step: 9
Training loss: 1.38982449754629
Validation loss: 2.408688152061224

Epoch: 6| Step: 10
Training loss: 1.349244439654143
Validation loss: 2.376032211525793

Epoch: 6| Step: 11
Training loss: 1.8538811567419184
Validation loss: 2.4014555992678024

Epoch: 6| Step: 12
Training loss: 1.9115621623459425
Validation loss: 2.3628166862834243

Epoch: 6| Step: 13
Training loss: 1.1393677562790963
Validation loss: 2.390510411029274

Epoch: 324| Step: 0
Training loss: 1.2462258582804329
Validation loss: 2.409451050955503

Epoch: 6| Step: 1
Training loss: 2.0633478444975237
Validation loss: 2.3629782189271515

Epoch: 6| Step: 2
Training loss: 2.046304870876467
Validation loss: 2.395405953173492

Epoch: 6| Step: 3
Training loss: 1.1470407309047452
Validation loss: 2.339512598764413

Epoch: 6| Step: 4
Training loss: 1.6647318895084977
Validation loss: 2.335623365233477

Epoch: 6| Step: 5
Training loss: 1.9054443658110756
Validation loss: 2.3919195377497156

Epoch: 6| Step: 6
Training loss: 1.6584087913764132
Validation loss: 2.400804667358315

Epoch: 6| Step: 7
Training loss: 2.3741279808133777
Validation loss: 2.3599970111129296

Epoch: 6| Step: 8
Training loss: 1.9006783403854082
Validation loss: 2.402070211128802

Epoch: 6| Step: 9
Training loss: 1.5093720430143784
Validation loss: 2.4264667848753874

Epoch: 6| Step: 10
Training loss: 1.4814799134369783
Validation loss: 2.4651782089717016

Epoch: 6| Step: 11
Training loss: 1.6274707057912343
Validation loss: 2.422877260652904

Epoch: 6| Step: 12
Training loss: 1.6258130607077554
Validation loss: 2.3678806183258594

Epoch: 6| Step: 13
Training loss: 1.6102847148468071
Validation loss: 2.3825406849292876

Epoch: 325| Step: 0
Training loss: 1.2739723814062123
Validation loss: 2.3611784096797663

Epoch: 6| Step: 1
Training loss: 1.4681111021589854
Validation loss: 2.444588645365323

Epoch: 6| Step: 2
Training loss: 1.24018170102219
Validation loss: 2.369843018435298

Epoch: 6| Step: 3
Training loss: 1.9031567725925953
Validation loss: 2.3875667821032036

Epoch: 6| Step: 4
Training loss: 1.5836440919120756
Validation loss: 2.3880344880327016

Epoch: 6| Step: 5
Training loss: 1.450481019309777
Validation loss: 2.4562693834577187

Epoch: 6| Step: 6
Training loss: 0.7896952594214337
Validation loss: 2.395104658503426

Epoch: 6| Step: 7
Training loss: 2.7099546030331374
Validation loss: 2.36235512513172

Epoch: 6| Step: 8
Training loss: 2.024279445031226
Validation loss: 2.3617661476145124

Epoch: 6| Step: 9
Training loss: 1.4920966635013335
Validation loss: 2.381987677925563

Epoch: 6| Step: 10
Training loss: 1.7376534346201045
Validation loss: 2.403258173831205

Epoch: 6| Step: 11
Training loss: 1.8811109776630468
Validation loss: 2.3539967702037594

Epoch: 6| Step: 12
Training loss: 1.926238526069387
Validation loss: 2.3738130022215915

Epoch: 6| Step: 13
Training loss: 1.8184976986106678
Validation loss: 2.367616328487665

Epoch: 326| Step: 0
Training loss: 1.497085043678542
Validation loss: 2.3366894051154636

Epoch: 6| Step: 1
Training loss: 1.8435529183267017
Validation loss: 2.402619406705989

Epoch: 6| Step: 2
Training loss: 1.367744550300497
Validation loss: 2.3751283426370216

Epoch: 6| Step: 3
Training loss: 1.2159596313564447
Validation loss: 2.367917222137579

Epoch: 6| Step: 4
Training loss: 1.8981901407981154
Validation loss: 2.3831422198075614

Epoch: 6| Step: 5
Training loss: 1.3648634421680825
Validation loss: 2.444670037828752

Epoch: 6| Step: 6
Training loss: 1.664103905964099
Validation loss: 2.3950177773909336

Epoch: 6| Step: 7
Training loss: 1.7358817351661018
Validation loss: 2.3383168941245014

Epoch: 6| Step: 8
Training loss: 2.2612073250914255
Validation loss: 2.418640354099836

Epoch: 6| Step: 9
Training loss: 1.677089225174247
Validation loss: 2.3674579310073933

Epoch: 6| Step: 10
Training loss: 2.058334884437049
Validation loss: 2.4282224192299933

Epoch: 6| Step: 11
Training loss: 1.9616241468727795
Validation loss: 2.4291198054600294

Epoch: 6| Step: 12
Training loss: 1.7479897260647668
Validation loss: 2.37236815364241

Epoch: 6| Step: 13
Training loss: 1.4184889666693294
Validation loss: 2.3907512899798435

Epoch: 327| Step: 0
Training loss: 1.2779986368031762
Validation loss: 2.3737264801372002

Epoch: 6| Step: 1
Training loss: 1.2328363800636908
Validation loss: 2.38307396745082

Epoch: 6| Step: 2
Training loss: 2.3388713669391157
Validation loss: 2.376376128459775

Epoch: 6| Step: 3
Training loss: 1.6075552865305502
Validation loss: 2.4281251641152277

Epoch: 6| Step: 4
Training loss: 1.9201136635872265
Validation loss: 2.387627017428532

Epoch: 6| Step: 5
Training loss: 2.108997791612897
Validation loss: 2.398977098380932

Epoch: 6| Step: 6
Training loss: 1.414748557567788
Validation loss: 2.344323199331357

Epoch: 6| Step: 7
Training loss: 2.151408634487839
Validation loss: 2.3557785021794797

Epoch: 6| Step: 8
Training loss: 1.5941043534624022
Validation loss: 2.3512134739279302

Epoch: 6| Step: 9
Training loss: 1.5644570873272232
Validation loss: 2.350544985285742

Epoch: 6| Step: 10
Training loss: 1.2894804768173416
Validation loss: 2.4008487265052736

Epoch: 6| Step: 11
Training loss: 1.3335419531374286
Validation loss: 2.3771163619192137

Epoch: 6| Step: 12
Training loss: 1.6823523385491306
Validation loss: 2.372459667858018

Epoch: 6| Step: 13
Training loss: 1.7282093875968645
Validation loss: 2.379723444277019

Epoch: 328| Step: 0
Training loss: 1.2317243194938075
Validation loss: 2.378522261246469

Epoch: 6| Step: 1
Training loss: 1.8157648738486658
Validation loss: 2.3783246233595716

Epoch: 6| Step: 2
Training loss: 1.2489879325729656
Validation loss: 2.4193069259452273

Epoch: 6| Step: 3
Training loss: 1.834643423271893
Validation loss: 2.4226265007632932

Epoch: 6| Step: 4
Training loss: 1.6919913392217298
Validation loss: 2.4038796567388565

Epoch: 6| Step: 5
Training loss: 1.7145930565349383
Validation loss: 2.4362035153115724

Epoch: 6| Step: 6
Training loss: 1.5693000072456156
Validation loss: 2.4263445272684976

Epoch: 6| Step: 7
Training loss: 1.4572082084805724
Validation loss: 2.441615919466151

Epoch: 6| Step: 8
Training loss: 1.8923354805271226
Validation loss: 2.3617381313109824

Epoch: 6| Step: 9
Training loss: 1.584921751166652
Validation loss: 2.4186519552373986

Epoch: 6| Step: 10
Training loss: 1.607583762043737
Validation loss: 2.372293272703775

Epoch: 6| Step: 11
Training loss: 2.6201473977945273
Validation loss: 2.4477814046388096

Epoch: 6| Step: 12
Training loss: 0.8029392844081057
Validation loss: 2.43977723395137

Epoch: 6| Step: 13
Training loss: 1.4023949233895143
Validation loss: 2.365159074184479

Epoch: 329| Step: 0
Training loss: 1.4466259735876776
Validation loss: 2.4219873101282787

Epoch: 6| Step: 1
Training loss: 2.1781887794909656
Validation loss: 2.389499353988925

Epoch: 6| Step: 2
Training loss: 1.804644365331878
Validation loss: 2.361990879315297

Epoch: 6| Step: 3
Training loss: 2.089990571470759
Validation loss: 2.416887776744473

Epoch: 6| Step: 4
Training loss: 1.1359889253627224
Validation loss: 2.344774536653935

Epoch: 6| Step: 5
Training loss: 1.6983842576428005
Validation loss: 2.384598492046735

Epoch: 6| Step: 6
Training loss: 2.0513458346726803
Validation loss: 2.434820535647214

Epoch: 6| Step: 7
Training loss: 1.397539329862517
Validation loss: 2.365833845350846

Epoch: 6| Step: 8
Training loss: 1.5965821029286944
Validation loss: 2.374294927629168

Epoch: 6| Step: 9
Training loss: 1.6911584967806892
Validation loss: 2.3443599391288172

Epoch: 6| Step: 10
Training loss: 2.052617411815541
Validation loss: 2.31604432261518

Epoch: 6| Step: 11
Training loss: 1.5100699015726053
Validation loss: 2.3132573588972516

Epoch: 6| Step: 12
Training loss: 1.516812439435137
Validation loss: 2.409307874119003

Epoch: 6| Step: 13
Training loss: 1.3852133733220044
Validation loss: 2.3767830125555185

Epoch: 330| Step: 0
Training loss: 1.7097814129106366
Validation loss: 2.381799292498919

Epoch: 6| Step: 1
Training loss: 1.592223988901989
Validation loss: 2.345310318560448

Epoch: 6| Step: 2
Training loss: 1.5267444420178184
Validation loss: 2.3873872342586826

Epoch: 6| Step: 3
Training loss: 1.4492963168626543
Validation loss: 2.4075698791097153

Epoch: 6| Step: 4
Training loss: 2.1179902641641766
Validation loss: 2.3736342986906767

Epoch: 6| Step: 5
Training loss: 1.33469096246519
Validation loss: 2.3333497614509278

Epoch: 6| Step: 6
Training loss: 1.4766798023273984
Validation loss: 2.396090780357092

Epoch: 6| Step: 7
Training loss: 2.0320390782540962
Validation loss: 2.4216161477765645

Epoch: 6| Step: 8
Training loss: 2.0777748214419587
Validation loss: 2.3314621721006175

Epoch: 6| Step: 9
Training loss: 1.490585745688464
Validation loss: 2.40933713710176

Epoch: 6| Step: 10
Training loss: 1.7461986126230207
Validation loss: 2.4138833744878463

Epoch: 6| Step: 11
Training loss: 1.1765575190992157
Validation loss: 2.40105736032246

Epoch: 6| Step: 12
Training loss: 2.3039924219987014
Validation loss: 2.4161924496978777

Epoch: 6| Step: 13
Training loss: 1.4174152901986474
Validation loss: 2.391913888862405

Epoch: 331| Step: 0
Training loss: 1.6189997741765034
Validation loss: 2.404235251536736

Epoch: 6| Step: 1
Training loss: 1.1144358219444088
Validation loss: 2.4379525764953702

Epoch: 6| Step: 2
Training loss: 1.8232284569900103
Validation loss: 2.390002370191214

Epoch: 6| Step: 3
Training loss: 2.016266595023647
Validation loss: 2.357827841199699

Epoch: 6| Step: 4
Training loss: 1.5173961869101018
Validation loss: 2.3933804111281978

Epoch: 6| Step: 5
Training loss: 2.191643088423038
Validation loss: 2.3777622864487906

Epoch: 6| Step: 6
Training loss: 0.9958936303264544
Validation loss: 2.344840346176033

Epoch: 6| Step: 7
Training loss: 2.029305099162233
Validation loss: 2.367525027707036

Epoch: 6| Step: 8
Training loss: 1.4725880897998798
Validation loss: 2.401826081524782

Epoch: 6| Step: 9
Training loss: 1.9411378978187996
Validation loss: 2.3488052747943162

Epoch: 6| Step: 10
Training loss: 1.2576290494404139
Validation loss: 2.360722028590878

Epoch: 6| Step: 11
Training loss: 1.6566557477185702
Validation loss: 2.344399114161231

Epoch: 6| Step: 12
Training loss: 1.9032901235019244
Validation loss: 2.3673904810059616

Epoch: 6| Step: 13
Training loss: 1.4051026644140046
Validation loss: 2.3500613694173063

Epoch: 332| Step: 0
Training loss: 1.1184392998449868
Validation loss: 2.407329177225191

Epoch: 6| Step: 1
Training loss: 2.463494610219409
Validation loss: 2.3825967616728683

Epoch: 6| Step: 2
Training loss: 1.7593541145778975
Validation loss: 2.3838785939965574

Epoch: 6| Step: 3
Training loss: 1.2218572668949768
Validation loss: 2.373444644282888

Epoch: 6| Step: 4
Training loss: 1.0719659105012027
Validation loss: 2.376253413658454

Epoch: 6| Step: 5
Training loss: 1.9922760588465949
Validation loss: 2.349105670087021

Epoch: 6| Step: 6
Training loss: 1.2337019811868664
Validation loss: 2.4367415760403595

Epoch: 6| Step: 7
Training loss: 1.965906360181314
Validation loss: 2.3982406021793494

Epoch: 6| Step: 8
Training loss: 2.072782259725833
Validation loss: 2.396888672397318

Epoch: 6| Step: 9
Training loss: 1.1673191266991814
Validation loss: 2.4037572923111465

Epoch: 6| Step: 10
Training loss: 1.818082171657252
Validation loss: 2.411541213225899

Epoch: 6| Step: 11
Training loss: 1.448457420236831
Validation loss: 2.3857023422103096

Epoch: 6| Step: 12
Training loss: 1.6832773570709125
Validation loss: 2.401686262466228

Epoch: 6| Step: 13
Training loss: 1.586953274755922
Validation loss: 2.375803044751001

Epoch: 333| Step: 0
Training loss: 2.178189217319968
Validation loss: 2.3484890776971947

Epoch: 6| Step: 1
Training loss: 1.6925245997163945
Validation loss: 2.4723203497939648

Epoch: 6| Step: 2
Training loss: 1.5108637005713326
Validation loss: 2.3882033621333236

Epoch: 6| Step: 3
Training loss: 1.5816526360219416
Validation loss: 2.3624893916149556

Epoch: 6| Step: 4
Training loss: 1.3650599465114657
Validation loss: 2.429769210145778

Epoch: 6| Step: 5
Training loss: 1.8622998226044218
Validation loss: 2.4212672026313204

Epoch: 6| Step: 6
Training loss: 1.317193132888497
Validation loss: 2.3816056919254427

Epoch: 6| Step: 7
Training loss: 1.9325078824414255
Validation loss: 2.4307527459975597

Epoch: 6| Step: 8
Training loss: 2.0594839527443103
Validation loss: 2.478499771541063

Epoch: 6| Step: 9
Training loss: 1.0747423595148897
Validation loss: 2.4045220445865536

Epoch: 6| Step: 10
Training loss: 1.3624880868933384
Validation loss: 2.410681326391746

Epoch: 6| Step: 11
Training loss: 1.8259360094797192
Validation loss: 2.3870733683862357

Epoch: 6| Step: 12
Training loss: 1.6684318096251762
Validation loss: 2.333815215235509

Epoch: 6| Step: 13
Training loss: 1.9114234013358198
Validation loss: 2.3813637603121243

Epoch: 334| Step: 0
Training loss: 2.6521105656770203
Validation loss: 2.419636292203014

Epoch: 6| Step: 1
Training loss: 1.56723829892589
Validation loss: 2.3833807515292715

Epoch: 6| Step: 2
Training loss: 2.0410831421996463
Validation loss: 2.3612812487834267

Epoch: 6| Step: 3
Training loss: 1.6110355735843476
Validation loss: 2.3449126555824895

Epoch: 6| Step: 4
Training loss: 1.8588206001629335
Validation loss: 2.3597708369152928

Epoch: 6| Step: 5
Training loss: 1.4438429501159775
Validation loss: 2.375632736642769

Epoch: 6| Step: 6
Training loss: 1.4615469084816055
Validation loss: 2.382686859804668

Epoch: 6| Step: 7
Training loss: 1.6648549087128974
Validation loss: 2.3401435094274325

Epoch: 6| Step: 8
Training loss: 1.3163453039895447
Validation loss: 2.3762013668080364

Epoch: 6| Step: 9
Training loss: 1.183271307506169
Validation loss: 2.377222542135283

Epoch: 6| Step: 10
Training loss: 1.3094694481337483
Validation loss: 2.3557719156278902

Epoch: 6| Step: 11
Training loss: 1.4833191178029994
Validation loss: 2.3593699571946365

Epoch: 6| Step: 12
Training loss: 1.5656840878603595
Validation loss: 2.3532348666866816

Epoch: 6| Step: 13
Training loss: 1.5147433518677638
Validation loss: 2.320449528398144

Epoch: 335| Step: 0
Training loss: 1.5633220798816718
Validation loss: 2.3467435110976216

Epoch: 6| Step: 1
Training loss: 1.4495868883622054
Validation loss: 2.383511365710358

Epoch: 6| Step: 2
Training loss: 1.4395413209974242
Validation loss: 2.3629227680519675

Epoch: 6| Step: 3
Training loss: 1.6469287204847896
Validation loss: 2.4050911823293806

Epoch: 6| Step: 4
Training loss: 1.4609908639881983
Validation loss: 2.42601224955894

Epoch: 6| Step: 5
Training loss: 2.283627042420034
Validation loss: 2.39620767551758

Epoch: 6| Step: 6
Training loss: 1.468706901404939
Validation loss: 2.3763217874750397

Epoch: 6| Step: 7
Training loss: 1.5367615050441692
Validation loss: 2.3570168705265737

Epoch: 6| Step: 8
Training loss: 1.9989172865837934
Validation loss: 2.3142619339813053

Epoch: 6| Step: 9
Training loss: 1.7195854237405641
Validation loss: 2.396711599583781

Epoch: 6| Step: 10
Training loss: 1.7064550199753215
Validation loss: 2.377454198855014

Epoch: 6| Step: 11
Training loss: 2.0841666144617994
Validation loss: 2.3801429042860365

Epoch: 6| Step: 12
Training loss: 0.9853198043499264
Validation loss: 2.359567607321593

Epoch: 6| Step: 13
Training loss: 1.5568920971005538
Validation loss: 2.389406723149158

Epoch: 336| Step: 0
Training loss: 1.451770438256513
Validation loss: 2.4128056327431535

Epoch: 6| Step: 1
Training loss: 1.7812373512220514
Validation loss: 2.3469425834049322

Epoch: 6| Step: 2
Training loss: 1.705383483181138
Validation loss: 2.3858498438236353

Epoch: 6| Step: 3
Training loss: 1.250934251699583
Validation loss: 2.302605790502631

Epoch: 6| Step: 4
Training loss: 1.2766428199629207
Validation loss: 2.422769602648928

Epoch: 6| Step: 5
Training loss: 1.947572001055428
Validation loss: 2.3485812756840523

Epoch: 6| Step: 6
Training loss: 2.281539585075258
Validation loss: 2.4441106653119697

Epoch: 6| Step: 7
Training loss: 1.4769091325416444
Validation loss: 2.3549365023544984

Epoch: 6| Step: 8
Training loss: 1.5699057740284934
Validation loss: 2.3858365519884095

Epoch: 6| Step: 9
Training loss: 1.7533850628265004
Validation loss: 2.360096348050145

Epoch: 6| Step: 10
Training loss: 1.5224639129120219
Validation loss: 2.400735003542439

Epoch: 6| Step: 11
Training loss: 2.0895913800597756
Validation loss: 2.382470534417611

Epoch: 6| Step: 12
Training loss: 1.6544804747032575
Validation loss: 2.3720022992470864

Epoch: 6| Step: 13
Training loss: 1.12612937823247
Validation loss: 2.361504005792259

Epoch: 337| Step: 0
Training loss: 2.190483456554169
Validation loss: 2.339647945469961

Epoch: 6| Step: 1
Training loss: 1.7369251919605062
Validation loss: 2.3986382004476856

Epoch: 6| Step: 2
Training loss: 1.9311651217379089
Validation loss: 2.345082604903483

Epoch: 6| Step: 3
Training loss: 1.7325291476749634
Validation loss: 2.428573751708069

Epoch: 6| Step: 4
Training loss: 1.6378427801915947
Validation loss: 2.3696067682935418

Epoch: 6| Step: 5
Training loss: 0.992462000083377
Validation loss: 2.3828289664170406

Epoch: 6| Step: 6
Training loss: 1.558013655092193
Validation loss: 2.397642678852328

Epoch: 6| Step: 7
Training loss: 1.4174763478722825
Validation loss: 2.4249593803438327

Epoch: 6| Step: 8
Training loss: 1.5364716696295109
Validation loss: 2.4119108509877663

Epoch: 6| Step: 9
Training loss: 1.5285450925455448
Validation loss: 2.4136888306622835

Epoch: 6| Step: 10
Training loss: 1.6051518111166174
Validation loss: 2.3997622224518387

Epoch: 6| Step: 11
Training loss: 1.83044403880067
Validation loss: 2.3357623095599105

Epoch: 6| Step: 12
Training loss: 1.7842534493168076
Validation loss: 2.333073917667423

Epoch: 6| Step: 13
Training loss: 2.0910678594041507
Validation loss: 2.36594398900958

Epoch: 338| Step: 0
Training loss: 1.7128403067945943
Validation loss: 2.3906015556762807

Epoch: 6| Step: 1
Training loss: 1.9042922425825066
Validation loss: 2.351543104965078

Epoch: 6| Step: 2
Training loss: 1.5775968971055565
Validation loss: 2.398911283204229

Epoch: 6| Step: 3
Training loss: 1.3443901400243403
Validation loss: 2.3568417632903627

Epoch: 6| Step: 4
Training loss: 1.532356174061158
Validation loss: 2.3472010400635916

Epoch: 6| Step: 5
Training loss: 1.9232293295989784
Validation loss: 2.4098661461569013

Epoch: 6| Step: 6
Training loss: 1.7574184399885162
Validation loss: 2.3807506186320775

Epoch: 6| Step: 7
Training loss: 1.0427842566369578
Validation loss: 2.391081256344547

Epoch: 6| Step: 8
Training loss: 1.4011829215200013
Validation loss: 2.340754783139898

Epoch: 6| Step: 9
Training loss: 2.390376458306674
Validation loss: 2.394210904543283

Epoch: 6| Step: 10
Training loss: 0.984589598742447
Validation loss: 2.3755930110039185

Epoch: 6| Step: 11
Training loss: 1.272471617436474
Validation loss: 2.3731783933531676

Epoch: 6| Step: 12
Training loss: 1.9900765997554686
Validation loss: 2.3248590902780686

Epoch: 6| Step: 13
Training loss: 1.47592948787016
Validation loss: 2.361138093405321

Epoch: 339| Step: 0
Training loss: 1.1188918764309572
Validation loss: 2.3924373159521513

Epoch: 6| Step: 1
Training loss: 1.8219559090447754
Validation loss: 2.3575872254239454

Epoch: 6| Step: 2
Training loss: 1.5678197709162645
Validation loss: 2.403379238852468

Epoch: 6| Step: 3
Training loss: 1.4596052163839757
Validation loss: 2.393847118011784

Epoch: 6| Step: 4
Training loss: 1.4159714264384407
Validation loss: 2.370762430216425

Epoch: 6| Step: 5
Training loss: 1.1621115804699398
Validation loss: 2.38774620210116

Epoch: 6| Step: 6
Training loss: 1.7134895973835957
Validation loss: 2.372377254109456

Epoch: 6| Step: 7
Training loss: 1.709034457971499
Validation loss: 2.387311152410442

Epoch: 6| Step: 8
Training loss: 2.191196261594048
Validation loss: 2.363304197328302

Epoch: 6| Step: 9
Training loss: 1.9136293505031683
Validation loss: 2.333157252188307

Epoch: 6| Step: 10
Training loss: 1.7471819394711754
Validation loss: 2.350599494103356

Epoch: 6| Step: 11
Training loss: 1.5591229374576097
Validation loss: 2.3532169120306903

Epoch: 6| Step: 12
Training loss: 1.7910095680658555
Validation loss: 2.395543980257171

Epoch: 6| Step: 13
Training loss: 1.4745705706814856
Validation loss: 2.373719367202048

Epoch: 340| Step: 0
Training loss: 1.6614525614511648
Validation loss: 2.3682704654762707

Epoch: 6| Step: 1
Training loss: 1.342283557656378
Validation loss: 2.409716421895804

Epoch: 6| Step: 2
Training loss: 1.6431138551841205
Validation loss: 2.314599651258732

Epoch: 6| Step: 3
Training loss: 1.5147556289137623
Validation loss: 2.3853223998498323

Epoch: 6| Step: 4
Training loss: 1.5783192732177
Validation loss: 2.37154601531451

Epoch: 6| Step: 5
Training loss: 2.5655506862048796
Validation loss: 2.3880430816717233

Epoch: 6| Step: 6
Training loss: 1.2644909617054612
Validation loss: 2.4345455833549265

Epoch: 6| Step: 7
Training loss: 1.2703462302972062
Validation loss: 2.380016019082528

Epoch: 6| Step: 8
Training loss: 1.5542795230637987
Validation loss: 2.34970851337132

Epoch: 6| Step: 9
Training loss: 1.8664894874250137
Validation loss: 2.378255548785908

Epoch: 6| Step: 10
Training loss: 1.4762220848086367
Validation loss: 2.367789654715974

Epoch: 6| Step: 11
Training loss: 1.7482821343522235
Validation loss: 2.364682581502199

Epoch: 6| Step: 12
Training loss: 1.8256958040052036
Validation loss: 2.4364653885042356

Epoch: 6| Step: 13
Training loss: 1.556504917331848
Validation loss: 2.3890299335301264

Epoch: 341| Step: 0
Training loss: 1.2723019925882113
Validation loss: 2.3724402410493477

Epoch: 6| Step: 1
Training loss: 2.1358239010431292
Validation loss: 2.423338326991663

Epoch: 6| Step: 2
Training loss: 1.4825797216842311
Validation loss: 2.3904239115013715

Epoch: 6| Step: 3
Training loss: 1.503081811613581
Validation loss: 2.324986452316136

Epoch: 6| Step: 4
Training loss: 2.051500641121928
Validation loss: 2.3395369643243766

Epoch: 6| Step: 5
Training loss: 1.5523791788605374
Validation loss: 2.4013813832755804

Epoch: 6| Step: 6
Training loss: 1.4206782743951492
Validation loss: 2.3407597871931323

Epoch: 6| Step: 7
Training loss: 1.57438897284546
Validation loss: 2.3436801290180904

Epoch: 6| Step: 8
Training loss: 1.4021953621140817
Validation loss: 2.400098980273421

Epoch: 6| Step: 9
Training loss: 1.9198361879244685
Validation loss: 2.428980947462517

Epoch: 6| Step: 10
Training loss: 1.4464164023585466
Validation loss: 2.357556036407356

Epoch: 6| Step: 11
Training loss: 1.6341323993415835
Validation loss: 2.377410122387676

Epoch: 6| Step: 12
Training loss: 1.7712349679291537
Validation loss: 2.3643697638856476

Epoch: 6| Step: 13
Training loss: 0.7695518142353628
Validation loss: 2.4336620508145397

Epoch: 342| Step: 0
Training loss: 1.6423514591907487
Validation loss: 2.3609029126368974

Epoch: 6| Step: 1
Training loss: 1.7907074940903887
Validation loss: 2.3686810504998683

Epoch: 6| Step: 2
Training loss: 1.5863287682662295
Validation loss: 2.3407601223296046

Epoch: 6| Step: 3
Training loss: 1.2391194776636905
Validation loss: 2.3698620641169357

Epoch: 6| Step: 4
Training loss: 1.8214336429920701
Validation loss: 2.3571864371103697

Epoch: 6| Step: 5
Training loss: 2.129721837036333
Validation loss: 2.3918544319199877

Epoch: 6| Step: 6
Training loss: 1.5412204543450627
Validation loss: 2.3967388819008932

Epoch: 6| Step: 7
Training loss: 1.904199278849235
Validation loss: 2.364397186271227

Epoch: 6| Step: 8
Training loss: 1.1607261824784163
Validation loss: 2.3505605876416316

Epoch: 6| Step: 9
Training loss: 1.204525912242468
Validation loss: 2.438264687413063

Epoch: 6| Step: 10
Training loss: 1.2959109940312215
Validation loss: 2.44372678486097

Epoch: 6| Step: 11
Training loss: 1.9814458539650874
Validation loss: 2.3653755965854826

Epoch: 6| Step: 12
Training loss: 1.9011285492016576
Validation loss: 2.3429489221507924

Epoch: 6| Step: 13
Training loss: 1.517916176553557
Validation loss: 2.369216857527173

Epoch: 343| Step: 0
Training loss: 1.2331040031706564
Validation loss: 2.3501179162635966

Epoch: 6| Step: 1
Training loss: 1.44514645834134
Validation loss: 2.365315554380488

Epoch: 6| Step: 2
Training loss: 1.9520585467360485
Validation loss: 2.3717635543736977

Epoch: 6| Step: 3
Training loss: 2.373814337060912
Validation loss: 2.4125325553491637

Epoch: 6| Step: 4
Training loss: 1.5580775426682991
Validation loss: 2.3588706976174603

Epoch: 6| Step: 5
Training loss: 1.7826060437175648
Validation loss: 2.3118253398326227

Epoch: 6| Step: 6
Training loss: 1.6859383598092108
Validation loss: 2.400987473205628

Epoch: 6| Step: 7
Training loss: 1.3128905850483945
Validation loss: 2.3681515704562233

Epoch: 6| Step: 8
Training loss: 1.324167166186255
Validation loss: 2.3833811462861876

Epoch: 6| Step: 9
Training loss: 1.2216639285210857
Validation loss: 2.325525374457998

Epoch: 6| Step: 10
Training loss: 1.8001563587094322
Validation loss: 2.395231333070615

Epoch: 6| Step: 11
Training loss: 1.7909838757878054
Validation loss: 2.4220810097661163

Epoch: 6| Step: 12
Training loss: 1.4394696880407332
Validation loss: 2.3566269251338627

Epoch: 6| Step: 13
Training loss: 0.9292048956757253
Validation loss: 2.421184067574451

Epoch: 344| Step: 0
Training loss: 1.7043100836113254
Validation loss: 2.3332431218365355

Epoch: 6| Step: 1
Training loss: 2.563812849966019
Validation loss: 2.356155853901782

Epoch: 6| Step: 2
Training loss: 1.7062799472067138
Validation loss: 2.4271870217340212

Epoch: 6| Step: 3
Training loss: 1.6607799121529372
Validation loss: 2.359402817272375

Epoch: 6| Step: 4
Training loss: 1.6388835565656277
Validation loss: 2.396328562897121

Epoch: 6| Step: 5
Training loss: 1.3291551521703382
Validation loss: 2.416862513449785

Epoch: 6| Step: 6
Training loss: 0.9709387940249923
Validation loss: 2.4358239944531186

Epoch: 6| Step: 7
Training loss: 1.6181804170397887
Validation loss: 2.3376805626457484

Epoch: 6| Step: 8
Training loss: 1.5575760886770291
Validation loss: 2.391801009067965

Epoch: 6| Step: 9
Training loss: 1.5318673893876824
Validation loss: 2.4200334796752414

Epoch: 6| Step: 10
Training loss: 1.659620202980082
Validation loss: 2.3897200819492044

Epoch: 6| Step: 11
Training loss: 1.4400890917503488
Validation loss: 2.3691033756723656

Epoch: 6| Step: 12
Training loss: 1.5666330225693526
Validation loss: 2.3684102536560783

Epoch: 6| Step: 13
Training loss: 1.444381248893079
Validation loss: 2.3387439537153245

Epoch: 345| Step: 0
Training loss: 1.4439867692483903
Validation loss: 2.361391837120092

Epoch: 6| Step: 1
Training loss: 1.5760262763597075
Validation loss: 2.388143565372273

Epoch: 6| Step: 2
Training loss: 1.9547507881878188
Validation loss: 2.3650693077368206

Epoch: 6| Step: 3
Training loss: 1.7186831374601155
Validation loss: 2.3813774964237147

Epoch: 6| Step: 4
Training loss: 1.3316411764468827
Validation loss: 2.4331717945623006

Epoch: 6| Step: 5
Training loss: 1.560287664129078
Validation loss: 2.373602759979097

Epoch: 6| Step: 6
Training loss: 1.469683735879356
Validation loss: 2.432330579938938

Epoch: 6| Step: 7
Training loss: 2.5179622052350563
Validation loss: 2.4175188035343234

Epoch: 6| Step: 8
Training loss: 1.3195153713682535
Validation loss: 2.39065465306194

Epoch: 6| Step: 9
Training loss: 1.129323862308195
Validation loss: 2.3799488059604763

Epoch: 6| Step: 10
Training loss: 1.4868824710794544
Validation loss: 2.39594265624626

Epoch: 6| Step: 11
Training loss: 1.5809712944633867
Validation loss: 2.393239897266802

Epoch: 6| Step: 12
Training loss: 1.705584508765405
Validation loss: 2.386840013784438

Epoch: 6| Step: 13
Training loss: 1.4025660261636217
Validation loss: 2.4046254250627945

Epoch: 346| Step: 0
Training loss: 1.7808777269546152
Validation loss: 2.4249515233016803

Epoch: 6| Step: 1
Training loss: 1.2222540928317023
Validation loss: 2.399182656190089

Epoch: 6| Step: 2
Training loss: 1.573891125230195
Validation loss: 2.382376990014949

Epoch: 6| Step: 3
Training loss: 1.4935797143383027
Validation loss: 2.372082341337331

Epoch: 6| Step: 4
Training loss: 1.4939061996959482
Validation loss: 2.3901055742402657

Epoch: 6| Step: 5
Training loss: 1.6421863211093086
Validation loss: 2.4023110717717184

Epoch: 6| Step: 6
Training loss: 1.2310378923076915
Validation loss: 2.3283358380234946

Epoch: 6| Step: 7
Training loss: 1.3936046439013534
Validation loss: 2.4283347292811115

Epoch: 6| Step: 8
Training loss: 1.2206631829402872
Validation loss: 2.3923288078402756

Epoch: 6| Step: 9
Training loss: 2.5871693422906197
Validation loss: 2.316594687785422

Epoch: 6| Step: 10
Training loss: 1.5280313724472758
Validation loss: 2.382288792438842

Epoch: 6| Step: 11
Training loss: 1.855382270805424
Validation loss: 2.375073911577859

Epoch: 6| Step: 12
Training loss: 1.6450595324332897
Validation loss: 2.332296786896485

Epoch: 6| Step: 13
Training loss: 0.9214568078613994
Validation loss: 2.3939397507869336

Epoch: 347| Step: 0
Training loss: 1.7253552527123606
Validation loss: 2.369496669931946

Epoch: 6| Step: 1
Training loss: 0.9165823998877551
Validation loss: 2.3930982717530296

Epoch: 6| Step: 2
Training loss: 1.3390344783739858
Validation loss: 2.35373959128167

Epoch: 6| Step: 3
Training loss: 1.689181161500568
Validation loss: 2.3983107254050604

Epoch: 6| Step: 4
Training loss: 1.7480358954569641
Validation loss: 2.392043369947649

Epoch: 6| Step: 5
Training loss: 1.5194570332032205
Validation loss: 2.3878883372205952

Epoch: 6| Step: 6
Training loss: 1.8240620384457533
Validation loss: 2.407934154810137

Epoch: 6| Step: 7
Training loss: 1.795298008739927
Validation loss: 2.3124071932381027

Epoch: 6| Step: 8
Training loss: 1.6907754122516339
Validation loss: 2.389634404020809

Epoch: 6| Step: 9
Training loss: 1.4965706406326313
Validation loss: 2.380852494422548

Epoch: 6| Step: 10
Training loss: 1.2205955030683162
Validation loss: 2.413348939292558

Epoch: 6| Step: 11
Training loss: 2.1928873479865474
Validation loss: 2.3524669319335927

Epoch: 6| Step: 12
Training loss: 1.2555888642522444
Validation loss: 2.3799365691289878

Epoch: 6| Step: 13
Training loss: 1.6029490353864613
Validation loss: 2.37456336160772

Epoch: 348| Step: 0
Training loss: 1.4387373367401879
Validation loss: 2.411673945738482

Epoch: 6| Step: 1
Training loss: 1.5672701691172333
Validation loss: 2.404965928918759

Epoch: 6| Step: 2
Training loss: 1.8598309126260835
Validation loss: 2.3975833794807135

Epoch: 6| Step: 3
Training loss: 1.290908508935619
Validation loss: 2.3595117633778777

Epoch: 6| Step: 4
Training loss: 1.6782366497043522
Validation loss: 2.4129660670778215

Epoch: 6| Step: 5
Training loss: 1.5444437051370317
Validation loss: 2.3667915137847437

Epoch: 6| Step: 6
Training loss: 1.5214379907082354
Validation loss: 2.4099367066030055

Epoch: 6| Step: 7
Training loss: 1.553365173804826
Validation loss: 2.357885874000401

Epoch: 6| Step: 8
Training loss: 1.8093761621975502
Validation loss: 2.4138377461642335

Epoch: 6| Step: 9
Training loss: 1.4083336546105614
Validation loss: 2.442547821985073

Epoch: 6| Step: 10
Training loss: 1.117989419016985
Validation loss: 2.4134225092243553

Epoch: 6| Step: 11
Training loss: 1.250785199551658
Validation loss: 2.3613815386394608

Epoch: 6| Step: 12
Training loss: 2.292756000897365
Validation loss: 2.396748817738578

Epoch: 6| Step: 13
Training loss: 1.4064342378091046
Validation loss: 2.4293095677533714

Epoch: 349| Step: 0
Training loss: 2.113616409095696
Validation loss: 2.3956559763387952

Epoch: 6| Step: 1
Training loss: 1.7917604052248295
Validation loss: 2.4339435737920723

Epoch: 6| Step: 2
Training loss: 1.144107362544354
Validation loss: 2.4265762180276864

Epoch: 6| Step: 3
Training loss: 1.4694889725683136
Validation loss: 2.4150504176784042

Epoch: 6| Step: 4
Training loss: 1.3543003114140135
Validation loss: 2.385732175735089

Epoch: 6| Step: 5
Training loss: 1.3484247642437248
Validation loss: 2.4542037894065363

Epoch: 6| Step: 6
Training loss: 1.969870354506106
Validation loss: 2.414380306005431

Epoch: 6| Step: 7
Training loss: 1.3440906625124065
Validation loss: 2.40619832390776

Epoch: 6| Step: 8
Training loss: 1.7661257683542175
Validation loss: 2.3864209316723106

Epoch: 6| Step: 9
Training loss: 1.4112721516278808
Validation loss: 2.3964475025521197

Epoch: 6| Step: 10
Training loss: 1.6312549225597721
Validation loss: 2.3788584522797587

Epoch: 6| Step: 11
Training loss: 1.2413997431513117
Validation loss: 2.3818330023472423

Epoch: 6| Step: 12
Training loss: 1.7236895241201426
Validation loss: 2.383267120668115

Epoch: 6| Step: 13
Training loss: 1.7629612772211076
Validation loss: 2.3733799292722466

Epoch: 350| Step: 0
Training loss: 1.1321516016450097
Validation loss: 2.448663505373333

Epoch: 6| Step: 1
Training loss: 1.6351043095110378
Validation loss: 2.4131356101395047

Epoch: 6| Step: 2
Training loss: 1.5909946783997007
Validation loss: 2.483348555709896

Epoch: 6| Step: 3
Training loss: 1.4187703034548806
Validation loss: 2.4068075268493554

Epoch: 6| Step: 4
Training loss: 1.7756306535307895
Validation loss: 2.424293189396161

Epoch: 6| Step: 5
Training loss: 1.445790804513239
Validation loss: 2.4203868357274554

Epoch: 6| Step: 6
Training loss: 1.726548345861631
Validation loss: 2.4423624240648647

Epoch: 6| Step: 7
Training loss: 1.5014627794701256
Validation loss: 2.462594467007657

Epoch: 6| Step: 8
Training loss: 1.9911481352551728
Validation loss: 2.4234009200557005

Epoch: 6| Step: 9
Training loss: 1.417651096209754
Validation loss: 2.4051925856560787

Epoch: 6| Step: 10
Training loss: 1.0468534780539012
Validation loss: 2.426709880790029

Epoch: 6| Step: 11
Training loss: 1.486766534980514
Validation loss: 2.352752315860655

Epoch: 6| Step: 12
Training loss: 1.6076630310633364
Validation loss: 2.346487535469411

Epoch: 6| Step: 13
Training loss: 2.8663584994489577
Validation loss: 2.406625189721047

Epoch: 351| Step: 0
Training loss: 2.1962840689555283
Validation loss: 2.350686396290494

Epoch: 6| Step: 1
Training loss: 1.7681368624416356
Validation loss: 2.4059805402887946

Epoch: 6| Step: 2
Training loss: 1.4699249437854127
Validation loss: 2.346296922519137

Epoch: 6| Step: 3
Training loss: 1.8392838519082977
Validation loss: 2.3648743473190224

Epoch: 6| Step: 4
Training loss: 1.8562716704365587
Validation loss: 2.390312519169664

Epoch: 6| Step: 5
Training loss: 1.7759697266567414
Validation loss: 2.4122355476903206

Epoch: 6| Step: 6
Training loss: 1.6032275964577523
Validation loss: 2.3945780978703572

Epoch: 6| Step: 7
Training loss: 1.2454503230812475
Validation loss: 2.373618008260253

Epoch: 6| Step: 8
Training loss: 1.4431698149425634
Validation loss: 2.3934437327539326

Epoch: 6| Step: 9
Training loss: 1.3395475721950016
Validation loss: 2.3731734684601142

Epoch: 6| Step: 10
Training loss: 1.6606023929479927
Validation loss: 2.365695623096084

Epoch: 6| Step: 11
Training loss: 1.5457833802137095
Validation loss: 2.347351350351474

Epoch: 6| Step: 12
Training loss: 1.2971935570377175
Validation loss: 2.38435471855553

Epoch: 6| Step: 13
Training loss: 1.3073807289617323
Validation loss: 2.401565091818268

Epoch: 352| Step: 0
Training loss: 1.718694096436374
Validation loss: 2.399971489625878

Epoch: 6| Step: 1
Training loss: 1.5914833555798333
Validation loss: 2.431426517835479

Epoch: 6| Step: 2
Training loss: 2.058805451193545
Validation loss: 2.4097923894584103

Epoch: 6| Step: 3
Training loss: 1.575121675060218
Validation loss: 2.423879451144981

Epoch: 6| Step: 4
Training loss: 1.0302049370000312
Validation loss: 2.3700951065649334

Epoch: 6| Step: 5
Training loss: 1.5471678177319956
Validation loss: 2.419719219010964

Epoch: 6| Step: 6
Training loss: 1.4508992859415006
Validation loss: 2.3600345616793277

Epoch: 6| Step: 7
Training loss: 1.281207665465091
Validation loss: 2.3984664044648154

Epoch: 6| Step: 8
Training loss: 1.4461295627835589
Validation loss: 2.3583976722335076

Epoch: 6| Step: 9
Training loss: 1.7203913394279828
Validation loss: 2.3277287261241084

Epoch: 6| Step: 10
Training loss: 1.8659793664173743
Validation loss: 2.397246932379162

Epoch: 6| Step: 11
Training loss: 1.4146016815898257
Validation loss: 2.3801801617965004

Epoch: 6| Step: 12
Training loss: 1.1573896719668677
Validation loss: 2.352397665328604

Epoch: 6| Step: 13
Training loss: 2.036500570992573
Validation loss: 2.391912938180315

Epoch: 353| Step: 0
Training loss: 1.7504441515096452
Validation loss: 2.4227277352078245

Epoch: 6| Step: 1
Training loss: 1.1409110141794587
Validation loss: 2.384689647643444

Epoch: 6| Step: 2
Training loss: 1.4524222694910645
Validation loss: 2.3989114157191045

Epoch: 6| Step: 3
Training loss: 1.2546175071414272
Validation loss: 2.374690383781064

Epoch: 6| Step: 4
Training loss: 1.177242802758128
Validation loss: 2.361379235425782

Epoch: 6| Step: 5
Training loss: 1.7763502089751748
Validation loss: 2.4301515912903175

Epoch: 6| Step: 6
Training loss: 1.2646548002222902
Validation loss: 2.3524983366269825

Epoch: 6| Step: 7
Training loss: 1.5691647106826323
Validation loss: 2.3903468302148134

Epoch: 6| Step: 8
Training loss: 1.7134292782118892
Validation loss: 2.406570518698855

Epoch: 6| Step: 9
Training loss: 1.7206446521882441
Validation loss: 2.4183051658390924

Epoch: 6| Step: 10
Training loss: 2.391288715055127
Validation loss: 2.374810837885661

Epoch: 6| Step: 11
Training loss: 0.9351513370904326
Validation loss: 2.35459068095971

Epoch: 6| Step: 12
Training loss: 1.5157741984443316
Validation loss: 2.3943759103869877

Epoch: 6| Step: 13
Training loss: 1.385564791378295
Validation loss: 2.4008877171241485

Epoch: 354| Step: 0
Training loss: 1.7589460320882013
Validation loss: 2.373504559695327

Epoch: 6| Step: 1
Training loss: 1.6730733836850775
Validation loss: 2.389411731531293

Epoch: 6| Step: 2
Training loss: 1.8522723161236316
Validation loss: 2.373361923942665

Epoch: 6| Step: 3
Training loss: 1.741691484533045
Validation loss: 2.3705175215570473

Epoch: 6| Step: 4
Training loss: 1.374077704360472
Validation loss: 2.4267825887831553

Epoch: 6| Step: 5
Training loss: 1.1708469204549825
Validation loss: 2.3298181154375395

Epoch: 6| Step: 6
Training loss: 1.1341598390760979
Validation loss: 2.356996254867129

Epoch: 6| Step: 7
Training loss: 1.4484291084647274
Validation loss: 2.377425487510011

Epoch: 6| Step: 8
Training loss: 2.4706088443906293
Validation loss: 2.3948490862188185

Epoch: 6| Step: 9
Training loss: 1.142576507828049
Validation loss: 2.370771263805598

Epoch: 6| Step: 10
Training loss: 1.6518603760919568
Validation loss: 2.4038377189141165

Epoch: 6| Step: 11
Training loss: 0.9728469048974251
Validation loss: 2.4022791587936263

Epoch: 6| Step: 12
Training loss: 1.592336364315716
Validation loss: 2.371717355151442

Epoch: 6| Step: 13
Training loss: 1.1898193296755573
Validation loss: 2.382658288982908

Epoch: 355| Step: 0
Training loss: 1.2377086964347566
Validation loss: 2.4317256705220593

Epoch: 6| Step: 1
Training loss: 1.381149757855928
Validation loss: 2.3907907540964146

Epoch: 6| Step: 2
Training loss: 1.263815351356688
Validation loss: 2.421886815344298

Epoch: 6| Step: 3
Training loss: 1.5225326589705181
Validation loss: 2.4236652237258154

Epoch: 6| Step: 4
Training loss: 0.9698599947341272
Validation loss: 2.4153292338783485

Epoch: 6| Step: 5
Training loss: 1.2522881546102416
Validation loss: 2.441748788344292

Epoch: 6| Step: 6
Training loss: 1.4438563254040977
Validation loss: 2.4246764980985716

Epoch: 6| Step: 7
Training loss: 1.8443442857822616
Validation loss: 2.4224725680055985

Epoch: 6| Step: 8
Training loss: 1.4624730164736628
Validation loss: 2.356968762689965

Epoch: 6| Step: 9
Training loss: 2.4260183025025075
Validation loss: 2.4175407524816976

Epoch: 6| Step: 10
Training loss: 1.6470909946970178
Validation loss: 2.45104776207217

Epoch: 6| Step: 11
Training loss: 1.5649462052627274
Validation loss: 2.4011352764966603

Epoch: 6| Step: 12
Training loss: 1.5564975648855441
Validation loss: 2.3690711057221177

Epoch: 6| Step: 13
Training loss: 1.7931190710278866
Validation loss: 2.392695200342884

Epoch: 356| Step: 0
Training loss: 1.3926168599566642
Validation loss: 2.3348327036892123

Epoch: 6| Step: 1
Training loss: 1.4761252588450666
Validation loss: 2.41074249317052

Epoch: 6| Step: 2
Training loss: 1.6068925692926852
Validation loss: 2.4018312582708328

Epoch: 6| Step: 3
Training loss: 1.4552701477742644
Validation loss: 2.353226307166597

Epoch: 6| Step: 4
Training loss: 1.182349328246833
Validation loss: 2.3728568192694124

Epoch: 6| Step: 5
Training loss: 1.1371839167996294
Validation loss: 2.377201327392986

Epoch: 6| Step: 6
Training loss: 1.3453075342385759
Validation loss: 2.350110554609185

Epoch: 6| Step: 7
Training loss: 1.424077183587267
Validation loss: 2.3530521631417725

Epoch: 6| Step: 8
Training loss: 1.819170679684155
Validation loss: 2.3702320041811076

Epoch: 6| Step: 9
Training loss: 1.4889371132671803
Validation loss: 2.31343132251185

Epoch: 6| Step: 10
Training loss: 1.4343962125518632
Validation loss: 2.3543075213018922

Epoch: 6| Step: 11
Training loss: 2.5150825436888953
Validation loss: 2.3935654816181384

Epoch: 6| Step: 12
Training loss: 1.377777156052056
Validation loss: 2.3671024541023042

Epoch: 6| Step: 13
Training loss: 1.9684289943028634
Validation loss: 2.3932415469155575

Epoch: 357| Step: 0
Training loss: 1.6700103914771314
Validation loss: 2.4422220411218514

Epoch: 6| Step: 1
Training loss: 1.2229944315960584
Validation loss: 2.3944954459522987

Epoch: 6| Step: 2
Training loss: 2.276359960674661
Validation loss: 2.392539387921546

Epoch: 6| Step: 3
Training loss: 1.9045696669595706
Validation loss: 2.388597413406528

Epoch: 6| Step: 4
Training loss: 1.161012891988616
Validation loss: 2.320158159626405

Epoch: 6| Step: 5
Training loss: 1.176526210676141
Validation loss: 2.3938151165610524

Epoch: 6| Step: 6
Training loss: 1.5162596013078862
Validation loss: 2.372771967255061

Epoch: 6| Step: 7
Training loss: 1.8864801544269887
Validation loss: 2.3941436624125485

Epoch: 6| Step: 8
Training loss: 1.3335992975013453
Validation loss: 2.40281557548188

Epoch: 6| Step: 9
Training loss: 1.2477157702786719
Validation loss: 2.335951874726091

Epoch: 6| Step: 10
Training loss: 1.8240038726832453
Validation loss: 2.3525403451159845

Epoch: 6| Step: 11
Training loss: 1.3034338495920885
Validation loss: 2.3314954266100565

Epoch: 6| Step: 12
Training loss: 1.4823199854076021
Validation loss: 2.392080547400596

Epoch: 6| Step: 13
Training loss: 1.3817746853142672
Validation loss: 2.390149025098368

Epoch: 358| Step: 0
Training loss: 1.1363113564689618
Validation loss: 2.3626466671173287

Epoch: 6| Step: 1
Training loss: 1.6245048942456968
Validation loss: 2.4431206115431907

Epoch: 6| Step: 2
Training loss: 1.6500326818061641
Validation loss: 2.373094494853859

Epoch: 6| Step: 3
Training loss: 1.6133170135450279
Validation loss: 2.375596306750721

Epoch: 6| Step: 4
Training loss: 1.6443446545064557
Validation loss: 2.4306588659485273

Epoch: 6| Step: 5
Training loss: 1.4710288529305517
Validation loss: 2.413748853818543

Epoch: 6| Step: 6
Training loss: 1.4278400762962857
Validation loss: 2.4417428583895155

Epoch: 6| Step: 7
Training loss: 1.1555812551369185
Validation loss: 2.4251748956809567

Epoch: 6| Step: 8
Training loss: 1.1918280183267025
Validation loss: 2.3658572598745837

Epoch: 6| Step: 9
Training loss: 1.551222884857969
Validation loss: 2.410830738705438

Epoch: 6| Step: 10
Training loss: 2.1318125633953935
Validation loss: 2.360091162315313

Epoch: 6| Step: 11
Training loss: 1.7488868442788965
Validation loss: 2.374449477214263

Epoch: 6| Step: 12
Training loss: 1.9349860833034755
Validation loss: 2.3859137102203527

Epoch: 6| Step: 13
Training loss: 1.6299914214721734
Validation loss: 2.3635191921453327

Epoch: 359| Step: 0
Training loss: 1.1987413083458485
Validation loss: 2.333764593055245

Epoch: 6| Step: 1
Training loss: 1.395921799242866
Validation loss: 2.3260170786141403

Epoch: 6| Step: 2
Training loss: 1.6485244221843758
Validation loss: 2.369362468362773

Epoch: 6| Step: 3
Training loss: 1.8041250169746494
Validation loss: 2.3859216700296564

Epoch: 6| Step: 4
Training loss: 1.7262128242837498
Validation loss: 2.3862836155896643

Epoch: 6| Step: 5
Training loss: 1.6072481786943358
Validation loss: 2.3755801635910188

Epoch: 6| Step: 6
Training loss: 2.023584662428742
Validation loss: 2.3438824403594603

Epoch: 6| Step: 7
Training loss: 1.433724296093308
Validation loss: 2.315364684061716

Epoch: 6| Step: 8
Training loss: 1.5541649328363614
Validation loss: 2.4008216265042717

Epoch: 6| Step: 9
Training loss: 1.1513062542685413
Validation loss: 2.3845063481516817

Epoch: 6| Step: 10
Training loss: 1.0536695300743861
Validation loss: 2.4082915636469764

Epoch: 6| Step: 11
Training loss: 1.208750565064228
Validation loss: 2.3416493748850535

Epoch: 6| Step: 12
Training loss: 1.383148454276799
Validation loss: 2.3671043747181018

Epoch: 6| Step: 13
Training loss: 2.0754297891429294
Validation loss: 2.324464657877176

Epoch: 360| Step: 0
Training loss: 1.5561234633390426
Validation loss: 2.3618778415464172

Epoch: 6| Step: 1
Training loss: 1.4746012908511847
Validation loss: 2.361155093163635

Epoch: 6| Step: 2
Training loss: 1.0634195611983746
Validation loss: 2.4069657248804948

Epoch: 6| Step: 3
Training loss: 1.3344880210307382
Validation loss: 2.3578165121631565

Epoch: 6| Step: 4
Training loss: 2.081743116642042
Validation loss: 2.367572721808153

Epoch: 6| Step: 5
Training loss: 1.4134876916522883
Validation loss: 2.449171741456626

Epoch: 6| Step: 6
Training loss: 1.0599884192715825
Validation loss: 2.4156600233249357

Epoch: 6| Step: 7
Training loss: 1.5019847137343803
Validation loss: 2.3951295947101867

Epoch: 6| Step: 8
Training loss: 1.4168957730702654
Validation loss: 2.404405376652802

Epoch: 6| Step: 9
Training loss: 1.404212577740891
Validation loss: 2.4070071251943004

Epoch: 6| Step: 10
Training loss: 1.5695142852337263
Validation loss: 2.354496333214808

Epoch: 6| Step: 11
Training loss: 1.7607953343381166
Validation loss: 2.402498355682361

Epoch: 6| Step: 12
Training loss: 2.3844015857419283
Validation loss: 2.3699183153785435

Epoch: 6| Step: 13
Training loss: 1.95944010795217
Validation loss: 2.3867886639456564

Epoch: 361| Step: 0
Training loss: 1.3029960129384823
Validation loss: 2.4284990295913444

Epoch: 6| Step: 1
Training loss: 1.363519554842872
Validation loss: 2.4193520341535604

Epoch: 6| Step: 2
Training loss: 1.544975733149789
Validation loss: 2.3331959972602108

Epoch: 6| Step: 3
Training loss: 1.5259368738989139
Validation loss: 2.359663957236077

Epoch: 6| Step: 4
Training loss: 1.5169999483041874
Validation loss: 2.3808206550721467

Epoch: 6| Step: 5
Training loss: 1.3666088514582038
Validation loss: 2.3937587307239814

Epoch: 6| Step: 6
Training loss: 1.0588352167272987
Validation loss: 2.380163952788498

Epoch: 6| Step: 7
Training loss: 1.2518695202315673
Validation loss: 2.406410969406888

Epoch: 6| Step: 8
Training loss: 1.3473488277360413
Validation loss: 2.4108244051775642

Epoch: 6| Step: 9
Training loss: 1.6754710659532976
Validation loss: 2.420051419018559

Epoch: 6| Step: 10
Training loss: 1.6860110460419553
Validation loss: 2.4096322060894413

Epoch: 6| Step: 11
Training loss: 1.3956940662123152
Validation loss: 2.3573725117547846

Epoch: 6| Step: 12
Training loss: 2.4775661997799356
Validation loss: 2.366321126442888

Epoch: 6| Step: 13
Training loss: 1.526105998726217
Validation loss: 2.3517943335337357

Epoch: 362| Step: 0
Training loss: 1.0441751539327366
Validation loss: 2.41864293825937

Epoch: 6| Step: 1
Training loss: 1.738687120695171
Validation loss: 2.411255775998074

Epoch: 6| Step: 2
Training loss: 1.064093348746336
Validation loss: 2.3687318864662794

Epoch: 6| Step: 3
Training loss: 1.612632048175508
Validation loss: 2.389500582433607

Epoch: 6| Step: 4
Training loss: 1.4305454035689895
Validation loss: 2.393337183893905

Epoch: 6| Step: 5
Training loss: 1.3907942508183717
Validation loss: 2.385832575168668

Epoch: 6| Step: 6
Training loss: 1.3074622429233766
Validation loss: 2.422242439016529

Epoch: 6| Step: 7
Training loss: 1.8632921262539617
Validation loss: 2.318967913907947

Epoch: 6| Step: 8
Training loss: 1.9317052384881888
Validation loss: 2.41691231106812

Epoch: 6| Step: 9
Training loss: 1.3645088330769588
Validation loss: 2.3843343510944313

Epoch: 6| Step: 10
Training loss: 1.1312776361957109
Validation loss: 2.366921961925097

Epoch: 6| Step: 11
Training loss: 1.07816779010278
Validation loss: 2.3823264726593245

Epoch: 6| Step: 12
Training loss: 2.506838220075899
Validation loss: 2.317484872094295

Epoch: 6| Step: 13
Training loss: 1.3469139376718506
Validation loss: 2.3897270399812687

Epoch: 363| Step: 0
Training loss: 1.4028234484868407
Validation loss: 2.3181547687363473

Epoch: 6| Step: 1
Training loss: 1.3273718100686474
Validation loss: 2.3275924968874158

Epoch: 6| Step: 2
Training loss: 1.2131720813732227
Validation loss: 2.4053058004984686

Epoch: 6| Step: 3
Training loss: 1.2245983263213953
Validation loss: 2.3620586566176085

Epoch: 6| Step: 4
Training loss: 1.5945295035741907
Validation loss: 2.3814232132754176

Epoch: 6| Step: 5
Training loss: 1.433289955650846
Validation loss: 2.3834508402941257

Epoch: 6| Step: 6
Training loss: 1.419698369670807
Validation loss: 2.383530548478858

Epoch: 6| Step: 7
Training loss: 1.8905433447993367
Validation loss: 2.31104778397804

Epoch: 6| Step: 8
Training loss: 2.485116236249749
Validation loss: 2.3829056733526324

Epoch: 6| Step: 9
Training loss: 1.2734053906096119
Validation loss: 2.397920566241099

Epoch: 6| Step: 10
Training loss: 1.5968139965252375
Validation loss: 2.3753367980203564

Epoch: 6| Step: 11
Training loss: 1.4718996730283411
Validation loss: 2.3638758196951732

Epoch: 6| Step: 12
Training loss: 1.3451675212865113
Validation loss: 2.399433355323849

Epoch: 6| Step: 13
Training loss: 1.2929871894927585
Validation loss: 2.35313121672432

Epoch: 364| Step: 0
Training loss: 1.2988600648093478
Validation loss: 2.3957366040156858

Epoch: 6| Step: 1
Training loss: 1.3672241641986738
Validation loss: 2.3688643949079733

Epoch: 6| Step: 2
Training loss: 1.3226913600707224
Validation loss: 2.3757958862377415

Epoch: 6| Step: 3
Training loss: 1.7714562461159113
Validation loss: 2.3938482202653475

Epoch: 6| Step: 4
Training loss: 1.4339831080751946
Validation loss: 2.417823591663973

Epoch: 6| Step: 5
Training loss: 1.691451426689004
Validation loss: 2.3830655925628856

Epoch: 6| Step: 6
Training loss: 0.9761705145916079
Validation loss: 2.3766675593481734

Epoch: 6| Step: 7
Training loss: 2.445925212306287
Validation loss: 2.359536252171419

Epoch: 6| Step: 8
Training loss: 1.608231814380819
Validation loss: 2.391747107504884

Epoch: 6| Step: 9
Training loss: 1.3983659779250865
Validation loss: 2.3891877270614676

Epoch: 6| Step: 10
Training loss: 1.5972579049072877
Validation loss: 2.3971628495867043

Epoch: 6| Step: 11
Training loss: 1.5602267704490365
Validation loss: 2.3738998240722853

Epoch: 6| Step: 12
Training loss: 1.4983446205797462
Validation loss: 2.3864287533590174

Epoch: 6| Step: 13
Training loss: 1.065336816028477
Validation loss: 2.3844512737376125

Epoch: 365| Step: 0
Training loss: 1.8030088469911874
Validation loss: 2.4202514880554613

Epoch: 6| Step: 1
Training loss: 1.4394774726040422
Validation loss: 2.302190413346685

Epoch: 6| Step: 2
Training loss: 2.4638211264521326
Validation loss: 2.3570740776564265

Epoch: 6| Step: 3
Training loss: 1.1500892956936661
Validation loss: 2.35864684901216

Epoch: 6| Step: 4
Training loss: 1.7709040758550778
Validation loss: 2.330325800729393

Epoch: 6| Step: 5
Training loss: 1.5000364775990642
Validation loss: 2.4105239475728633

Epoch: 6| Step: 6
Training loss: 1.356711134326318
Validation loss: 2.334357202558184

Epoch: 6| Step: 7
Training loss: 1.2677780487442136
Validation loss: 2.38584551135969

Epoch: 6| Step: 8
Training loss: 1.1356460386268374
Validation loss: 2.410584674868343

Epoch: 6| Step: 9
Training loss: 1.2516541027212298
Validation loss: 2.365299803860569

Epoch: 6| Step: 10
Training loss: 1.027498240875446
Validation loss: 2.319869136812943

Epoch: 6| Step: 11
Training loss: 1.788290131939737
Validation loss: 2.3927935762316843

Epoch: 6| Step: 12
Training loss: 1.4489926884205424
Validation loss: 2.345313337132874

Epoch: 6| Step: 13
Training loss: 1.798552683597639
Validation loss: 2.365748537176585

Epoch: 366| Step: 0
Training loss: 1.3863305636524497
Validation loss: 2.431758132693475

Epoch: 6| Step: 1
Training loss: 1.3286635709341466
Validation loss: 2.390965295354768

Epoch: 6| Step: 2
Training loss: 1.3579411453392678
Validation loss: 2.3396865173131873

Epoch: 6| Step: 3
Training loss: 2.1761845706260554
Validation loss: 2.3614693945489544

Epoch: 6| Step: 4
Training loss: 1.8839869971180954
Validation loss: 2.3840596491601205

Epoch: 6| Step: 5
Training loss: 1.6692412835499604
Validation loss: 2.357794275257347

Epoch: 6| Step: 6
Training loss: 1.3609370322505878
Validation loss: 2.3396609786866316

Epoch: 6| Step: 7
Training loss: 1.1895094483919497
Validation loss: 2.367365933763893

Epoch: 6| Step: 8
Training loss: 1.6819926213614045
Validation loss: 2.3131377558253643

Epoch: 6| Step: 9
Training loss: 1.2781298257228342
Validation loss: 2.294032446530376

Epoch: 6| Step: 10
Training loss: 1.4076851197596791
Validation loss: 2.3352955889528135

Epoch: 6| Step: 11
Training loss: 1.3124468656411297
Validation loss: 2.370101126544384

Epoch: 6| Step: 12
Training loss: 1.7212108681302185
Validation loss: 2.3504445755318755

Epoch: 6| Step: 13
Training loss: 1.1785580109992582
Validation loss: 2.3151960401872986

Epoch: 367| Step: 0
Training loss: 1.5514693187073532
Validation loss: 2.3718865933396307

Epoch: 6| Step: 1
Training loss: 0.9341152123451862
Validation loss: 2.3372405226167965

Epoch: 6| Step: 2
Training loss: 1.4420007652989657
Validation loss: 2.3473608082808006

Epoch: 6| Step: 3
Training loss: 2.0199046278619095
Validation loss: 2.395927629759683

Epoch: 6| Step: 4
Training loss: 1.3939456939162247
Validation loss: 2.365215170658281

Epoch: 6| Step: 5
Training loss: 1.3629086922661362
Validation loss: 2.340686007811577

Epoch: 6| Step: 6
Training loss: 1.128370692584546
Validation loss: 2.3712976869428792

Epoch: 6| Step: 7
Training loss: 1.3625648168142834
Validation loss: 2.390184145063509

Epoch: 6| Step: 8
Training loss: 1.7783591922404136
Validation loss: 2.3437586575693454

Epoch: 6| Step: 9
Training loss: 1.105135432699472
Validation loss: 2.4522226629759807

Epoch: 6| Step: 10
Training loss: 2.000079987833775
Validation loss: 2.3928104389473766

Epoch: 6| Step: 11
Training loss: 1.0273905116125224
Validation loss: 2.470703166504632

Epoch: 6| Step: 12
Training loss: 1.8074968278363726
Validation loss: 2.41312276181376

Epoch: 6| Step: 13
Training loss: 1.9181130659888734
Validation loss: 2.3681795596009056

Epoch: 368| Step: 0
Training loss: 1.1695986700915384
Validation loss: 2.3299860816669073

Epoch: 6| Step: 1
Training loss: 2.2163583464583905
Validation loss: 2.384567736957003

Epoch: 6| Step: 2
Training loss: 1.7226608172505355
Validation loss: 2.362408512295347

Epoch: 6| Step: 3
Training loss: 1.572318015795405
Validation loss: 2.3120609882209693

Epoch: 6| Step: 4
Training loss: 1.3156926515994913
Validation loss: 2.38161694924251

Epoch: 6| Step: 5
Training loss: 1.540434095459333
Validation loss: 2.375504365138591

Epoch: 6| Step: 6
Training loss: 1.3480874518911865
Validation loss: 2.3625404481625885

Epoch: 6| Step: 7
Training loss: 1.5922514658349325
Validation loss: 2.3659565588059617

Epoch: 6| Step: 8
Training loss: 1.3963522681859262
Validation loss: 2.393889197928368

Epoch: 6| Step: 9
Training loss: 1.734360016079348
Validation loss: 2.379296928270524

Epoch: 6| Step: 10
Training loss: 1.1233433075149806
Validation loss: 2.3244827916073536

Epoch: 6| Step: 11
Training loss: 1.401490443321958
Validation loss: 2.403975224553436

Epoch: 6| Step: 12
Training loss: 1.1534348833896224
Validation loss: 2.393549325767735

Epoch: 6| Step: 13
Training loss: 1.8810107842622446
Validation loss: 2.3487264194322206

Epoch: 369| Step: 0
Training loss: 1.5521445635637685
Validation loss: 2.3390863151898915

Epoch: 6| Step: 1
Training loss: 1.3786703021341593
Validation loss: 2.3894424886469996

Epoch: 6| Step: 2
Training loss: 1.3385129497530064
Validation loss: 2.3945006760189704

Epoch: 6| Step: 3
Training loss: 1.6360678459640021
Validation loss: 2.315630195816329

Epoch: 6| Step: 4
Training loss: 1.0999546626891576
Validation loss: 2.398758505782352

Epoch: 6| Step: 5
Training loss: 1.6174857191725975
Validation loss: 2.3860700869205984

Epoch: 6| Step: 6
Training loss: 1.082058737505524
Validation loss: 2.3770361792702572

Epoch: 6| Step: 7
Training loss: 1.2343520150277933
Validation loss: 2.315533698727097

Epoch: 6| Step: 8
Training loss: 1.3054941390631731
Validation loss: 2.4172994886936903

Epoch: 6| Step: 9
Training loss: 1.1962866709159767
Validation loss: 2.3749917661117195

Epoch: 6| Step: 10
Training loss: 1.1694102497996268
Validation loss: 2.3771397116852087

Epoch: 6| Step: 11
Training loss: 1.6124422048221143
Validation loss: 2.3003384927584127

Epoch: 6| Step: 12
Training loss: 1.778465034675233
Validation loss: 2.3236147505148232

Epoch: 6| Step: 13
Training loss: 2.8330828799085905
Validation loss: 2.332861186380099

Epoch: 370| Step: 0
Training loss: 1.734357816593861
Validation loss: 2.373637116536059

Epoch: 6| Step: 1
Training loss: 1.2027376715679032
Validation loss: 2.3596353515589645

Epoch: 6| Step: 2
Training loss: 1.3562965613604177
Validation loss: 2.368938742493363

Epoch: 6| Step: 3
Training loss: 1.8904207607956727
Validation loss: 2.3691600409920044

Epoch: 6| Step: 4
Training loss: 1.1429119437566662
Validation loss: 2.404842200874059

Epoch: 6| Step: 5
Training loss: 1.4336497116599989
Validation loss: 2.3951818135849208

Epoch: 6| Step: 6
Training loss: 1.1412101185443322
Validation loss: 2.384143847827047

Epoch: 6| Step: 7
Training loss: 1.7816226636319534
Validation loss: 2.384081363113302

Epoch: 6| Step: 8
Training loss: 1.046500067683991
Validation loss: 2.3878177967988155

Epoch: 6| Step: 9
Training loss: 2.370678835518282
Validation loss: 2.4179114557715384

Epoch: 6| Step: 10
Training loss: 1.577950798466667
Validation loss: 2.356254200297714

Epoch: 6| Step: 11
Training loss: 1.6754127933230054
Validation loss: 2.3973372359643

Epoch: 6| Step: 12
Training loss: 1.0253628390952567
Validation loss: 2.378216199511534

Epoch: 6| Step: 13
Training loss: 1.0682435469804081
Validation loss: 2.386692262670427

Epoch: 371| Step: 0
Training loss: 1.4057531962744223
Validation loss: 2.3463328687654923

Epoch: 6| Step: 1
Training loss: 1.4640756449725063
Validation loss: 2.3709883214277734

Epoch: 6| Step: 2
Training loss: 2.5141836266413953
Validation loss: 2.3654426461400324

Epoch: 6| Step: 3
Training loss: 1.2429455057844376
Validation loss: 2.4076330564786526

Epoch: 6| Step: 4
Training loss: 1.5006588442607167
Validation loss: 2.362957841885314

Epoch: 6| Step: 5
Training loss: 1.7075582777497291
Validation loss: 2.329661471604284

Epoch: 6| Step: 6
Training loss: 1.324800346735204
Validation loss: 2.392104148434734

Epoch: 6| Step: 7
Training loss: 1.538261553714289
Validation loss: 2.3809776639841167

Epoch: 6| Step: 8
Training loss: 1.5833514697726006
Validation loss: 2.360803719315759

Epoch: 6| Step: 9
Training loss: 1.2209457766640717
Validation loss: 2.340643649659004

Epoch: 6| Step: 10
Training loss: 1.3305975842104056
Validation loss: 2.382879322499566

Epoch: 6| Step: 11
Training loss: 1.6244957948620287
Validation loss: 2.390855520030784

Epoch: 6| Step: 12
Training loss: 1.4373687186624322
Validation loss: 2.333397876122245

Epoch: 6| Step: 13
Training loss: 1.1371891582127847
Validation loss: 2.3593125894994578

Epoch: 372| Step: 0
Training loss: 1.2946819468643165
Validation loss: 2.3616457793622647

Epoch: 6| Step: 1
Training loss: 1.6229140758697762
Validation loss: 2.3440668254266495

Epoch: 6| Step: 2
Training loss: 1.3311415578883603
Validation loss: 2.4013766878350613

Epoch: 6| Step: 3
Training loss: 1.6365228139637342
Validation loss: 2.430450133006743

Epoch: 6| Step: 4
Training loss: 1.217682297392642
Validation loss: 2.41267664642705

Epoch: 6| Step: 5
Training loss: 2.009005062524124
Validation loss: 2.384590809493235

Epoch: 6| Step: 6
Training loss: 1.417019865474214
Validation loss: 2.4058949837616828

Epoch: 6| Step: 7
Training loss: 1.424064710764773
Validation loss: 2.3588210217966075

Epoch: 6| Step: 8
Training loss: 1.7324721749453407
Validation loss: 2.3471264009462782

Epoch: 6| Step: 9
Training loss: 1.7488426741283902
Validation loss: 2.3835314401215895

Epoch: 6| Step: 10
Training loss: 0.9311824927727629
Validation loss: 2.3814343681100145

Epoch: 6| Step: 11
Training loss: 1.285501961168346
Validation loss: 2.4225632995762916

Epoch: 6| Step: 12
Training loss: 1.3689970847294533
Validation loss: 2.3773278570693153

Epoch: 6| Step: 13
Training loss: 1.3196853863868345
Validation loss: 2.3422965976203467

Epoch: 373| Step: 0
Training loss: 1.3182833275230958
Validation loss: 2.2792671864509386

Epoch: 6| Step: 1
Training loss: 1.3353096451428634
Validation loss: 2.387179684564091

Epoch: 6| Step: 2
Training loss: 1.263498851598981
Validation loss: 2.37838333578967

Epoch: 6| Step: 3
Training loss: 1.2142011408645128
Validation loss: 2.3986304121619675

Epoch: 6| Step: 4
Training loss: 1.1398487846571845
Validation loss: 2.3314934259429805

Epoch: 6| Step: 5
Training loss: 1.473681995741535
Validation loss: 2.332592750691246

Epoch: 6| Step: 6
Training loss: 2.2829038294931205
Validation loss: 2.403610539780779

Epoch: 6| Step: 7
Training loss: 1.6731272490881366
Validation loss: 2.413993758274776

Epoch: 6| Step: 8
Training loss: 1.1196489228340474
Validation loss: 2.3954672205090946

Epoch: 6| Step: 9
Training loss: 1.0949969676598494
Validation loss: 2.3702044600201777

Epoch: 6| Step: 10
Training loss: 1.0087503608598973
Validation loss: 2.3609313189026557

Epoch: 6| Step: 11
Training loss: 1.6587011086014807
Validation loss: 2.3909918460533044

Epoch: 6| Step: 12
Training loss: 1.5982069637925465
Validation loss: 2.3726256764065767

Epoch: 6| Step: 13
Training loss: 1.4743467791849272
Validation loss: 2.3671665927837258

Epoch: 374| Step: 0
Training loss: 1.5687801039037614
Validation loss: 2.3806175904560662

Epoch: 6| Step: 1
Training loss: 1.1004025459659457
Validation loss: 2.353270539189046

Epoch: 6| Step: 2
Training loss: 1.8472050767196868
Validation loss: 2.3784980660145694

Epoch: 6| Step: 3
Training loss: 1.3819634799934857
Validation loss: 2.3721992945538317

Epoch: 6| Step: 4
Training loss: 1.3401472898924047
Validation loss: 2.3458401062453667

Epoch: 6| Step: 5
Training loss: 2.2593112709691905
Validation loss: 2.3100432505325554

Epoch: 6| Step: 6
Training loss: 1.6418278961917723
Validation loss: 2.331936636497925

Epoch: 6| Step: 7
Training loss: 1.496833160389054
Validation loss: 2.4106490951138255

Epoch: 6| Step: 8
Training loss: 1.410160138661103
Validation loss: 2.3741900472121396

Epoch: 6| Step: 9
Training loss: 0.9168428699607895
Validation loss: 2.330359810725713

Epoch: 6| Step: 10
Training loss: 1.525653967795274
Validation loss: 2.4117039948013494

Epoch: 6| Step: 11
Training loss: 1.412839497639664
Validation loss: 2.2865371356022424

Epoch: 6| Step: 12
Training loss: 1.6224352330240077
Validation loss: 2.3099228095887447

Epoch: 6| Step: 13
Training loss: 1.2161540236050938
Validation loss: 2.3307472762225068

Epoch: 375| Step: 0
Training loss: 1.1475594206407644
Validation loss: 2.3653236832205033

Epoch: 6| Step: 1
Training loss: 1.2851830105763666
Validation loss: 2.3261410219077074

Epoch: 6| Step: 2
Training loss: 1.0314078354704133
Validation loss: 2.339033595309945

Epoch: 6| Step: 3
Training loss: 2.1657863320151423
Validation loss: 2.309886922690906

Epoch: 6| Step: 4
Training loss: 1.0877976437731987
Validation loss: 2.3637522265519975

Epoch: 6| Step: 5
Training loss: 1.5418541081207262
Validation loss: 2.330989028780823

Epoch: 6| Step: 6
Training loss: 1.7208575418661427
Validation loss: 2.4041492543493064

Epoch: 6| Step: 7
Training loss: 1.0866006157602117
Validation loss: 2.3385425878870523

Epoch: 6| Step: 8
Training loss: 1.6778844337723928
Validation loss: 2.2867085870255695

Epoch: 6| Step: 9
Training loss: 1.6629146144965474
Validation loss: 2.372845420454586

Epoch: 6| Step: 10
Training loss: 1.7724821231301024
Validation loss: 2.3406223963637536

Epoch: 6| Step: 11
Training loss: 1.4064369077448582
Validation loss: 2.353945844179559

Epoch: 6| Step: 12
Training loss: 1.574992630956456
Validation loss: 2.3011198706406604

Epoch: 6| Step: 13
Training loss: 1.3995577198731064
Validation loss: 2.3811779390382237

Epoch: 376| Step: 0
Training loss: 2.50454308658092
Validation loss: 2.3773756974243865

Epoch: 6| Step: 1
Training loss: 1.6364694919930152
Validation loss: 2.3804880435928157

Epoch: 6| Step: 2
Training loss: 0.8422572742214839
Validation loss: 2.3475439787949854

Epoch: 6| Step: 3
Training loss: 0.956602288471398
Validation loss: 2.341268864410409

Epoch: 6| Step: 4
Training loss: 1.5872374219830145
Validation loss: 2.354481795687978

Epoch: 6| Step: 5
Training loss: 1.7083053896719766
Validation loss: 2.323593207408725

Epoch: 6| Step: 6
Training loss: 1.254866900510134
Validation loss: 2.3410265554285368

Epoch: 6| Step: 7
Training loss: 2.0329636607752524
Validation loss: 2.4145853859720536

Epoch: 6| Step: 8
Training loss: 1.251001767240354
Validation loss: 2.45426313298181

Epoch: 6| Step: 9
Training loss: 1.414703139717305
Validation loss: 2.328308681838158

Epoch: 6| Step: 10
Training loss: 0.9478510040904109
Validation loss: 2.421464999793544

Epoch: 6| Step: 11
Training loss: 1.2590365407032915
Validation loss: 2.3434288794823557

Epoch: 6| Step: 12
Training loss: 1.5326447654664848
Validation loss: 2.3982053431047405

Epoch: 6| Step: 13
Training loss: 1.2801646776363094
Validation loss: 2.4019014687886053

Epoch: 377| Step: 0
Training loss: 1.4111142695175496
Validation loss: 2.435204431757629

Epoch: 6| Step: 1
Training loss: 2.160969862071541
Validation loss: 2.3823168716041785

Epoch: 6| Step: 2
Training loss: 1.461844749056143
Validation loss: 2.392662208189651

Epoch: 6| Step: 3
Training loss: 1.1824772670891468
Validation loss: 2.368402450398278

Epoch: 6| Step: 4
Training loss: 1.2112295475385515
Validation loss: 2.3424661359038725

Epoch: 6| Step: 5
Training loss: 1.5025849321832268
Validation loss: 2.3547629333516267

Epoch: 6| Step: 6
Training loss: 1.3967272567276598
Validation loss: 2.4206926956429586

Epoch: 6| Step: 7
Training loss: 1.370089301588881
Validation loss: 2.49149502601919

Epoch: 6| Step: 8
Training loss: 1.377021430735984
Validation loss: 2.366114528055498

Epoch: 6| Step: 9
Training loss: 1.431559603325312
Validation loss: 2.370155352992866

Epoch: 6| Step: 10
Training loss: 1.2035561321688533
Validation loss: 2.3584246825119197

Epoch: 6| Step: 11
Training loss: 1.2154663060805269
Validation loss: 2.356955141565683

Epoch: 6| Step: 12
Training loss: 1.8339179436267858
Validation loss: 2.346245438196218

Epoch: 6| Step: 13
Training loss: 1.8291910437811159
Validation loss: 2.330995321324424

Epoch: 378| Step: 0
Training loss: 1.5669785973621544
Validation loss: 2.3668964111845217

Epoch: 6| Step: 1
Training loss: 1.6554938695639125
Validation loss: 2.380684177891431

Epoch: 6| Step: 2
Training loss: 1.1761416266335736
Validation loss: 2.3649043850532965

Epoch: 6| Step: 3
Training loss: 1.2126790966412606
Validation loss: 2.420192222011285

Epoch: 6| Step: 4
Training loss: 2.0168920275451403
Validation loss: 2.381065854677112

Epoch: 6| Step: 5
Training loss: 1.3340908918399936
Validation loss: 2.3254732604956967

Epoch: 6| Step: 6
Training loss: 1.4050923987038233
Validation loss: 2.3651883116323287

Epoch: 6| Step: 7
Training loss: 1.2084142175547068
Validation loss: 2.356887237079967

Epoch: 6| Step: 8
Training loss: 1.200108747720508
Validation loss: 2.4225263065821556

Epoch: 6| Step: 9
Training loss: 0.8891860983267679
Validation loss: 2.3586425741849384

Epoch: 6| Step: 10
Training loss: 1.3161342351130947
Validation loss: 2.3738166492686705

Epoch: 6| Step: 11
Training loss: 1.5462605961256923
Validation loss: 2.430279921759714

Epoch: 6| Step: 12
Training loss: 1.634037999844717
Validation loss: 2.3563910199622375

Epoch: 6| Step: 13
Training loss: 2.6912112670605883
Validation loss: 2.3697345656896984

Epoch: 379| Step: 0
Training loss: 1.2518206688474733
Validation loss: 2.3853481197077837

Epoch: 6| Step: 1
Training loss: 2.161735192151228
Validation loss: 2.349253977731442

Epoch: 6| Step: 2
Training loss: 0.9756003561090412
Validation loss: 2.348302746198777

Epoch: 6| Step: 3
Training loss: 1.6854941137726516
Validation loss: 2.42871648444095

Epoch: 6| Step: 4
Training loss: 1.3554328671853464
Validation loss: 2.3231168204825923

Epoch: 6| Step: 5
Training loss: 1.5953746817161902
Validation loss: 2.3375016379217666

Epoch: 6| Step: 6
Training loss: 1.2538259129918004
Validation loss: 2.3357074056417315

Epoch: 6| Step: 7
Training loss: 1.310236204706859
Validation loss: 2.358777076991872

Epoch: 6| Step: 8
Training loss: 1.3309435388697215
Validation loss: 2.3995755471021245

Epoch: 6| Step: 9
Training loss: 1.023294336919996
Validation loss: 2.3712784960292637

Epoch: 6| Step: 10
Training loss: 1.5806578149251378
Validation loss: 2.4836458444222815

Epoch: 6| Step: 11
Training loss: 1.547332233708517
Validation loss: 2.324118444357323

Epoch: 6| Step: 12
Training loss: 1.4465167003607693
Validation loss: 2.35772890342205

Epoch: 6| Step: 13
Training loss: 1.3880923063712587
Validation loss: 2.325913638692842

Epoch: 380| Step: 0
Training loss: 1.3207571872137984
Validation loss: 2.3687054044520437

Epoch: 6| Step: 1
Training loss: 1.4668381605166771
Validation loss: 2.3786898319091345

Epoch: 6| Step: 2
Training loss: 1.0548513779656106
Validation loss: 2.313416206119234

Epoch: 6| Step: 3
Training loss: 1.0999017736620926
Validation loss: 2.346647149611488

Epoch: 6| Step: 4
Training loss: 1.2442865450817036
Validation loss: 2.3888243724311207

Epoch: 6| Step: 5
Training loss: 1.2655576994156497
Validation loss: 2.3683301188524113

Epoch: 6| Step: 6
Training loss: 1.8114034031997222
Validation loss: 2.3982999601266033

Epoch: 6| Step: 7
Training loss: 1.4192664563406083
Validation loss: 2.3556778105394107

Epoch: 6| Step: 8
Training loss: 1.675311042601427
Validation loss: 2.393094784785341

Epoch: 6| Step: 9
Training loss: 1.2189907912046538
Validation loss: 2.4700341872892118

Epoch: 6| Step: 10
Training loss: 1.4095554498494398
Validation loss: 2.3678892212306373

Epoch: 6| Step: 11
Training loss: 1.5938479823492022
Validation loss: 2.407420539158416

Epoch: 6| Step: 12
Training loss: 2.1441052957057605
Validation loss: 2.3514368112715847

Epoch: 6| Step: 13
Training loss: 1.2215909369148106
Validation loss: 2.359514621992329

Epoch: 381| Step: 0
Training loss: 1.6643591961054827
Validation loss: 2.425490237848645

Epoch: 6| Step: 1
Training loss: 1.1110323493910663
Validation loss: 2.345765109621876

Epoch: 6| Step: 2
Training loss: 1.3076647749112542
Validation loss: 2.376714150435761

Epoch: 6| Step: 3
Training loss: 1.470073671635752
Validation loss: 2.362427437774731

Epoch: 6| Step: 4
Training loss: 1.4843274560642512
Validation loss: 2.369655598643552

Epoch: 6| Step: 5
Training loss: 0.9527101395556019
Validation loss: 2.3829196388746183

Epoch: 6| Step: 6
Training loss: 1.734191678642974
Validation loss: 2.368046426070332

Epoch: 6| Step: 7
Training loss: 1.2454101696506459
Validation loss: 2.4053571525764106

Epoch: 6| Step: 8
Training loss: 1.4972924592091357
Validation loss: 2.3142553167833966

Epoch: 6| Step: 9
Training loss: 1.2185594947794711
Validation loss: 2.3988802381868997

Epoch: 6| Step: 10
Training loss: 2.1436356583511094
Validation loss: 2.3225738089898385

Epoch: 6| Step: 11
Training loss: 0.8064723913146241
Validation loss: 2.440636969274618

Epoch: 6| Step: 12
Training loss: 1.4212802858908624
Validation loss: 2.341421427267253

Epoch: 6| Step: 13
Training loss: 1.6177670826983421
Validation loss: 2.3321566544658605

Epoch: 382| Step: 0
Training loss: 1.6601910037722611
Validation loss: 2.376795863174107

Epoch: 6| Step: 1
Training loss: 1.3690933458814774
Validation loss: 2.331827192523221

Epoch: 6| Step: 2
Training loss: 1.0868342148343821
Validation loss: 2.425479158264023

Epoch: 6| Step: 3
Training loss: 1.3910972136362578
Validation loss: 2.3283163056634857

Epoch: 6| Step: 4
Training loss: 1.6357407299433804
Validation loss: 2.3382241039199485

Epoch: 6| Step: 5
Training loss: 1.3039068753450698
Validation loss: 2.3335592963270484

Epoch: 6| Step: 6
Training loss: 1.1645043577781762
Validation loss: 2.369138587680463

Epoch: 6| Step: 7
Training loss: 1.5754508599329904
Validation loss: 2.315902285767195

Epoch: 6| Step: 8
Training loss: 1.113891006260543
Validation loss: 2.3410142054902328

Epoch: 6| Step: 9
Training loss: 1.4784524921760942
Validation loss: 2.3902898643756445

Epoch: 6| Step: 10
Training loss: 2.1029959969257996
Validation loss: 2.316650406532594

Epoch: 6| Step: 11
Training loss: 1.0290597718564964
Validation loss: 2.2863307265745543

Epoch: 6| Step: 12
Training loss: 1.4624387809786608
Validation loss: 2.4093168393136217

Epoch: 6| Step: 13
Training loss: 1.4652200037618337
Validation loss: 2.389569204818141

Epoch: 383| Step: 0
Training loss: 1.5791489706666744
Validation loss: 2.358690846783622

Epoch: 6| Step: 1
Training loss: 1.2563111247664387
Validation loss: 2.3622646747822333

Epoch: 6| Step: 2
Training loss: 1.013341243382584
Validation loss: 2.3381679812887715

Epoch: 6| Step: 3
Training loss: 2.2693700946575195
Validation loss: 2.385828727285705

Epoch: 6| Step: 4
Training loss: 1.4614792089768107
Validation loss: 2.3839765836408833

Epoch: 6| Step: 5
Training loss: 1.4661129755253461
Validation loss: 2.377939996248299

Epoch: 6| Step: 6
Training loss: 1.3795213057064213
Validation loss: 2.3193058479054125

Epoch: 6| Step: 7
Training loss: 1.1480576282684234
Validation loss: 2.3566216713891492

Epoch: 6| Step: 8
Training loss: 1.18945537999132
Validation loss: 2.3250556672297455

Epoch: 6| Step: 9
Training loss: 1.5415239353950998
Validation loss: 2.40711480389432

Epoch: 6| Step: 10
Training loss: 1.7830763705976782
Validation loss: 2.408403636480923

Epoch: 6| Step: 11
Training loss: 1.0613654193636706
Validation loss: 2.4369587493215046

Epoch: 6| Step: 12
Training loss: 1.7910339953563061
Validation loss: 2.434890425060075

Epoch: 6| Step: 13
Training loss: 0.910204218963337
Validation loss: 2.334803162975706

Epoch: 384| Step: 0
Training loss: 1.9132928663331839
Validation loss: 2.4107571003138313

Epoch: 6| Step: 1
Training loss: 1.6980629684356052
Validation loss: 2.4636640100556777

Epoch: 6| Step: 2
Training loss: 1.2091870854391282
Validation loss: 2.3928229940346846

Epoch: 6| Step: 3
Training loss: 1.4573925071585467
Validation loss: 2.328087365313639

Epoch: 6| Step: 4
Training loss: 1.7210968640923088
Validation loss: 2.3740340072603

Epoch: 6| Step: 5
Training loss: 1.184182753850738
Validation loss: 2.308762222116356

Epoch: 6| Step: 6
Training loss: 0.9951900496682273
Validation loss: 2.344158516013849

Epoch: 6| Step: 7
Training loss: 0.7545031620563558
Validation loss: 2.3644804002212165

Epoch: 6| Step: 8
Training loss: 1.6455330232675558
Validation loss: 2.37090722274612

Epoch: 6| Step: 9
Training loss: 1.4394326693816657
Validation loss: 2.2733827130532465

Epoch: 6| Step: 10
Training loss: 2.269926840993858
Validation loss: 2.354769722502131

Epoch: 6| Step: 11
Training loss: 1.1247441742681084
Validation loss: 2.405157004270529

Epoch: 6| Step: 12
Training loss: 1.3146438346921634
Validation loss: 2.396378841778102

Epoch: 6| Step: 13
Training loss: 1.358621936788676
Validation loss: 2.3349458188548566

Epoch: 385| Step: 0
Training loss: 1.255314781561049
Validation loss: 2.4029048162781956

Epoch: 6| Step: 1
Training loss: 1.5896894300391733
Validation loss: 2.4052239488967286

Epoch: 6| Step: 2
Training loss: 1.9903155938254873
Validation loss: 2.411175972682789

Epoch: 6| Step: 3
Training loss: 0.9047325847770021
Validation loss: 2.429129963456135

Epoch: 6| Step: 4
Training loss: 1.412430469523294
Validation loss: 2.3427607668444788

Epoch: 6| Step: 5
Training loss: 0.962896753256836
Validation loss: 2.3374090763886572

Epoch: 6| Step: 6
Training loss: 1.0895605231985823
Validation loss: 2.3862452597827706

Epoch: 6| Step: 7
Training loss: 1.6112629455330458
Validation loss: 2.345263461051552

Epoch: 6| Step: 8
Training loss: 2.371555842662821
Validation loss: 2.3045993616357756

Epoch: 6| Step: 9
Training loss: 1.2079206726667477
Validation loss: 2.3817693488973766

Epoch: 6| Step: 10
Training loss: 1.1520203734722232
Validation loss: 2.420450669927071

Epoch: 6| Step: 11
Training loss: 1.701364009268714
Validation loss: 2.3602018275948384

Epoch: 6| Step: 12
Training loss: 1.346437693894197
Validation loss: 2.3139097901810053

Epoch: 6| Step: 13
Training loss: 0.9986965804441317
Validation loss: 2.338977803654842

Epoch: 386| Step: 0
Training loss: 1.4866864327683365
Validation loss: 2.3729002294480948

Epoch: 6| Step: 1
Training loss: 1.1776278876247055
Validation loss: 2.409971087170877

Epoch: 6| Step: 2
Training loss: 2.2192926952040564
Validation loss: 2.3555436118105533

Epoch: 6| Step: 3
Training loss: 1.4895120172390393
Validation loss: 2.340689956738722

Epoch: 6| Step: 4
Training loss: 0.9486979558991641
Validation loss: 2.2736715848816176

Epoch: 6| Step: 5
Training loss: 0.9398869961930493
Validation loss: 2.327584289143266

Epoch: 6| Step: 6
Training loss: 1.3878489012691209
Validation loss: 2.378545091714029

Epoch: 6| Step: 7
Training loss: 1.3921294914173836
Validation loss: 2.3981484212248017

Epoch: 6| Step: 8
Training loss: 1.441920243087931
Validation loss: 2.4022000849855947

Epoch: 6| Step: 9
Training loss: 1.202010641869709
Validation loss: 2.367733700442511

Epoch: 6| Step: 10
Training loss: 1.9349478863936056
Validation loss: 2.4555970723430898

Epoch: 6| Step: 11
Training loss: 0.9994275719685859
Validation loss: 2.427759966557288

Epoch: 6| Step: 12
Training loss: 1.4297322750897203
Validation loss: 2.356294435032227

Epoch: 6| Step: 13
Training loss: 1.19816160047621
Validation loss: 2.4286199426376793

Epoch: 387| Step: 0
Training loss: 0.756406167354788
Validation loss: 2.3270707321108572

Epoch: 6| Step: 1
Training loss: 2.2276284326589293
Validation loss: 2.3578570711564524

Epoch: 6| Step: 2
Training loss: 1.4625335787317317
Validation loss: 2.385850897926396

Epoch: 6| Step: 3
Training loss: 1.2867536733458897
Validation loss: 2.3336785042116808

Epoch: 6| Step: 4
Training loss: 1.642688724817659
Validation loss: 2.342790113111897

Epoch: 6| Step: 5
Training loss: 1.0847707834145164
Validation loss: 2.4015382550334134

Epoch: 6| Step: 6
Training loss: 1.3788095932062654
Validation loss: 2.334817409081963

Epoch: 6| Step: 7
Training loss: 1.1103912319588847
Validation loss: 2.3129717072198144

Epoch: 6| Step: 8
Training loss: 1.4558293598705294
Validation loss: 2.335829575884162

Epoch: 6| Step: 9
Training loss: 1.4116257384100777
Validation loss: 2.3117449524705114

Epoch: 6| Step: 10
Training loss: 1.7580530976836002
Validation loss: 2.392757897252041

Epoch: 6| Step: 11
Training loss: 1.6131738068130008
Validation loss: 2.3712155236380887

Epoch: 6| Step: 12
Training loss: 1.1896208846828815
Validation loss: 2.4075372015378544

Epoch: 6| Step: 13
Training loss: 1.4729872111576559
Validation loss: 2.3527876175818108

Epoch: 388| Step: 0
Training loss: 1.267099863354532
Validation loss: 2.4117757791661107

Epoch: 6| Step: 1
Training loss: 1.4550763226184307
Validation loss: 2.3199508085117073

Epoch: 6| Step: 2
Training loss: 1.0429592632190852
Validation loss: 2.307607352264314

Epoch: 6| Step: 3
Training loss: 1.2862007511301032
Validation loss: 2.3643735079041344

Epoch: 6| Step: 4
Training loss: 1.5664318206298162
Validation loss: 2.420554665396162

Epoch: 6| Step: 5
Training loss: 1.1715472971168146
Validation loss: 2.351362134891115

Epoch: 6| Step: 6
Training loss: 1.8902664475105695
Validation loss: 2.339048751102461

Epoch: 6| Step: 7
Training loss: 0.9717191908584333
Validation loss: 2.289459321794539

Epoch: 6| Step: 8
Training loss: 1.339610354722999
Validation loss: 2.3649033031854816

Epoch: 6| Step: 9
Training loss: 1.5680832863311482
Validation loss: 2.4118874945224706

Epoch: 6| Step: 10
Training loss: 1.6372298942446282
Validation loss: 2.4118593142538027

Epoch: 6| Step: 11
Training loss: 2.1900775437583393
Validation loss: 2.3398942757213446

Epoch: 6| Step: 12
Training loss: 1.3698571869974456
Validation loss: 2.3383971760104583

Epoch: 6| Step: 13
Training loss: 1.572214976377531
Validation loss: 2.3658936652711455

Epoch: 389| Step: 0
Training loss: 1.266507394506266
Validation loss: 2.369389295218911

Epoch: 6| Step: 1
Training loss: 1.3001044176422007
Validation loss: 2.3820003702386874

Epoch: 6| Step: 2
Training loss: 1.1771634617541809
Validation loss: 2.4474184980261895

Epoch: 6| Step: 3
Training loss: 1.438576171078159
Validation loss: 2.3479184343888018

Epoch: 6| Step: 4
Training loss: 1.131696480164966
Validation loss: 2.3818661541868607

Epoch: 6| Step: 5
Training loss: 1.4048420109280384
Validation loss: 2.3529977544503953

Epoch: 6| Step: 6
Training loss: 2.276199393550402
Validation loss: 2.3751336110327705

Epoch: 6| Step: 7
Training loss: 1.297800492199672
Validation loss: 2.3638859093875135

Epoch: 6| Step: 8
Training loss: 1.3588734721046316
Validation loss: 2.418987295747126

Epoch: 6| Step: 9
Training loss: 1.7348010940207035
Validation loss: 2.3295250290953673

Epoch: 6| Step: 10
Training loss: 1.3263073769111786
Validation loss: 2.3565678044643508

Epoch: 6| Step: 11
Training loss: 1.5100310611688026
Validation loss: 2.345167742745404

Epoch: 6| Step: 12
Training loss: 1.2673589813818376
Validation loss: 2.388011405826823

Epoch: 6| Step: 13
Training loss: 1.8408554761852027
Validation loss: 2.3232847470534312

Epoch: 390| Step: 0
Training loss: 1.53421892665944
Validation loss: 2.4011758895776376

Epoch: 6| Step: 1
Training loss: 0.9479707276295534
Validation loss: 2.3726383139925713

Epoch: 6| Step: 2
Training loss: 1.4773823717415757
Validation loss: 2.317772813494361

Epoch: 6| Step: 3
Training loss: 1.3075909316352072
Validation loss: 2.4003952676339737

Epoch: 6| Step: 4
Training loss: 1.1400826092118639
Validation loss: 2.3381531884645455

Epoch: 6| Step: 5
Training loss: 1.6634923110293476
Validation loss: 2.3793341214507358

Epoch: 6| Step: 6
Training loss: 1.7588769021304886
Validation loss: 2.3957273063008375

Epoch: 6| Step: 7
Training loss: 2.1305745998339893
Validation loss: 2.366939945841798

Epoch: 6| Step: 8
Training loss: 0.8780494073661063
Validation loss: 2.41710283076098

Epoch: 6| Step: 9
Training loss: 1.2937374077520445
Validation loss: 2.3674663751844838

Epoch: 6| Step: 10
Training loss: 1.3798930065861064
Validation loss: 2.335465856646637

Epoch: 6| Step: 11
Training loss: 1.1320370354777702
Validation loss: 2.3864935764406345

Epoch: 6| Step: 12
Training loss: 1.541706583004637
Validation loss: 2.3707179222243746

Epoch: 6| Step: 13
Training loss: 1.2652217081159596
Validation loss: 2.3957081832050235

Epoch: 391| Step: 0
Training loss: 1.3658646205292326
Validation loss: 2.334672973616961

Epoch: 6| Step: 1
Training loss: 1.296842827455322
Validation loss: 2.3504166855052486

Epoch: 6| Step: 2
Training loss: 1.5308687942265722
Validation loss: 2.390141835006592

Epoch: 6| Step: 3
Training loss: 1.4792360191026215
Validation loss: 2.301307938145683

Epoch: 6| Step: 4
Training loss: 1.0837016518795937
Validation loss: 2.3810607313005097

Epoch: 6| Step: 5
Training loss: 1.3159231776769587
Validation loss: 2.323248109017396

Epoch: 6| Step: 6
Training loss: 1.5255540279147088
Validation loss: 2.393063191876645

Epoch: 6| Step: 7
Training loss: 2.2476896504296224
Validation loss: 2.329867048795813

Epoch: 6| Step: 8
Training loss: 1.3477661088034922
Validation loss: 2.375913002480336

Epoch: 6| Step: 9
Training loss: 1.173103400769815
Validation loss: 2.3629620275362964

Epoch: 6| Step: 10
Training loss: 1.1839158529491522
Validation loss: 2.3656173177515183

Epoch: 6| Step: 11
Training loss: 1.3214167204071385
Validation loss: 2.3418231779848075

Epoch: 6| Step: 12
Training loss: 1.5403468006576917
Validation loss: 2.3772323589581115

Epoch: 6| Step: 13
Training loss: 1.218806632266702
Validation loss: 2.3664524601325714

Epoch: 392| Step: 0
Training loss: 1.6486207399173691
Validation loss: 2.356129187558748

Epoch: 6| Step: 1
Training loss: 2.0010108777255255
Validation loss: 2.3419433291786986

Epoch: 6| Step: 2
Training loss: 1.090789821816755
Validation loss: 2.364751737610564

Epoch: 6| Step: 3
Training loss: 1.2975344073046169
Validation loss: 2.303309958545188

Epoch: 6| Step: 4
Training loss: 0.9291382136642791
Validation loss: 2.3447225345419582

Epoch: 6| Step: 5
Training loss: 1.680996265196183
Validation loss: 2.40637731941098

Epoch: 6| Step: 6
Training loss: 1.7148640485878641
Validation loss: 2.3235254770578573

Epoch: 6| Step: 7
Training loss: 1.1025320345145249
Validation loss: 2.470738548949961

Epoch: 6| Step: 8
Training loss: 1.8038638658859958
Validation loss: 2.3468301562576026

Epoch: 6| Step: 9
Training loss: 1.0630784423608761
Validation loss: 2.3940995861493137

Epoch: 6| Step: 10
Training loss: 1.1638697522233237
Validation loss: 2.3810710948619724

Epoch: 6| Step: 11
Training loss: 1.4076794035357387
Validation loss: 2.36305730062515

Epoch: 6| Step: 12
Training loss: 1.1090102334818779
Validation loss: 2.3487202202358883

Epoch: 6| Step: 13
Training loss: 1.1845148109711305
Validation loss: 2.2950561556763316

Epoch: 393| Step: 0
Training loss: 1.1719559705099696
Validation loss: 2.33114963592463

Epoch: 6| Step: 1
Training loss: 1.3393631676575344
Validation loss: 2.3600252998302795

Epoch: 6| Step: 2
Training loss: 1.2349542152165116
Validation loss: 2.393444769052277

Epoch: 6| Step: 3
Training loss: 1.0554019344931622
Validation loss: 2.3875863209819106

Epoch: 6| Step: 4
Training loss: 1.2533263770038916
Validation loss: 2.331321889434246

Epoch: 6| Step: 5
Training loss: 2.1725935810684325
Validation loss: 2.3654509479489305

Epoch: 6| Step: 6
Training loss: 0.9824135933559205
Validation loss: 2.4088097785689104

Epoch: 6| Step: 7
Training loss: 1.140135045836567
Validation loss: 2.3129867256559353

Epoch: 6| Step: 8
Training loss: 1.6762358220103162
Validation loss: 2.3971004229644404

Epoch: 6| Step: 9
Training loss: 1.4541704252498697
Validation loss: 2.3568206348549774

Epoch: 6| Step: 10
Training loss: 1.4465668055498513
Validation loss: 2.3844036608220254

Epoch: 6| Step: 11
Training loss: 1.5943641227372065
Validation loss: 2.3732770964686396

Epoch: 6| Step: 12
Training loss: 1.4755570959861277
Validation loss: 2.3696626253276194

Epoch: 6| Step: 13
Training loss: 1.2150980201867685
Validation loss: 2.3205538316521004

Epoch: 394| Step: 0
Training loss: 1.0942986883182608
Validation loss: 2.2825484390940556

Epoch: 6| Step: 1
Training loss: 1.0458594563376518
Validation loss: 2.3357606193160056

Epoch: 6| Step: 2
Training loss: 2.1712550094801455
Validation loss: 2.361716584257108

Epoch: 6| Step: 3
Training loss: 1.4418631142340104
Validation loss: 2.322118793099473

Epoch: 6| Step: 4
Training loss: 1.5529825648000288
Validation loss: 2.317145996527492

Epoch: 6| Step: 5
Training loss: 1.0681683301535245
Validation loss: 2.4171306375472272

Epoch: 6| Step: 6
Training loss: 1.5280485356396596
Validation loss: 2.3227908340740067

Epoch: 6| Step: 7
Training loss: 1.1328872129860996
Validation loss: 2.33130276202488

Epoch: 6| Step: 8
Training loss: 1.4146782814637278
Validation loss: 2.3670329804268024

Epoch: 6| Step: 9
Training loss: 1.5330679086722505
Validation loss: 2.3717188219616667

Epoch: 6| Step: 10
Training loss: 1.5079548032347099
Validation loss: 2.318024981443088

Epoch: 6| Step: 11
Training loss: 0.9512936868548547
Validation loss: 2.4072746893891197

Epoch: 6| Step: 12
Training loss: 1.0995640584439936
Validation loss: 2.3810306917370587

Epoch: 6| Step: 13
Training loss: 1.6479674478158448
Validation loss: 2.3348050625347634

Epoch: 395| Step: 0
Training loss: 1.3660100607885497
Validation loss: 2.4026070762024054

Epoch: 6| Step: 1
Training loss: 0.9572491144817298
Validation loss: 2.396882499365107

Epoch: 6| Step: 2
Training loss: 1.2494915404932116
Validation loss: 2.3432159471666947

Epoch: 6| Step: 3
Training loss: 1.4768078312590773
Validation loss: 2.3206565090642033

Epoch: 6| Step: 4
Training loss: 1.0728705251209956
Validation loss: 2.388689744535522

Epoch: 6| Step: 5
Training loss: 1.470420212403142
Validation loss: 2.3590684308692063

Epoch: 6| Step: 6
Training loss: 1.3818082449466758
Validation loss: 2.4108774968744084

Epoch: 6| Step: 7
Training loss: 2.0562685841007533
Validation loss: 2.4069705476135517

Epoch: 6| Step: 8
Training loss: 1.6509480093816995
Validation loss: 2.419020066633895

Epoch: 6| Step: 9
Training loss: 1.4804798618996742
Validation loss: 2.318297723646592

Epoch: 6| Step: 10
Training loss: 1.1901228699442215
Validation loss: 2.3706053373564173

Epoch: 6| Step: 11
Training loss: 0.9930418646401462
Validation loss: 2.418546614443

Epoch: 6| Step: 12
Training loss: 1.381948125483958
Validation loss: 2.3438263145792773

Epoch: 6| Step: 13
Training loss: 1.8967371103359865
Validation loss: 2.397362126492327

Epoch: 396| Step: 0
Training loss: 1.352229576646345
Validation loss: 2.3614852248970135

Epoch: 6| Step: 1
Training loss: 1.1904615315034341
Validation loss: 2.3472456974480904

Epoch: 6| Step: 2
Training loss: 1.4940748811107865
Validation loss: 2.366604240139525

Epoch: 6| Step: 3
Training loss: 1.3919183096209198
Validation loss: 2.3867963029056107

Epoch: 6| Step: 4
Training loss: 1.3465011290195972
Validation loss: 2.293244335830569

Epoch: 6| Step: 5
Training loss: 1.3237640140213096
Validation loss: 2.359526608360793

Epoch: 6| Step: 6
Training loss: 1.3900892961758873
Validation loss: 2.4256130907465954

Epoch: 6| Step: 7
Training loss: 1.3562774444475358
Validation loss: 2.374491848255733

Epoch: 6| Step: 8
Training loss: 1.0859549541580107
Validation loss: 2.3737443855016767

Epoch: 6| Step: 9
Training loss: 1.5464435322439645
Validation loss: 2.359637013293253

Epoch: 6| Step: 10
Training loss: 1.2280364686539713
Validation loss: 2.3720096767204426

Epoch: 6| Step: 11
Training loss: 2.2651683478707616
Validation loss: 2.345249057588946

Epoch: 6| Step: 12
Training loss: 1.3416947016343914
Validation loss: 2.3662572377300286

Epoch: 6| Step: 13
Training loss: 1.5302055066287958
Validation loss: 2.4499932334547796

Epoch: 397| Step: 0
Training loss: 1.4292531839027993
Validation loss: 2.3640996053221635

Epoch: 6| Step: 1
Training loss: 1.2652100718826684
Validation loss: 2.4012306973035735

Epoch: 6| Step: 2
Training loss: 1.2148800565439908
Validation loss: 2.4408816535681854

Epoch: 6| Step: 3
Training loss: 1.3631193398240506
Validation loss: 2.3717608856286287

Epoch: 6| Step: 4
Training loss: 1.6082580542200382
Validation loss: 2.4186560498056027

Epoch: 6| Step: 5
Training loss: 1.3116149643172617
Validation loss: 2.3254158591527814

Epoch: 6| Step: 6
Training loss: 1.506581332538657
Validation loss: 2.3844810793721885

Epoch: 6| Step: 7
Training loss: 1.2912707747554297
Validation loss: 2.3698747683647396

Epoch: 6| Step: 8
Training loss: 1.7416011353839052
Validation loss: 2.38626620450187

Epoch: 6| Step: 9
Training loss: 1.0238807824779212
Validation loss: 2.358151042387368

Epoch: 6| Step: 10
Training loss: 1.243159028168199
Validation loss: 2.3669777807771566

Epoch: 6| Step: 11
Training loss: 1.2290097745346837
Validation loss: 2.3270131762764557

Epoch: 6| Step: 12
Training loss: 2.0096078408513516
Validation loss: 2.326895119786253

Epoch: 6| Step: 13
Training loss: 1.6507367916592652
Validation loss: 2.418982845646479

Epoch: 398| Step: 0
Training loss: 1.5907930356585689
Validation loss: 2.3942389916524593

Epoch: 6| Step: 1
Training loss: 1.2004862992070089
Validation loss: 2.362869873148872

Epoch: 6| Step: 2
Training loss: 1.0093689956722658
Validation loss: 2.3840337895871926

Epoch: 6| Step: 3
Training loss: 1.190146358529517
Validation loss: 2.398647356754544

Epoch: 6| Step: 4
Training loss: 1.2590790999684718
Validation loss: 2.331740658335838

Epoch: 6| Step: 5
Training loss: 1.856119334955515
Validation loss: 2.333116012185898

Epoch: 6| Step: 6
Training loss: 0.6858876568665961
Validation loss: 2.3417645177744153

Epoch: 6| Step: 7
Training loss: 1.3066838233090647
Validation loss: 2.378279977702954

Epoch: 6| Step: 8
Training loss: 1.5945223264617403
Validation loss: 2.39754336315068

Epoch: 6| Step: 9
Training loss: 2.2229134623663227
Validation loss: 2.310027940506833

Epoch: 6| Step: 10
Training loss: 0.9947202001068953
Validation loss: 2.3359330080171405

Epoch: 6| Step: 11
Training loss: 1.2505094443738278
Validation loss: 2.409940821297589

Epoch: 6| Step: 12
Training loss: 1.1037274452747647
Validation loss: 2.3949401535242334

Epoch: 6| Step: 13
Training loss: 1.3547502971732615
Validation loss: 2.382954134901605

Epoch: 399| Step: 0
Training loss: 1.2222535564037695
Validation loss: 2.393132819240229

Epoch: 6| Step: 1
Training loss: 2.2621055891518784
Validation loss: 2.3225645525635725

Epoch: 6| Step: 2
Training loss: 0.7354797413679156
Validation loss: 2.3650605417356836

Epoch: 6| Step: 3
Training loss: 1.2710286391638494
Validation loss: 2.3548509578074457

Epoch: 6| Step: 4
Training loss: 1.3725997609221239
Validation loss: 2.4052207310523945

Epoch: 6| Step: 5
Training loss: 1.232823229454161
Validation loss: 2.392333112489007

Epoch: 6| Step: 6
Training loss: 1.0081204675713267
Validation loss: 2.3892355842430253

Epoch: 6| Step: 7
Training loss: 1.0281713944840334
Validation loss: 2.3620319277576076

Epoch: 6| Step: 8
Training loss: 1.3435338312197498
Validation loss: 2.379269096845147

Epoch: 6| Step: 9
Training loss: 0.9891891530980523
Validation loss: 2.374899719055507

Epoch: 6| Step: 10
Training loss: 1.929610092525595
Validation loss: 2.3113809270759296

Epoch: 6| Step: 11
Training loss: 1.4379374626260142
Validation loss: 2.3324431253546667

Epoch: 6| Step: 12
Training loss: 1.1350556362480828
Validation loss: 2.4388667456341695

Epoch: 6| Step: 13
Training loss: 1.3671752493173237
Validation loss: 2.3716899006635646

Epoch: 400| Step: 0
Training loss: 1.9780950221581903
Validation loss: 2.3993313132558742

Epoch: 6| Step: 1
Training loss: 1.5279491424784832
Validation loss: 2.343683797796886

Epoch: 6| Step: 2
Training loss: 1.3622423820877665
Validation loss: 2.31560549179304

Epoch: 6| Step: 3
Training loss: 1.2514361714246165
Validation loss: 2.351467124229369

Epoch: 6| Step: 4
Training loss: 1.3353431673498812
Validation loss: 2.2986507431149734

Epoch: 6| Step: 5
Training loss: 1.2217511126452882
Validation loss: 2.3924112720752433

Epoch: 6| Step: 6
Training loss: 1.4705879399355424
Validation loss: 2.329533761540849

Epoch: 6| Step: 7
Training loss: 0.7613391419382306
Validation loss: 2.3212045829015477

Epoch: 6| Step: 8
Training loss: 1.2794379935435773
Validation loss: 2.328847110933076

Epoch: 6| Step: 9
Training loss: 1.2373938524594468
Validation loss: 2.339044862425694

Epoch: 6| Step: 10
Training loss: 1.806210622391244
Validation loss: 2.3770136977690406

Epoch: 6| Step: 11
Training loss: 1.7619929132048409
Validation loss: 2.3716088713736494

Epoch: 6| Step: 12
Training loss: 1.3700959142119649
Validation loss: 2.3344297367469977

Epoch: 6| Step: 13
Training loss: 1.1015566561929433
Validation loss: 2.3304974221057644

Testing loss: 2.9546430925465694
