Epoch: 1| Step: 0
Training loss: 3.9030510583108873
Validation loss: 4.899598019643979

Epoch: 6| Step: 1
Training loss: 4.700760865004828
Validation loss: 4.89684677090234

Epoch: 6| Step: 2
Training loss: 5.189983830362464
Validation loss: 4.892155589892975

Epoch: 6| Step: 3
Training loss: 4.370287291556722
Validation loss: 4.883295782114878

Epoch: 6| Step: 4
Training loss: 4.995290636498623
Validation loss: 4.8814213387005925

Epoch: 6| Step: 5
Training loss: 5.375880679350434
Validation loss: 4.87319139282777

Epoch: 6| Step: 6
Training loss: 4.81176851336349
Validation loss: 4.868568509047353

Epoch: 6| Step: 7
Training loss: 5.153023374907565
Validation loss: 4.8634190493369145

Epoch: 6| Step: 8
Training loss: 5.5504051473018015
Validation loss: 4.855194518852801

Epoch: 6| Step: 9
Training loss: 4.999535348282925
Validation loss: 4.85327261392739

Epoch: 6| Step: 10
Training loss: 5.0798400799668
Validation loss: 4.847147643026062

Epoch: 6| Step: 11
Training loss: 4.9152539481202515
Validation loss: 4.842162440465909

Epoch: 6| Step: 12
Training loss: 4.956042083573875
Validation loss: 4.836027684706802

Epoch: 6| Step: 13
Training loss: 5.197622144327172
Validation loss: 4.8351726483435495

Epoch: 2| Step: 0
Training loss: 4.786627444440408
Validation loss: 4.8274575728671065

Epoch: 6| Step: 1
Training loss: 6.488586969769136
Validation loss: 4.820934597019694

Epoch: 6| Step: 2
Training loss: 5.211504812399962
Validation loss: 4.816193623730523

Epoch: 6| Step: 3
Training loss: 4.354333950400604
Validation loss: 4.80804289379625

Epoch: 6| Step: 4
Training loss: 3.864663519974233
Validation loss: 4.804206252722315

Epoch: 6| Step: 5
Training loss: 5.077218593986578
Validation loss: 4.799372002921427

Epoch: 6| Step: 6
Training loss: 5.281174698693475
Validation loss: 4.794960628952981

Epoch: 6| Step: 7
Training loss: 4.918362384341069
Validation loss: 4.790766763739182

Epoch: 6| Step: 8
Training loss: 3.825329814977968
Validation loss: 4.7873066537569695

Epoch: 6| Step: 9
Training loss: 4.631085284517614
Validation loss: 4.781893013542316

Epoch: 6| Step: 10
Training loss: 5.274518660871514
Validation loss: 4.775930533022663

Epoch: 6| Step: 11
Training loss: 3.084171610796213
Validation loss: 4.772647394379191

Epoch: 6| Step: 12
Training loss: 5.946078558152975
Validation loss: 4.765354617238883

Epoch: 6| Step: 13
Training loss: 4.3611590928814845
Validation loss: 4.763025262674347

Epoch: 3| Step: 0
Training loss: 4.4776929456585775
Validation loss: 4.757577418802724

Epoch: 6| Step: 1
Training loss: 4.337057323018055
Validation loss: 4.752585742986089

Epoch: 6| Step: 2
Training loss: 4.830299850539111
Validation loss: 4.747484908926755

Epoch: 6| Step: 3
Training loss: 5.2625781563144844
Validation loss: 4.743692209116382

Epoch: 6| Step: 4
Training loss: 4.79068359020658
Validation loss: 4.738191125588508

Epoch: 6| Step: 5
Training loss: 5.993157936106735
Validation loss: 4.734113292540112

Epoch: 6| Step: 6
Training loss: 4.664395983353725
Validation loss: 4.728489696379769

Epoch: 6| Step: 7
Training loss: 5.045815560361818
Validation loss: 4.724685357755459

Epoch: 6| Step: 8
Training loss: 3.736364114192197
Validation loss: 4.717054173580248

Epoch: 6| Step: 9
Training loss: 5.076589311063396
Validation loss: 4.714611531097362

Epoch: 6| Step: 10
Training loss: 4.594583448720977
Validation loss: 4.706913235781043

Epoch: 6| Step: 11
Training loss: 5.266029772496481
Validation loss: 4.703003957265515

Epoch: 6| Step: 12
Training loss: 4.554073756957991
Validation loss: 4.699582420986697

Epoch: 6| Step: 13
Training loss: 4.089462247906292
Validation loss: 4.691559552061122

Epoch: 4| Step: 0
Training loss: 5.209771570627184
Validation loss: 4.687152700376581

Epoch: 6| Step: 1
Training loss: 4.828399551634538
Validation loss: 4.682458622477527

Epoch: 6| Step: 2
Training loss: 5.437105888027386
Validation loss: 4.67787181121337

Epoch: 6| Step: 3
Training loss: 4.704144237499754
Validation loss: 4.673769238808532

Epoch: 6| Step: 4
Training loss: 4.330187364713609
Validation loss: 4.667414606749852

Epoch: 6| Step: 5
Training loss: 4.586169365345314
Validation loss: 4.663745002165735

Epoch: 6| Step: 6
Training loss: 3.9558738831029627
Validation loss: 4.657717711096376

Epoch: 6| Step: 7
Training loss: 4.55350077170896
Validation loss: 4.651539232858157

Epoch: 6| Step: 8
Training loss: 3.6919422870559813
Validation loss: 4.6465106266059495

Epoch: 6| Step: 9
Training loss: 4.222141513276157
Validation loss: 4.6424354912572925

Epoch: 6| Step: 10
Training loss: 5.490891456977598
Validation loss: 4.637334707967534

Epoch: 6| Step: 11
Training loss: 4.704448526394991
Validation loss: 4.631800360608277

Epoch: 6| Step: 12
Training loss: 5.171757722660114
Validation loss: 4.628732717603395

Epoch: 6| Step: 13
Training loss: 5.484173458558689
Validation loss: 4.619269259771427

Epoch: 5| Step: 0
Training loss: 5.168316772460647
Validation loss: 4.61704339112978

Epoch: 6| Step: 1
Training loss: 4.823113565840446
Validation loss: 4.606463049185061

Epoch: 6| Step: 2
Training loss: 4.550404650122712
Validation loss: 4.603608706702713

Epoch: 6| Step: 3
Training loss: 4.016785687678917
Validation loss: 4.595297316131676

Epoch: 6| Step: 4
Training loss: 4.329700610093829
Validation loss: 4.591494735132057

Epoch: 6| Step: 5
Training loss: 5.322429935823761
Validation loss: 4.587923821129623

Epoch: 6| Step: 6
Training loss: 3.6343621999133067
Validation loss: 4.579039569149278

Epoch: 6| Step: 7
Training loss: 4.382128112995563
Validation loss: 4.576481847208851

Epoch: 6| Step: 8
Training loss: 4.85644599980515
Validation loss: 4.566894509637904

Epoch: 6| Step: 9
Training loss: 5.122619448191163
Validation loss: 4.560713668492136

Epoch: 6| Step: 10
Training loss: 5.409556177235612
Validation loss: 4.554186785845012

Epoch: 6| Step: 11
Training loss: 4.4848381627375655
Validation loss: 4.551370103561332

Epoch: 6| Step: 12
Training loss: 4.434870195865354
Validation loss: 4.544571025295754

Epoch: 6| Step: 13
Training loss: 4.478629761683402
Validation loss: 4.538363945970552

Epoch: 6| Step: 0
Training loss: 3.284560214118611
Validation loss: 4.5332186701302355

Epoch: 6| Step: 1
Training loss: 4.818699596255217
Validation loss: 4.5252576379488145

Epoch: 6| Step: 2
Training loss: 3.38345732500852
Validation loss: 4.5187169468625275

Epoch: 6| Step: 3
Training loss: 4.153670578965603
Validation loss: 4.510011931569276

Epoch: 6| Step: 4
Training loss: 5.785915162704992
Validation loss: 4.50783412118676

Epoch: 6| Step: 5
Training loss: 4.6625448598058705
Validation loss: 4.500204140921904

Epoch: 6| Step: 6
Training loss: 5.1208585427607565
Validation loss: 4.4923699648744595

Epoch: 6| Step: 7
Training loss: 4.286714282762617
Validation loss: 4.482693584808468

Epoch: 6| Step: 8
Training loss: 4.643916032372103
Validation loss: 4.478455143834665

Epoch: 6| Step: 9
Training loss: 5.1308292639247775
Validation loss: 4.471155048514289

Epoch: 6| Step: 10
Training loss: 4.541654020985955
Validation loss: 4.462092059015319

Epoch: 6| Step: 11
Training loss: 5.266938631463957
Validation loss: 4.455315173321375

Epoch: 6| Step: 12
Training loss: 4.419402708544784
Validation loss: 4.444780987043402

Epoch: 6| Step: 13
Training loss: 3.5494251914152417
Validation loss: 4.44069698587403

Epoch: 7| Step: 0
Training loss: 4.64560275795738
Validation loss: 4.432780717586751

Epoch: 6| Step: 1
Training loss: 4.270530479051726
Validation loss: 4.425335715941734

Epoch: 6| Step: 2
Training loss: 3.7078248150376236
Validation loss: 4.419641531110822

Epoch: 6| Step: 3
Training loss: 3.425268154367084
Validation loss: 4.411370181278883

Epoch: 6| Step: 4
Training loss: 3.9308789003788145
Validation loss: 4.399042160993406

Epoch: 6| Step: 5
Training loss: 5.640874714488495
Validation loss: 4.388811106001433

Epoch: 6| Step: 6
Training loss: 4.974067194148496
Validation loss: 4.385652806954429

Epoch: 6| Step: 7
Training loss: 4.299465660784107
Validation loss: 4.378075471784272

Epoch: 6| Step: 8
Training loss: 4.470791010494842
Validation loss: 4.362507915551348

Epoch: 6| Step: 9
Training loss: 4.294814180877515
Validation loss: 4.354020284005628

Epoch: 6| Step: 10
Training loss: 3.975854716987383
Validation loss: 4.3448173726562125

Epoch: 6| Step: 11
Training loss: 4.759034649707768
Validation loss: 4.339630806080137

Epoch: 6| Step: 12
Training loss: 5.086135696323009
Validation loss: 4.330805751674958

Epoch: 6| Step: 13
Training loss: 5.06401660949008
Validation loss: 4.321964478200623

Epoch: 8| Step: 0
Training loss: 4.249582157912199
Validation loss: 4.308798565357348

Epoch: 6| Step: 1
Training loss: 4.140054915427909
Validation loss: 4.297591346251391

Epoch: 6| Step: 2
Training loss: 4.811876132705819
Validation loss: 4.28936426177181

Epoch: 6| Step: 3
Training loss: 4.430890816361161
Validation loss: 4.277219964944254

Epoch: 6| Step: 4
Training loss: 4.791113957026982
Validation loss: 4.263622738498395

Epoch: 6| Step: 5
Training loss: 3.737691515860668
Validation loss: 4.256658495570279

Epoch: 6| Step: 6
Training loss: 5.269438225990442
Validation loss: 4.244656187314167

Epoch: 6| Step: 7
Training loss: 4.13933177401865
Validation loss: 4.2379811911429766

Epoch: 6| Step: 8
Training loss: 4.275021442560328
Validation loss: 4.225968554037458

Epoch: 6| Step: 9
Training loss: 3.7672452487894077
Validation loss: 4.212570021003473

Epoch: 6| Step: 10
Training loss: 4.046489446824459
Validation loss: 4.202743235414591

Epoch: 6| Step: 11
Training loss: 5.149444527900349
Validation loss: 4.190912697918265

Epoch: 6| Step: 12
Training loss: 3.8347521657825077
Validation loss: 4.18059134820906

Epoch: 6| Step: 13
Training loss: 3.6723062464927656
Validation loss: 4.170921792886277

Epoch: 9| Step: 0
Training loss: 4.146247702486669
Validation loss: 4.155678851014739

Epoch: 6| Step: 1
Training loss: 4.100449300198818
Validation loss: 4.140325390622845

Epoch: 6| Step: 2
Training loss: 4.099117109559186
Validation loss: 4.134661767733804

Epoch: 6| Step: 3
Training loss: 4.481557565772421
Validation loss: 4.12384173805394

Epoch: 6| Step: 4
Training loss: 4.829222717925337
Validation loss: 4.112772053061053

Epoch: 6| Step: 5
Training loss: 4.927501937579389
Validation loss: 4.1002045733189805

Epoch: 6| Step: 6
Training loss: 4.4310606320140735
Validation loss: 4.088190645734194

Epoch: 6| Step: 7
Training loss: 3.5080456220820286
Validation loss: 4.072306187106207

Epoch: 6| Step: 8
Training loss: 3.6851361990490923
Validation loss: 4.056341584970095

Epoch: 6| Step: 9
Training loss: 4.73587989180568
Validation loss: 4.048883072065642

Epoch: 6| Step: 10
Training loss: 3.4005894654851465
Validation loss: 4.0338895626396996

Epoch: 6| Step: 11
Training loss: 3.8371933009947803
Validation loss: 4.022013298183814

Epoch: 6| Step: 12
Training loss: 3.579456065109041
Validation loss: 4.00740982095961

Epoch: 6| Step: 13
Training loss: 5.0797154210196585
Validation loss: 3.9928888129109685

Epoch: 10| Step: 0
Training loss: 3.320265538500616
Validation loss: 3.9824176250322574

Epoch: 6| Step: 1
Training loss: 4.582884518005128
Validation loss: 3.9688649605400235

Epoch: 6| Step: 2
Training loss: 3.68969118350887
Validation loss: 3.957317813122384

Epoch: 6| Step: 3
Training loss: 4.2506094102948015
Validation loss: 3.948105211480072

Epoch: 6| Step: 4
Training loss: 3.5289720597970344
Validation loss: 3.9238685333014236

Epoch: 6| Step: 5
Training loss: 3.953029465557575
Validation loss: 3.9164660033010823

Epoch: 6| Step: 6
Training loss: 3.813478688179625
Validation loss: 3.8974009679663317

Epoch: 6| Step: 7
Training loss: 5.652128456723944
Validation loss: 3.8938400954190633

Epoch: 6| Step: 8
Training loss: 3.9457666721104157
Validation loss: 3.883227538272756

Epoch: 6| Step: 9
Training loss: 3.5288858517404975
Validation loss: 3.8600855380796975

Epoch: 6| Step: 10
Training loss: 4.1331812328122615
Validation loss: 3.852297405044562

Epoch: 6| Step: 11
Training loss: 4.571468578742576
Validation loss: 3.830892750759404

Epoch: 6| Step: 12
Training loss: 3.839035492407291
Validation loss: 3.81863268616367

Epoch: 6| Step: 13
Training loss: 1.7237961645770354
Validation loss: 3.8086222504673994

Epoch: 11| Step: 0
Training loss: 4.067130399018107
Validation loss: 3.7933717810949896

Epoch: 6| Step: 1
Training loss: 3.967930866923598
Validation loss: 3.772576816874677

Epoch: 6| Step: 2
Training loss: 4.1990652224841405
Validation loss: 3.762198018446292

Epoch: 6| Step: 3
Training loss: 4.005677961671056
Validation loss: 3.744136372964892

Epoch: 6| Step: 4
Training loss: 4.135209136803426
Validation loss: 3.7321345158775063

Epoch: 6| Step: 5
Training loss: 4.100865826249665
Validation loss: 3.7159652244679156

Epoch: 6| Step: 6
Training loss: 4.583330859559288
Validation loss: 3.7052248990142247

Epoch: 6| Step: 7
Training loss: 3.9435652990360426
Validation loss: 3.69534097713565

Epoch: 6| Step: 8
Training loss: 3.237889246572725
Validation loss: 3.6737292437365214

Epoch: 6| Step: 9
Training loss: 3.39146307506816
Validation loss: 3.651344738347819

Epoch: 6| Step: 10
Training loss: 3.389895312287901
Validation loss: 3.640074694181618

Epoch: 6| Step: 11
Training loss: 4.407983317238035
Validation loss: 3.6248224983703743

Epoch: 6| Step: 12
Training loss: 2.8139520075920794
Validation loss: 3.6022028815614546

Epoch: 6| Step: 13
Training loss: 2.8053905912776043
Validation loss: 3.5921502018097877

Epoch: 12| Step: 0
Training loss: 4.05888511045136
Validation loss: 3.5818677987872496

Epoch: 6| Step: 1
Training loss: 4.120496198532301
Validation loss: 3.564999297907859

Epoch: 6| Step: 2
Training loss: 3.0794389892520018
Validation loss: 3.5487635282306096

Epoch: 6| Step: 3
Training loss: 3.9639671521716844
Validation loss: 3.528279886279537

Epoch: 6| Step: 4
Training loss: 3.9626408211989177
Validation loss: 3.522179358599499

Epoch: 6| Step: 5
Training loss: 3.0484702604675475
Validation loss: 3.4934528528031037

Epoch: 6| Step: 6
Training loss: 3.7561916099237305
Validation loss: 3.4813781900255836

Epoch: 6| Step: 7
Training loss: 3.481341628233389
Validation loss: 3.463690988136225

Epoch: 6| Step: 8
Training loss: 3.443226292938401
Validation loss: 3.45139396717011

Epoch: 6| Step: 9
Training loss: 3.768133950057531
Validation loss: 3.4392003616740197

Epoch: 6| Step: 10
Training loss: 3.751091098998183
Validation loss: 3.4181515520612744

Epoch: 6| Step: 11
Training loss: 3.1470389845245306
Validation loss: 3.407165869339079

Epoch: 6| Step: 12
Training loss: 4.034759886072136
Validation loss: 3.3817723461300297

Epoch: 6| Step: 13
Training loss: 2.8307787842015224
Validation loss: 3.3692219874857066

Epoch: 13| Step: 0
Training loss: 3.7700054601736017
Validation loss: 3.354864702994685

Epoch: 6| Step: 1
Training loss: 3.6346076713731685
Validation loss: 3.3369862934042853

Epoch: 6| Step: 2
Training loss: 3.2195184771722487
Validation loss: 3.3238029942509177

Epoch: 6| Step: 3
Training loss: 3.50744327904428
Validation loss: 3.3037439137290923

Epoch: 6| Step: 4
Training loss: 3.9414121780880222
Validation loss: 3.287458845367791

Epoch: 6| Step: 5
Training loss: 3.0182121919292313
Validation loss: 3.265290419956028

Epoch: 6| Step: 6
Training loss: 3.44175567758158
Validation loss: 3.2559304269874567

Epoch: 6| Step: 7
Training loss: 4.020117476915101
Validation loss: 3.2386876473737543

Epoch: 6| Step: 8
Training loss: 3.2197495177089643
Validation loss: 3.2179967674122327

Epoch: 6| Step: 9
Training loss: 2.2949627032604885
Validation loss: 3.2119413804137267

Epoch: 6| Step: 10
Training loss: 3.019553990050207
Validation loss: 3.185963567818139

Epoch: 6| Step: 11
Training loss: 3.783556526311318
Validation loss: 3.168036131293151

Epoch: 6| Step: 12
Training loss: 3.8157789794445254
Validation loss: 3.15193500484691

Epoch: 6| Step: 13
Training loss: 3.0637852054535823
Validation loss: 3.1386786592632023

Epoch: 14| Step: 0
Training loss: 3.1800614870472814
Validation loss: 3.128136648472941

Epoch: 6| Step: 1
Training loss: 3.831529745869324
Validation loss: 3.10256927368209

Epoch: 6| Step: 2
Training loss: 3.323374622003037
Validation loss: 3.0826260377115693

Epoch: 6| Step: 3
Training loss: 3.7719936096202
Validation loss: 3.078233999176902

Epoch: 6| Step: 4
Training loss: 3.3889834038178086
Validation loss: 3.0562350163403997

Epoch: 6| Step: 5
Training loss: 2.612064551608792
Validation loss: 3.0445472258265753

Epoch: 6| Step: 6
Training loss: 2.7700354973897565
Validation loss: 3.027543423855916

Epoch: 6| Step: 7
Training loss: 2.652624730549085
Validation loss: 3.013086987635088

Epoch: 6| Step: 8
Training loss: 3.962938514296029
Validation loss: 2.9967899119368484

Epoch: 6| Step: 9
Training loss: 2.714210491285342
Validation loss: 2.974545448110836

Epoch: 6| Step: 10
Training loss: 3.1983213551747416
Validation loss: 2.97298985356892

Epoch: 6| Step: 11
Training loss: 2.7049654830450853
Validation loss: 2.9447859082848953

Epoch: 6| Step: 12
Training loss: 3.3299326397838813
Validation loss: 2.9358907117006092

Epoch: 6| Step: 13
Training loss: 3.9227308578097095
Validation loss: 2.9245407432145742

Epoch: 15| Step: 0
Training loss: 3.3967122225815167
Validation loss: 2.9051465742581493

Epoch: 6| Step: 1
Training loss: 2.9180965370069565
Validation loss: 2.893247574387804

Epoch: 6| Step: 2
Training loss: 3.5465235599050957
Validation loss: 2.862503799254687

Epoch: 6| Step: 3
Training loss: 2.924270056259934
Validation loss: 2.8690086112167474

Epoch: 6| Step: 4
Training loss: 2.2293450352500055
Validation loss: 2.8588330594535956

Epoch: 6| Step: 5
Training loss: 2.8828202741151103
Validation loss: 2.836210019844058

Epoch: 6| Step: 6
Training loss: 3.8823590695065904
Validation loss: 2.8183601700091883

Epoch: 6| Step: 7
Training loss: 2.7167243865576594
Validation loss: 2.8117617865429825

Epoch: 6| Step: 8
Training loss: 2.664401125152309
Validation loss: 2.79186000775864

Epoch: 6| Step: 9
Training loss: 2.4585947662826584
Validation loss: 2.793332714090825

Epoch: 6| Step: 10
Training loss: 3.9057199347390696
Validation loss: 2.7881037095089667

Epoch: 6| Step: 11
Training loss: 2.9992935620472183
Validation loss: 2.766249545198205

Epoch: 6| Step: 12
Training loss: 3.1607953569977223
Validation loss: 2.7507463218097574

Epoch: 6| Step: 13
Training loss: 3.1581603963269855
Validation loss: 2.7386302056543905

Epoch: 16| Step: 0
Training loss: 3.0394119022615027
Validation loss: 2.7244190596680573

Epoch: 6| Step: 1
Training loss: 3.020945229047408
Validation loss: 2.7175351848060907

Epoch: 6| Step: 2
Training loss: 3.062603540032632
Validation loss: 2.710814870862501

Epoch: 6| Step: 3
Training loss: 2.6608726220277323
Validation loss: 2.716091505907053

Epoch: 6| Step: 4
Training loss: 3.3256165986796455
Validation loss: 2.693411175405961

Epoch: 6| Step: 5
Training loss: 3.345048598776082
Validation loss: 2.6995821147090187

Epoch: 6| Step: 6
Training loss: 3.5910354313282924
Validation loss: 2.676564791044289

Epoch: 6| Step: 7
Training loss: 2.3855579006801655
Validation loss: 2.671672074290818

Epoch: 6| Step: 8
Training loss: 2.7563422501192556
Validation loss: 2.663566643529392

Epoch: 6| Step: 9
Training loss: 2.890113909103372
Validation loss: 2.6689160426286986

Epoch: 6| Step: 10
Training loss: 2.746843433741229
Validation loss: 2.666437487854929

Epoch: 6| Step: 11
Training loss: 3.0129615208561273
Validation loss: 2.652882251064953

Epoch: 6| Step: 12
Training loss: 3.331665018935859
Validation loss: 2.6541447557731797

Epoch: 6| Step: 13
Training loss: 1.8372981447168437
Validation loss: 2.632258616975601

Epoch: 17| Step: 0
Training loss: 3.0641952804904555
Validation loss: 2.619052659839456

Epoch: 6| Step: 1
Training loss: 3.7100393392939766
Validation loss: 2.6266708047265905

Epoch: 6| Step: 2
Training loss: 2.762230206601889
Validation loss: 2.6221489666335773

Epoch: 6| Step: 3
Training loss: 2.987084242489407
Validation loss: 2.615866607250645

Epoch: 6| Step: 4
Training loss: 2.962018864831086
Validation loss: 2.608542975973339

Epoch: 6| Step: 5
Training loss: 2.495119194134467
Validation loss: 2.62026877360324

Epoch: 6| Step: 6
Training loss: 3.0903910888776447
Validation loss: 2.5955958681770666

Epoch: 6| Step: 7
Training loss: 3.5762653432368263
Validation loss: 2.599535484641704

Epoch: 6| Step: 8
Training loss: 2.7581181775528867
Validation loss: 2.5824047186699226

Epoch: 6| Step: 9
Training loss: 2.6733915252567204
Validation loss: 2.605834865354426

Epoch: 6| Step: 10
Training loss: 3.120968774386928
Validation loss: 2.595728728656836

Epoch: 6| Step: 11
Training loss: 2.673459570307014
Validation loss: 2.597760086149272

Epoch: 6| Step: 12
Training loss: 2.515428428788799
Validation loss: 2.589587401337373

Epoch: 6| Step: 13
Training loss: 2.1209047911271557
Validation loss: 2.5775886561948718

Epoch: 18| Step: 0
Training loss: 2.955578304703561
Validation loss: 2.5771534262096747

Epoch: 6| Step: 1
Training loss: 2.9224513500331444
Validation loss: 2.5844185290139166

Epoch: 6| Step: 2
Training loss: 3.0323728074636245
Validation loss: 2.5860970364922333

Epoch: 6| Step: 3
Training loss: 2.9414754709961746
Validation loss: 2.5855233376578974

Epoch: 6| Step: 4
Training loss: 2.267561933014433
Validation loss: 2.578115631911832

Epoch: 6| Step: 5
Training loss: 3.113893073067154
Validation loss: 2.5701742989426193

Epoch: 6| Step: 6
Training loss: 3.4080191401360542
Validation loss: 2.5644608545386403

Epoch: 6| Step: 7
Training loss: 2.8917059449561475
Validation loss: 2.5742367367199543

Epoch: 6| Step: 8
Training loss: 2.6582921872995566
Validation loss: 2.566229466615777

Epoch: 6| Step: 9
Training loss: 3.310805841180235
Validation loss: 2.549509980026837

Epoch: 6| Step: 10
Training loss: 2.004459654183397
Validation loss: 2.5659174367225552

Epoch: 6| Step: 11
Training loss: 2.9683074621336485
Validation loss: 2.574585556239802

Epoch: 6| Step: 12
Training loss: 2.957100105239873
Validation loss: 2.562877082042144

Epoch: 6| Step: 13
Training loss: 3.1133109633345244
Validation loss: 2.558273462461635

Epoch: 19| Step: 0
Training loss: 2.1233316491967216
Validation loss: 2.5570913109811504

Epoch: 6| Step: 1
Training loss: 2.9907253268482976
Validation loss: 2.5605715256294714

Epoch: 6| Step: 2
Training loss: 3.0237563800468488
Validation loss: 2.5638173076626942

Epoch: 6| Step: 3
Training loss: 3.007432948353591
Validation loss: 2.561901541876976

Epoch: 6| Step: 4
Training loss: 2.811832094359063
Validation loss: 2.5584951970904872

Epoch: 6| Step: 5
Training loss: 3.046297928374769
Validation loss: 2.568504741311594

Epoch: 6| Step: 6
Training loss: 2.519756833409073
Validation loss: 2.5545736016968768

Epoch: 6| Step: 7
Training loss: 3.143484910591695
Validation loss: 2.5599733807701353

Epoch: 6| Step: 8
Training loss: 3.2158317299277277
Validation loss: 2.551029343448131

Epoch: 6| Step: 9
Training loss: 2.884734053493876
Validation loss: 2.5515380353825874

Epoch: 6| Step: 10
Training loss: 3.2632083986062512
Validation loss: 2.5489533876975994

Epoch: 6| Step: 11
Training loss: 3.0552387959604395
Validation loss: 2.5516872022394312

Epoch: 6| Step: 12
Training loss: 2.308945578989912
Validation loss: 2.5577344523397785

Epoch: 6| Step: 13
Training loss: 3.1029516995721877
Validation loss: 2.55443926305082

Epoch: 20| Step: 0
Training loss: 2.8388728983860685
Validation loss: 2.554602995487749

Epoch: 6| Step: 1
Training loss: 2.93885057933559
Validation loss: 2.555092713122543

Epoch: 6| Step: 2
Training loss: 2.8375001075509343
Validation loss: 2.5610931720561685

Epoch: 6| Step: 3
Training loss: 2.393980775072351
Validation loss: 2.5491628340724257

Epoch: 6| Step: 4
Training loss: 3.728394000316254
Validation loss: 2.5469265485980257

Epoch: 6| Step: 5
Training loss: 2.8789860832087344
Validation loss: 2.5507929355890298

Epoch: 6| Step: 6
Training loss: 3.0357930854379345
Validation loss: 2.5433234213543954

Epoch: 6| Step: 7
Training loss: 2.781696583758595
Validation loss: 2.545082816080739

Epoch: 6| Step: 8
Training loss: 2.7191533633518605
Validation loss: 2.551854733911812

Epoch: 6| Step: 9
Training loss: 2.7538579408994184
Validation loss: 2.5433687128961813

Epoch: 6| Step: 10
Training loss: 2.7327813436259976
Validation loss: 2.544913401112789

Epoch: 6| Step: 11
Training loss: 2.5602239409488416
Validation loss: 2.5631380064774523

Epoch: 6| Step: 12
Training loss: 2.790185696838
Validation loss: 2.557582706252075

Epoch: 6| Step: 13
Training loss: 3.9864343444937087
Validation loss: 2.535177753837054

Epoch: 21| Step: 0
Training loss: 2.960057754468659
Validation loss: 2.547451475203913

Epoch: 6| Step: 1
Training loss: 3.196134503500335
Validation loss: 2.5446377305349195

Epoch: 6| Step: 2
Training loss: 3.1399625013019694
Validation loss: 2.555879830766518

Epoch: 6| Step: 3
Training loss: 2.6183971740917196
Validation loss: 2.5464833970955327

Epoch: 6| Step: 4
Training loss: 2.57335114510784
Validation loss: 2.556286325103097

Epoch: 6| Step: 5
Training loss: 2.6279006553812536
Validation loss: 2.543602822421911

Epoch: 6| Step: 6
Training loss: 2.7233217758655632
Validation loss: 2.5454545752360587

Epoch: 6| Step: 7
Training loss: 3.5353448132549103
Validation loss: 2.555334749717347

Epoch: 6| Step: 8
Training loss: 2.300252494221104
Validation loss: 2.561988217209587

Epoch: 6| Step: 9
Training loss: 2.8694382650139163
Validation loss: 2.560598237468883

Epoch: 6| Step: 10
Training loss: 2.2813344443381878
Validation loss: 2.542534773906991

Epoch: 6| Step: 11
Training loss: 3.023510835926238
Validation loss: 2.5399448685948407

Epoch: 6| Step: 12
Training loss: 3.553983178420393
Validation loss: 2.5537087916877703

Epoch: 6| Step: 13
Training loss: 2.948320628459232
Validation loss: 2.5444929542976817

Epoch: 22| Step: 0
Training loss: 2.8764754116917777
Validation loss: 2.5519182250151453

Epoch: 6| Step: 1
Training loss: 2.7958314962897446
Validation loss: 2.546062066203886

Epoch: 6| Step: 2
Training loss: 2.9671536620964187
Validation loss: 2.5514580224035237

Epoch: 6| Step: 3
Training loss: 2.91281551240197
Validation loss: 2.561864242302767

Epoch: 6| Step: 4
Training loss: 3.0396974189653725
Validation loss: 2.55418043600781

Epoch: 6| Step: 5
Training loss: 2.5468553413615345
Validation loss: 2.5421552079291327

Epoch: 6| Step: 6
Training loss: 2.587651079715262
Validation loss: 2.5486902587125657

Epoch: 6| Step: 7
Training loss: 2.6580971073756445
Validation loss: 2.5417475520240997

Epoch: 6| Step: 8
Training loss: 2.534917552743391
Validation loss: 2.533703533394303

Epoch: 6| Step: 9
Training loss: 3.323306324911867
Validation loss: 2.554388395974989

Epoch: 6| Step: 10
Training loss: 2.986870166992569
Validation loss: 2.5489293880901016

Epoch: 6| Step: 11
Training loss: 3.415661888935491
Validation loss: 2.542703588157589

Epoch: 6| Step: 12
Training loss: 2.9739591172056397
Validation loss: 2.5430324679974685

Epoch: 6| Step: 13
Training loss: 2.8246931466410055
Validation loss: 2.5463192794805

Epoch: 23| Step: 0
Training loss: 3.0694886478177486
Validation loss: 2.54970093947344

Epoch: 6| Step: 1
Training loss: 2.7780176302883888
Validation loss: 2.5515160093058427

Epoch: 6| Step: 2
Training loss: 2.4607797723511737
Validation loss: 2.539872438095515

Epoch: 6| Step: 3
Training loss: 3.163843820809293
Validation loss: 2.5500662317105607

Epoch: 6| Step: 4
Training loss: 3.2018008588807017
Validation loss: 2.544208317561259

Epoch: 6| Step: 5
Training loss: 3.328843160164375
Validation loss: 2.548509792938873

Epoch: 6| Step: 6
Training loss: 2.611101504459249
Validation loss: 2.5620310804791737

Epoch: 6| Step: 7
Training loss: 2.8629783064179897
Validation loss: 2.559074186789166

Epoch: 6| Step: 8
Training loss: 2.816484468725727
Validation loss: 2.539299139791354

Epoch: 6| Step: 9
Training loss: 3.0807678959729214
Validation loss: 2.541246032067721

Epoch: 6| Step: 10
Training loss: 3.0517940622847064
Validation loss: 2.536852931222813

Epoch: 6| Step: 11
Training loss: 2.7495172250238995
Validation loss: 2.544946988244667

Epoch: 6| Step: 12
Training loss: 2.210905256811324
Validation loss: 2.5436766907238084

Epoch: 6| Step: 13
Training loss: 2.7789097058540415
Validation loss: 2.536562145283729

Epoch: 24| Step: 0
Training loss: 2.9924564888068703
Validation loss: 2.5408613276292913

Epoch: 6| Step: 1
Training loss: 3.8024864644970275
Validation loss: 2.547627678858765

Epoch: 6| Step: 2
Training loss: 3.5775392544323528
Validation loss: 2.544457473044756

Epoch: 6| Step: 3
Training loss: 2.257096860254842
Validation loss: 2.545888587310833

Epoch: 6| Step: 4
Training loss: 2.9552088252862614
Validation loss: 2.539562856186554

Epoch: 6| Step: 5
Training loss: 2.9787202158218062
Validation loss: 2.549451732809464

Epoch: 6| Step: 6
Training loss: 2.735935833819899
Validation loss: 2.5421249839490345

Epoch: 6| Step: 7
Training loss: 2.0415045485715626
Validation loss: 2.537049138905623

Epoch: 6| Step: 8
Training loss: 2.6478932589485007
Validation loss: 2.5376011967136813

Epoch: 6| Step: 9
Training loss: 2.970902636247115
Validation loss: 2.5556546953376733

Epoch: 6| Step: 10
Training loss: 2.864936464680373
Validation loss: 2.5476040129279056

Epoch: 6| Step: 11
Training loss: 2.8790125833695472
Validation loss: 2.5427724717993296

Epoch: 6| Step: 12
Training loss: 2.813892613122184
Validation loss: 2.550850476308933

Epoch: 6| Step: 13
Training loss: 2.177411603742907
Validation loss: 2.546468760095204

Epoch: 25| Step: 0
Training loss: 2.823043135359058
Validation loss: 2.5458704889238306

Epoch: 6| Step: 1
Training loss: 2.1912082303859512
Validation loss: 2.5324202141342522

Epoch: 6| Step: 2
Training loss: 2.691029382460932
Validation loss: 2.534123315057113

Epoch: 6| Step: 3
Training loss: 3.46530956762525
Validation loss: 2.5316157105302257

Epoch: 6| Step: 4
Training loss: 3.0542029267188724
Validation loss: 2.5464715890426066

Epoch: 6| Step: 5
Training loss: 2.8239653118802
Validation loss: 2.551804655194305

Epoch: 6| Step: 6
Training loss: 2.339370909026613
Validation loss: 2.53227684414287

Epoch: 6| Step: 7
Training loss: 2.9793953618833653
Validation loss: 2.544203224954396

Epoch: 6| Step: 8
Training loss: 3.050137225956886
Validation loss: 2.546415967937194

Epoch: 6| Step: 9
Training loss: 3.12283769184916
Validation loss: 2.5489154520815496

Epoch: 6| Step: 10
Training loss: 2.489150537728704
Validation loss: 2.5377788469897795

Epoch: 6| Step: 11
Training loss: 2.879787439608462
Validation loss: 2.542488195010541

Epoch: 6| Step: 12
Training loss: 3.00256524084202
Validation loss: 2.5407073700112237

Epoch: 6| Step: 13
Training loss: 3.300997791297634
Validation loss: 2.5464425091255576

Epoch: 26| Step: 0
Training loss: 3.2043579705866367
Validation loss: 2.5455736773610176

Epoch: 6| Step: 1
Training loss: 2.923110619053467
Validation loss: 2.5513726764123312

Epoch: 6| Step: 2
Training loss: 2.5986522629392335
Validation loss: 2.552448442638712

Epoch: 6| Step: 3
Training loss: 3.235075943776206
Validation loss: 2.553951705756813

Epoch: 6| Step: 4
Training loss: 3.0232228441948537
Validation loss: 2.553341844329212

Epoch: 6| Step: 5
Training loss: 1.9513903429682855
Validation loss: 2.5350792937912887

Epoch: 6| Step: 6
Training loss: 2.8797495213834488
Validation loss: 2.5394365750405457

Epoch: 6| Step: 7
Training loss: 3.404202186900313
Validation loss: 2.5411640122743044

Epoch: 6| Step: 8
Training loss: 2.3929437101114526
Validation loss: 2.535869087166492

Epoch: 6| Step: 9
Training loss: 3.0827840023589386
Validation loss: 2.5448316395458592

Epoch: 6| Step: 10
Training loss: 2.7308160781974853
Validation loss: 2.5419971292252206

Epoch: 6| Step: 11
Training loss: 2.578704861251883
Validation loss: 2.535796303680324

Epoch: 6| Step: 12
Training loss: 2.935629066235441
Validation loss: 2.5451798687940483

Epoch: 6| Step: 13
Training loss: 3.08083445008223
Validation loss: 2.5250694854217373

Epoch: 27| Step: 0
Training loss: 2.555169389637644
Validation loss: 2.549792650508193

Epoch: 6| Step: 1
Training loss: 3.115816431468153
Validation loss: 2.5265702478054095

Epoch: 6| Step: 2
Training loss: 2.7935050396127
Validation loss: 2.5569395658272978

Epoch: 6| Step: 3
Training loss: 3.456636740378086
Validation loss: 2.539007173981398

Epoch: 6| Step: 4
Training loss: 2.2326954751550496
Validation loss: 2.5500862807914726

Epoch: 6| Step: 5
Training loss: 2.8700444178849085
Validation loss: 2.5371512864008423

Epoch: 6| Step: 6
Training loss: 3.143330637450965
Validation loss: 2.537723846560137

Epoch: 6| Step: 7
Training loss: 2.936713904853512
Validation loss: 2.5498890725365544

Epoch: 6| Step: 8
Training loss: 2.5407470748871015
Validation loss: 2.5453958479614274

Epoch: 6| Step: 9
Training loss: 2.698885553444388
Validation loss: 2.54415827878048

Epoch: 6| Step: 10
Training loss: 2.7294561994496918
Validation loss: 2.543810967869226

Epoch: 6| Step: 11
Training loss: 2.481130917091354
Validation loss: 2.545462825750625

Epoch: 6| Step: 12
Training loss: 3.3116691555045197
Validation loss: 2.5454461907440913

Epoch: 6| Step: 13
Training loss: 3.354522891507953
Validation loss: 2.5436163904357083

Epoch: 28| Step: 0
Training loss: 3.031012142326981
Validation loss: 2.532840826918641

Epoch: 6| Step: 1
Training loss: 2.9194041529943244
Validation loss: 2.544966292938647

Epoch: 6| Step: 2
Training loss: 2.8551973769710566
Validation loss: 2.536670242786117

Epoch: 6| Step: 3
Training loss: 2.999228060271431
Validation loss: 2.539081851453216

Epoch: 6| Step: 4
Training loss: 3.5202023695080427
Validation loss: 2.5268673608599244

Epoch: 6| Step: 5
Training loss: 3.1185899223267066
Validation loss: 2.542809367869693

Epoch: 6| Step: 6
Training loss: 2.5350195049912405
Validation loss: 2.5411657101598903

Epoch: 6| Step: 7
Training loss: 3.08730932720321
Validation loss: 2.546725920720321

Epoch: 6| Step: 8
Training loss: 2.754347745528131
Validation loss: 2.527037632610824

Epoch: 6| Step: 9
Training loss: 2.629451247429749
Validation loss: 2.5451633759762764

Epoch: 6| Step: 10
Training loss: 2.638361937351162
Validation loss: 2.546545337384419

Epoch: 6| Step: 11
Training loss: 3.1274361841901173
Validation loss: 2.519321388585162

Epoch: 6| Step: 12
Training loss: 2.532507501649431
Validation loss: 2.539168862007429

Epoch: 6| Step: 13
Training loss: 1.6943586628294063
Validation loss: 2.5254380633503897

Epoch: 29| Step: 0
Training loss: 2.4580827897844135
Validation loss: 2.511966541593447

Epoch: 6| Step: 1
Training loss: 2.812372162350749
Validation loss: 2.5264623168456826

Epoch: 6| Step: 2
Training loss: 2.5038342636639235
Validation loss: 2.5211312173852454

Epoch: 6| Step: 3
Training loss: 2.521001153409241
Validation loss: 2.539788828565819

Epoch: 6| Step: 4
Training loss: 3.0544288311096666
Validation loss: 2.5240191250946546

Epoch: 6| Step: 5
Training loss: 3.212642170769603
Validation loss: 2.5288722163978825

Epoch: 6| Step: 6
Training loss: 3.076661667356497
Validation loss: 2.5227646642637356

Epoch: 6| Step: 7
Training loss: 2.742384248723228
Validation loss: 2.535095489171738

Epoch: 6| Step: 8
Training loss: 2.809178064761316
Validation loss: 2.5222789243661228

Epoch: 6| Step: 9
Training loss: 3.0908803249999313
Validation loss: 2.521135711907954

Epoch: 6| Step: 10
Training loss: 3.089569504017317
Validation loss: 2.521872803860582

Epoch: 6| Step: 11
Training loss: 2.693144614749566
Validation loss: 2.515267095657512

Epoch: 6| Step: 12
Training loss: 3.1077223176371533
Validation loss: 2.515975324455968

Epoch: 6| Step: 13
Training loss: 2.80673219747751
Validation loss: 2.5449252939617204

Epoch: 30| Step: 0
Training loss: 2.7812315693791096
Validation loss: 2.5373038037815223

Epoch: 6| Step: 1
Training loss: 2.6114673563118256
Validation loss: 2.5289162172656225

Epoch: 6| Step: 2
Training loss: 2.5964875998433223
Validation loss: 2.5328302265428593

Epoch: 6| Step: 3
Training loss: 3.501311737573076
Validation loss: 2.531578564230602

Epoch: 6| Step: 4
Training loss: 3.578882928392143
Validation loss: 2.542542466224525

Epoch: 6| Step: 5
Training loss: 2.86003397034431
Validation loss: 2.5404412395046774

Epoch: 6| Step: 6
Training loss: 3.1074786513708483
Validation loss: 2.5244983223859294

Epoch: 6| Step: 7
Training loss: 2.516355041342894
Validation loss: 2.5190255990235033

Epoch: 6| Step: 8
Training loss: 2.42935305927753
Validation loss: 2.5218466933245938

Epoch: 6| Step: 9
Training loss: 2.2255333379109548
Validation loss: 2.538551935272802

Epoch: 6| Step: 10
Training loss: 2.8477813316472207
Validation loss: 2.520953313266751

Epoch: 6| Step: 11
Training loss: 2.942002761559451
Validation loss: 2.545786581940568

Epoch: 6| Step: 12
Training loss: 2.636704463213609
Validation loss: 2.528191243007869

Epoch: 6| Step: 13
Training loss: 3.241813031367892
Validation loss: 2.5359612701136816

Epoch: 31| Step: 0
Training loss: 3.124436899950527
Validation loss: 2.5325240682829224

Epoch: 6| Step: 1
Training loss: 2.8880488282828423
Validation loss: 2.5368158424102947

Epoch: 6| Step: 2
Training loss: 2.4731028365963392
Validation loss: 2.537666712332495

Epoch: 6| Step: 3
Training loss: 2.6180384832399506
Validation loss: 2.5390617346624413

Epoch: 6| Step: 4
Training loss: 2.79534239307879
Validation loss: 2.5442431533790146

Epoch: 6| Step: 5
Training loss: 3.6110553215477497
Validation loss: 2.537172501522712

Epoch: 6| Step: 6
Training loss: 2.961583532548706
Validation loss: 2.537145482423471

Epoch: 6| Step: 7
Training loss: 2.985400438142597
Validation loss: 2.5301696465018364

Epoch: 6| Step: 8
Training loss: 2.552118999206032
Validation loss: 2.523202836251823

Epoch: 6| Step: 9
Training loss: 2.7542439571583364
Validation loss: 2.5269184968528573

Epoch: 6| Step: 10
Training loss: 2.999065412540021
Validation loss: 2.5325254627075786

Epoch: 6| Step: 11
Training loss: 2.7754431980638175
Validation loss: 2.5343486597333014

Epoch: 6| Step: 12
Training loss: 2.492240594280386
Validation loss: 2.5318030904265703

Epoch: 6| Step: 13
Training loss: 2.884382941833341
Validation loss: 2.533304416610736

Epoch: 32| Step: 0
Training loss: 2.904395054977194
Validation loss: 2.5295973578021433

Epoch: 6| Step: 1
Training loss: 3.045369720312862
Validation loss: 2.5237497730624066

Epoch: 6| Step: 2
Training loss: 2.592149447483142
Validation loss: 2.52561087978206

Epoch: 6| Step: 3
Training loss: 2.330951178577454
Validation loss: 2.5277836200920505

Epoch: 6| Step: 4
Training loss: 3.2287424772841735
Validation loss: 2.5350223962685594

Epoch: 6| Step: 5
Training loss: 3.346686669045461
Validation loss: 2.5241055838721365

Epoch: 6| Step: 6
Training loss: 2.3661726485243024
Validation loss: 2.5227911026746836

Epoch: 6| Step: 7
Training loss: 3.035931305380807
Validation loss: 2.527695193769655

Epoch: 6| Step: 8
Training loss: 2.0366989995176583
Validation loss: 2.516192573523862

Epoch: 6| Step: 9
Training loss: 3.170858887524755
Validation loss: 2.5378321390415537

Epoch: 6| Step: 10
Training loss: 2.705072131649498
Validation loss: 2.5128763844127806

Epoch: 6| Step: 11
Training loss: 2.9487617997616216
Validation loss: 2.537818110273779

Epoch: 6| Step: 12
Training loss: 2.94448071783343
Validation loss: 2.5155251529735243

Epoch: 6| Step: 13
Training loss: 3.2411544440881137
Validation loss: 2.5360521315248623

Epoch: 33| Step: 0
Training loss: 2.748945901160094
Validation loss: 2.5290015897107514

Epoch: 6| Step: 1
Training loss: 2.6894049879100326
Validation loss: 2.5258994137376924

Epoch: 6| Step: 2
Training loss: 3.1064967343374463
Validation loss: 2.520787872667949

Epoch: 6| Step: 3
Training loss: 3.1532258001572524
Validation loss: 2.530459992832849

Epoch: 6| Step: 4
Training loss: 2.8904752125464945
Validation loss: 2.5209476011475744

Epoch: 6| Step: 5
Training loss: 3.3406822891961205
Validation loss: 2.5248356089751796

Epoch: 6| Step: 6
Training loss: 2.679617655652959
Validation loss: 2.5353892229562103

Epoch: 6| Step: 7
Training loss: 2.627455153586155
Validation loss: 2.508309567396498

Epoch: 6| Step: 8
Training loss: 2.8036590645780426
Validation loss: 2.516412143947616

Epoch: 6| Step: 9
Training loss: 2.618526287128284
Validation loss: 2.5298616122895994

Epoch: 6| Step: 10
Training loss: 2.396337229494663
Validation loss: 2.5250440272656887

Epoch: 6| Step: 11
Training loss: 2.9125385134528594
Validation loss: 2.521298993908522

Epoch: 6| Step: 12
Training loss: 2.678848624645646
Validation loss: 2.5206089501286315

Epoch: 6| Step: 13
Training loss: 3.2940279703996733
Validation loss: 2.5194628664978302

Epoch: 34| Step: 0
Training loss: 2.7570909631477605
Validation loss: 2.5089853201093515

Epoch: 6| Step: 1
Training loss: 2.997743393638215
Validation loss: 2.530957158330129

Epoch: 6| Step: 2
Training loss: 2.4991469835314186
Validation loss: 2.5263895759132917

Epoch: 6| Step: 3
Training loss: 2.117758023013221
Validation loss: 2.5274834054853885

Epoch: 6| Step: 4
Training loss: 2.930752085222184
Validation loss: 2.5116163714644473

Epoch: 6| Step: 5
Training loss: 2.5502607623642506
Validation loss: 2.5319921827679828

Epoch: 6| Step: 6
Training loss: 3.088946379744795
Validation loss: 2.532442953962628

Epoch: 6| Step: 7
Training loss: 2.651087152856544
Validation loss: 2.527837500132822

Epoch: 6| Step: 8
Training loss: 3.2226322797403997
Validation loss: 2.5240005621336694

Epoch: 6| Step: 9
Training loss: 2.6457905102565884
Validation loss: 2.5266425421665897

Epoch: 6| Step: 10
Training loss: 2.771276357316355
Validation loss: 2.530215403498569

Epoch: 6| Step: 11
Training loss: 3.3066161099024787
Validation loss: 2.5164787083617464

Epoch: 6| Step: 12
Training loss: 3.0168405563509397
Validation loss: 2.5241437694648945

Epoch: 6| Step: 13
Training loss: 3.1264788370982526
Validation loss: 2.518300785633933

Epoch: 35| Step: 0
Training loss: 2.6933737153466133
Validation loss: 2.5188285817617677

Epoch: 6| Step: 1
Training loss: 2.8540130536770643
Validation loss: 2.5220581783518585

Epoch: 6| Step: 2
Training loss: 3.464577854968014
Validation loss: 2.527194747035821

Epoch: 6| Step: 3
Training loss: 2.5503536876656816
Validation loss: 2.5041407973668894

Epoch: 6| Step: 4
Training loss: 2.9483211136545475
Validation loss: 2.518729626122206

Epoch: 6| Step: 5
Training loss: 2.3115902735109293
Validation loss: 2.507124509383707

Epoch: 6| Step: 6
Training loss: 3.1942447286638322
Validation loss: 2.514116603779749

Epoch: 6| Step: 7
Training loss: 2.919378999492149
Validation loss: 2.5189658495064164

Epoch: 6| Step: 8
Training loss: 3.4412323542986707
Validation loss: 2.5062935152189487

Epoch: 6| Step: 9
Training loss: 2.875694356909787
Validation loss: 2.5057751134654183

Epoch: 6| Step: 10
Training loss: 2.8127149711681065
Validation loss: 2.519988638921762

Epoch: 6| Step: 11
Training loss: 2.499400066871029
Validation loss: 2.5129706227529955

Epoch: 6| Step: 12
Training loss: 2.4185222429786983
Validation loss: 2.5124265066283287

Epoch: 6| Step: 13
Training loss: 2.336632564566105
Validation loss: 2.5265975266133736

Epoch: 36| Step: 0
Training loss: 2.297939961909902
Validation loss: 2.5086797554393416

Epoch: 6| Step: 1
Training loss: 2.8397922012708827
Validation loss: 2.512049848416192

Epoch: 6| Step: 2
Training loss: 2.640428163313692
Validation loss: 2.53272168982667

Epoch: 6| Step: 3
Training loss: 2.4545711458191013
Validation loss: 2.5151544934852335

Epoch: 6| Step: 4
Training loss: 2.9368439611404966
Validation loss: 2.509473891612061

Epoch: 6| Step: 5
Training loss: 2.345537038445196
Validation loss: 2.508138015041269

Epoch: 6| Step: 6
Training loss: 3.4177664560671452
Validation loss: 2.5109802139136557

Epoch: 6| Step: 7
Training loss: 3.186553515363333
Validation loss: 2.520211092056911

Epoch: 6| Step: 8
Training loss: 3.0455613654565754
Validation loss: 2.5161446613131897

Epoch: 6| Step: 9
Training loss: 2.6613956650574013
Validation loss: 2.5137361214434746

Epoch: 6| Step: 10
Training loss: 2.9456605579116757
Validation loss: 2.516276733787193

Epoch: 6| Step: 11
Training loss: 2.847409586957239
Validation loss: 2.518039726317963

Epoch: 6| Step: 12
Training loss: 2.8729579141563617
Validation loss: 2.5148168453091677

Epoch: 6| Step: 13
Training loss: 3.1024878824567574
Validation loss: 2.509089023916215

Epoch: 37| Step: 0
Training loss: 2.287906498045501
Validation loss: 2.5251099641228048

Epoch: 6| Step: 1
Training loss: 3.2737352331410348
Validation loss: 2.52325250014838

Epoch: 6| Step: 2
Training loss: 3.2157338649460923
Validation loss: 2.503708202728349

Epoch: 6| Step: 3
Training loss: 3.006867812787769
Validation loss: 2.515361136394869

Epoch: 6| Step: 4
Training loss: 2.984059581765152
Validation loss: 2.505076858631403

Epoch: 6| Step: 5
Training loss: 2.49197176295489
Validation loss: 2.496495119886895

Epoch: 6| Step: 6
Training loss: 2.417069127563263
Validation loss: 2.5140653807490634

Epoch: 6| Step: 7
Training loss: 2.826034363285971
Validation loss: 2.512063941997131

Epoch: 6| Step: 8
Training loss: 2.6184687424710367
Validation loss: 2.520332161178531

Epoch: 6| Step: 9
Training loss: 2.0119086018576997
Validation loss: 2.505666553799369

Epoch: 6| Step: 10
Training loss: 3.037542988037339
Validation loss: 2.5083915443957854

Epoch: 6| Step: 11
Training loss: 3.152603611404334
Validation loss: 2.5130067679022057

Epoch: 6| Step: 12
Training loss: 3.3102927861562526
Validation loss: 2.5136080399758556

Epoch: 6| Step: 13
Training loss: 2.4599480471513697
Validation loss: 2.507350895120645

Epoch: 38| Step: 0
Training loss: 2.7642269588040436
Validation loss: 2.5182207570205613

Epoch: 6| Step: 1
Training loss: 2.909023807033503
Validation loss: 2.5149319585224092

Epoch: 6| Step: 2
Training loss: 2.9651875855673175
Validation loss: 2.513574497126517

Epoch: 6| Step: 3
Training loss: 3.043265841161509
Validation loss: 2.518819711699057

Epoch: 6| Step: 4
Training loss: 2.3828109991350295
Validation loss: 2.504469439803049

Epoch: 6| Step: 5
Training loss: 2.7359911692794703
Validation loss: 2.5116170614666515

Epoch: 6| Step: 6
Training loss: 2.8373752448935043
Validation loss: 2.510178103060013

Epoch: 6| Step: 7
Training loss: 3.130468238200295
Validation loss: 2.522829974775352

Epoch: 6| Step: 8
Training loss: 2.5115290877191674
Validation loss: 2.5085150960844715

Epoch: 6| Step: 9
Training loss: 3.1002529656348585
Validation loss: 2.5158207997487443

Epoch: 6| Step: 10
Training loss: 3.463035481495064
Validation loss: 2.51789765935711

Epoch: 6| Step: 11
Training loss: 1.82247396997353
Validation loss: 2.5166627382561395

Epoch: 6| Step: 12
Training loss: 2.9339259704944496
Validation loss: 2.522715441966215

Epoch: 6| Step: 13
Training loss: 2.783761936773668
Validation loss: 2.506244760132987

Epoch: 39| Step: 0
Training loss: 2.546322066308316
Validation loss: 2.5080441051800473

Epoch: 6| Step: 1
Training loss: 3.074858970819587
Validation loss: 2.512231680665826

Epoch: 6| Step: 2
Training loss: 2.1977234766035187
Validation loss: 2.518126036105515

Epoch: 6| Step: 3
Training loss: 3.0303950726373365
Validation loss: 2.5077381937639553

Epoch: 6| Step: 4
Training loss: 3.1204000568665196
Validation loss: 2.5151553456011624

Epoch: 6| Step: 5
Training loss: 3.0318664238627
Validation loss: 2.5116376328358183

Epoch: 6| Step: 6
Training loss: 3.156419503976461
Validation loss: 2.5101831635880005

Epoch: 6| Step: 7
Training loss: 3.009320720686177
Validation loss: 2.517179151348956

Epoch: 6| Step: 8
Training loss: 2.5640526696388055
Validation loss: 2.511470142859596

Epoch: 6| Step: 9
Training loss: 2.379143764120614
Validation loss: 2.5119206695621688

Epoch: 6| Step: 10
Training loss: 3.224873172129155
Validation loss: 2.5081778225619367

Epoch: 6| Step: 11
Training loss: 3.120595498353361
Validation loss: 2.5169532676522954

Epoch: 6| Step: 12
Training loss: 1.9744018083366262
Validation loss: 2.5151649869262345

Epoch: 6| Step: 13
Training loss: 2.731508158130253
Validation loss: 2.515822728729482

Epoch: 40| Step: 0
Training loss: 2.6406387238456244
Validation loss: 2.5182985114116487

Epoch: 6| Step: 1
Training loss: 2.4868209602138993
Validation loss: 2.5216764889042906

Epoch: 6| Step: 2
Training loss: 3.0442189695423494
Validation loss: 2.513530826905181

Epoch: 6| Step: 3
Training loss: 2.892941098618021
Validation loss: 2.5135148311976336

Epoch: 6| Step: 4
Training loss: 2.406008027035585
Validation loss: 2.5240307558231976

Epoch: 6| Step: 5
Training loss: 2.6219246424270866
Validation loss: 2.5234245529307455

Epoch: 6| Step: 6
Training loss: 3.254169430570776
Validation loss: 2.508318311096915

Epoch: 6| Step: 7
Training loss: 2.9334778540584665
Validation loss: 2.502573704561626

Epoch: 6| Step: 8
Training loss: 3.4973886830173244
Validation loss: 2.514876290740917

Epoch: 6| Step: 9
Training loss: 2.5446586092124353
Validation loss: 2.519851216804593

Epoch: 6| Step: 10
Training loss: 2.5894952830175737
Validation loss: 2.523005049821405

Epoch: 6| Step: 11
Training loss: 2.933224752612868
Validation loss: 2.5140108231426472

Epoch: 6| Step: 12
Training loss: 2.906711336661715
Validation loss: 2.521420478495736

Epoch: 6| Step: 13
Training loss: 2.2665588558961383
Validation loss: 2.502164053789095

Epoch: 41| Step: 0
Training loss: 2.9910264912627484
Validation loss: 2.522354777049172

Epoch: 6| Step: 1
Training loss: 3.20574010769144
Validation loss: 2.5126436554371816

Epoch: 6| Step: 2
Training loss: 1.9295337322298531
Validation loss: 2.5100367217757795

Epoch: 6| Step: 3
Training loss: 2.519031374528101
Validation loss: 2.5200739714887432

Epoch: 6| Step: 4
Training loss: 3.1161249400543634
Validation loss: 2.5259362193152124

Epoch: 6| Step: 5
Training loss: 2.569492754324551
Validation loss: 2.5181643184808467

Epoch: 6| Step: 6
Training loss: 2.59765863633584
Validation loss: 2.5161441467805106

Epoch: 6| Step: 7
Training loss: 2.7462489815433577
Validation loss: 2.5147111634506327

Epoch: 6| Step: 8
Training loss: 3.1332511309398954
Validation loss: 2.511819859801533

Epoch: 6| Step: 9
Training loss: 3.059370972549858
Validation loss: 2.4993304371197302

Epoch: 6| Step: 10
Training loss: 2.668840525608293
Validation loss: 2.5176847322617464

Epoch: 6| Step: 11
Training loss: 2.8797485278861252
Validation loss: 2.5198163393268755

Epoch: 6| Step: 12
Training loss: 2.8021529707829087
Validation loss: 2.5085584846954094

Epoch: 6| Step: 13
Training loss: 2.8131054544437264
Validation loss: 2.520575711998476

Epoch: 42| Step: 0
Training loss: 2.5160442500506406
Validation loss: 2.5189984595719914

Epoch: 6| Step: 1
Training loss: 2.431056087968836
Validation loss: 2.5141296579245567

Epoch: 6| Step: 2
Training loss: 2.3174182038753455
Validation loss: 2.517198738252356

Epoch: 6| Step: 3
Training loss: 3.147544260842475
Validation loss: 2.510552162459405

Epoch: 6| Step: 4
Training loss: 2.760460983976259
Validation loss: 2.5206285388580842

Epoch: 6| Step: 5
Training loss: 2.7932630690642166
Validation loss: 2.4962777309337896

Epoch: 6| Step: 6
Training loss: 2.298397156693917
Validation loss: 2.517296511611295

Epoch: 6| Step: 7
Training loss: 2.565100861884504
Validation loss: 2.5095388983036266

Epoch: 6| Step: 8
Training loss: 2.8847980226261347
Validation loss: 2.5091229618557005

Epoch: 6| Step: 9
Training loss: 3.672227168949532
Validation loss: 2.5084541937891123

Epoch: 6| Step: 10
Training loss: 3.012163141814818
Validation loss: 2.5023412370539964

Epoch: 6| Step: 11
Training loss: 2.7825655451181053
Validation loss: 2.4963367161669177

Epoch: 6| Step: 12
Training loss: 3.4577004339965263
Validation loss: 2.517613699950213

Epoch: 6| Step: 13
Training loss: 1.9176277432420537
Validation loss: 2.4998822707481576

Epoch: 43| Step: 0
Training loss: 2.849428480968044
Validation loss: 2.5080378832400614

Epoch: 6| Step: 1
Training loss: 2.317338263866738
Validation loss: 2.5052539397546663

Epoch: 6| Step: 2
Training loss: 2.614479052729833
Validation loss: 2.5126228178426073

Epoch: 6| Step: 3
Training loss: 3.2875648405113482
Validation loss: 2.4985829582706884

Epoch: 6| Step: 4
Training loss: 2.6477961931252127
Validation loss: 2.5165782414872986

Epoch: 6| Step: 5
Training loss: 2.9180272516516763
Validation loss: 2.5052655992726756

Epoch: 6| Step: 6
Training loss: 2.9258246017524234
Validation loss: 2.4980196646467068

Epoch: 6| Step: 7
Training loss: 2.3338013134276534
Validation loss: 2.503359406900506

Epoch: 6| Step: 8
Training loss: 2.3349686977077235
Validation loss: 2.511074712288153

Epoch: 6| Step: 9
Training loss: 2.4712586995783545
Validation loss: 2.5173584220474887

Epoch: 6| Step: 10
Training loss: 3.296005351275202
Validation loss: 2.5093671051135353

Epoch: 6| Step: 11
Training loss: 2.8130967248912273
Validation loss: 2.5165697144365833

Epoch: 6| Step: 12
Training loss: 3.4954998513539417
Validation loss: 2.507869260437797

Epoch: 6| Step: 13
Training loss: 2.6897554913260975
Validation loss: 2.5021998304709756

Epoch: 44| Step: 0
Training loss: 2.7119066776096785
Validation loss: 2.5031469289057156

Epoch: 6| Step: 1
Training loss: 3.0140264355690514
Validation loss: 2.507035352343176

Epoch: 6| Step: 2
Training loss: 2.330142382417621
Validation loss: 2.5063986805479352

Epoch: 6| Step: 3
Training loss: 2.9365617592901887
Validation loss: 2.494771917542722

Epoch: 6| Step: 4
Training loss: 2.6246521128873597
Validation loss: 2.514483292187838

Epoch: 6| Step: 5
Training loss: 2.724765743020783
Validation loss: 2.492326292635774

Epoch: 6| Step: 6
Training loss: 2.589634767503893
Validation loss: 2.518026764730189

Epoch: 6| Step: 7
Training loss: 3.1424585560301646
Validation loss: 2.505429344584003

Epoch: 6| Step: 8
Training loss: 2.2280362789686325
Validation loss: 2.5080172220363552

Epoch: 6| Step: 9
Training loss: 2.4971424938237803
Validation loss: 2.51133628687459

Epoch: 6| Step: 10
Training loss: 2.6787871246684665
Validation loss: 2.5131286084511184

Epoch: 6| Step: 11
Training loss: 3.504325782045177
Validation loss: 2.5211546671134237

Epoch: 6| Step: 12
Training loss: 3.1761127594501724
Validation loss: 2.505387359915587

Epoch: 6| Step: 13
Training loss: 2.738487595036082
Validation loss: 2.4970754067786007

Epoch: 45| Step: 0
Training loss: 2.6493062532778704
Validation loss: 2.495247129419212

Epoch: 6| Step: 1
Training loss: 2.7004258455782564
Validation loss: 2.5136730223633794

Epoch: 6| Step: 2
Training loss: 2.306597419353508
Validation loss: 2.495769330661857

Epoch: 6| Step: 3
Training loss: 3.00819771021539
Validation loss: 2.511320528824569

Epoch: 6| Step: 4
Training loss: 2.5478699033931655
Validation loss: 2.50969668019509

Epoch: 6| Step: 5
Training loss: 3.2211585061250916
Validation loss: 2.5150635967434973

Epoch: 6| Step: 6
Training loss: 3.2458578269599108
Validation loss: 2.508014589414911

Epoch: 6| Step: 7
Training loss: 2.425254187092412
Validation loss: 2.5007897027027663

Epoch: 6| Step: 8
Training loss: 2.534722195513535
Validation loss: 2.5144501321354

Epoch: 6| Step: 9
Training loss: 2.0390475334699776
Validation loss: 2.500633499933137

Epoch: 6| Step: 10
Training loss: 3.729501137394341
Validation loss: 2.5035957728940477

Epoch: 6| Step: 11
Training loss: 3.027774351936603
Validation loss: 2.5128202176033914

Epoch: 6| Step: 12
Training loss: 2.486251410344387
Validation loss: 2.5104508188081316

Epoch: 6| Step: 13
Training loss: 2.754744944457634
Validation loss: 2.5044973559822776

Epoch: 46| Step: 0
Training loss: 2.5620191169400757
Validation loss: 2.4965534643502143

Epoch: 6| Step: 1
Training loss: 2.4281780300952818
Validation loss: 2.505265420195005

Epoch: 6| Step: 2
Training loss: 2.365449475084439
Validation loss: 2.5027846855298996

Epoch: 6| Step: 3
Training loss: 2.4758184139487405
Validation loss: 2.491812784644339

Epoch: 6| Step: 4
Training loss: 2.8825812518404255
Validation loss: 2.5096894331939317

Epoch: 6| Step: 5
Training loss: 3.31028587190154
Validation loss: 2.492718802265812

Epoch: 6| Step: 6
Training loss: 2.856726248204006
Validation loss: 2.49936046008492

Epoch: 6| Step: 7
Training loss: 2.966481195145579
Validation loss: 2.4927069112800746

Epoch: 6| Step: 8
Training loss: 2.705804367905091
Validation loss: 2.521401025046414

Epoch: 6| Step: 9
Training loss: 2.9812388293938716
Validation loss: 2.494249696598563

Epoch: 6| Step: 10
Training loss: 2.9802636392193445
Validation loss: 2.483880557570572

Epoch: 6| Step: 11
Training loss: 2.398942527658193
Validation loss: 2.508562588363159

Epoch: 6| Step: 12
Training loss: 3.2677590729934267
Validation loss: 2.5032656557291917

Epoch: 6| Step: 13
Training loss: 2.8091324885064033
Validation loss: 2.507421155869903

Epoch: 47| Step: 0
Training loss: 2.6928811426744734
Validation loss: 2.4973304339028295

Epoch: 6| Step: 1
Training loss: 2.764434040775055
Validation loss: 2.5030879597441986

Epoch: 6| Step: 2
Training loss: 3.4097090490172612
Validation loss: 2.4998539717900106

Epoch: 6| Step: 3
Training loss: 2.7497518600872377
Validation loss: 2.4952890576491304

Epoch: 6| Step: 4
Training loss: 3.2210291228471517
Validation loss: 2.5019397209300065

Epoch: 6| Step: 5
Training loss: 2.5661804936022388
Validation loss: 2.499743766369191

Epoch: 6| Step: 6
Training loss: 3.2715231457590677
Validation loss: 2.5077933999899162

Epoch: 6| Step: 7
Training loss: 2.7526259456026767
Validation loss: 2.495373866410628

Epoch: 6| Step: 8
Training loss: 2.11167669109724
Validation loss: 2.5115816496146888

Epoch: 6| Step: 9
Training loss: 2.4584499805599633
Validation loss: 2.505495282965484

Epoch: 6| Step: 10
Training loss: 1.9630084405718555
Validation loss: 2.506655110387317

Epoch: 6| Step: 11
Training loss: 3.2028247227297357
Validation loss: 2.4940772408800442

Epoch: 6| Step: 12
Training loss: 2.7528137204257055
Validation loss: 2.499091688884551

Epoch: 6| Step: 13
Training loss: 2.840430365714954
Validation loss: 2.495621206354037

Epoch: 48| Step: 0
Training loss: 2.6571965943160336
Validation loss: 2.5063077086789383

Epoch: 6| Step: 1
Training loss: 2.4305812749561535
Validation loss: 2.505714887868724

Epoch: 6| Step: 2
Training loss: 2.743972849213873
Validation loss: 2.4940395920162737

Epoch: 6| Step: 3
Training loss: 2.9774882961911167
Validation loss: 2.5106542372153298

Epoch: 6| Step: 4
Training loss: 2.582637282911212
Validation loss: 2.5083353589254527

Epoch: 6| Step: 5
Training loss: 2.1232730355476863
Validation loss: 2.4997459159448927

Epoch: 6| Step: 6
Training loss: 2.6595045907600774
Validation loss: 2.4847643477425616

Epoch: 6| Step: 7
Training loss: 2.664277098841564
Validation loss: 2.4922541857817166

Epoch: 6| Step: 8
Training loss: 3.3238358775819656
Validation loss: 2.4934111235038197

Epoch: 6| Step: 9
Training loss: 3.0484913768924775
Validation loss: 2.5000497761765015

Epoch: 6| Step: 10
Training loss: 2.4985028552393453
Validation loss: 2.5108732086571517

Epoch: 6| Step: 11
Training loss: 2.4998279512331645
Validation loss: 2.5030625863030607

Epoch: 6| Step: 12
Training loss: 3.5085002675213333
Validation loss: 2.501268024245473

Epoch: 6| Step: 13
Training loss: 3.4278113027781463
Validation loss: 2.4955575978822204

Epoch: 49| Step: 0
Training loss: 2.2749584655323845
Validation loss: 2.5004591920046844

Epoch: 6| Step: 1
Training loss: 2.8612436327648854
Validation loss: 2.5081926150456892

Epoch: 6| Step: 2
Training loss: 2.661454610703783
Validation loss: 2.5061239587338124

Epoch: 6| Step: 3
Training loss: 3.1752429238449213
Validation loss: 2.4986821315800536

Epoch: 6| Step: 4
Training loss: 2.6446937049090664
Validation loss: 2.5054155022354263

Epoch: 6| Step: 5
Training loss: 2.69330820943741
Validation loss: 2.4994450989033195

Epoch: 6| Step: 6
Training loss: 3.1957522511713417
Validation loss: 2.5125192252007067

Epoch: 6| Step: 7
Training loss: 2.6350379842666087
Validation loss: 2.5079673571305414

Epoch: 6| Step: 8
Training loss: 2.71559494932556
Validation loss: 2.514554461865599

Epoch: 6| Step: 9
Training loss: 2.4751224603123134
Validation loss: 2.509801093118579

Epoch: 6| Step: 10
Training loss: 3.381171764660327
Validation loss: 2.521234775966834

Epoch: 6| Step: 11
Training loss: 2.553849482379473
Validation loss: 2.5039201467654184

Epoch: 6| Step: 12
Training loss: 3.182454622698823
Validation loss: 2.521160748896643

Epoch: 6| Step: 13
Training loss: 1.8871479059706473
Validation loss: 2.50859200059593

Epoch: 50| Step: 0
Training loss: 2.8441010981536072
Validation loss: 2.510587513268541

Epoch: 6| Step: 1
Training loss: 2.061827116355602
Validation loss: 2.5046552354046696

Epoch: 6| Step: 2
Training loss: 3.2575575182177627
Validation loss: 2.510654091197365

Epoch: 6| Step: 3
Training loss: 2.647036831895318
Validation loss: 2.50360847742447

Epoch: 6| Step: 4
Training loss: 2.314591982253357
Validation loss: 2.496290198504689

Epoch: 6| Step: 5
Training loss: 2.848204760059327
Validation loss: 2.5090381069504

Epoch: 6| Step: 6
Training loss: 3.438850553672428
Validation loss: 2.500683783264016

Epoch: 6| Step: 7
Training loss: 2.2971637570271564
Validation loss: 2.500091100899205

Epoch: 6| Step: 8
Training loss: 2.830295804473503
Validation loss: 2.498163697376141

Epoch: 6| Step: 9
Training loss: 2.6756787802573814
Validation loss: 2.5059214728560946

Epoch: 6| Step: 10
Training loss: 3.343903154805148
Validation loss: 2.5043916430005115

Epoch: 6| Step: 11
Training loss: 2.9680380519679472
Validation loss: 2.496504651516564

Epoch: 6| Step: 12
Training loss: 2.6783141239650847
Validation loss: 2.500676284091392

Epoch: 6| Step: 13
Training loss: 2.2097123596666104
Validation loss: 2.494337462691109

Epoch: 51| Step: 0
Training loss: 2.6912182657839843
Validation loss: 2.5034880116765867

Epoch: 6| Step: 1
Training loss: 2.7882614053804007
Validation loss: 2.4986652338635813

Epoch: 6| Step: 2
Training loss: 2.682762672525915
Validation loss: 2.5013338919406607

Epoch: 6| Step: 3
Training loss: 2.9551536414260418
Validation loss: 2.4979778089331157

Epoch: 6| Step: 4
Training loss: 3.0198227518373737
Validation loss: 2.5048675199541313

Epoch: 6| Step: 5
Training loss: 3.148432956436703
Validation loss: 2.498628740685238

Epoch: 6| Step: 6
Training loss: 2.329370562296111
Validation loss: 2.489898686038616

Epoch: 6| Step: 7
Training loss: 2.9324095427341588
Validation loss: 2.5003263814207455

Epoch: 6| Step: 8
Training loss: 2.5098485554452785
Validation loss: 2.496628011057612

Epoch: 6| Step: 9
Training loss: 2.7591854492611234
Validation loss: 2.4963903866296264

Epoch: 6| Step: 10
Training loss: 2.675600900628373
Validation loss: 2.5091617361253853

Epoch: 6| Step: 11
Training loss: 2.3164519487218604
Validation loss: 2.4922427307833104

Epoch: 6| Step: 12
Training loss: 3.0733863256137726
Validation loss: 2.4988696167963274

Epoch: 6| Step: 13
Training loss: 3.353221278306008
Validation loss: 2.507057765120176

Epoch: 52| Step: 0
Training loss: 2.8822088669240618
Validation loss: 2.494324815774457

Epoch: 6| Step: 1
Training loss: 3.507993153973188
Validation loss: 2.506860713359411

Epoch: 6| Step: 2
Training loss: 3.365973092074175
Validation loss: 2.4910595586743542

Epoch: 6| Step: 3
Training loss: 2.1506320911347103
Validation loss: 2.5003244558645448

Epoch: 6| Step: 4
Training loss: 2.9268547502819553
Validation loss: 2.493023384281155

Epoch: 6| Step: 5
Training loss: 2.8336061084563005
Validation loss: 2.509855065025527

Epoch: 6| Step: 6
Training loss: 2.5087128446115052
Validation loss: 2.5036253422894985

Epoch: 6| Step: 7
Training loss: 2.475245080238495
Validation loss: 2.5165501628764786

Epoch: 6| Step: 8
Training loss: 2.9476149082191454
Validation loss: 2.509430809985424

Epoch: 6| Step: 9
Training loss: 2.4941817289951866
Validation loss: 2.51128847648341

Epoch: 6| Step: 10
Training loss: 2.767723192762045
Validation loss: 2.507636525788254

Epoch: 6| Step: 11
Training loss: 2.948126867413814
Validation loss: 2.493546707157424

Epoch: 6| Step: 12
Training loss: 2.4420936532272495
Validation loss: 2.495350095303478

Epoch: 6| Step: 13
Training loss: 1.6928881349192757
Validation loss: 2.486185673075095

Epoch: 53| Step: 0
Training loss: 2.3387169266059047
Validation loss: 2.498180839129622

Epoch: 6| Step: 1
Training loss: 2.5561851288041963
Validation loss: 2.4987304950765763

Epoch: 6| Step: 2
Training loss: 3.616150412798588
Validation loss: 2.4985967081658096

Epoch: 6| Step: 3
Training loss: 1.7320126778136404
Validation loss: 2.4944053828852906

Epoch: 6| Step: 4
Training loss: 2.1431348802322647
Validation loss: 2.5012227001224354

Epoch: 6| Step: 5
Training loss: 3.250498219962367
Validation loss: 2.501598498279668

Epoch: 6| Step: 6
Training loss: 2.849306818670785
Validation loss: 2.493773515415503

Epoch: 6| Step: 7
Training loss: 3.0154003000300618
Validation loss: 2.4973118398893703

Epoch: 6| Step: 8
Training loss: 2.652850859624537
Validation loss: 2.4978436491731313

Epoch: 6| Step: 9
Training loss: 3.198479386480736
Validation loss: 2.5040041175042975

Epoch: 6| Step: 10
Training loss: 2.9464238748884544
Validation loss: 2.5113840718561926

Epoch: 6| Step: 11
Training loss: 2.3756509190053463
Validation loss: 2.5087967755158376

Epoch: 6| Step: 12
Training loss: 2.4560068296468005
Validation loss: 2.498415165696394

Epoch: 6| Step: 13
Training loss: 3.228543096242017
Validation loss: 2.494565249352669

Epoch: 54| Step: 0
Training loss: 2.6417129352099677
Validation loss: 2.501296474780631

Epoch: 6| Step: 1
Training loss: 2.87536784596924
Validation loss: 2.500876279276441

Epoch: 6| Step: 2
Training loss: 2.067783293498342
Validation loss: 2.497022021056223

Epoch: 6| Step: 3
Training loss: 3.051687499189981
Validation loss: 2.496352471753997

Epoch: 6| Step: 4
Training loss: 2.8526796425796705
Validation loss: 2.4961967035563344

Epoch: 6| Step: 5
Training loss: 3.522777284060237
Validation loss: 2.4978374213250536

Epoch: 6| Step: 6
Training loss: 1.6747773549154519
Validation loss: 2.4907189168880937

Epoch: 6| Step: 7
Training loss: 2.657969288627754
Validation loss: 2.485104181999312

Epoch: 6| Step: 8
Training loss: 2.8945213657472935
Validation loss: 2.4877378890754636

Epoch: 6| Step: 9
Training loss: 2.8296614209157678
Validation loss: 2.495131400355447

Epoch: 6| Step: 10
Training loss: 3.4958463272259412
Validation loss: 2.488412199990233

Epoch: 6| Step: 11
Training loss: 2.275055195065492
Validation loss: 2.5078655977543987

Epoch: 6| Step: 12
Training loss: 2.940835722650898
Validation loss: 2.493377096116614

Epoch: 6| Step: 13
Training loss: 2.399712736104118
Validation loss: 2.49628152872269

Epoch: 55| Step: 0
Training loss: 2.1537193153573337
Validation loss: 2.496557292012341

Epoch: 6| Step: 1
Training loss: 2.6523399746268232
Validation loss: 2.487239186273548

Epoch: 6| Step: 2
Training loss: 2.739675561394389
Validation loss: 2.4918375246893003

Epoch: 6| Step: 3
Training loss: 2.7986008418052277
Validation loss: 2.4876907788305083

Epoch: 6| Step: 4
Training loss: 2.4991734091869278
Validation loss: 2.4998827896534044

Epoch: 6| Step: 5
Training loss: 2.9136039639030695
Validation loss: 2.485605879272338

Epoch: 6| Step: 6
Training loss: 3.0156422352668906
Validation loss: 2.4872217382286896

Epoch: 6| Step: 7
Training loss: 2.9668151975446393
Validation loss: 2.501206318213516

Epoch: 6| Step: 8
Training loss: 3.009169710788615
Validation loss: 2.494183912144178

Epoch: 6| Step: 9
Training loss: 2.295840179470076
Validation loss: 2.4918588221043523

Epoch: 6| Step: 10
Training loss: 2.3171254886038746
Validation loss: 2.5033137724497374

Epoch: 6| Step: 11
Training loss: 3.4741800781732906
Validation loss: 2.493269251061394

Epoch: 6| Step: 12
Training loss: 2.766677569938531
Validation loss: 2.499135885308784

Epoch: 6| Step: 13
Training loss: 2.8624774382255986
Validation loss: 2.5012228000555425

Epoch: 56| Step: 0
Training loss: 2.7757667753710256
Validation loss: 2.497954096473457

Epoch: 6| Step: 1
Training loss: 2.2583366234486766
Validation loss: 2.4986563835370204

Epoch: 6| Step: 2
Training loss: 2.850753042217941
Validation loss: 2.498238232977109

Epoch: 6| Step: 3
Training loss: 1.7614544249374129
Validation loss: 2.4970513387360858

Epoch: 6| Step: 4
Training loss: 3.4154309775205576
Validation loss: 2.4992885223236083

Epoch: 6| Step: 5
Training loss: 2.1895644119659847
Validation loss: 2.505854983006178

Epoch: 6| Step: 6
Training loss: 2.83593413717948
Validation loss: 2.501147079851594

Epoch: 6| Step: 7
Training loss: 3.6842466323918943
Validation loss: 2.4941261464471696

Epoch: 6| Step: 8
Training loss: 3.473690878635072
Validation loss: 2.4944141444916377

Epoch: 6| Step: 9
Training loss: 2.870280995453039
Validation loss: 2.4904274501665657

Epoch: 6| Step: 10
Training loss: 2.577470176072833
Validation loss: 2.485563958914201

Epoch: 6| Step: 11
Training loss: 2.2548400954160797
Validation loss: 2.496768229481065

Epoch: 6| Step: 12
Training loss: 2.630506643368472
Validation loss: 2.49219504837527

Epoch: 6| Step: 13
Training loss: 2.3855834858185236
Validation loss: 2.499468594134341

Epoch: 57| Step: 0
Training loss: 2.229610886089575
Validation loss: 2.487066996915004

Epoch: 6| Step: 1
Training loss: 2.9408605304893394
Validation loss: 2.4974211774362547

Epoch: 6| Step: 2
Training loss: 2.5200613011367037
Validation loss: 2.504582325831556

Epoch: 6| Step: 3
Training loss: 2.8652060831723523
Validation loss: 2.490464691443138

Epoch: 6| Step: 4
Training loss: 2.5959499175790848
Validation loss: 2.4926635532336943

Epoch: 6| Step: 5
Training loss: 2.3160515396233943
Validation loss: 2.493734834961948

Epoch: 6| Step: 6
Training loss: 2.586495238486508
Validation loss: 2.505710254677052

Epoch: 6| Step: 7
Training loss: 2.394529358208113
Validation loss: 2.482346521620335

Epoch: 6| Step: 8
Training loss: 3.3256375325437633
Validation loss: 2.5029969653602806

Epoch: 6| Step: 9
Training loss: 3.2306167956082192
Validation loss: 2.5021983797010776

Epoch: 6| Step: 10
Training loss: 3.252323200601668
Validation loss: 2.5039580386847446

Epoch: 6| Step: 11
Training loss: 3.1405533360138396
Validation loss: 2.4997927590067355

Epoch: 6| Step: 12
Training loss: 2.7102015482992337
Validation loss: 2.500031375688123

Epoch: 6| Step: 13
Training loss: 1.8656778657154631
Validation loss: 2.492187533946138

Epoch: 58| Step: 0
Training loss: 2.321795981539941
Validation loss: 2.482543809097295

Epoch: 6| Step: 1
Training loss: 2.454983147215637
Validation loss: 2.497771157620004

Epoch: 6| Step: 2
Training loss: 3.0308696075553843
Validation loss: 2.4896973410350594

Epoch: 6| Step: 3
Training loss: 2.71585068725148
Validation loss: 2.480253323905808

Epoch: 6| Step: 4
Training loss: 2.7288846945273066
Validation loss: 2.5067668435983976

Epoch: 6| Step: 5
Training loss: 2.836065956758408
Validation loss: 2.4939016122493074

Epoch: 6| Step: 6
Training loss: 2.4219478473167153
Validation loss: 2.5060402636221086

Epoch: 6| Step: 7
Training loss: 2.944773819532761
Validation loss: 2.498418842234131

Epoch: 6| Step: 8
Training loss: 3.198811226810752
Validation loss: 2.49676825104352

Epoch: 6| Step: 9
Training loss: 2.4223096888126476
Validation loss: 2.488260267112586

Epoch: 6| Step: 10
Training loss: 3.317106678463717
Validation loss: 2.4980965341056556

Epoch: 6| Step: 11
Training loss: 2.252494700570599
Validation loss: 2.483689577684023

Epoch: 6| Step: 12
Training loss: 2.8142733599230474
Validation loss: 2.4868378141890717

Epoch: 6| Step: 13
Training loss: 3.013693551698209
Validation loss: 2.490408480608292

Epoch: 59| Step: 0
Training loss: 2.449446915458751
Validation loss: 2.4830378104748108

Epoch: 6| Step: 1
Training loss: 3.4765763528955045
Validation loss: 2.487699367254905

Epoch: 6| Step: 2
Training loss: 2.1258335722540953
Validation loss: 2.487799307788447

Epoch: 6| Step: 3
Training loss: 2.334051180725394
Validation loss: 2.495954038058316

Epoch: 6| Step: 4
Training loss: 2.9143710957369504
Validation loss: 2.488206767470083

Epoch: 6| Step: 5
Training loss: 2.5142528511661606
Validation loss: 2.495301725363399

Epoch: 6| Step: 6
Training loss: 2.5087475325910127
Validation loss: 2.4928312357153457

Epoch: 6| Step: 7
Training loss: 3.76438965854264
Validation loss: 2.4825324321808053

Epoch: 6| Step: 8
Training loss: 2.997809245977561
Validation loss: 2.4811283938816464

Epoch: 6| Step: 9
Training loss: 2.111304862629134
Validation loss: 2.4926572867313395

Epoch: 6| Step: 10
Training loss: 2.6635386379813015
Validation loss: 2.4926103681984757

Epoch: 6| Step: 11
Training loss: 2.9805847385380537
Validation loss: 2.4992498287515037

Epoch: 6| Step: 12
Training loss: 2.8035576119746297
Validation loss: 2.4947363806460348

Epoch: 6| Step: 13
Training loss: 2.071507868165089
Validation loss: 2.477698508646303

Epoch: 60| Step: 0
Training loss: 2.972529525161037
Validation loss: 2.492498176264572

Epoch: 6| Step: 1
Training loss: 2.8505958068195887
Validation loss: 2.4948808207665736

Epoch: 6| Step: 2
Training loss: 2.4269847495122905
Validation loss: 2.492889368727338

Epoch: 6| Step: 3
Training loss: 2.536634675357649
Validation loss: 2.472737239046605

Epoch: 6| Step: 4
Training loss: 2.4335886555675006
Validation loss: 2.486483817540846

Epoch: 6| Step: 5
Training loss: 3.041916318777013
Validation loss: 2.487774082410709

Epoch: 6| Step: 6
Training loss: 2.0359236721877885
Validation loss: 2.5006267305516867

Epoch: 6| Step: 7
Training loss: 3.1202557982219807
Validation loss: 2.4922529215787477

Epoch: 6| Step: 8
Training loss: 2.427195064827083
Validation loss: 2.482174609449668

Epoch: 6| Step: 9
Training loss: 2.874657652001528
Validation loss: 2.4874016096592917

Epoch: 6| Step: 10
Training loss: 2.877728867166322
Validation loss: 2.5019067968110162

Epoch: 6| Step: 11
Training loss: 1.8703702352053038
Validation loss: 2.4882435762872186

Epoch: 6| Step: 12
Training loss: 3.3704987638499824
Validation loss: 2.4869575845307756

Epoch: 6| Step: 13
Training loss: 3.5607930159538648
Validation loss: 2.48666734347485

Epoch: 61| Step: 0
Training loss: 2.683745489591976
Validation loss: 2.4892513644034118

Epoch: 6| Step: 1
Training loss: 2.6718126256254227
Validation loss: 2.4955496246226185

Epoch: 6| Step: 2
Training loss: 2.3695566137649893
Validation loss: 2.5003942224946805

Epoch: 6| Step: 3
Training loss: 2.690171267080969
Validation loss: 2.491764305913279

Epoch: 6| Step: 4
Training loss: 3.393331686692753
Validation loss: 2.4802807446719917

Epoch: 6| Step: 5
Training loss: 3.0351293849860763
Validation loss: 2.486039807403597

Epoch: 6| Step: 6
Training loss: 2.74901459118248
Validation loss: 2.4838403647758525

Epoch: 6| Step: 7
Training loss: 2.914734954562195
Validation loss: 2.488854076499236

Epoch: 6| Step: 8
Training loss: 2.673094710864535
Validation loss: 2.4837820292609583

Epoch: 6| Step: 9
Training loss: 2.452835940685089
Validation loss: 2.4955470656544323

Epoch: 6| Step: 10
Training loss: 2.467945015923883
Validation loss: 2.4998090260893986

Epoch: 6| Step: 11
Training loss: 2.870452933907185
Validation loss: 2.492353557946431

Epoch: 6| Step: 12
Training loss: 2.577888246705043
Validation loss: 2.496351747750904

Epoch: 6| Step: 13
Training loss: 2.830864185715003
Validation loss: 2.4884088352518767

Epoch: 62| Step: 0
Training loss: 2.668157836111522
Validation loss: 2.5055982298126116

Epoch: 6| Step: 1
Training loss: 2.255832424250536
Validation loss: 2.504368042453245

Epoch: 6| Step: 2
Training loss: 3.5403911462843998
Validation loss: 2.481498598396062

Epoch: 6| Step: 3
Training loss: 3.3693025323415764
Validation loss: 2.489764488392356

Epoch: 6| Step: 4
Training loss: 2.905326122158859
Validation loss: 2.4854687082484905

Epoch: 6| Step: 5
Training loss: 2.075292392030736
Validation loss: 2.4792868699752257

Epoch: 6| Step: 6
Training loss: 3.226763185628584
Validation loss: 2.4962071390712963

Epoch: 6| Step: 7
Training loss: 2.37265943339225
Validation loss: 2.5006357123061393

Epoch: 6| Step: 8
Training loss: 1.6397576355370334
Validation loss: 2.48716735041971

Epoch: 6| Step: 9
Training loss: 2.7610677467111726
Validation loss: 2.4838773394461513

Epoch: 6| Step: 10
Training loss: 2.870957559482482
Validation loss: 2.491488287372293

Epoch: 6| Step: 11
Training loss: 2.142786869531663
Validation loss: 2.500366520419708

Epoch: 6| Step: 12
Training loss: 2.8442972516016587
Validation loss: 2.4904212624484683

Epoch: 6| Step: 13
Training loss: 3.3272546337524496
Validation loss: 2.4923466303002226

Epoch: 63| Step: 0
Training loss: 2.398499329605629
Validation loss: 2.490789487777099

Epoch: 6| Step: 1
Training loss: 2.4380406489249817
Validation loss: 2.4843217618684794

Epoch: 6| Step: 2
Training loss: 3.05458728206367
Validation loss: 2.4866270225214233

Epoch: 6| Step: 3
Training loss: 3.3952742664415716
Validation loss: 2.4856618751205843

Epoch: 6| Step: 4
Training loss: 2.866231733048495
Validation loss: 2.4781734586214412

Epoch: 6| Step: 5
Training loss: 2.867718307047298
Validation loss: 2.4801569307210385

Epoch: 6| Step: 6
Training loss: 2.967010309554376
Validation loss: 2.487158271582322

Epoch: 6| Step: 7
Training loss: 2.591675445770735
Validation loss: 2.484682596164148

Epoch: 6| Step: 8
Training loss: 2.0050460815841924
Validation loss: 2.494765332639807

Epoch: 6| Step: 9
Training loss: 2.498697227542869
Validation loss: 2.478504411121602

Epoch: 6| Step: 10
Training loss: 2.7401665959910906
Validation loss: 2.477665584710348

Epoch: 6| Step: 11
Training loss: 2.390292774128522
Validation loss: 2.4901361053013145

Epoch: 6| Step: 12
Training loss: 3.1362065601343274
Validation loss: 2.480025311217481

Epoch: 6| Step: 13
Training loss: 2.7974791486984034
Validation loss: 2.474677452315621

Epoch: 64| Step: 0
Training loss: 2.8050139085829415
Validation loss: 2.4799323743166823

Epoch: 6| Step: 1
Training loss: 2.715992373077965
Validation loss: 2.4835668647565945

Epoch: 6| Step: 2
Training loss: 2.791519578693214
Validation loss: 2.4838220382474248

Epoch: 6| Step: 3
Training loss: 2.962285442067189
Validation loss: 2.4913471018918036

Epoch: 6| Step: 4
Training loss: 3.127455090292565
Validation loss: 2.4763707911352193

Epoch: 6| Step: 5
Training loss: 2.8632932405103646
Validation loss: 2.488572854255635

Epoch: 6| Step: 6
Training loss: 2.6306917155536707
Validation loss: 2.4825840435361273

Epoch: 6| Step: 7
Training loss: 2.414092424818318
Validation loss: 2.480877359919103

Epoch: 6| Step: 8
Training loss: 2.736276717319116
Validation loss: 2.485009171620896

Epoch: 6| Step: 9
Training loss: 2.1231160507934366
Validation loss: 2.491708388558679

Epoch: 6| Step: 10
Training loss: 1.7982418666461033
Validation loss: 2.4834849963386723

Epoch: 6| Step: 11
Training loss: 3.126312132976394
Validation loss: 2.4814845667679246

Epoch: 6| Step: 12
Training loss: 2.908857918750844
Validation loss: 2.482504931984889

Epoch: 6| Step: 13
Training loss: 3.1498104159509515
Validation loss: 2.4882074948734676

Epoch: 65| Step: 0
Training loss: 2.457435659534539
Validation loss: 2.4781705806742322

Epoch: 6| Step: 1
Training loss: 3.2685883870480406
Validation loss: 2.463124045710277

Epoch: 6| Step: 2
Training loss: 2.935026385369048
Validation loss: 2.482266561814571

Epoch: 6| Step: 3
Training loss: 2.574157065779825
Validation loss: 2.4919330370448596

Epoch: 6| Step: 4
Training loss: 3.067986381291647
Validation loss: 2.4956756651970866

Epoch: 6| Step: 5
Training loss: 2.4974978323040204
Validation loss: 2.490044340587322

Epoch: 6| Step: 6
Training loss: 3.269531833370617
Validation loss: 2.475404914414784

Epoch: 6| Step: 7
Training loss: 2.224029170627161
Validation loss: 2.4766994190160676

Epoch: 6| Step: 8
Training loss: 2.6824120553168704
Validation loss: 2.489111335350044

Epoch: 6| Step: 9
Training loss: 2.7910125497490057
Validation loss: 2.4798574094603363

Epoch: 6| Step: 10
Training loss: 2.585486243021611
Validation loss: 2.479195526801627

Epoch: 6| Step: 11
Training loss: 3.073985147870929
Validation loss: 2.4814764485949024

Epoch: 6| Step: 12
Training loss: 2.2386874750672434
Validation loss: 2.4903342642425828

Epoch: 6| Step: 13
Training loss: 2.1540299195714945
Validation loss: 2.4777559703168475

Epoch: 66| Step: 0
Training loss: 2.4224218920072484
Validation loss: 2.475090688073771

Epoch: 6| Step: 1
Training loss: 2.7633026199873414
Validation loss: 2.487632607808564

Epoch: 6| Step: 2
Training loss: 2.5612020229092707
Validation loss: 2.4992328738399494

Epoch: 6| Step: 3
Training loss: 2.160404349733101
Validation loss: 2.4848085916253715

Epoch: 6| Step: 4
Training loss: 2.9503588765275954
Validation loss: 2.4851643907721375

Epoch: 6| Step: 5
Training loss: 2.7040370218462497
Validation loss: 2.4919361686367103

Epoch: 6| Step: 6
Training loss: 3.248178411723218
Validation loss: 2.4891399320440404

Epoch: 6| Step: 7
Training loss: 2.629321220034745
Validation loss: 2.5028962760477684

Epoch: 6| Step: 8
Training loss: 2.2992340222187524
Validation loss: 2.5009851996056085

Epoch: 6| Step: 9
Training loss: 2.6791760370813447
Validation loss: 2.490160414168246

Epoch: 6| Step: 10
Training loss: 3.3963740255758705
Validation loss: 2.4862064734292812

Epoch: 6| Step: 11
Training loss: 3.0099576360312987
Validation loss: 2.491530702781299

Epoch: 6| Step: 12
Training loss: 2.3736694021739106
Validation loss: 2.4926985889961513

Epoch: 6| Step: 13
Training loss: 2.918991216130777
Validation loss: 2.487239893345564

Epoch: 67| Step: 0
Training loss: 2.5070685593398654
Validation loss: 2.4823888967532604

Epoch: 6| Step: 1
Training loss: 2.634449888275856
Validation loss: 2.4751769884984536

Epoch: 6| Step: 2
Training loss: 2.607396454990789
Validation loss: 2.482904598734707

Epoch: 6| Step: 3
Training loss: 2.595301703993857
Validation loss: 2.5064491254037926

Epoch: 6| Step: 4
Training loss: 2.7420068230297137
Validation loss: 2.479342768650003

Epoch: 6| Step: 5
Training loss: 2.4928853842610774
Validation loss: 2.476182678625745

Epoch: 6| Step: 6
Training loss: 2.2877208957432
Validation loss: 2.4785815579379507

Epoch: 6| Step: 7
Training loss: 2.835185474067487
Validation loss: 2.472651640399741

Epoch: 6| Step: 8
Training loss: 3.2064516238345484
Validation loss: 2.4962950982224688

Epoch: 6| Step: 9
Training loss: 2.4270558717235526
Validation loss: 2.48634188080108

Epoch: 6| Step: 10
Training loss: 2.6596689996354943
Validation loss: 2.490856190402311

Epoch: 6| Step: 11
Training loss: 3.0862374075489387
Validation loss: 2.4918718323578046

Epoch: 6| Step: 12
Training loss: 2.7380308289781126
Validation loss: 2.490071639120821

Epoch: 6| Step: 13
Training loss: 3.530146198433149
Validation loss: 2.4707166004798347

Epoch: 68| Step: 0
Training loss: 3.1397460922312876
Validation loss: 2.4951273398414258

Epoch: 6| Step: 1
Training loss: 2.2706200619094457
Validation loss: 2.4855589782203875

Epoch: 6| Step: 2
Training loss: 3.095987146868381
Validation loss: 2.4800978873216684

Epoch: 6| Step: 3
Training loss: 2.3808115077350767
Validation loss: 2.4751397450674033

Epoch: 6| Step: 4
Training loss: 2.4823840338751344
Validation loss: 2.47982699943957

Epoch: 6| Step: 5
Training loss: 2.346984767251629
Validation loss: 2.4851395461260757

Epoch: 6| Step: 6
Training loss: 2.9176219647303774
Validation loss: 2.492466865173089

Epoch: 6| Step: 7
Training loss: 2.6958881150525955
Validation loss: 2.4815057639797082

Epoch: 6| Step: 8
Training loss: 3.089039925862762
Validation loss: 2.4859973483251956

Epoch: 6| Step: 9
Training loss: 2.527801802338209
Validation loss: 2.4879128646776882

Epoch: 6| Step: 10
Training loss: 3.0529702279132063
Validation loss: 2.4912927784182877

Epoch: 6| Step: 11
Training loss: 2.707248871658179
Validation loss: 2.484266374075455

Epoch: 6| Step: 12
Training loss: 2.442160430387206
Validation loss: 2.4880863143668575

Epoch: 6| Step: 13
Training loss: 3.0095075314692625
Validation loss: 2.4875914615548127

Epoch: 69| Step: 0
Training loss: 2.1034588394363416
Validation loss: 2.4770647821064893

Epoch: 6| Step: 1
Training loss: 2.2869661385681948
Validation loss: 2.4960773467542796

Epoch: 6| Step: 2
Training loss: 3.364999436354342
Validation loss: 2.479108573113667

Epoch: 6| Step: 3
Training loss: 2.965899574745508
Validation loss: 2.4841440420694654

Epoch: 6| Step: 4
Training loss: 2.754976364975919
Validation loss: 2.4832119000741804

Epoch: 6| Step: 5
Training loss: 2.795173852252995
Validation loss: 2.4967747136109897

Epoch: 6| Step: 6
Training loss: 2.556967741320052
Validation loss: 2.4893045377863174

Epoch: 6| Step: 7
Training loss: 2.36077435155087
Validation loss: 2.4989028953718253

Epoch: 6| Step: 8
Training loss: 2.902293147060546
Validation loss: 2.488096461394857

Epoch: 6| Step: 9
Training loss: 3.147299283924675
Validation loss: 2.4826375306203166

Epoch: 6| Step: 10
Training loss: 2.8449915596513295
Validation loss: 2.491030940793174

Epoch: 6| Step: 11
Training loss: 2.0927598804171827
Validation loss: 2.4784647988264927

Epoch: 6| Step: 12
Training loss: 3.0478506237983174
Validation loss: 2.4905150195011605

Epoch: 6| Step: 13
Training loss: 2.5481115042633395
Validation loss: 2.4901266203313535

Epoch: 70| Step: 0
Training loss: 2.938669174945589
Validation loss: 2.499815942285135

Epoch: 6| Step: 1
Training loss: 2.9689750184562493
Validation loss: 2.498097904132499

Epoch: 6| Step: 2
Training loss: 2.4454534812968762
Validation loss: 2.4874917723849994

Epoch: 6| Step: 3
Training loss: 2.674381976170901
Validation loss: 2.4849916666522978

Epoch: 6| Step: 4
Training loss: 2.432460465928366
Validation loss: 2.482342327623516

Epoch: 6| Step: 5
Training loss: 2.3511005340719646
Validation loss: 2.4751929916705873

Epoch: 6| Step: 6
Training loss: 3.805634617660982
Validation loss: 2.482038550220407

Epoch: 6| Step: 7
Training loss: 2.749868910005856
Validation loss: 2.5000279583957083

Epoch: 6| Step: 8
Training loss: 2.6588459568974216
Validation loss: 2.4685253001072422

Epoch: 6| Step: 9
Training loss: 2.7689141149513037
Validation loss: 2.4762512303335154

Epoch: 6| Step: 10
Training loss: 2.6215175962496016
Validation loss: 2.4990941200980106

Epoch: 6| Step: 11
Training loss: 2.31992221208587
Validation loss: 2.4887757689133188

Epoch: 6| Step: 12
Training loss: 2.269347927023421
Validation loss: 2.4826512289071623

Epoch: 6| Step: 13
Training loss: 2.7756892130243624
Validation loss: 2.481844650968313

Epoch: 71| Step: 0
Training loss: 3.040832161192713
Validation loss: 2.489174481331127

Epoch: 6| Step: 1
Training loss: 2.7968060362427734
Validation loss: 2.465551295559697

Epoch: 6| Step: 2
Training loss: 2.5039246271324935
Validation loss: 2.488647366004202

Epoch: 6| Step: 3
Training loss: 2.7905582296109
Validation loss: 2.4879990778933427

Epoch: 6| Step: 4
Training loss: 2.1036986658334977
Validation loss: 2.487423061517282

Epoch: 6| Step: 5
Training loss: 1.9860453146444794
Validation loss: 2.484828858244549

Epoch: 6| Step: 6
Training loss: 2.8616835650073034
Validation loss: 2.484894394635202

Epoch: 6| Step: 7
Training loss: 2.8999417660884332
Validation loss: 2.473315008916102

Epoch: 6| Step: 8
Training loss: 2.5553323007819224
Validation loss: 2.4851595433829106

Epoch: 6| Step: 9
Training loss: 2.887640654866139
Validation loss: 2.480992787733627

Epoch: 6| Step: 10
Training loss: 3.2926390133232197
Validation loss: 2.4831900566917726

Epoch: 6| Step: 11
Training loss: 2.7292885692443303
Validation loss: 2.4785517813056175

Epoch: 6| Step: 12
Training loss: 2.8667826769516584
Validation loss: 2.4884493596478987

Epoch: 6| Step: 13
Training loss: 2.5833754279696084
Validation loss: 2.4988673967041857

Epoch: 72| Step: 0
Training loss: 2.7846365038415
Validation loss: 2.4836099222705155

Epoch: 6| Step: 1
Training loss: 3.1847091125168174
Validation loss: 2.4862809952605276

Epoch: 6| Step: 2
Training loss: 2.146812240371793
Validation loss: 2.491480873707796

Epoch: 6| Step: 3
Training loss: 2.841857280285847
Validation loss: 2.483334672867895

Epoch: 6| Step: 4
Training loss: 2.5952192075016227
Validation loss: 2.483886360092265

Epoch: 6| Step: 5
Training loss: 2.697726907034013
Validation loss: 2.4874495993554233

Epoch: 6| Step: 6
Training loss: 3.306116971835316
Validation loss: 2.4715237449040806

Epoch: 6| Step: 7
Training loss: 2.1125417039354986
Validation loss: 2.4814361145802377

Epoch: 6| Step: 8
Training loss: 3.002264439778319
Validation loss: 2.4758755030035844

Epoch: 6| Step: 9
Training loss: 2.3451750428481666
Validation loss: 2.476446846019678

Epoch: 6| Step: 10
Training loss: 2.7872309294019213
Validation loss: 2.4784159431526125

Epoch: 6| Step: 11
Training loss: 2.9054516752048527
Validation loss: 2.50698159481119

Epoch: 6| Step: 12
Training loss: 2.383521002825577
Validation loss: 2.4860787576220997

Epoch: 6| Step: 13
Training loss: 2.6704138614351924
Validation loss: 2.4831196213665296

Epoch: 73| Step: 0
Training loss: 3.3404591846619067
Validation loss: 2.488833124192647

Epoch: 6| Step: 1
Training loss: 3.1823773078611914
Validation loss: 2.4801144562073936

Epoch: 6| Step: 2
Training loss: 2.4845667351204495
Validation loss: 2.4724559245625097

Epoch: 6| Step: 3
Training loss: 2.1710998469181666
Validation loss: 2.482972554960963

Epoch: 6| Step: 4
Training loss: 2.494486642134627
Validation loss: 2.465855184361472

Epoch: 6| Step: 5
Training loss: 3.057602372159492
Validation loss: 2.4784527634273803

Epoch: 6| Step: 6
Training loss: 3.123338639191389
Validation loss: 2.4874327536480423

Epoch: 6| Step: 7
Training loss: 2.120838803307375
Validation loss: 2.493377505332248

Epoch: 6| Step: 8
Training loss: 2.6435005737673487
Validation loss: 2.4782592854987886

Epoch: 6| Step: 9
Training loss: 2.831913049796276
Validation loss: 2.4821415930595543

Epoch: 6| Step: 10
Training loss: 2.737707929683507
Validation loss: 2.486208881152875

Epoch: 6| Step: 11
Training loss: 2.253155720537036
Validation loss: 2.4831783761124755

Epoch: 6| Step: 12
Training loss: 2.7427633610087816
Validation loss: 2.4886824644874075

Epoch: 6| Step: 13
Training loss: 2.29701896787193
Validation loss: 2.4884710595104553

Epoch: 74| Step: 0
Training loss: 2.556800644939661
Validation loss: 2.472721150517596

Epoch: 6| Step: 1
Training loss: 2.9231386766976293
Validation loss: 2.486563582451024

Epoch: 6| Step: 2
Training loss: 2.5050738345474817
Validation loss: 2.4770778478107376

Epoch: 6| Step: 3
Training loss: 2.182351948369074
Validation loss: 2.4820272360595035

Epoch: 6| Step: 4
Training loss: 3.4102861482365383
Validation loss: 2.4916485375218698

Epoch: 6| Step: 5
Training loss: 2.54885431619685
Validation loss: 2.4733079895922567

Epoch: 6| Step: 6
Training loss: 3.3023657612803667
Validation loss: 2.4783643660233494

Epoch: 6| Step: 7
Training loss: 2.8713025075572904
Validation loss: 2.4938964857884534

Epoch: 6| Step: 8
Training loss: 2.7258577064381573
Validation loss: 2.477884213387365

Epoch: 6| Step: 9
Training loss: 2.725466794970777
Validation loss: 2.476547401097268

Epoch: 6| Step: 10
Training loss: 2.184829607851431
Validation loss: 2.4800039752375262

Epoch: 6| Step: 11
Training loss: 2.314766057101427
Validation loss: 2.484354869502738

Epoch: 6| Step: 12
Training loss: 3.185777834735574
Validation loss: 2.492102022158466

Epoch: 6| Step: 13
Training loss: 1.6318874385247195
Validation loss: 2.485486655441251

Epoch: 75| Step: 0
Training loss: 1.9170512007162466
Validation loss: 2.4941731125273807

Epoch: 6| Step: 1
Training loss: 2.6250984536735937
Validation loss: 2.483388697106236

Epoch: 6| Step: 2
Training loss: 2.7091507093964236
Validation loss: 2.4823659919589574

Epoch: 6| Step: 3
Training loss: 2.954364496304809
Validation loss: 2.4785984746624345

Epoch: 6| Step: 4
Training loss: 3.238273003985279
Validation loss: 2.475673839198363

Epoch: 6| Step: 5
Training loss: 2.9849910399847204
Validation loss: 2.4866722271010406

Epoch: 6| Step: 6
Training loss: 2.698138273311199
Validation loss: 2.4930521104010177

Epoch: 6| Step: 7
Training loss: 3.0249489645948278
Validation loss: 2.484229567214132

Epoch: 6| Step: 8
Training loss: 2.253827653965697
Validation loss: 2.4796649679912686

Epoch: 6| Step: 9
Training loss: 2.243789472737478
Validation loss: 2.4645954282160436

Epoch: 6| Step: 10
Training loss: 2.726163381313785
Validation loss: 2.484422267021228

Epoch: 6| Step: 11
Training loss: 2.6669975512578796
Validation loss: 2.4787278899128125

Epoch: 6| Step: 12
Training loss: 2.996968326965107
Validation loss: 2.480359172653471

Epoch: 6| Step: 13
Training loss: 2.486889795957748
Validation loss: 2.485457989380519

Epoch: 76| Step: 0
Training loss: 2.5798949668263544
Validation loss: 2.481679956919882

Epoch: 6| Step: 1
Training loss: 3.2845651500765904
Validation loss: 2.474046869339854

Epoch: 6| Step: 2
Training loss: 2.2123957162192442
Validation loss: 2.4773642803679516

Epoch: 6| Step: 3
Training loss: 3.032224832678653
Validation loss: 2.487340252242747

Epoch: 6| Step: 4
Training loss: 2.8144063634647605
Validation loss: 2.4911876520171394

Epoch: 6| Step: 5
Training loss: 2.4364797951377017
Validation loss: 2.482900262160488

Epoch: 6| Step: 6
Training loss: 2.4986823424224496
Validation loss: 2.4792884892553393

Epoch: 6| Step: 7
Training loss: 3.347472498512258
Validation loss: 2.4679132063377867

Epoch: 6| Step: 8
Training loss: 2.0077091888091294
Validation loss: 2.484854441088038

Epoch: 6| Step: 9
Training loss: 2.735537908404018
Validation loss: 2.477340326103008

Epoch: 6| Step: 10
Training loss: 2.377848272476902
Validation loss: 2.477438283799585

Epoch: 6| Step: 11
Training loss: 2.7376211897270197
Validation loss: 2.4807817009279964

Epoch: 6| Step: 12
Training loss: 3.0540844256130137
Validation loss: 2.4905984838915174

Epoch: 6| Step: 13
Training loss: 2.233391605395103
Validation loss: 2.474712831806814

Epoch: 77| Step: 0
Training loss: 3.165903568343915
Validation loss: 2.4712369953654685

Epoch: 6| Step: 1
Training loss: 2.3500444448610467
Validation loss: 2.4779154438896356

Epoch: 6| Step: 2
Training loss: 2.380061728694754
Validation loss: 2.4667353625765975

Epoch: 6| Step: 3
Training loss: 2.6473000933826576
Validation loss: 2.4739029589394286

Epoch: 6| Step: 4
Training loss: 2.915022213885563
Validation loss: 2.4882514127467013

Epoch: 6| Step: 5
Training loss: 2.557493296415879
Validation loss: 2.4784808811026258

Epoch: 6| Step: 6
Training loss: 2.4855644209867593
Validation loss: 2.4760673185502027

Epoch: 6| Step: 7
Training loss: 2.4545728942030918
Validation loss: 2.502313160048928

Epoch: 6| Step: 8
Training loss: 3.221241255405267
Validation loss: 2.4835819261457686

Epoch: 6| Step: 9
Training loss: 2.6231464926634684
Validation loss: 2.4849272846939336

Epoch: 6| Step: 10
Training loss: 3.019735272659403
Validation loss: 2.4843129878870536

Epoch: 6| Step: 11
Training loss: 2.7880603688899837
Validation loss: 2.4685523869303765

Epoch: 6| Step: 12
Training loss: 2.340618126404554
Validation loss: 2.4671631366912674

Epoch: 6| Step: 13
Training loss: 2.683971661607115
Validation loss: 2.4768236076397168

Epoch: 78| Step: 0
Training loss: 2.679391116108709
Validation loss: 2.4763701834486636

Epoch: 6| Step: 1
Training loss: 2.4533710720780846
Validation loss: 2.481077353096661

Epoch: 6| Step: 2
Training loss: 2.9966761931825583
Validation loss: 2.46813174120819

Epoch: 6| Step: 3
Training loss: 2.377082213107042
Validation loss: 2.4873291446281796

Epoch: 6| Step: 4
Training loss: 3.485770044617843
Validation loss: 2.4706821837488837

Epoch: 6| Step: 5
Training loss: 2.7274205297820973
Validation loss: 2.4863034755194207

Epoch: 6| Step: 6
Training loss: 2.509585980468786
Validation loss: 2.4831190937960925

Epoch: 6| Step: 7
Training loss: 2.6334830768679534
Validation loss: 2.4758531185849324

Epoch: 6| Step: 8
Training loss: 2.009625636675886
Validation loss: 2.460340966609717

Epoch: 6| Step: 9
Training loss: 2.7463341468000806
Validation loss: 2.477265066521087

Epoch: 6| Step: 10
Training loss: 2.9189134572429554
Validation loss: 2.4735831680330658

Epoch: 6| Step: 11
Training loss: 2.265999177749094
Validation loss: 2.478205258577672

Epoch: 6| Step: 12
Training loss: 3.0974576677165255
Validation loss: 2.4709810783409525

Epoch: 6| Step: 13
Training loss: 2.532550618907567
Validation loss: 2.4817683994391593

Epoch: 79| Step: 0
Training loss: 2.177410727772092
Validation loss: 2.4795414272636758

Epoch: 6| Step: 1
Training loss: 3.0081973931902284
Validation loss: 2.4834918062505946

Epoch: 6| Step: 2
Training loss: 2.985973469324414
Validation loss: 2.4744341269161345

Epoch: 6| Step: 3
Training loss: 2.8080144929484683
Validation loss: 2.4789191874196703

Epoch: 6| Step: 4
Training loss: 2.4865717742275226
Validation loss: 2.464277732486478

Epoch: 6| Step: 5
Training loss: 2.6541577345509646
Validation loss: 2.4765649367675304

Epoch: 6| Step: 6
Training loss: 2.635805505908588
Validation loss: 2.4865628488962526

Epoch: 6| Step: 7
Training loss: 3.416606034151807
Validation loss: 2.4640136317299

Epoch: 6| Step: 8
Training loss: 2.240977316255168
Validation loss: 2.489597092086442

Epoch: 6| Step: 9
Training loss: 2.83650626371927
Validation loss: 2.468033986474189

Epoch: 6| Step: 10
Training loss: 2.843782026508789
Validation loss: 2.4688016076883548

Epoch: 6| Step: 11
Training loss: 2.541300471039669
Validation loss: 2.474100209406377

Epoch: 6| Step: 12
Training loss: 2.644653858402214
Validation loss: 2.472871927383509

Epoch: 6| Step: 13
Training loss: 1.960652790450241
Validation loss: 2.4838505900446974

Epoch: 80| Step: 0
Training loss: 2.6099107386500218
Validation loss: 2.4772582663986595

Epoch: 6| Step: 1
Training loss: 2.744668126568311
Validation loss: 2.485410390323224

Epoch: 6| Step: 2
Training loss: 3.121452759683
Validation loss: 2.4770726027012597

Epoch: 6| Step: 3
Training loss: 2.7482354832108546
Validation loss: 2.4718693680581953

Epoch: 6| Step: 4
Training loss: 3.1087701103685834
Validation loss: 2.4662473440932744

Epoch: 6| Step: 5
Training loss: 2.142495444970647
Validation loss: 2.4678763695726946

Epoch: 6| Step: 6
Training loss: 2.994996507798644
Validation loss: 2.4750064842310713

Epoch: 6| Step: 7
Training loss: 2.9489498596896113
Validation loss: 2.4790352772487436

Epoch: 6| Step: 8
Training loss: 2.757989375248196
Validation loss: 2.4750065639885697

Epoch: 6| Step: 9
Training loss: 2.8304406901986874
Validation loss: 2.4675376545677485

Epoch: 6| Step: 10
Training loss: 2.639076456018364
Validation loss: 2.4721181958308502

Epoch: 6| Step: 11
Training loss: 2.718857160188325
Validation loss: 2.4895927414261747

Epoch: 6| Step: 12
Training loss: 1.894234986097594
Validation loss: 2.4794254779713003

Epoch: 6| Step: 13
Training loss: 1.9361570072191987
Validation loss: 2.4709687465959234

Epoch: 81| Step: 0
Training loss: 3.1570015191988934
Validation loss: 2.476626708127191

Epoch: 6| Step: 1
Training loss: 3.281720082352176
Validation loss: 2.4736511740985105

Epoch: 6| Step: 2
Training loss: 2.124521089330202
Validation loss: 2.485071429423588

Epoch: 6| Step: 3
Training loss: 2.5138620395057907
Validation loss: 2.469747491093584

Epoch: 6| Step: 4
Training loss: 2.14116411311881
Validation loss: 2.4837704835816425

Epoch: 6| Step: 5
Training loss: 3.1257262339728498
Validation loss: 2.4696672510524174

Epoch: 6| Step: 6
Training loss: 2.3136696821437774
Validation loss: 2.476081008146817

Epoch: 6| Step: 7
Training loss: 2.71897817070782
Validation loss: 2.490929861956409

Epoch: 6| Step: 8
Training loss: 3.1455243361002667
Validation loss: 2.478216698806947

Epoch: 6| Step: 9
Training loss: 2.8312071133832775
Validation loss: 2.4624754101025363

Epoch: 6| Step: 10
Training loss: 2.318047750815551
Validation loss: 2.4671957685172305

Epoch: 6| Step: 11
Training loss: 2.4354066907832292
Validation loss: 2.4844540798639216

Epoch: 6| Step: 12
Training loss: 2.4604861859850664
Validation loss: 2.4698934745709757

Epoch: 6| Step: 13
Training loss: 2.6601210268352244
Validation loss: 2.4680917427462434

Epoch: 82| Step: 0
Training loss: 2.441398828113719
Validation loss: 2.467855829209383

Epoch: 6| Step: 1
Training loss: 2.2904450599594988
Validation loss: 2.48342231371669

Epoch: 6| Step: 2
Training loss: 3.12814904812497
Validation loss: 2.474311505137182

Epoch: 6| Step: 3
Training loss: 3.2228286234676946
Validation loss: 2.461669893105679

Epoch: 6| Step: 4
Training loss: 2.862504757539885
Validation loss: 2.491079042727374

Epoch: 6| Step: 5
Training loss: 2.666564035427501
Validation loss: 2.484562935934095

Epoch: 6| Step: 6
Training loss: 2.1407760232708894
Validation loss: 2.4748312404420023

Epoch: 6| Step: 7
Training loss: 2.5545496538868813
Validation loss: 2.496111905805453

Epoch: 6| Step: 8
Training loss: 2.9252868968102774
Validation loss: 2.4841050914435665

Epoch: 6| Step: 9
Training loss: 2.7284799735949306
Validation loss: 2.487829750199154

Epoch: 6| Step: 10
Training loss: 2.3284122366655264
Validation loss: 2.4923254471152796

Epoch: 6| Step: 11
Training loss: 2.758220437112634
Validation loss: 2.4765438266623514

Epoch: 6| Step: 12
Training loss: 2.6411922229345577
Validation loss: 2.4855330668997118

Epoch: 6| Step: 13
Training loss: 3.0350324490114984
Validation loss: 2.4717095194346794

Epoch: 83| Step: 0
Training loss: 2.731417555219618
Validation loss: 2.469652638364827

Epoch: 6| Step: 1
Training loss: 2.1863210498394765
Validation loss: 2.4683442743592656

Epoch: 6| Step: 2
Training loss: 3.110745075430709
Validation loss: 2.480597833593755

Epoch: 6| Step: 3
Training loss: 3.1865256821264696
Validation loss: 2.476370995077693

Epoch: 6| Step: 4
Training loss: 2.976209724727329
Validation loss: 2.4718484973597725

Epoch: 6| Step: 5
Training loss: 2.3674006098636977
Validation loss: 2.4771417134758176

Epoch: 6| Step: 6
Training loss: 2.8682214187638415
Validation loss: 2.4820493954056526

Epoch: 6| Step: 7
Training loss: 2.0812949190075094
Validation loss: 2.4678591056233055

Epoch: 6| Step: 8
Training loss: 2.4600661899997096
Validation loss: 2.481174718445725

Epoch: 6| Step: 9
Training loss: 2.6229917928063355
Validation loss: 2.482762849753837

Epoch: 6| Step: 10
Training loss: 2.4893989867161666
Validation loss: 2.481110776805431

Epoch: 6| Step: 11
Training loss: 2.7237250749096185
Validation loss: 2.48074624884286

Epoch: 6| Step: 12
Training loss: 2.97415343990219
Validation loss: 2.4891499898080593

Epoch: 6| Step: 13
Training loss: 2.714253093767261
Validation loss: 2.481180780437701

Epoch: 84| Step: 0
Training loss: 3.1289800094692524
Validation loss: 2.4780984840060176

Epoch: 6| Step: 1
Training loss: 2.646797505114635
Validation loss: 2.4707013735038843

Epoch: 6| Step: 2
Training loss: 2.497493345540053
Validation loss: 2.4731078859135787

Epoch: 6| Step: 3
Training loss: 2.3001661530892994
Validation loss: 2.4834503116407607

Epoch: 6| Step: 4
Training loss: 2.389886081167266
Validation loss: 2.4864938865642503

Epoch: 6| Step: 5
Training loss: 3.327951775999235
Validation loss: 2.486241921896821

Epoch: 6| Step: 6
Training loss: 2.310699586827852
Validation loss: 2.468162144716075

Epoch: 6| Step: 7
Training loss: 2.110690462578727
Validation loss: 2.472184800774297

Epoch: 6| Step: 8
Training loss: 2.6219908405670638
Validation loss: 2.4789618820057298

Epoch: 6| Step: 9
Training loss: 2.965790407735305
Validation loss: 2.480460939596106

Epoch: 6| Step: 10
Training loss: 2.940730489689302
Validation loss: 2.4764696443276346

Epoch: 6| Step: 11
Training loss: 2.621494586613763
Validation loss: 2.4906360818404827

Epoch: 6| Step: 12
Training loss: 2.7948003138691457
Validation loss: 2.4889000069721607

Epoch: 6| Step: 13
Training loss: 2.9002434792745775
Validation loss: 2.469183562216869

Epoch: 85| Step: 0
Training loss: 3.7470999630293518
Validation loss: 2.4828933840284875

Epoch: 6| Step: 1
Training loss: 2.3148152900977883
Validation loss: 2.483401021374209

Epoch: 6| Step: 2
Training loss: 2.230105609360271
Validation loss: 2.481622883627206

Epoch: 6| Step: 3
Training loss: 2.639387213073267
Validation loss: 2.486403692808223

Epoch: 6| Step: 4
Training loss: 2.679835991039991
Validation loss: 2.475124052279763

Epoch: 6| Step: 5
Training loss: 3.0163519580996905
Validation loss: 2.483258157896986

Epoch: 6| Step: 6
Training loss: 2.7130183168574
Validation loss: 2.4825328173672667

Epoch: 6| Step: 7
Training loss: 2.518333824741695
Validation loss: 2.474080439319156

Epoch: 6| Step: 8
Training loss: 2.6652902587506513
Validation loss: 2.4842294495699973

Epoch: 6| Step: 9
Training loss: 2.6806999940670195
Validation loss: 2.477536745687259

Epoch: 6| Step: 10
Training loss: 2.6294646669064177
Validation loss: 2.487791024733754

Epoch: 6| Step: 11
Training loss: 1.767072371317149
Validation loss: 2.47854439928092

Epoch: 6| Step: 12
Training loss: 2.830619933902303
Validation loss: 2.4868290599090495

Epoch: 6| Step: 13
Training loss: 2.8067808706859507
Validation loss: 2.4889232103404098

Epoch: 86| Step: 0
Training loss: 2.375946458656393
Validation loss: 2.469152047880723

Epoch: 6| Step: 1
Training loss: 2.7869097097476345
Validation loss: 2.4749413991839213

Epoch: 6| Step: 2
Training loss: 2.833175617391109
Validation loss: 2.4737788568666867

Epoch: 6| Step: 3
Training loss: 2.5294931225144976
Validation loss: 2.47007432295222

Epoch: 6| Step: 4
Training loss: 3.089948688562517
Validation loss: 2.4919875883182674

Epoch: 6| Step: 5
Training loss: 2.3963297675143322
Validation loss: 2.4846645410167647

Epoch: 6| Step: 6
Training loss: 2.405454033326206
Validation loss: 2.481397296565762

Epoch: 6| Step: 7
Training loss: 2.7699218818859292
Validation loss: 2.4796646857459077

Epoch: 6| Step: 8
Training loss: 2.7627184406066196
Validation loss: 2.464802856740541

Epoch: 6| Step: 9
Training loss: 2.38324991182459
Validation loss: 2.478515257807442

Epoch: 6| Step: 10
Training loss: 2.790711500444096
Validation loss: 2.4787135349070133

Epoch: 6| Step: 11
Training loss: 3.094859223006677
Validation loss: 2.489655240891526

Epoch: 6| Step: 12
Training loss: 2.969474944895858
Validation loss: 2.4797957402870243

Epoch: 6| Step: 13
Training loss: 1.7907785239988168
Validation loss: 2.4728515518840455

Epoch: 87| Step: 0
Training loss: 1.6206507065893485
Validation loss: 2.478739751256045

Epoch: 6| Step: 1
Training loss: 2.6278301604329948
Validation loss: 2.4864807759990324

Epoch: 6| Step: 2
Training loss: 3.0889787970371247
Validation loss: 2.456901848555448

Epoch: 6| Step: 3
Training loss: 2.77012173877464
Validation loss: 2.46736410381068

Epoch: 6| Step: 4
Training loss: 2.406431909596127
Validation loss: 2.4732129966535616

Epoch: 6| Step: 5
Training loss: 2.447415650953118
Validation loss: 2.4683546219831287

Epoch: 6| Step: 6
Training loss: 3.226784021933687
Validation loss: 2.471178686004828

Epoch: 6| Step: 7
Training loss: 2.0807755854604646
Validation loss: 2.470669785141318

Epoch: 6| Step: 8
Training loss: 2.481156189343829
Validation loss: 2.476586368624724

Epoch: 6| Step: 9
Training loss: 2.9408842031335123
Validation loss: 2.482178475293509

Epoch: 6| Step: 10
Training loss: 2.3770070880917413
Validation loss: 2.4673929437200957

Epoch: 6| Step: 11
Training loss: 2.7937541577609055
Validation loss: 2.4717657180793657

Epoch: 6| Step: 12
Training loss: 3.450945550463053
Validation loss: 2.4637350104390174

Epoch: 6| Step: 13
Training loss: 2.607914498758906
Validation loss: 2.4750496409486424

Epoch: 88| Step: 0
Training loss: 2.5130998720906517
Validation loss: 2.4809349752973624

Epoch: 6| Step: 1
Training loss: 2.324331995665468
Validation loss: 2.466403937323188

Epoch: 6| Step: 2
Training loss: 2.8477791549051523
Validation loss: 2.465438243498951

Epoch: 6| Step: 3
Training loss: 2.5518061169425814
Validation loss: 2.4734626256986934

Epoch: 6| Step: 4
Training loss: 2.9868374397069806
Validation loss: 2.483325418973233

Epoch: 6| Step: 5
Training loss: 2.480000032609509
Validation loss: 2.4679318722634167

Epoch: 6| Step: 6
Training loss: 2.8136622252769503
Validation loss: 2.4789283160812006

Epoch: 6| Step: 7
Training loss: 2.8521284821983888
Validation loss: 2.466552111147615

Epoch: 6| Step: 8
Training loss: 3.325337420100332
Validation loss: 2.4631978618709756

Epoch: 6| Step: 9
Training loss: 2.476505122437658
Validation loss: 2.4681275521402872

Epoch: 6| Step: 10
Training loss: 2.9286008727025674
Validation loss: 2.4676875581064506

Epoch: 6| Step: 11
Training loss: 2.6225731848731826
Validation loss: 2.4777743065338833

Epoch: 6| Step: 12
Training loss: 2.273325075076738
Validation loss: 2.4691705788117786

Epoch: 6| Step: 13
Training loss: 2.03058554712294
Validation loss: 2.46878440628386

Epoch: 89| Step: 0
Training loss: 2.0538065947468103
Validation loss: 2.4670902226811218

Epoch: 6| Step: 1
Training loss: 2.8916238244773744
Validation loss: 2.482023867829831

Epoch: 6| Step: 2
Training loss: 2.7844867516899616
Validation loss: 2.467914882942365

Epoch: 6| Step: 3
Training loss: 2.092790526134734
Validation loss: 2.4740431099546107

Epoch: 6| Step: 4
Training loss: 2.567580420433422
Validation loss: 2.482498045012423

Epoch: 6| Step: 5
Training loss: 2.8045450243451433
Validation loss: 2.467524276531524

Epoch: 6| Step: 6
Training loss: 2.6198726714840204
Validation loss: 2.469815535304653

Epoch: 6| Step: 7
Training loss: 3.105979100163795
Validation loss: 2.4675564687857183

Epoch: 6| Step: 8
Training loss: 3.2540205515263514
Validation loss: 2.4597970669495055

Epoch: 6| Step: 9
Training loss: 2.7564719943307576
Validation loss: 2.47783356049551

Epoch: 6| Step: 10
Training loss: 2.689953238779226
Validation loss: 2.4824253604192825

Epoch: 6| Step: 11
Training loss: 2.257446048129896
Validation loss: 2.4786252859163795

Epoch: 6| Step: 12
Training loss: 2.411290821384465
Validation loss: 2.479248738001115

Epoch: 6| Step: 13
Training loss: 3.0330647807310886
Validation loss: 2.474747988069451

Epoch: 90| Step: 0
Training loss: 3.243667595612287
Validation loss: 2.4786902969866214

Epoch: 6| Step: 1
Training loss: 2.7178856363551995
Validation loss: 2.4895995541963742

Epoch: 6| Step: 2
Training loss: 2.2896480917920172
Validation loss: 2.4760042286384376

Epoch: 6| Step: 3
Training loss: 2.894733210839727
Validation loss: 2.4749590922853364

Epoch: 6| Step: 4
Training loss: 2.984326427124354
Validation loss: 2.479336193434739

Epoch: 6| Step: 5
Training loss: 3.071483592557607
Validation loss: 2.4735051615777226

Epoch: 6| Step: 6
Training loss: 2.571171208399793
Validation loss: 2.4773510345614627

Epoch: 6| Step: 7
Training loss: 2.103645738634896
Validation loss: 2.4866661594234416

Epoch: 6| Step: 8
Training loss: 1.857648673185288
Validation loss: 2.47802102419956

Epoch: 6| Step: 9
Training loss: 2.6522373183726886
Validation loss: 2.468524295847331

Epoch: 6| Step: 10
Training loss: 2.3986047941133415
Validation loss: 2.475758491494634

Epoch: 6| Step: 11
Training loss: 2.634492513585526
Validation loss: 2.464287580148309

Epoch: 6| Step: 12
Training loss: 2.4249382089824087
Validation loss: 2.485546314485516

Epoch: 6| Step: 13
Training loss: 3.2769060717878857
Validation loss: 2.478237612597117

Epoch: 91| Step: 0
Training loss: 3.3660334403903613
Validation loss: 2.4827281146962346

Epoch: 6| Step: 1
Training loss: 2.562776783207163
Validation loss: 2.483142048684792

Epoch: 6| Step: 2
Training loss: 2.1777591173622475
Validation loss: 2.470460321863884

Epoch: 6| Step: 3
Training loss: 2.998783977740612
Validation loss: 2.4680145121377244

Epoch: 6| Step: 4
Training loss: 1.9428339722397703
Validation loss: 2.477506304077328

Epoch: 6| Step: 5
Training loss: 3.349684538150862
Validation loss: 2.492536096285893

Epoch: 6| Step: 6
Training loss: 2.7759433654977417
Validation loss: 2.4727450427437834

Epoch: 6| Step: 7
Training loss: 2.0099298022713614
Validation loss: 2.471200277652469

Epoch: 6| Step: 8
Training loss: 3.195189233468168
Validation loss: 2.480126245281032

Epoch: 6| Step: 9
Training loss: 2.1967277987612817
Validation loss: 2.474611010808571

Epoch: 6| Step: 10
Training loss: 2.78002817125935
Validation loss: 2.4845797794309035

Epoch: 6| Step: 11
Training loss: 2.673529486352861
Validation loss: 2.478902096555472

Epoch: 6| Step: 12
Training loss: 2.3037154911993993
Validation loss: 2.4748509962445135

Epoch: 6| Step: 13
Training loss: 2.283745850474195
Validation loss: 2.4738188483526637

Epoch: 92| Step: 0
Training loss: 2.823532422089842
Validation loss: 2.479676754032595

Epoch: 6| Step: 1
Training loss: 2.7418414383889163
Validation loss: 2.4709040023685005

Epoch: 6| Step: 2
Training loss: 2.5664961754127362
Validation loss: 2.4752584636707047

Epoch: 6| Step: 3
Training loss: 2.4640049784349953
Validation loss: 2.4699360890419393

Epoch: 6| Step: 4
Training loss: 3.0131025289517757
Validation loss: 2.484276094000886

Epoch: 6| Step: 5
Training loss: 3.080493615959746
Validation loss: 2.4698004875365185

Epoch: 6| Step: 6
Training loss: 2.9804252331357852
Validation loss: 2.4794038193994195

Epoch: 6| Step: 7
Training loss: 2.5604461254373407
Validation loss: 2.4813883205947813

Epoch: 6| Step: 8
Training loss: 2.6468585773845787
Validation loss: 2.4703711891180475

Epoch: 6| Step: 9
Training loss: 2.2536917176118445
Validation loss: 2.491705142475987

Epoch: 6| Step: 10
Training loss: 1.748879755317549
Validation loss: 2.467735765480137

Epoch: 6| Step: 11
Training loss: 2.8621204307803905
Validation loss: 2.4714195633285247

Epoch: 6| Step: 12
Training loss: 2.5000349996024176
Validation loss: 2.4807315060992208

Epoch: 6| Step: 13
Training loss: 2.9005589702827783
Validation loss: 2.4764131155675857

Epoch: 93| Step: 0
Training loss: 2.7302066966467566
Validation loss: 2.468754390506519

Epoch: 6| Step: 1
Training loss: 2.761954333928477
Validation loss: 2.4668757202350577

Epoch: 6| Step: 2
Training loss: 2.6844906481165918
Validation loss: 2.477663846413701

Epoch: 6| Step: 3
Training loss: 2.4111677177315984
Validation loss: 2.4563981868068496

Epoch: 6| Step: 4
Training loss: 2.4143850364150583
Validation loss: 2.473892403432743

Epoch: 6| Step: 5
Training loss: 2.6133362631716492
Validation loss: 2.4777064643362836

Epoch: 6| Step: 6
Training loss: 2.48633416617859
Validation loss: 2.470232978047238

Epoch: 6| Step: 7
Training loss: 3.0147852543763185
Validation loss: 2.479041341369911

Epoch: 6| Step: 8
Training loss: 2.8863070843562504
Validation loss: 2.4835067555779284

Epoch: 6| Step: 9
Training loss: 2.768314067200144
Validation loss: 2.4796721771265333

Epoch: 6| Step: 10
Training loss: 2.488735187511345
Validation loss: 2.4811647735231106

Epoch: 6| Step: 11
Training loss: 3.285614308322972
Validation loss: 2.4746167470077896

Epoch: 6| Step: 12
Training loss: 2.2396438472172155
Validation loss: 2.472895129786857

Epoch: 6| Step: 13
Training loss: 2.049845280274876
Validation loss: 2.4547298227826375

Epoch: 94| Step: 0
Training loss: 2.2412320005137696
Validation loss: 2.4768322192553933

Epoch: 6| Step: 1
Training loss: 2.469630217266176
Validation loss: 2.4799582686917403

Epoch: 6| Step: 2
Training loss: 2.5942488041353258
Validation loss: 2.468184772344231

Epoch: 6| Step: 3
Training loss: 2.99795239824673
Validation loss: 2.4597081121785385

Epoch: 6| Step: 4
Training loss: 2.924439635764011
Validation loss: 2.474330499933622

Epoch: 6| Step: 5
Training loss: 2.0511371993920786
Validation loss: 2.476657038404278

Epoch: 6| Step: 6
Training loss: 2.6164795786394
Validation loss: 2.4639575392775925

Epoch: 6| Step: 7
Training loss: 2.5053778978938253
Validation loss: 2.463604661915319

Epoch: 6| Step: 8
Training loss: 3.0404910772613296
Validation loss: 2.4741887384364096

Epoch: 6| Step: 9
Training loss: 3.168534046165353
Validation loss: 2.4836380873624315

Epoch: 6| Step: 10
Training loss: 2.426011030091875
Validation loss: 2.4689639793032527

Epoch: 6| Step: 11
Training loss: 2.8415834327060145
Validation loss: 2.4673640477035996

Epoch: 6| Step: 12
Training loss: 2.0428187824005026
Validation loss: 2.4817804063632747

Epoch: 6| Step: 13
Training loss: 3.022512999349679
Validation loss: 2.4888233849821715

Epoch: 95| Step: 0
Training loss: 2.389307394505666
Validation loss: 2.481867732301629

Epoch: 6| Step: 1
Training loss: 3.133162253017764
Validation loss: 2.464307708122352

Epoch: 6| Step: 2
Training loss: 2.5966223932424946
Validation loss: 2.4696256684541584

Epoch: 6| Step: 3
Training loss: 2.9051199736253968
Validation loss: 2.483539921044388

Epoch: 6| Step: 4
Training loss: 2.12384057671912
Validation loss: 2.478038890841422

Epoch: 6| Step: 5
Training loss: 2.5579704632041786
Validation loss: 2.4742097650208206

Epoch: 6| Step: 6
Training loss: 2.7882911619959887
Validation loss: 2.4719754643163605

Epoch: 6| Step: 7
Training loss: 2.3466128348909625
Validation loss: 2.458230500515072

Epoch: 6| Step: 8
Training loss: 3.1679416565965366
Validation loss: 2.462488683351097

Epoch: 6| Step: 9
Training loss: 2.3870773420648757
Validation loss: 2.464226641777391

Epoch: 6| Step: 10
Training loss: 2.3291760830583663
Validation loss: 2.4588604249541444

Epoch: 6| Step: 11
Training loss: 2.671466729275553
Validation loss: 2.469480432170733

Epoch: 6| Step: 12
Training loss: 2.522056177903647
Validation loss: 2.475264047156745

Epoch: 6| Step: 13
Training loss: 3.5173171654571376
Validation loss: 2.4702990713407864

Epoch: 96| Step: 0
Training loss: 2.891773387540963
Validation loss: 2.469755607337558

Epoch: 6| Step: 1
Training loss: 2.8971365505030553
Validation loss: 2.479703672520586

Epoch: 6| Step: 2
Training loss: 2.335622402615388
Validation loss: 2.473645272948282

Epoch: 6| Step: 3
Training loss: 2.6103405108433746
Validation loss: 2.472136305277444

Epoch: 6| Step: 4
Training loss: 2.583709217740723
Validation loss: 2.4560994328984824

Epoch: 6| Step: 5
Training loss: 3.00070261674709
Validation loss: 2.4619336517360746

Epoch: 6| Step: 6
Training loss: 2.4615039960575773
Validation loss: 2.462308540228291

Epoch: 6| Step: 7
Training loss: 2.959016765757122
Validation loss: 2.4756106310430366

Epoch: 6| Step: 8
Training loss: 2.4536946601087894
Validation loss: 2.4672622694376596

Epoch: 6| Step: 9
Training loss: 2.147735703026546
Validation loss: 2.4785068351192616

Epoch: 6| Step: 10
Training loss: 2.8536864013536083
Validation loss: 2.467489910339286

Epoch: 6| Step: 11
Training loss: 2.5774527858254124
Validation loss: 2.4786815253079943

Epoch: 6| Step: 12
Training loss: 2.601944995518658
Validation loss: 2.4678982051429146

Epoch: 6| Step: 13
Training loss: 2.8390789864984645
Validation loss: 2.4813859123263247

Epoch: 97| Step: 0
Training loss: 2.1424907711724983
Validation loss: 2.4770789174267076

Epoch: 6| Step: 1
Training loss: 2.5681533788884843
Validation loss: 2.475918579859267

Epoch: 6| Step: 2
Training loss: 2.542342757892491
Validation loss: 2.4704096137823255

Epoch: 6| Step: 3
Training loss: 3.128225264338129
Validation loss: 2.486632347481534

Epoch: 6| Step: 4
Training loss: 3.6662552053607724
Validation loss: 2.476084654689737

Epoch: 6| Step: 5
Training loss: 2.197273871512303
Validation loss: 2.486916517823603

Epoch: 6| Step: 6
Training loss: 2.768895860537016
Validation loss: 2.4601025507644585

Epoch: 6| Step: 7
Training loss: 2.428205031717031
Validation loss: 2.4681500575202686

Epoch: 6| Step: 8
Training loss: 2.6664242832972267
Validation loss: 2.4697855715028707

Epoch: 6| Step: 9
Training loss: 3.0371790838061186
Validation loss: 2.4833132589893867

Epoch: 6| Step: 10
Training loss: 1.659993673105707
Validation loss: 2.4560497189861348

Epoch: 6| Step: 11
Training loss: 2.86169806162328
Validation loss: 2.4613120683851712

Epoch: 6| Step: 12
Training loss: 2.3473032147982393
Validation loss: 2.4627764920832607

Epoch: 6| Step: 13
Training loss: 2.4717583012673456
Validation loss: 2.4674395677178143

Epoch: 98| Step: 0
Training loss: 3.077549604671526
Validation loss: 2.4763631655380904

Epoch: 6| Step: 1
Training loss: 2.563055582992454
Validation loss: 2.462021257824232

Epoch: 6| Step: 2
Training loss: 1.9364724049117614
Validation loss: 2.4750686176508663

Epoch: 6| Step: 3
Training loss: 2.696054992131905
Validation loss: 2.4810357762573663

Epoch: 6| Step: 4
Training loss: 2.9611326772331115
Validation loss: 2.469574832677991

Epoch: 6| Step: 5
Training loss: 2.845740994192949
Validation loss: 2.482740564604647

Epoch: 6| Step: 6
Training loss: 3.000189139443799
Validation loss: 2.46380655296847

Epoch: 6| Step: 7
Training loss: 2.516154736962605
Validation loss: 2.474351494230794

Epoch: 6| Step: 8
Training loss: 2.641161260382396
Validation loss: 2.467760131903433

Epoch: 6| Step: 9
Training loss: 2.6411053824381563
Validation loss: 2.471903126806031

Epoch: 6| Step: 10
Training loss: 2.7110623817372588
Validation loss: 2.4781848979630334

Epoch: 6| Step: 11
Training loss: 1.9724112481286413
Validation loss: 2.462580929385079

Epoch: 6| Step: 12
Training loss: 2.7759954986645705
Validation loss: 2.465797845118154

Epoch: 6| Step: 13
Training loss: 2.3667745198492436
Validation loss: 2.471381006028434

Epoch: 99| Step: 0
Training loss: 2.540234855547394
Validation loss: 2.4829597675578294

Epoch: 6| Step: 1
Training loss: 2.864815960310574
Validation loss: 2.47141914010396

Epoch: 6| Step: 2
Training loss: 3.0871432882109313
Validation loss: 2.4641301184353224

Epoch: 6| Step: 3
Training loss: 3.2320356524361182
Validation loss: 2.467094975681585

Epoch: 6| Step: 4
Training loss: 2.239373331795959
Validation loss: 2.485361351417627

Epoch: 6| Step: 5
Training loss: 2.1526222118104665
Validation loss: 2.4773490145697497

Epoch: 6| Step: 6
Training loss: 2.3678412714933628
Validation loss: 2.4659916484043864

Epoch: 6| Step: 7
Training loss: 2.819086627355857
Validation loss: 2.460036891119065

Epoch: 6| Step: 8
Training loss: 3.0846302981942726
Validation loss: 2.464278181905242

Epoch: 6| Step: 9
Training loss: 2.6883112547934114
Validation loss: 2.48963849969423

Epoch: 6| Step: 10
Training loss: 2.323597031473584
Validation loss: 2.45806997302249

Epoch: 6| Step: 11
Training loss: 2.104622014194434
Validation loss: 2.462047523840366

Epoch: 6| Step: 12
Training loss: 2.368631759550968
Validation loss: 2.4765359635084785

Epoch: 6| Step: 13
Training loss: 2.770960601713781
Validation loss: 2.4636624595903003

Epoch: 100| Step: 0
Training loss: 2.9147747079672497
Validation loss: 2.467655307306359

Epoch: 6| Step: 1
Training loss: 2.3913255051668263
Validation loss: 2.478804989956284

Epoch: 6| Step: 2
Training loss: 2.7942099207590525
Validation loss: 2.479687045061816

Epoch: 6| Step: 3
Training loss: 3.1702762577247063
Validation loss: 2.469579329679246

Epoch: 6| Step: 4
Training loss: 2.0725285024489133
Validation loss: 2.4705150281836965

Epoch: 6| Step: 5
Training loss: 2.3713499430426044
Validation loss: 2.47186847457376

Epoch: 6| Step: 6
Training loss: 3.053378475916063
Validation loss: 2.469698176475099

Epoch: 6| Step: 7
Training loss: 2.787749678715648
Validation loss: 2.474487954892747

Epoch: 6| Step: 8
Training loss: 2.417869750724742
Validation loss: 2.461951900658256

Epoch: 6| Step: 9
Training loss: 2.810246476057762
Validation loss: 2.463883446215811

Epoch: 6| Step: 10
Training loss: 2.5380357749828457
Validation loss: 2.467000232958643

Epoch: 6| Step: 11
Training loss: 2.613934217225059
Validation loss: 2.4866997358510745

Epoch: 6| Step: 12
Training loss: 2.1316906560164863
Validation loss: 2.4841127304274697

Epoch: 6| Step: 13
Training loss: 2.7028774081933356
Validation loss: 2.465632013965237

Epoch: 101| Step: 0
Training loss: 2.515945887979842
Validation loss: 2.4708074550673844

Epoch: 6| Step: 1
Training loss: 2.672628642198602
Validation loss: 2.486967558345924

Epoch: 6| Step: 2
Training loss: 2.9940699141601397
Validation loss: 2.4717760773091353

Epoch: 6| Step: 3
Training loss: 2.3273875457443562
Validation loss: 2.4557682299973536

Epoch: 6| Step: 4
Training loss: 2.753873351421402
Validation loss: 2.4657940055770267

Epoch: 6| Step: 5
Training loss: 2.7748107948754233
Validation loss: 2.4665893491297117

Epoch: 6| Step: 6
Training loss: 2.550674973708466
Validation loss: 2.4795250137731233

Epoch: 6| Step: 7
Training loss: 2.084863164605921
Validation loss: 2.470259676687879

Epoch: 6| Step: 8
Training loss: 2.854110624408217
Validation loss: 2.4722729789436784

Epoch: 6| Step: 9
Training loss: 2.6532632528887214
Validation loss: 2.4798693796337674

Epoch: 6| Step: 10
Training loss: 2.426869613558961
Validation loss: 2.4834357800535405

Epoch: 6| Step: 11
Training loss: 2.602672260017847
Validation loss: 2.460365944969298

Epoch: 6| Step: 12
Training loss: 3.0390210774008657
Validation loss: 2.4569178298989005

Epoch: 6| Step: 13
Training loss: 2.7455999546311114
Validation loss: 2.4696676683488965

Epoch: 102| Step: 0
Training loss: 2.290198763421324
Validation loss: 2.4581983482992165

Epoch: 6| Step: 1
Training loss: 2.2672773978289587
Validation loss: 2.4731135716957486

Epoch: 6| Step: 2
Training loss: 2.391316432319232
Validation loss: 2.4640160236837776

Epoch: 6| Step: 3
Training loss: 2.6708306842697582
Validation loss: 2.4565390568238925

Epoch: 6| Step: 4
Training loss: 2.1761048108902603
Validation loss: 2.4591410210211198

Epoch: 6| Step: 5
Training loss: 2.8174064225343045
Validation loss: 2.4708752013648674

Epoch: 6| Step: 6
Training loss: 3.3743500260264243
Validation loss: 2.4760256342874203

Epoch: 6| Step: 7
Training loss: 3.1193052665239676
Validation loss: 2.4668063426305165

Epoch: 6| Step: 8
Training loss: 2.446507950848403
Validation loss: 2.4715237490531656

Epoch: 6| Step: 9
Training loss: 2.395953852621457
Validation loss: 2.471909240574283

Epoch: 6| Step: 10
Training loss: 2.6562370748766417
Validation loss: 2.4688871529112615

Epoch: 6| Step: 11
Training loss: 2.939067016792781
Validation loss: 2.466860258586709

Epoch: 6| Step: 12
Training loss: 2.8840312914162642
Validation loss: 2.479792186041536

Epoch: 6| Step: 13
Training loss: 1.8376682645607532
Validation loss: 2.457742080444753

Epoch: 103| Step: 0
Training loss: 2.488183323536648
Validation loss: 2.4552602938326795

Epoch: 6| Step: 1
Training loss: 2.4672640420782934
Validation loss: 2.475600808229551

Epoch: 6| Step: 2
Training loss: 3.105323029943953
Validation loss: 2.4629113327211956

Epoch: 6| Step: 3
Training loss: 2.7512376774430054
Validation loss: 2.4750833941252934

Epoch: 6| Step: 4
Training loss: 3.020689037866819
Validation loss: 2.4749912422152014

Epoch: 6| Step: 5
Training loss: 2.4714066902155913
Validation loss: 2.4640578268386077

Epoch: 6| Step: 6
Training loss: 2.8696300278759295
Validation loss: 2.485035392735491

Epoch: 6| Step: 7
Training loss: 2.2235442467677555
Validation loss: 2.4808817434304142

Epoch: 6| Step: 8
Training loss: 3.656410539803141
Validation loss: 2.4793824408478957

Epoch: 6| Step: 9
Training loss: 2.582544134451603
Validation loss: 2.483524548690525

Epoch: 6| Step: 10
Training loss: 2.109686256332607
Validation loss: 2.464743854300416

Epoch: 6| Step: 11
Training loss: 2.3415649401016787
Validation loss: 2.4663167311857035

Epoch: 6| Step: 12
Training loss: 2.097048083465822
Validation loss: 2.4701490797954238

Epoch: 6| Step: 13
Training loss: 2.1683747332425383
Validation loss: 2.465052228823292

Epoch: 104| Step: 0
Training loss: 2.360786672504259
Validation loss: 2.4603349147480746

Epoch: 6| Step: 1
Training loss: 3.2157196297915585
Validation loss: 2.4880098198169103

Epoch: 6| Step: 2
Training loss: 3.238889482940509
Validation loss: 2.4704950286105727

Epoch: 6| Step: 3
Training loss: 3.281653097914786
Validation loss: 2.467568734468997

Epoch: 6| Step: 4
Training loss: 2.4155281827210744
Validation loss: 2.4673974208008556

Epoch: 6| Step: 5
Training loss: 1.8031442492431078
Validation loss: 2.4767044889486094

Epoch: 6| Step: 6
Training loss: 2.5830379030028983
Validation loss: 2.464808992280852

Epoch: 6| Step: 7
Training loss: 2.0209572219889096
Validation loss: 2.4713108503233165

Epoch: 6| Step: 8
Training loss: 2.115374136945475
Validation loss: 2.4767020419673558

Epoch: 6| Step: 9
Training loss: 2.40835815821682
Validation loss: 2.458502210097096

Epoch: 6| Step: 10
Training loss: 2.226212537601305
Validation loss: 2.480274692883594

Epoch: 6| Step: 11
Training loss: 2.8461769563049946
Validation loss: 2.4734769039057274

Epoch: 6| Step: 12
Training loss: 3.0620376860768044
Validation loss: 2.4499317404534384

Epoch: 6| Step: 13
Training loss: 2.7412718197727806
Validation loss: 2.458662865773242

Epoch: 105| Step: 0
Training loss: 2.6662506335293945
Validation loss: 2.4797446219310455

Epoch: 6| Step: 1
Training loss: 2.2136897018896846
Validation loss: 2.4814073758977893

Epoch: 6| Step: 2
Training loss: 2.499278727435111
Validation loss: 2.4731215597570566

Epoch: 6| Step: 3
Training loss: 2.0085368352754815
Validation loss: 2.4664151007168638

Epoch: 6| Step: 4
Training loss: 2.6519507227903762
Validation loss: 2.4564583592393623

Epoch: 6| Step: 5
Training loss: 2.422760635385698
Validation loss: 2.4575900071074197

Epoch: 6| Step: 6
Training loss: 3.2677354335826516
Validation loss: 2.4724207450402313

Epoch: 6| Step: 7
Training loss: 2.2054346842065558
Validation loss: 2.466284672953399

Epoch: 6| Step: 8
Training loss: 2.5101369382731007
Validation loss: 2.4706732041291977

Epoch: 6| Step: 9
Training loss: 3.2261205929413417
Validation loss: 2.476716023575783

Epoch: 6| Step: 10
Training loss: 2.435380258497429
Validation loss: 2.468831052808662

Epoch: 6| Step: 11
Training loss: 2.976699625696401
Validation loss: 2.4678105916065003

Epoch: 6| Step: 12
Training loss: 2.3471839670929966
Validation loss: 2.446153365321479

Epoch: 6| Step: 13
Training loss: 3.2930424547375052
Validation loss: 2.45154883478285

Epoch: 106| Step: 0
Training loss: 2.1692464826361246
Validation loss: 2.456822289844072

Epoch: 6| Step: 1
Training loss: 2.7894338152251406
Validation loss: 2.4711236743272464

Epoch: 6| Step: 2
Training loss: 2.775743154730847
Validation loss: 2.448382579177216

Epoch: 6| Step: 3
Training loss: 2.8652037532446837
Validation loss: 2.4726739169443515

Epoch: 6| Step: 4
Training loss: 1.8678992921814097
Validation loss: 2.4501237586245175

Epoch: 6| Step: 5
Training loss: 2.2892271640126434
Validation loss: 2.45887105020355

Epoch: 6| Step: 6
Training loss: 2.766334227233343
Validation loss: 2.477970031660688

Epoch: 6| Step: 7
Training loss: 2.6156859688164746
Validation loss: 2.4643284725956094

Epoch: 6| Step: 8
Training loss: 2.0958225753032815
Validation loss: 2.455409725858306

Epoch: 6| Step: 9
Training loss: 2.2057969144094858
Validation loss: 2.445704712050026

Epoch: 6| Step: 10
Training loss: 3.1672145637217834
Validation loss: 2.474819301838228

Epoch: 6| Step: 11
Training loss: 2.592461507248457
Validation loss: 2.4805133226785814

Epoch: 6| Step: 12
Training loss: 3.303315150508886
Validation loss: 2.460454744672965

Epoch: 6| Step: 13
Training loss: 2.8469187091440826
Validation loss: 2.4777055289827197

Epoch: 107| Step: 0
Training loss: 2.4813025327257323
Validation loss: 2.4534533016917015

Epoch: 6| Step: 1
Training loss: 2.8608077998530757
Validation loss: 2.4613460630688673

Epoch: 6| Step: 2
Training loss: 2.294870137382229
Validation loss: 2.4697028455657546

Epoch: 6| Step: 3
Training loss: 2.8545860669218497
Validation loss: 2.462075938720632

Epoch: 6| Step: 4
Training loss: 2.3148471158917587
Validation loss: 2.459896056747738

Epoch: 6| Step: 5
Training loss: 2.5474646886113415
Validation loss: 2.461319396373797

Epoch: 6| Step: 6
Training loss: 2.9926902408409246
Validation loss: 2.4669428470663144

Epoch: 6| Step: 7
Training loss: 2.133109830036201
Validation loss: 2.484034349745158

Epoch: 6| Step: 8
Training loss: 2.851009618383672
Validation loss: 2.4733362937640644

Epoch: 6| Step: 9
Training loss: 2.555985147424088
Validation loss: 2.454505541875288

Epoch: 6| Step: 10
Training loss: 2.591864394549585
Validation loss: 2.4637870472984607

Epoch: 6| Step: 11
Training loss: 2.2816870283839554
Validation loss: 2.4741755543773887

Epoch: 6| Step: 12
Training loss: 3.0562050408486967
Validation loss: 2.4733159448935442

Epoch: 6| Step: 13
Training loss: 2.7045153090892993
Validation loss: 2.468860632568516

Epoch: 108| Step: 0
Training loss: 3.0080307918453797
Validation loss: 2.4725478733903956

Epoch: 6| Step: 1
Training loss: 2.393840447452609
Validation loss: 2.4831331130906187

Epoch: 6| Step: 2
Training loss: 2.506679956556491
Validation loss: 2.4575350459283225

Epoch: 6| Step: 3
Training loss: 3.1126458681541513
Validation loss: 2.464566108284831

Epoch: 6| Step: 4
Training loss: 2.592898309434137
Validation loss: 2.465397471364112

Epoch: 6| Step: 5
Training loss: 2.545175090380255
Validation loss: 2.473909082273294

Epoch: 6| Step: 6
Training loss: 3.11407391689139
Validation loss: 2.465387971287048

Epoch: 6| Step: 7
Training loss: 2.1248099298181953
Validation loss: 2.471477299089526

Epoch: 6| Step: 8
Training loss: 1.9950432149848238
Validation loss: 2.468643068817411

Epoch: 6| Step: 9
Training loss: 2.760632939533461
Validation loss: 2.476087410818273

Epoch: 6| Step: 10
Training loss: 2.8153243400772747
Validation loss: 2.444444853850051

Epoch: 6| Step: 11
Training loss: 2.8442801515829057
Validation loss: 2.4642606888435394

Epoch: 6| Step: 12
Training loss: 2.2114257273439217
Validation loss: 2.4695320972622414

Epoch: 6| Step: 13
Training loss: 2.1375813251216407
Validation loss: 2.4764474019269724

Epoch: 109| Step: 0
Training loss: 2.544922811840292
Validation loss: 2.455989361178028

Epoch: 6| Step: 1
Training loss: 3.132859683930057
Validation loss: 2.4814735145579045

Epoch: 6| Step: 2
Training loss: 2.2998935301642884
Validation loss: 2.45727068161941

Epoch: 6| Step: 3
Training loss: 2.411585058146567
Validation loss: 2.465920027360754

Epoch: 6| Step: 4
Training loss: 2.883078462070887
Validation loss: 2.4833297671930916

Epoch: 6| Step: 5
Training loss: 3.021096755194717
Validation loss: 2.4622221157005146

Epoch: 6| Step: 6
Training loss: 2.3935640506880307
Validation loss: 2.4796115858273597

Epoch: 6| Step: 7
Training loss: 2.113715333479494
Validation loss: 2.461672358153638

Epoch: 6| Step: 8
Training loss: 2.54049585818888
Validation loss: 2.469916684194993

Epoch: 6| Step: 9
Training loss: 2.620648182776197
Validation loss: 2.482076469945582

Epoch: 6| Step: 10
Training loss: 2.7688085476646096
Validation loss: 2.4540318248036503

Epoch: 6| Step: 11
Training loss: 2.480595238531824
Validation loss: 2.47297572848189

Epoch: 6| Step: 12
Training loss: 2.598383613803008
Validation loss: 2.461568619886573

Epoch: 6| Step: 13
Training loss: 2.548820174047704
Validation loss: 2.4741664713860785

Epoch: 110| Step: 0
Training loss: 2.8324189861189755
Validation loss: 2.4610958404568493

Epoch: 6| Step: 1
Training loss: 2.397642320658972
Validation loss: 2.4710112590053472

Epoch: 6| Step: 2
Training loss: 2.1988248590908306
Validation loss: 2.4538301993507363

Epoch: 6| Step: 3
Training loss: 2.6133996682927987
Validation loss: 2.472436101407055

Epoch: 6| Step: 4
Training loss: 2.638252592058227
Validation loss: 2.4523712206111186

Epoch: 6| Step: 5
Training loss: 2.365624242099656
Validation loss: 2.490242875382459

Epoch: 6| Step: 6
Training loss: 3.0072705858207662
Validation loss: 2.4679872646363856

Epoch: 6| Step: 7
Training loss: 2.7798888058002476
Validation loss: 2.460681709920196

Epoch: 6| Step: 8
Training loss: 1.9421675051137897
Validation loss: 2.470729972125722

Epoch: 6| Step: 9
Training loss: 2.2702368789964122
Validation loss: 2.4563886268771755

Epoch: 6| Step: 10
Training loss: 3.0535875764577587
Validation loss: 2.4708582198311806

Epoch: 6| Step: 11
Training loss: 2.989261481386592
Validation loss: 2.4693504777692468

Epoch: 6| Step: 12
Training loss: 2.8344877546567084
Validation loss: 2.463661053764809

Epoch: 6| Step: 13
Training loss: 2.1546754478466075
Validation loss: 2.471543957089887

Epoch: 111| Step: 0
Training loss: 2.2675249223275284
Validation loss: 2.4790003151912963

Epoch: 6| Step: 1
Training loss: 2.9188639583845206
Validation loss: 2.4861961196756823

Epoch: 6| Step: 2
Training loss: 2.7475533438754938
Validation loss: 2.4676727082566865

Epoch: 6| Step: 3
Training loss: 2.7561208058914035
Validation loss: 2.456820289495443

Epoch: 6| Step: 4
Training loss: 2.5537299831985765
Validation loss: 2.4656226247458415

Epoch: 6| Step: 5
Training loss: 2.52517215406273
Validation loss: 2.4685175682300677

Epoch: 6| Step: 6
Training loss: 2.6868129118058954
Validation loss: 2.4798593209289916

Epoch: 6| Step: 7
Training loss: 3.003829101841729
Validation loss: 2.4739581336823897

Epoch: 6| Step: 8
Training loss: 2.7714508248167498
Validation loss: 2.4613695084822234

Epoch: 6| Step: 9
Training loss: 2.664705707840814
Validation loss: 2.4892194182206

Epoch: 6| Step: 10
Training loss: 2.358816421778433
Validation loss: 2.4654204716727306

Epoch: 6| Step: 11
Training loss: 2.0827432814111844
Validation loss: 2.4734553518243083

Epoch: 6| Step: 12
Training loss: 2.6540288277550204
Validation loss: 2.4688153926090703

Epoch: 6| Step: 13
Training loss: 2.6455177259065827
Validation loss: 2.472133733480707

Epoch: 112| Step: 0
Training loss: 2.2339562510524265
Validation loss: 2.4664170704165556

Epoch: 6| Step: 1
Training loss: 2.506063356370421
Validation loss: 2.4547843888239895

Epoch: 6| Step: 2
Training loss: 2.682887977067148
Validation loss: 2.4669810206488947

Epoch: 6| Step: 3
Training loss: 3.050162864464103
Validation loss: 2.4723600143928333

Epoch: 6| Step: 4
Training loss: 2.4470569372439557
Validation loss: 2.4660343484937735

Epoch: 6| Step: 5
Training loss: 2.0051510757264195
Validation loss: 2.4789690487169453

Epoch: 6| Step: 6
Training loss: 2.951760597507867
Validation loss: 2.444860931504033

Epoch: 6| Step: 7
Training loss: 1.9954298972153663
Validation loss: 2.475872291041432

Epoch: 6| Step: 8
Training loss: 3.0483175921846244
Validation loss: 2.4751662561338668

Epoch: 6| Step: 9
Training loss: 2.9451580462444453
Validation loss: 2.467259734122934

Epoch: 6| Step: 10
Training loss: 2.379209702654245
Validation loss: 2.466569134799731

Epoch: 6| Step: 11
Training loss: 2.8728998225665525
Validation loss: 2.467989031562505

Epoch: 6| Step: 12
Training loss: 2.739551722896565
Validation loss: 2.48216934567479

Epoch: 6| Step: 13
Training loss: 1.7840969690817452
Validation loss: 2.4648905647049224

Epoch: 113| Step: 0
Training loss: 2.7172745833829572
Validation loss: 2.458396979276822

Epoch: 6| Step: 1
Training loss: 2.711516392706985
Validation loss: 2.473827417576604

Epoch: 6| Step: 2
Training loss: 2.4139888221336547
Validation loss: 2.459798626104619

Epoch: 6| Step: 3
Training loss: 2.7582874267384496
Validation loss: 2.4809944947651403

Epoch: 6| Step: 4
Training loss: 3.229032665466684
Validation loss: 2.462333557973582

Epoch: 6| Step: 5
Training loss: 2.69173045205832
Validation loss: 2.470794726101287

Epoch: 6| Step: 6
Training loss: 2.347516707908315
Validation loss: 2.4692307898802093

Epoch: 6| Step: 7
Training loss: 2.6201606829342605
Validation loss: 2.4447437306232467

Epoch: 6| Step: 8
Training loss: 2.8119649590090163
Validation loss: 2.4702335529957384

Epoch: 6| Step: 9
Training loss: 2.670517961645583
Validation loss: 2.460237995406712

Epoch: 6| Step: 10
Training loss: 1.561558554268204
Validation loss: 2.4551171847666944

Epoch: 6| Step: 11
Training loss: 2.9684981389874365
Validation loss: 2.4783696839106417

Epoch: 6| Step: 12
Training loss: 2.3306343840750023
Validation loss: 2.4606639016568304

Epoch: 6| Step: 13
Training loss: 2.1585168394731284
Validation loss: 2.463703195923106

Epoch: 114| Step: 0
Training loss: 2.276642627654313
Validation loss: 2.46155289057157

Epoch: 6| Step: 1
Training loss: 2.7574563809608326
Validation loss: 2.459965600060758

Epoch: 6| Step: 2
Training loss: 2.600948410185463
Validation loss: 2.471394833614705

Epoch: 6| Step: 3
Training loss: 2.5858948119175307
Validation loss: 2.4628712140856552

Epoch: 6| Step: 4
Training loss: 3.0691387854773664
Validation loss: 2.471834187966513

Epoch: 6| Step: 5
Training loss: 2.760659625799429
Validation loss: 2.4640036060989123

Epoch: 6| Step: 6
Training loss: 2.8566464605992974
Validation loss: 2.4594111831883896

Epoch: 6| Step: 7
Training loss: 2.678016074601718
Validation loss: 2.4703193942112587

Epoch: 6| Step: 8
Training loss: 2.9351037173815695
Validation loss: 2.461051925496531

Epoch: 6| Step: 9
Training loss: 2.6268492043513123
Validation loss: 2.4687177469834425

Epoch: 6| Step: 10
Training loss: 2.7153771185257103
Validation loss: 2.4541624514354514

Epoch: 6| Step: 11
Training loss: 2.1791780484876626
Validation loss: 2.4670839234346533

Epoch: 6| Step: 12
Training loss: 2.0300133094915034
Validation loss: 2.4635046254340645

Epoch: 6| Step: 13
Training loss: 1.6826751397902435
Validation loss: 2.4674719740669713

Epoch: 115| Step: 0
Training loss: 2.5467585437571807
Validation loss: 2.457850113797012

Epoch: 6| Step: 1
Training loss: 2.9432764275803915
Validation loss: 2.4585613534656954

Epoch: 6| Step: 2
Training loss: 2.7498934465052582
Validation loss: 2.483272128917685

Epoch: 6| Step: 3
Training loss: 2.4508260657773335
Validation loss: 2.4685636143428593

Epoch: 6| Step: 4
Training loss: 2.5235488914256785
Validation loss: 2.476870896633115

Epoch: 6| Step: 5
Training loss: 2.2577706831389235
Validation loss: 2.4672514787460704

Epoch: 6| Step: 6
Training loss: 2.2395437784176533
Validation loss: 2.4600995162055406

Epoch: 6| Step: 7
Training loss: 2.9674072441381343
Validation loss: 2.4804796795632096

Epoch: 6| Step: 8
Training loss: 3.0973920865846334
Validation loss: 2.4689411521835614

Epoch: 6| Step: 9
Training loss: 2.325120049115282
Validation loss: 2.4507024928992296

Epoch: 6| Step: 10
Training loss: 2.865668037116336
Validation loss: 2.45835801906994

Epoch: 6| Step: 11
Training loss: 2.40410012649492
Validation loss: 2.4581441651802773

Epoch: 6| Step: 12
Training loss: 2.5256001089824065
Validation loss: 2.4736261132860244

Epoch: 6| Step: 13
Training loss: 2.261603950393676
Validation loss: 2.4807074479360356

Epoch: 116| Step: 0
Training loss: 2.7086419932225687
Validation loss: 2.4554562683509675

Epoch: 6| Step: 1
Training loss: 2.605251686399474
Validation loss: 2.4553929453704497

Epoch: 6| Step: 2
Training loss: 2.173475375692173
Validation loss: 2.4657572931070564

Epoch: 6| Step: 3
Training loss: 2.361596280783022
Validation loss: 2.4739103061092313

Epoch: 6| Step: 4
Training loss: 2.4122738430771373
Validation loss: 2.472338769875571

Epoch: 6| Step: 5
Training loss: 3.2682882883669344
Validation loss: 2.4564509817876754

Epoch: 6| Step: 6
Training loss: 2.0369391950877827
Validation loss: 2.4711532629543074

Epoch: 6| Step: 7
Training loss: 2.7108211437396506
Validation loss: 2.464120432964892

Epoch: 6| Step: 8
Training loss: 2.349852995637118
Validation loss: 2.473660237218049

Epoch: 6| Step: 9
Training loss: 2.7921490513439022
Validation loss: 2.4430075016051367

Epoch: 6| Step: 10
Training loss: 2.659080343810865
Validation loss: 2.45652748955016

Epoch: 6| Step: 11
Training loss: 2.1464359461950324
Validation loss: 2.4561231037488556

Epoch: 6| Step: 12
Training loss: 2.244241126244471
Validation loss: 2.4643617526046273

Epoch: 6| Step: 13
Training loss: 3.9106212114678813
Validation loss: 2.4711811498669145

Epoch: 117| Step: 0
Training loss: 2.3490916099434562
Validation loss: 2.459127937682146

Epoch: 6| Step: 1
Training loss: 3.0794312469690843
Validation loss: 2.4473476627441757

Epoch: 6| Step: 2
Training loss: 2.831978212057235
Validation loss: 2.459457518620554

Epoch: 6| Step: 3
Training loss: 2.2020726497490832
Validation loss: 2.4633048649923666

Epoch: 6| Step: 4
Training loss: 3.0751083230888745
Validation loss: 2.470819722250701

Epoch: 6| Step: 5
Training loss: 3.0703555193889023
Validation loss: 2.479280975000822

Epoch: 6| Step: 6
Training loss: 1.6495805727453885
Validation loss: 2.463459329782091

Epoch: 6| Step: 7
Training loss: 2.3146087722914017
Validation loss: 2.4638145961769524

Epoch: 6| Step: 8
Training loss: 2.6218055179378124
Validation loss: 2.4518000735555514

Epoch: 6| Step: 9
Training loss: 1.671844767359536
Validation loss: 2.4676281503793915

Epoch: 6| Step: 10
Training loss: 2.617545943125694
Validation loss: 2.4671518156203613

Epoch: 6| Step: 11
Training loss: 2.707514732088285
Validation loss: 2.4777573215854134

Epoch: 6| Step: 12
Training loss: 2.8746700926862316
Validation loss: 2.4472081995616817

Epoch: 6| Step: 13
Training loss: 2.6066005370425853
Validation loss: 2.471745261377121

Epoch: 118| Step: 0
Training loss: 2.7178389678083845
Validation loss: 2.475096547454188

Epoch: 6| Step: 1
Training loss: 2.6241471858031877
Validation loss: 2.4632930058206592

Epoch: 6| Step: 2
Training loss: 2.7722265044310714
Validation loss: 2.4547786475332516

Epoch: 6| Step: 3
Training loss: 2.4709410782770385
Validation loss: 2.4679139906232175

Epoch: 6| Step: 4
Training loss: 2.838882808425805
Validation loss: 2.4842365742538983

Epoch: 6| Step: 5
Training loss: 2.519757779605671
Validation loss: 2.4721687242051074

Epoch: 6| Step: 6
Training loss: 2.52008987266498
Validation loss: 2.475294691374147

Epoch: 6| Step: 7
Training loss: 2.1648718907465927
Validation loss: 2.4923843695382755

Epoch: 6| Step: 8
Training loss: 2.9212198593941787
Validation loss: 2.4666804139364746

Epoch: 6| Step: 9
Training loss: 2.565019624869244
Validation loss: 2.489026736010564

Epoch: 6| Step: 10
Training loss: 2.172176751779859
Validation loss: 2.4769130676178843

Epoch: 6| Step: 11
Training loss: 2.4367862536738323
Validation loss: 2.475903170022772

Epoch: 6| Step: 12
Training loss: 2.844131779457214
Validation loss: 2.4527794598707606

Epoch: 6| Step: 13
Training loss: 2.61445014482662
Validation loss: 2.4802025974283137

Epoch: 119| Step: 0
Training loss: 2.644618338611715
Validation loss: 2.4892670577292937

Epoch: 6| Step: 1
Training loss: 3.441048888271867
Validation loss: 2.4651541929702683

Epoch: 6| Step: 2
Training loss: 2.2355251953097612
Validation loss: 2.46432746038361

Epoch: 6| Step: 3
Training loss: 2.6126798613477016
Validation loss: 2.458829038965006

Epoch: 6| Step: 4
Training loss: 2.49936210123422
Validation loss: 2.4712779439869887

Epoch: 6| Step: 5
Training loss: 2.7411441393936453
Validation loss: 2.4769488146864838

Epoch: 6| Step: 6
Training loss: 2.5492612741087672
Validation loss: 2.463104358737348

Epoch: 6| Step: 7
Training loss: 2.452109934733564
Validation loss: 2.4689836642017884

Epoch: 6| Step: 8
Training loss: 2.7528041068044513
Validation loss: 2.4616748898500918

Epoch: 6| Step: 9
Training loss: 2.8598380625835547
Validation loss: 2.449861434088561

Epoch: 6| Step: 10
Training loss: 2.1360452486667523
Validation loss: 2.4597368407002125

Epoch: 6| Step: 11
Training loss: 2.4253341090701084
Validation loss: 2.4497242216709796

Epoch: 6| Step: 12
Training loss: 2.223684170431008
Validation loss: 2.477259754024055

Epoch: 6| Step: 13
Training loss: 1.797199186851883
Validation loss: 2.4589140303337618

Epoch: 120| Step: 0
Training loss: 2.763258961810647
Validation loss: 2.4555762105465098

Epoch: 6| Step: 1
Training loss: 3.0085988787872573
Validation loss: 2.4884848364323067

Epoch: 6| Step: 2
Training loss: 1.9288551914013017
Validation loss: 2.457850122141347

Epoch: 6| Step: 3
Training loss: 2.2240119111682084
Validation loss: 2.457368578670881

Epoch: 6| Step: 4
Training loss: 2.048065538192191
Validation loss: 2.4536514757106183

Epoch: 6| Step: 5
Training loss: 2.6252515763119204
Validation loss: 2.4589144327736974

Epoch: 6| Step: 6
Training loss: 2.3188048322831585
Validation loss: 2.473434951073316

Epoch: 6| Step: 7
Training loss: 2.8866470596434617
Validation loss: 2.4567213312485605

Epoch: 6| Step: 8
Training loss: 2.5527566034681595
Validation loss: 2.472256601709923

Epoch: 6| Step: 9
Training loss: 2.7625893349680477
Validation loss: 2.4601640393755195

Epoch: 6| Step: 10
Training loss: 2.8040027685763937
Validation loss: 2.47109881093364

Epoch: 6| Step: 11
Training loss: 3.0383199456345964
Validation loss: 2.4688290393451595

Epoch: 6| Step: 12
Training loss: 2.4196513150177426
Validation loss: 2.4500404530362965

Epoch: 6| Step: 13
Training loss: 2.4100211181348508
Validation loss: 2.447578323185974

Epoch: 121| Step: 0
Training loss: 2.4560758494987915
Validation loss: 2.4562236642217594

Epoch: 6| Step: 1
Training loss: 3.3473075409106796
Validation loss: 2.4479267868080656

Epoch: 6| Step: 2
Training loss: 2.7431044390436496
Validation loss: 2.4508054672435375

Epoch: 6| Step: 3
Training loss: 1.684325021770199
Validation loss: 2.4693423861483814

Epoch: 6| Step: 4
Training loss: 2.55321047020005
Validation loss: 2.4565691383683577

Epoch: 6| Step: 5
Training loss: 2.572351082068018
Validation loss: 2.4391292262838222

Epoch: 6| Step: 6
Training loss: 2.691311993768603
Validation loss: 2.4739372977035488

Epoch: 6| Step: 7
Training loss: 2.9162391530933585
Validation loss: 2.461660107871942

Epoch: 6| Step: 8
Training loss: 2.782864220045943
Validation loss: 2.462684976865607

Epoch: 6| Step: 9
Training loss: 2.8827033293607274
Validation loss: 2.4677964120282523

Epoch: 6| Step: 10
Training loss: 2.2745716110834
Validation loss: 2.470636837062066

Epoch: 6| Step: 11
Training loss: 2.302203582338819
Validation loss: 2.46249393037421

Epoch: 6| Step: 12
Training loss: 2.5061254798606725
Validation loss: 2.4630064981478514

Epoch: 6| Step: 13
Training loss: 1.8071860979745287
Validation loss: 2.439269842924404

Epoch: 122| Step: 0
Training loss: 2.4873863539302175
Validation loss: 2.4579640342785662

Epoch: 6| Step: 1
Training loss: 2.077701611519621
Validation loss: 2.4586147974884835

Epoch: 6| Step: 2
Training loss: 2.174001188149781
Validation loss: 2.4657901868235848

Epoch: 6| Step: 3
Training loss: 3.252596478215159
Validation loss: 2.456459988871515

Epoch: 6| Step: 4
Training loss: 2.1369045253520267
Validation loss: 2.450307063217785

Epoch: 6| Step: 5
Training loss: 2.8381046810401465
Validation loss: 2.447602682370393

Epoch: 6| Step: 6
Training loss: 2.5983138779292516
Validation loss: 2.457862954652214

Epoch: 6| Step: 7
Training loss: 2.4793073683703417
Validation loss: 2.4594017944552506

Epoch: 6| Step: 8
Training loss: 2.613728985257275
Validation loss: 2.458880107329658

Epoch: 6| Step: 9
Training loss: 2.389343117499471
Validation loss: 2.472973749492822

Epoch: 6| Step: 10
Training loss: 2.361051557450556
Validation loss: 2.442025260697622

Epoch: 6| Step: 11
Training loss: 3.009194272200896
Validation loss: 2.4505736025478564

Epoch: 6| Step: 12
Training loss: 2.5843371830194894
Validation loss: 2.4767689625142677

Epoch: 6| Step: 13
Training loss: 2.992095866182151
Validation loss: 2.4736721409973335

Epoch: 123| Step: 0
Training loss: 2.634003593355478
Validation loss: 2.44571228648796

Epoch: 6| Step: 1
Training loss: 2.43889265134961
Validation loss: 2.467265993955736

Epoch: 6| Step: 2
Training loss: 2.749179631025634
Validation loss: 2.47989096177559

Epoch: 6| Step: 3
Training loss: 2.722501862580474
Validation loss: 2.4618193005457556

Epoch: 6| Step: 4
Training loss: 2.4760325734302246
Validation loss: 2.464874985557116

Epoch: 6| Step: 5
Training loss: 2.673337837113973
Validation loss: 2.456582696597476

Epoch: 6| Step: 6
Training loss: 2.740136838823436
Validation loss: 2.4633738843427064

Epoch: 6| Step: 7
Training loss: 2.565289909234512
Validation loss: 2.4676493637672854

Epoch: 6| Step: 8
Training loss: 1.1764409948581929
Validation loss: 2.4599608103580763

Epoch: 6| Step: 9
Training loss: 2.4085448580273283
Validation loss: 2.446946155979917

Epoch: 6| Step: 10
Training loss: 2.8987217684049984
Validation loss: 2.465648313810576

Epoch: 6| Step: 11
Training loss: 3.123309479265781
Validation loss: 2.471907499266765

Epoch: 6| Step: 12
Training loss: 2.533236536468896
Validation loss: 2.4574390035669382

Epoch: 6| Step: 13
Training loss: 2.4550128645860907
Validation loss: 2.4577331265632716

Epoch: 124| Step: 0
Training loss: 2.306598866445676
Validation loss: 2.4687040695169165

Epoch: 6| Step: 1
Training loss: 3.016271966505629
Validation loss: 2.452776799839942

Epoch: 6| Step: 2
Training loss: 2.639082418561969
Validation loss: 2.4607176406918887

Epoch: 6| Step: 3
Training loss: 2.0841632969994386
Validation loss: 2.4519690287741374

Epoch: 6| Step: 4
Training loss: 2.3012870919026835
Validation loss: 2.4757474675684055

Epoch: 6| Step: 5
Training loss: 2.0573801013594273
Validation loss: 2.461392472480463

Epoch: 6| Step: 6
Training loss: 2.4280309396246196
Validation loss: 2.45623644051891

Epoch: 6| Step: 7
Training loss: 2.5334205269447896
Validation loss: 2.4665093846827886

Epoch: 6| Step: 8
Training loss: 2.7899612132832163
Validation loss: 2.460782924836285

Epoch: 6| Step: 9
Training loss: 2.2655168178643845
Validation loss: 2.47110678372146

Epoch: 6| Step: 10
Training loss: 3.079962322450527
Validation loss: 2.4665810509745

Epoch: 6| Step: 11
Training loss: 2.6911788423577416
Validation loss: 2.4481140074629377

Epoch: 6| Step: 12
Training loss: 2.5141665572875644
Validation loss: 2.4478070882351317

Epoch: 6| Step: 13
Training loss: 3.20220710814656
Validation loss: 2.4442133591126165

Epoch: 125| Step: 0
Training loss: 3.154921601495744
Validation loss: 2.4522278268992155

Epoch: 6| Step: 1
Training loss: 2.7680400067233135
Validation loss: 2.4555837759371366

Epoch: 6| Step: 2
Training loss: 2.5921274648454977
Validation loss: 2.4698748966464796

Epoch: 6| Step: 3
Training loss: 3.219841633095006
Validation loss: 2.4493538231021303

Epoch: 6| Step: 4
Training loss: 2.343165108496943
Validation loss: 2.4586590203033363

Epoch: 6| Step: 5
Training loss: 2.450502780005951
Validation loss: 2.471631712114932

Epoch: 6| Step: 6
Training loss: 2.5819461133255084
Validation loss: 2.4686679050206655

Epoch: 6| Step: 7
Training loss: 2.563170461635193
Validation loss: 2.4657564540713772

Epoch: 6| Step: 8
Training loss: 2.3686434356956023
Validation loss: 2.4611677789645188

Epoch: 6| Step: 9
Training loss: 2.481262752778842
Validation loss: 2.4736319294982057

Epoch: 6| Step: 10
Training loss: 2.1902216737289453
Validation loss: 2.4804423627870156

Epoch: 6| Step: 11
Training loss: 2.12221187114133
Validation loss: 2.4712025303808915

Epoch: 6| Step: 12
Training loss: 2.266298391306295
Validation loss: 2.4420217307391052

Epoch: 6| Step: 13
Training loss: 2.7625458381267567
Validation loss: 2.4689088715514265

Epoch: 126| Step: 0
Training loss: 3.28523869359987
Validation loss: 2.4671468039906492

Epoch: 6| Step: 1
Training loss: 2.6653076126030566
Validation loss: 2.466991912284445

Epoch: 6| Step: 2
Training loss: 2.4242835097371547
Validation loss: 2.470286788080693

Epoch: 6| Step: 3
Training loss: 2.15237055656231
Validation loss: 2.4693686511166892

Epoch: 6| Step: 4
Training loss: 2.949069998318193
Validation loss: 2.4692178731708045

Epoch: 6| Step: 5
Training loss: 2.802470741765803
Validation loss: 2.448176680985324

Epoch: 6| Step: 6
Training loss: 3.1494611491150604
Validation loss: 2.457565176828105

Epoch: 6| Step: 7
Training loss: 1.648741201474166
Validation loss: 2.471869853951801

Epoch: 6| Step: 8
Training loss: 2.7481374501997586
Validation loss: 2.465358282270408

Epoch: 6| Step: 9
Training loss: 2.29301200448981
Validation loss: 2.4802508302951427

Epoch: 6| Step: 10
Training loss: 2.393552994153573
Validation loss: 2.4386498384588684

Epoch: 6| Step: 11
Training loss: 2.2328278847358574
Validation loss: 2.4628169713855548

Epoch: 6| Step: 12
Training loss: 2.488523270890426
Validation loss: 2.4520228987731323

Epoch: 6| Step: 13
Training loss: 2.110997233191574
Validation loss: 2.470189523384396

Epoch: 127| Step: 0
Training loss: 2.889943800383073
Validation loss: 2.4559048072313683

Epoch: 6| Step: 1
Training loss: 3.0796495718824413
Validation loss: 2.472103969923899

Epoch: 6| Step: 2
Training loss: 2.3991123703800223
Validation loss: 2.4455934009561147

Epoch: 6| Step: 3
Training loss: 2.568591994277964
Validation loss: 2.4580901623385647

Epoch: 6| Step: 4
Training loss: 2.346821311204505
Validation loss: 2.4564548416723264

Epoch: 6| Step: 5
Training loss: 2.810058805861743
Validation loss: 2.4372825394086544

Epoch: 6| Step: 6
Training loss: 2.431941222948746
Validation loss: 2.456109952666724

Epoch: 6| Step: 7
Training loss: 2.957591559314111
Validation loss: 2.4494985321302223

Epoch: 6| Step: 8
Training loss: 2.378351557162138
Validation loss: 2.4547687105517473

Epoch: 6| Step: 9
Training loss: 2.6182324501220884
Validation loss: 2.4491595532113792

Epoch: 6| Step: 10
Training loss: 2.0780409028669378
Validation loss: 2.439073906925344

Epoch: 6| Step: 11
Training loss: 2.6467500335125496
Validation loss: 2.4688550641948988

Epoch: 6| Step: 12
Training loss: 1.9424289642267216
Validation loss: 2.455791957279839

Epoch: 6| Step: 13
Training loss: 1.9763456082365252
Validation loss: 2.4538365357550984

Epoch: 128| Step: 0
Training loss: 2.12977501177931
Validation loss: 2.4571290647762964

Epoch: 6| Step: 1
Training loss: 2.7383377570009944
Validation loss: 2.4756500787919116

Epoch: 6| Step: 2
Training loss: 2.448455448243086
Validation loss: 2.464081128884199

Epoch: 6| Step: 3
Training loss: 2.57465494306843
Validation loss: 2.4659358961984763

Epoch: 6| Step: 4
Training loss: 2.621297677715706
Validation loss: 2.4630408087602524

Epoch: 6| Step: 5
Training loss: 2.252090119084931
Validation loss: 2.4544272414004737

Epoch: 6| Step: 6
Training loss: 2.762552915040441
Validation loss: 2.462347355158131

Epoch: 6| Step: 7
Training loss: 2.6892293644434573
Validation loss: 2.457450391812226

Epoch: 6| Step: 8
Training loss: 2.5919762486794244
Validation loss: 2.4428520500574193

Epoch: 6| Step: 9
Training loss: 2.651548106166276
Validation loss: 2.472839154823033

Epoch: 6| Step: 10
Training loss: 1.7909460023016888
Validation loss: 2.4691771354139256

Epoch: 6| Step: 11
Training loss: 2.652976768135991
Validation loss: 2.4570219565120457

Epoch: 6| Step: 12
Training loss: 3.0369412194706733
Validation loss: 2.4730905527492917

Epoch: 6| Step: 13
Training loss: 2.5399844329837546
Validation loss: 2.45039535908607

Epoch: 129| Step: 0
Training loss: 2.7794958862340122
Validation loss: 2.464735942060131

Epoch: 6| Step: 1
Training loss: 2.8172238838948007
Validation loss: 2.4521411840381937

Epoch: 6| Step: 2
Training loss: 2.2274707748602327
Validation loss: 2.4452355511729507

Epoch: 6| Step: 3
Training loss: 2.6016843841685833
Validation loss: 2.4456495870243926

Epoch: 6| Step: 4
Training loss: 2.296992292458503
Validation loss: 2.4683417713141567

Epoch: 6| Step: 5
Training loss: 2.2506287014291755
Validation loss: 2.4627777235332617

Epoch: 6| Step: 6
Training loss: 2.9428556602304985
Validation loss: 2.4586757764148137

Epoch: 6| Step: 7
Training loss: 2.5620021801715183
Validation loss: 2.454481999562566

Epoch: 6| Step: 8
Training loss: 3.1254943456652033
Validation loss: 2.4555758947341397

Epoch: 6| Step: 9
Training loss: 2.18910681429874
Validation loss: 2.4656077104714007

Epoch: 6| Step: 10
Training loss: 2.1556699774328223
Validation loss: 2.46289099660385

Epoch: 6| Step: 11
Training loss: 2.709113395055302
Validation loss: 2.4501445920340537

Epoch: 6| Step: 12
Training loss: 2.095691293361289
Validation loss: 2.4644564261600856

Epoch: 6| Step: 13
Training loss: 2.905946120915874
Validation loss: 2.4627590456079598

Epoch: 130| Step: 0
Training loss: 3.1724879983204515
Validation loss: 2.462031026003535

Epoch: 6| Step: 1
Training loss: 2.0359292932609923
Validation loss: 2.462751893141941

Epoch: 6| Step: 2
Training loss: 3.070436120881219
Validation loss: 2.453946790750671

Epoch: 6| Step: 3
Training loss: 3.084056116565805
Validation loss: 2.456434821031316

Epoch: 6| Step: 4
Training loss: 2.45904390658428
Validation loss: 2.4781249396261007

Epoch: 6| Step: 5
Training loss: 2.3024628845603208
Validation loss: 2.464314003021979

Epoch: 6| Step: 6
Training loss: 2.7377472056072496
Validation loss: 2.45085359193491

Epoch: 6| Step: 7
Training loss: 1.8594319310808993
Validation loss: 2.4809327236561325

Epoch: 6| Step: 8
Training loss: 2.806159353172797
Validation loss: 2.4650957397270585

Epoch: 6| Step: 9
Training loss: 2.504496916851477
Validation loss: 2.474273326533258

Epoch: 6| Step: 10
Training loss: 2.5104168355052674
Validation loss: 2.443675634816127

Epoch: 6| Step: 11
Training loss: 2.106888046744799
Validation loss: 2.462420924955353

Epoch: 6| Step: 12
Training loss: 1.779145453130799
Validation loss: 2.4789745256009006

Epoch: 6| Step: 13
Training loss: 3.0777361474127085
Validation loss: 2.4685613358396368

Epoch: 131| Step: 0
Training loss: 2.767733271415517
Validation loss: 2.452689154130496

Epoch: 6| Step: 1
Training loss: 3.003690992165475
Validation loss: 2.4612459129139945

Epoch: 6| Step: 2
Training loss: 3.383361630877339
Validation loss: 2.4448800093563308

Epoch: 6| Step: 3
Training loss: 2.190475728694401
Validation loss: 2.43113421636742

Epoch: 6| Step: 4
Training loss: 2.382706836796585
Validation loss: 2.4693654286145645

Epoch: 6| Step: 5
Training loss: 2.6944026572361617
Validation loss: 2.4649164246872295

Epoch: 6| Step: 6
Training loss: 1.9502387120781226
Validation loss: 2.458146787072521

Epoch: 6| Step: 7
Training loss: 2.288346214323009
Validation loss: 2.4490153873344274

Epoch: 6| Step: 8
Training loss: 2.983163318016298
Validation loss: 2.464488198185092

Epoch: 6| Step: 9
Training loss: 2.3019005428143045
Validation loss: 2.4467699942115178

Epoch: 6| Step: 10
Training loss: 2.4090670654791997
Validation loss: 2.441009974979916

Epoch: 6| Step: 11
Training loss: 2.3585111539769827
Validation loss: 2.4636869755594506

Epoch: 6| Step: 12
Training loss: 2.389958905940125
Validation loss: 2.457953819178505

Epoch: 6| Step: 13
Training loss: 1.8302614167066702
Validation loss: 2.444376114930952

Epoch: 132| Step: 0
Training loss: 3.0047688727585573
Validation loss: 2.4391881924880385

Epoch: 6| Step: 1
Training loss: 2.474444810653832
Validation loss: 2.479056118983693

Epoch: 6| Step: 2
Training loss: 2.364897170785117
Validation loss: 2.4638571820830966

Epoch: 6| Step: 3
Training loss: 2.3548518396248355
Validation loss: 2.4496381035299266

Epoch: 6| Step: 4
Training loss: 2.342105542887305
Validation loss: 2.463637877819925

Epoch: 6| Step: 5
Training loss: 2.0740980555015835
Validation loss: 2.4574051462675133

Epoch: 6| Step: 6
Training loss: 2.0617170292658127
Validation loss: 2.4695998100322227

Epoch: 6| Step: 7
Training loss: 2.5462376083649287
Validation loss: 2.4525090657842123

Epoch: 6| Step: 8
Training loss: 2.2096968226235467
Validation loss: 2.465187142571266

Epoch: 6| Step: 9
Training loss: 3.193143747498302
Validation loss: 2.485745164187508

Epoch: 6| Step: 10
Training loss: 3.4094262669080293
Validation loss: 2.469569793784585

Epoch: 6| Step: 11
Training loss: 2.1157697033663907
Validation loss: 2.460753097956606

Epoch: 6| Step: 12
Training loss: 2.449000298646073
Validation loss: 2.466361188542038

Epoch: 6| Step: 13
Training loss: 3.0744177476393006
Validation loss: 2.4588314526444703

Epoch: 133| Step: 0
Training loss: 2.4973286661789125
Validation loss: 2.4722117873570717

Epoch: 6| Step: 1
Training loss: 2.3433290230651256
Validation loss: 2.461945021793688

Epoch: 6| Step: 2
Training loss: 2.1094083430162756
Validation loss: 2.4707789517625347

Epoch: 6| Step: 3
Training loss: 2.7109833199534212
Validation loss: 2.481284731944747

Epoch: 6| Step: 4
Training loss: 3.03766040770911
Validation loss: 2.4498963180679523

Epoch: 6| Step: 5
Training loss: 2.626454268386522
Validation loss: 2.4446486407683574

Epoch: 6| Step: 6
Training loss: 2.5045643148513
Validation loss: 2.441669246167263

Epoch: 6| Step: 7
Training loss: 2.8525434087180175
Validation loss: 2.4484905553773872

Epoch: 6| Step: 8
Training loss: 2.651014396562197
Validation loss: 2.433456395690111

Epoch: 6| Step: 9
Training loss: 2.5912912503688736
Validation loss: 2.4334051667198255

Epoch: 6| Step: 10
Training loss: 2.6163902776577452
Validation loss: 2.447774909074995

Epoch: 6| Step: 11
Training loss: 2.5183004049003546
Validation loss: 2.446377118796382

Epoch: 6| Step: 12
Training loss: 2.0445345244856994
Validation loss: 2.4652434368669818

Epoch: 6| Step: 13
Training loss: 2.6060261509037734
Validation loss: 2.448718061070039

Epoch: 134| Step: 0
Training loss: 2.2861186291475875
Validation loss: 2.456342196503979

Epoch: 6| Step: 1
Training loss: 3.275762710864544
Validation loss: 2.4586279841797807

Epoch: 6| Step: 2
Training loss: 2.3785275814052214
Validation loss: 2.460675956864008

Epoch: 6| Step: 3
Training loss: 2.4476471015279477
Validation loss: 2.445923625441259

Epoch: 6| Step: 4
Training loss: 2.4388853195712716
Validation loss: 2.4581570243147435

Epoch: 6| Step: 5
Training loss: 2.538911597829475
Validation loss: 2.457749851436141

Epoch: 6| Step: 6
Training loss: 2.6792187517085715
Validation loss: 2.450628681147615

Epoch: 6| Step: 7
Training loss: 2.5415426025962593
Validation loss: 2.4504700284127994

Epoch: 6| Step: 8
Training loss: 1.6253897859680753
Validation loss: 2.461836109083338

Epoch: 6| Step: 9
Training loss: 2.4707338112595365
Validation loss: 2.445294671018394

Epoch: 6| Step: 10
Training loss: 3.0137837377469068
Validation loss: 2.443947129997567

Epoch: 6| Step: 11
Training loss: 2.4172488421181795
Validation loss: 2.4771337518323655

Epoch: 6| Step: 12
Training loss: 2.5826598079014604
Validation loss: 2.461536230073155

Epoch: 6| Step: 13
Training loss: 2.7077703526601664
Validation loss: 2.46904610077914

Epoch: 135| Step: 0
Training loss: 2.656841975051491
Validation loss: 2.4586696161849884

Epoch: 6| Step: 1
Training loss: 2.615892687810068
Validation loss: 2.4689722756795605

Epoch: 6| Step: 2
Training loss: 2.122473392746651
Validation loss: 2.469475148085617

Epoch: 6| Step: 3
Training loss: 2.8007237044079547
Validation loss: 2.4589432560595643

Epoch: 6| Step: 4
Training loss: 2.0144691405992083
Validation loss: 2.4557431464120905

Epoch: 6| Step: 5
Training loss: 2.9222203014965378
Validation loss: 2.4754511752074526

Epoch: 6| Step: 6
Training loss: 2.475882162996936
Validation loss: 2.445692724557827

Epoch: 6| Step: 7
Training loss: 3.056441093976736
Validation loss: 2.4613949867586213

Epoch: 6| Step: 8
Training loss: 2.5144635475112174
Validation loss: 2.4432141355189434

Epoch: 6| Step: 9
Training loss: 2.0844668801344484
Validation loss: 2.4453391090362477

Epoch: 6| Step: 10
Training loss: 3.205421778023044
Validation loss: 2.4496730063874574

Epoch: 6| Step: 11
Training loss: 2.3507711403332383
Validation loss: 2.4568665485755994

Epoch: 6| Step: 12
Training loss: 2.10207261485104
Validation loss: 2.465756563239604

Epoch: 6| Step: 13
Training loss: 2.0400602157905814
Validation loss: 2.4356293158798312

Epoch: 136| Step: 0
Training loss: 2.6781798812246143
Validation loss: 2.4523173300380328

Epoch: 6| Step: 1
Training loss: 2.7986589421890664
Validation loss: 2.4470949517012963

Epoch: 6| Step: 2
Training loss: 2.055026762479466
Validation loss: 2.4533427580540494

Epoch: 6| Step: 3
Training loss: 1.9404327592215873
Validation loss: 2.447629466562168

Epoch: 6| Step: 4
Training loss: 3.4134601960845985
Validation loss: 2.443101381439297

Epoch: 6| Step: 5
Training loss: 2.6413246446813528
Validation loss: 2.4496890945420695

Epoch: 6| Step: 6
Training loss: 3.22857411187949
Validation loss: 2.4300716494644163

Epoch: 6| Step: 7
Training loss: 1.9025324859051203
Validation loss: 2.455016194688576

Epoch: 6| Step: 8
Training loss: 2.43607728959542
Validation loss: 2.4514260110344406

Epoch: 6| Step: 9
Training loss: 3.138427572944011
Validation loss: 2.447201768473986

Epoch: 6| Step: 10
Training loss: 2.00104697956715
Validation loss: 2.4538905308681787

Epoch: 6| Step: 11
Training loss: 2.348390283573136
Validation loss: 2.449669534019662

Epoch: 6| Step: 12
Training loss: 2.2250182033179944
Validation loss: 2.4729875111571955

Epoch: 6| Step: 13
Training loss: 1.937946022132321
Validation loss: 2.4601559571382734

Epoch: 137| Step: 0
Training loss: 3.2476625106123502
Validation loss: 2.459857233361555

Epoch: 6| Step: 1
Training loss: 2.531589814912123
Validation loss: 2.4621014534188768

Epoch: 6| Step: 2
Training loss: 2.6120116110422407
Validation loss: 2.443208975104317

Epoch: 6| Step: 3
Training loss: 1.6194158120056974
Validation loss: 2.452945116098359

Epoch: 6| Step: 4
Training loss: 2.1171862612787544
Validation loss: 2.469350140359361

Epoch: 6| Step: 5
Training loss: 3.0537217118354056
Validation loss: 2.441781956138478

Epoch: 6| Step: 6
Training loss: 2.6817030374997617
Validation loss: 2.4334545989491767

Epoch: 6| Step: 7
Training loss: 2.7596059700368967
Validation loss: 2.4545869438958974

Epoch: 6| Step: 8
Training loss: 1.9641679394080864
Validation loss: 2.4365550024419615

Epoch: 6| Step: 9
Training loss: 1.912387410757999
Validation loss: 2.4527699025599525

Epoch: 6| Step: 10
Training loss: 2.5590318610476372
Validation loss: 2.4672633375940674

Epoch: 6| Step: 11
Training loss: 2.490576435606404
Validation loss: 2.4509981271698105

Epoch: 6| Step: 12
Training loss: 2.601897530276056
Validation loss: 2.472729093192152

Epoch: 6| Step: 13
Training loss: 3.16065550680979
Validation loss: 2.4591627277428025

Epoch: 138| Step: 0
Training loss: 1.8289469639850995
Validation loss: 2.444943495568363

Epoch: 6| Step: 1
Training loss: 2.227257335729975
Validation loss: 2.447320937272493

Epoch: 6| Step: 2
Training loss: 2.1100422121860576
Validation loss: 2.4649321408590867

Epoch: 6| Step: 3
Training loss: 2.355963558523989
Validation loss: 2.454416510220089

Epoch: 6| Step: 4
Training loss: 2.732610863672906
Validation loss: 2.4347027266698205

Epoch: 6| Step: 5
Training loss: 2.570688330354594
Validation loss: 2.4320673481534665

Epoch: 6| Step: 6
Training loss: 2.445776947082037
Validation loss: 2.468624340767506

Epoch: 6| Step: 7
Training loss: 2.5618277807786263
Validation loss: 2.456380869321744

Epoch: 6| Step: 8
Training loss: 2.3819162152702567
Validation loss: 2.4487603724503506

Epoch: 6| Step: 9
Training loss: 2.3548417150349303
Validation loss: 2.462812801382993

Epoch: 6| Step: 10
Training loss: 3.3484008388319095
Validation loss: 2.4549235850370046

Epoch: 6| Step: 11
Training loss: 3.0353884417902286
Validation loss: 2.450969928507996

Epoch: 6| Step: 12
Training loss: 2.548448135288296
Validation loss: 2.450896525429015

Epoch: 6| Step: 13
Training loss: 2.6494461884398093
Validation loss: 2.4589960495677525

Epoch: 139| Step: 0
Training loss: 2.5874119729811147
Validation loss: 2.4574507131213625

Epoch: 6| Step: 1
Training loss: 2.619788855569493
Validation loss: 2.4435263685904043

Epoch: 6| Step: 2
Training loss: 3.0781943995983667
Validation loss: 2.438368294256741

Epoch: 6| Step: 3
Training loss: 2.8841156120671605
Validation loss: 2.447580227917127

Epoch: 6| Step: 4
Training loss: 2.7153059970682576
Validation loss: 2.4449564566359534

Epoch: 6| Step: 5
Training loss: 2.188968819268501
Validation loss: 2.4479100346175406

Epoch: 6| Step: 6
Training loss: 2.1304252035336897
Validation loss: 2.4389171062186388

Epoch: 6| Step: 7
Training loss: 1.7556053037207402
Validation loss: 2.4432958932690267

Epoch: 6| Step: 8
Training loss: 2.3412477487368943
Validation loss: 2.471837809141738

Epoch: 6| Step: 9
Training loss: 2.568381653895768
Validation loss: 2.4507897483495307

Epoch: 6| Step: 10
Training loss: 2.4056121178844787
Validation loss: 2.448739806792443

Epoch: 6| Step: 11
Training loss: 2.5892722763689986
Validation loss: 2.4533978998786403

Epoch: 6| Step: 12
Training loss: 2.663446081000647
Validation loss: 2.462575082908024

Epoch: 6| Step: 13
Training loss: 2.7379124021596115
Validation loss: 2.4449556073164205

Epoch: 140| Step: 0
Training loss: 2.94408684684324
Validation loss: 2.4461614712914166

Epoch: 6| Step: 1
Training loss: 2.1675499313921525
Validation loss: 2.4539451578824845

Epoch: 6| Step: 2
Training loss: 2.4323721524521904
Validation loss: 2.470778005485772

Epoch: 6| Step: 3
Training loss: 2.6351303628599396
Validation loss: 2.4572908002998646

Epoch: 6| Step: 4
Training loss: 2.4948605160912254
Validation loss: 2.4529752500772766

Epoch: 6| Step: 5
Training loss: 2.5618808277414695
Validation loss: 2.458226832701643

Epoch: 6| Step: 6
Training loss: 1.9418480598734489
Validation loss: 2.4448751775168636

Epoch: 6| Step: 7
Training loss: 2.7704413765386557
Validation loss: 2.4293171394902706

Epoch: 6| Step: 8
Training loss: 2.8705416401545767
Validation loss: 2.446996570819684

Epoch: 6| Step: 9
Training loss: 2.299560222874785
Validation loss: 2.446684143009802

Epoch: 6| Step: 10
Training loss: 2.1173468385541154
Validation loss: 2.4597736101961627

Epoch: 6| Step: 11
Training loss: 3.155907036305372
Validation loss: 2.468263279309323

Epoch: 6| Step: 12
Training loss: 2.0107393417597637
Validation loss: 2.4513594031355654

Epoch: 6| Step: 13
Training loss: 2.6637982100335744
Validation loss: 2.4612286701608372

Epoch: 141| Step: 0
Training loss: 2.702102908904481
Validation loss: 2.4591314613292923

Epoch: 6| Step: 1
Training loss: 2.7525801259088425
Validation loss: 2.4688593948071116

Epoch: 6| Step: 2
Training loss: 2.7725182097708108
Validation loss: 2.437156727222941

Epoch: 6| Step: 3
Training loss: 2.7186108257582458
Validation loss: 2.449982654199563

Epoch: 6| Step: 4
Training loss: 2.439446674518593
Validation loss: 2.4633325535163286

Epoch: 6| Step: 5
Training loss: 2.545666366904138
Validation loss: 2.4678958855123008

Epoch: 6| Step: 6
Training loss: 2.5241035078561223
Validation loss: 2.440240759482615

Epoch: 6| Step: 7
Training loss: 2.2619852228601096
Validation loss: 2.455900047710246

Epoch: 6| Step: 8
Training loss: 2.524853382952704
Validation loss: 2.44597282301895

Epoch: 6| Step: 9
Training loss: 2.0930324862274166
Validation loss: 2.4482135743627547

Epoch: 6| Step: 10
Training loss: 2.1823310818143695
Validation loss: 2.4566460296093093

Epoch: 6| Step: 11
Training loss: 2.6282252525050573
Validation loss: 2.4567352611727187

Epoch: 6| Step: 12
Training loss: 2.6135987230085855
Validation loss: 2.475715350240304

Epoch: 6| Step: 13
Training loss: 2.2240679771202605
Validation loss: 2.4598901465697574

Epoch: 142| Step: 0
Training loss: 3.0967999461728573
Validation loss: 2.454900564703711

Epoch: 6| Step: 1
Training loss: 2.69984227885417
Validation loss: 2.4673416380180995

Epoch: 6| Step: 2
Training loss: 2.497512151709579
Validation loss: 2.4556159550785424

Epoch: 6| Step: 3
Training loss: 1.8938674865134515
Validation loss: 2.4504304875988194

Epoch: 6| Step: 4
Training loss: 2.2651116151234767
Validation loss: 2.4638379619128408

Epoch: 6| Step: 5
Training loss: 2.4654869050587376
Validation loss: 2.436585140266942

Epoch: 6| Step: 6
Training loss: 2.2565273336373286
Validation loss: 2.44637314922091

Epoch: 6| Step: 7
Training loss: 2.3027896631801004
Validation loss: 2.435486571175922

Epoch: 6| Step: 8
Training loss: 2.4847264071318476
Validation loss: 2.4625186203828893

Epoch: 6| Step: 9
Training loss: 2.5181818697622336
Validation loss: 2.461788165761659

Epoch: 6| Step: 10
Training loss: 2.1809721411771448
Validation loss: 2.461506656030771

Epoch: 6| Step: 11
Training loss: 2.9770046116053517
Validation loss: 2.4413737491536285

Epoch: 6| Step: 12
Training loss: 3.1592137990816807
Validation loss: 2.4536477320936068

Epoch: 6| Step: 13
Training loss: 1.2187215850647641
Validation loss: 2.440947560657557

Epoch: 143| Step: 0
Training loss: 2.294458896118334
Validation loss: 2.4299051861040515

Epoch: 6| Step: 1
Training loss: 2.589601255085299
Validation loss: 2.441469792939879

Epoch: 6| Step: 2
Training loss: 2.339206003642695
Validation loss: 2.4310375354138283

Epoch: 6| Step: 3
Training loss: 2.4134740019560343
Validation loss: 2.4311531594025872

Epoch: 6| Step: 4
Training loss: 3.1517044421238056
Validation loss: 2.434067051684536

Epoch: 6| Step: 5
Training loss: 2.342287141132289
Validation loss: 2.4708359798321835

Epoch: 6| Step: 6
Training loss: 2.9283812191962655
Validation loss: 2.466942246410134

Epoch: 6| Step: 7
Training loss: 1.6146751459740647
Validation loss: 2.454349943265133

Epoch: 6| Step: 8
Training loss: 2.6689905134184673
Validation loss: 2.4644550384716957

Epoch: 6| Step: 9
Training loss: 2.4090454905368794
Validation loss: 2.4647055129303905

Epoch: 6| Step: 10
Training loss: 2.387805148291731
Validation loss: 2.4480572763317183

Epoch: 6| Step: 11
Training loss: 2.4775322300174314
Validation loss: 2.4558558884762727

Epoch: 6| Step: 12
Training loss: 2.6307954844169963
Validation loss: 2.4686746903824623

Epoch: 6| Step: 13
Training loss: 2.812132578268021
Validation loss: 2.448859375501594

Epoch: 144| Step: 0
Training loss: 2.2494525243358043
Validation loss: 2.466588783725233

Epoch: 6| Step: 1
Training loss: 2.149808910660656
Validation loss: 2.453549297888029

Epoch: 6| Step: 2
Training loss: 2.914055954667582
Validation loss: 2.467336218434514

Epoch: 6| Step: 3
Training loss: 2.6100829300548893
Validation loss: 2.453264417331863

Epoch: 6| Step: 4
Training loss: 2.5388587283015474
Validation loss: 2.439465191495017

Epoch: 6| Step: 5
Training loss: 2.014016744420925
Validation loss: 2.4492714485294833

Epoch: 6| Step: 6
Training loss: 2.562622439552927
Validation loss: 2.433442890866045

Epoch: 6| Step: 7
Training loss: 2.6685637540844023
Validation loss: 2.4296329722850585

Epoch: 6| Step: 8
Training loss: 1.743401143169652
Validation loss: 2.4527019373416152

Epoch: 6| Step: 9
Training loss: 2.989736005936456
Validation loss: 2.4697363022797054

Epoch: 6| Step: 10
Training loss: 2.304422136967413
Validation loss: 2.4576977091778796

Epoch: 6| Step: 11
Training loss: 2.8801354691645575
Validation loss: 2.4585248150579435

Epoch: 6| Step: 12
Training loss: 2.641177689536908
Validation loss: 2.448491586177228

Epoch: 6| Step: 13
Training loss: 2.8130829948606424
Validation loss: 2.437688657718404

Epoch: 145| Step: 0
Training loss: 2.4791165728810722
Validation loss: 2.4646557396127515

Epoch: 6| Step: 1
Training loss: 1.938391818637247
Validation loss: 2.460860209464754

Epoch: 6| Step: 2
Training loss: 3.0109678685587404
Validation loss: 2.4267633227055527

Epoch: 6| Step: 3
Training loss: 2.8427137226423147
Validation loss: 2.458706346900453

Epoch: 6| Step: 4
Training loss: 2.848033989864214
Validation loss: 2.4544348630795185

Epoch: 6| Step: 5
Training loss: 2.857834698156509
Validation loss: 2.483221527082889

Epoch: 6| Step: 6
Training loss: 2.647940890133615
Validation loss: 2.458002290984284

Epoch: 6| Step: 7
Training loss: 2.816662061187169
Validation loss: 2.4394248512091843

Epoch: 6| Step: 8
Training loss: 1.6737394543088342
Validation loss: 2.4593798167366074

Epoch: 6| Step: 9
Training loss: 2.043374132596417
Validation loss: 2.450656624825397

Epoch: 6| Step: 10
Training loss: 2.463750581707395
Validation loss: 2.456808994851654

Epoch: 6| Step: 11
Training loss: 2.7228720974843883
Validation loss: 2.447146194749725

Epoch: 6| Step: 12
Training loss: 1.9441887853971795
Validation loss: 2.447858128909209

Epoch: 6| Step: 13
Training loss: 2.1930386859979674
Validation loss: 2.4459018525848233

Epoch: 146| Step: 0
Training loss: 2.1183695853928284
Validation loss: 2.440731915020296

Epoch: 6| Step: 1
Training loss: 1.9883494786995017
Validation loss: 2.44310177389191

Epoch: 6| Step: 2
Training loss: 2.83609302609222
Validation loss: 2.4375747669723067

Epoch: 6| Step: 3
Training loss: 2.568139731874822
Validation loss: 2.4605446987226705

Epoch: 6| Step: 4
Training loss: 1.730186766647549
Validation loss: 2.470265666874233

Epoch: 6| Step: 5
Training loss: 2.7298085474645557
Validation loss: 2.4734227321006315

Epoch: 6| Step: 6
Training loss: 2.48081388700597
Validation loss: 2.441332077376301

Epoch: 6| Step: 7
Training loss: 2.2430807321537656
Validation loss: 2.4425875544274396

Epoch: 6| Step: 8
Training loss: 2.5603014190370716
Validation loss: 2.4425941341062183

Epoch: 6| Step: 9
Training loss: 2.409687509815017
Validation loss: 2.448647019440059

Epoch: 6| Step: 10
Training loss: 3.154335272115368
Validation loss: 2.4661695505172903

Epoch: 6| Step: 11
Training loss: 2.422460472957607
Validation loss: 2.4561133308612555

Epoch: 6| Step: 12
Training loss: 2.633260354909997
Validation loss: 2.440623535695298

Epoch: 6| Step: 13
Training loss: 3.152705856003306
Validation loss: 2.4464696422428274

Epoch: 147| Step: 0
Training loss: 2.23894327169693
Validation loss: 2.450373220028242

Epoch: 6| Step: 1
Training loss: 2.692266628455259
Validation loss: 2.441399262842824

Epoch: 6| Step: 2
Training loss: 2.6068031291250424
Validation loss: 2.4733468236583787

Epoch: 6| Step: 3
Training loss: 2.1729367083036397
Validation loss: 2.4480915383264685

Epoch: 6| Step: 4
Training loss: 2.143665465531596
Validation loss: 2.4726166336993485

Epoch: 6| Step: 5
Training loss: 2.194716729066306
Validation loss: 2.452576548199473

Epoch: 6| Step: 6
Training loss: 2.638893778835473
Validation loss: 2.4465871167126827

Epoch: 6| Step: 7
Training loss: 2.2404091192336746
Validation loss: 2.4478367241081007

Epoch: 6| Step: 8
Training loss: 1.3894511637058524
Validation loss: 2.456104683133242

Epoch: 6| Step: 9
Training loss: 3.1527959978993434
Validation loss: 2.445137941064625

Epoch: 6| Step: 10
Training loss: 2.37641824238069
Validation loss: 2.436152678750973

Epoch: 6| Step: 11
Training loss: 2.469764404489643
Validation loss: 2.4582103342522674

Epoch: 6| Step: 12
Training loss: 3.270751725330873
Validation loss: 2.449821675206146

Epoch: 6| Step: 13
Training loss: 3.1723578325165804
Validation loss: 2.4637621639743057

Epoch: 148| Step: 0
Training loss: 2.4181125086631563
Validation loss: 2.452077789039696

Epoch: 6| Step: 1
Training loss: 2.314876675379662
Validation loss: 2.4608250053334877

Epoch: 6| Step: 2
Training loss: 1.94046691643797
Validation loss: 2.451112270410856

Epoch: 6| Step: 3
Training loss: 2.2846885789470295
Validation loss: 2.450783411390165

Epoch: 6| Step: 4
Training loss: 2.638570403795842
Validation loss: 2.4611007592002743

Epoch: 6| Step: 5
Training loss: 2.2464246953878377
Validation loss: 2.4406151277222885

Epoch: 6| Step: 6
Training loss: 2.707964583504806
Validation loss: 2.4546524965773004

Epoch: 6| Step: 7
Training loss: 2.8786041225454984
Validation loss: 2.4510072201871718

Epoch: 6| Step: 8
Training loss: 2.874945101006499
Validation loss: 2.466158965029114

Epoch: 6| Step: 9
Training loss: 2.661265496262156
Validation loss: 2.4384960771870783

Epoch: 6| Step: 10
Training loss: 2.4375086075068375
Validation loss: 2.4523782308669007

Epoch: 6| Step: 11
Training loss: 2.2456178376582328
Validation loss: 2.459963354237446

Epoch: 6| Step: 12
Training loss: 2.691117624162429
Validation loss: 2.4438981129793675

Epoch: 6| Step: 13
Training loss: 2.2136386506020926
Validation loss: 2.453433644744981

Epoch: 149| Step: 0
Training loss: 2.1511568372681222
Validation loss: 2.4382120611635374

Epoch: 6| Step: 1
Training loss: 2.4438025349387273
Validation loss: 2.449243730837414

Epoch: 6| Step: 2
Training loss: 3.02942563243853
Validation loss: 2.4711648561716646

Epoch: 6| Step: 3
Training loss: 2.625620450762989
Validation loss: 2.454709755174501

Epoch: 6| Step: 4
Training loss: 2.461286150742864
Validation loss: 2.459603858512134

Epoch: 6| Step: 5
Training loss: 1.7224713353843375
Validation loss: 2.4607725771482007

Epoch: 6| Step: 6
Training loss: 2.5921337193387815
Validation loss: 2.43953619260308

Epoch: 6| Step: 7
Training loss: 2.7705959323534595
Validation loss: 2.4636432196906006

Epoch: 6| Step: 8
Training loss: 2.4493462682987084
Validation loss: 2.454077313265578

Epoch: 6| Step: 9
Training loss: 2.6548755455661324
Validation loss: 2.466456553468669

Epoch: 6| Step: 10
Training loss: 2.196922716298122
Validation loss: 2.452873883347549

Epoch: 6| Step: 11
Training loss: 2.1706715275165642
Validation loss: 2.4662207704154793

Epoch: 6| Step: 12
Training loss: 2.463454155580726
Validation loss: 2.4486310772962048

Epoch: 6| Step: 13
Training loss: 3.22945069735406
Validation loss: 2.4630302837257494

Epoch: 150| Step: 0
Training loss: 2.3748704975357957
Validation loss: 2.453363059417987

Epoch: 6| Step: 1
Training loss: 1.8475962461765012
Validation loss: 2.4401467906038534

Epoch: 6| Step: 2
Training loss: 3.3394690944831056
Validation loss: 2.454634447179101

Epoch: 6| Step: 3
Training loss: 2.2637544473723397
Validation loss: 2.4469807755982087

Epoch: 6| Step: 4
Training loss: 2.548093913648678
Validation loss: 2.4497364353622206

Epoch: 6| Step: 5
Training loss: 2.8528668490525195
Validation loss: 2.4232677994575997

Epoch: 6| Step: 6
Training loss: 1.6666265800741533
Validation loss: 2.453875476335626

Epoch: 6| Step: 7
Training loss: 2.4871018517609436
Validation loss: 2.4454045741474264

Epoch: 6| Step: 8
Training loss: 2.6830858752270257
Validation loss: 2.4647841203138894

Epoch: 6| Step: 9
Training loss: 2.406836896390197
Validation loss: 2.4454545925257247

Epoch: 6| Step: 10
Training loss: 2.621641280950055
Validation loss: 2.454555442684843

Epoch: 6| Step: 11
Training loss: 2.542913620874201
Validation loss: 2.4645874260428675

Epoch: 6| Step: 12
Training loss: 2.1178668857057206
Validation loss: 2.4355706508643133

Epoch: 6| Step: 13
Training loss: 2.434588625426261
Validation loss: 2.437529245311051

Epoch: 151| Step: 0
Training loss: 3.1773155419378085
Validation loss: 2.4530433383587997

Epoch: 6| Step: 1
Training loss: 2.4149816053491597
Validation loss: 2.4506090559423495

Epoch: 6| Step: 2
Training loss: 2.5481399484045757
Validation loss: 2.425624253742949

Epoch: 6| Step: 3
Training loss: 2.131950232062697
Validation loss: 2.4580438835248226

Epoch: 6| Step: 4
Training loss: 2.3965848545688773
Validation loss: 2.4519089950142052

Epoch: 6| Step: 5
Training loss: 1.7061149879109812
Validation loss: 2.4466902370188754

Epoch: 6| Step: 6
Training loss: 2.4687531869602153
Validation loss: 2.430516415782367

Epoch: 6| Step: 7
Training loss: 2.8944696376075925
Validation loss: 2.4497846794228826

Epoch: 6| Step: 8
Training loss: 2.807287344755244
Validation loss: 2.4334341994465367

Epoch: 6| Step: 9
Training loss: 2.385738489910919
Validation loss: 2.434228707105915

Epoch: 6| Step: 10
Training loss: 2.0602460162468312
Validation loss: 2.4436782879684342

Epoch: 6| Step: 11
Training loss: 2.7262111317182662
Validation loss: 2.4527494949010062

Epoch: 6| Step: 12
Training loss: 2.139080297759687
Validation loss: 2.440921184171713

Epoch: 6| Step: 13
Training loss: 2.6154982851752435
Validation loss: 2.438401716202819

Epoch: 152| Step: 0
Training loss: 2.222357168338832
Validation loss: 2.438296162523669

Epoch: 6| Step: 1
Training loss: 2.8866690294580577
Validation loss: 2.4333599955836713

Epoch: 6| Step: 2
Training loss: 2.607348906106789
Validation loss: 2.4460740030560464

Epoch: 6| Step: 3
Training loss: 1.7607327089144482
Validation loss: 2.4663915868505684

Epoch: 6| Step: 4
Training loss: 2.6808566998748127
Validation loss: 2.4507253047465714

Epoch: 6| Step: 5
Training loss: 2.5579315027367078
Validation loss: 2.4362208741508455

Epoch: 6| Step: 6
Training loss: 2.40047564561595
Validation loss: 2.4276350996969693

Epoch: 6| Step: 7
Training loss: 2.802934954440735
Validation loss: 2.4488670474860106

Epoch: 6| Step: 8
Training loss: 2.223805216060312
Validation loss: 2.4262592413514756

Epoch: 6| Step: 9
Training loss: 2.6591642661598374
Validation loss: 2.443057980408413

Epoch: 6| Step: 10
Training loss: 2.013386155734481
Validation loss: 2.4370520479609286

Epoch: 6| Step: 11
Training loss: 2.4629519982068655
Validation loss: 2.4342634259702782

Epoch: 6| Step: 12
Training loss: 2.790998113108769
Validation loss: 2.447535813830539

Epoch: 6| Step: 13
Training loss: 2.491831595619522
Validation loss: 2.449750650929597

Epoch: 153| Step: 0
Training loss: 2.4633507899937817
Validation loss: 2.473279990356037

Epoch: 6| Step: 1
Training loss: 2.317908689146996
Validation loss: 2.4562744725977264

Epoch: 6| Step: 2
Training loss: 2.448336842506063
Validation loss: 2.4420746858797764

Epoch: 6| Step: 3
Training loss: 2.261523935100666
Validation loss: 2.4521836276717273

Epoch: 6| Step: 4
Training loss: 2.972717525136374
Validation loss: 2.4509017606592844

Epoch: 6| Step: 5
Training loss: 2.443258477070899
Validation loss: 2.447680418771085

Epoch: 6| Step: 6
Training loss: 1.5930935872970435
Validation loss: 2.459345424819461

Epoch: 6| Step: 7
Training loss: 2.63215008561084
Validation loss: 2.4465958965783963

Epoch: 6| Step: 8
Training loss: 1.8846744179275572
Validation loss: 2.4456172421541527

Epoch: 6| Step: 9
Training loss: 2.1271239493213288
Validation loss: 2.445236016672617

Epoch: 6| Step: 10
Training loss: 2.078275746779257
Validation loss: 2.4234861838526207

Epoch: 6| Step: 11
Training loss: 2.9775448277043237
Validation loss: 2.4313418994312013

Epoch: 6| Step: 12
Training loss: 2.9824992571411744
Validation loss: 2.4462697504093587

Epoch: 6| Step: 13
Training loss: 2.9992088228276548
Validation loss: 2.4580188127324414

Epoch: 154| Step: 0
Training loss: 2.5449962590458024
Validation loss: 2.4451504334887244

Epoch: 6| Step: 1
Training loss: 2.3448439016219464
Validation loss: 2.4498746652796033

Epoch: 6| Step: 2
Training loss: 2.6273017056424877
Validation loss: 2.437561435098792

Epoch: 6| Step: 3
Training loss: 2.768782887145083
Validation loss: 2.4673803685760523

Epoch: 6| Step: 4
Training loss: 2.077195727012231
Validation loss: 2.442444653789734

Epoch: 6| Step: 5
Training loss: 2.109633366338486
Validation loss: 2.441120284201446

Epoch: 6| Step: 6
Training loss: 2.0878584228544512
Validation loss: 2.446827667771352

Epoch: 6| Step: 7
Training loss: 2.724481613828017
Validation loss: 2.459703372002748

Epoch: 6| Step: 8
Training loss: 2.7553554752819127
Validation loss: 2.4294329318877064

Epoch: 6| Step: 9
Training loss: 2.05535784907552
Validation loss: 2.4541402408544792

Epoch: 6| Step: 10
Training loss: 2.4470208876029713
Validation loss: 2.448907085673595

Epoch: 6| Step: 11
Training loss: 2.3342270728941585
Validation loss: 2.448325653226077

Epoch: 6| Step: 12
Training loss: 3.170093957128319
Validation loss: 2.457843605206982

Epoch: 6| Step: 13
Training loss: 2.4171797985898644
Validation loss: 2.4306899174724204

Epoch: 155| Step: 0
Training loss: 2.7837052384243473
Validation loss: 2.4392253058972035

Epoch: 6| Step: 1
Training loss: 2.3959628083999633
Validation loss: 2.468175832456441

Epoch: 6| Step: 2
Training loss: 1.7226419945643865
Validation loss: 2.4566136223751087

Epoch: 6| Step: 3
Training loss: 3.0005491072074095
Validation loss: 2.4400759448967198

Epoch: 6| Step: 4
Training loss: 2.559419967386753
Validation loss: 2.4418707744400434

Epoch: 6| Step: 5
Training loss: 2.775854985948498
Validation loss: 2.4539269047867998

Epoch: 6| Step: 6
Training loss: 2.192490579721881
Validation loss: 2.4528052092380457

Epoch: 6| Step: 7
Training loss: 2.1231888177020983
Validation loss: 2.454136206533984

Epoch: 6| Step: 8
Training loss: 2.437995664622432
Validation loss: 2.4462022994206145

Epoch: 6| Step: 9
Training loss: 2.2120074052462524
Validation loss: 2.45056914180707

Epoch: 6| Step: 10
Training loss: 2.7130370351173716
Validation loss: 2.442795015164904

Epoch: 6| Step: 11
Training loss: 2.617351469910187
Validation loss: 2.471525637923469

Epoch: 6| Step: 12
Training loss: 1.6433373691181719
Validation loss: 2.4365530433231326

Epoch: 6| Step: 13
Training loss: 3.348530284683692
Validation loss: 2.442516315596445

Epoch: 156| Step: 0
Training loss: 3.3522813288456343
Validation loss: 2.4626986096871617

Epoch: 6| Step: 1
Training loss: 2.1100174667213976
Validation loss: 2.4370069128626497

Epoch: 6| Step: 2
Training loss: 2.772941609496625
Validation loss: 2.4436386508948815

Epoch: 6| Step: 3
Training loss: 2.119531776436594
Validation loss: 2.4474727640931846

Epoch: 6| Step: 4
Training loss: 2.722835408997346
Validation loss: 2.4457743873990228

Epoch: 6| Step: 5
Training loss: 1.9366604616565848
Validation loss: 2.4572134101873586

Epoch: 6| Step: 6
Training loss: 2.3950475537510743
Validation loss: 2.4399295033929462

Epoch: 6| Step: 7
Training loss: 2.380768846976618
Validation loss: 2.4392889466383663

Epoch: 6| Step: 8
Training loss: 2.8455543243526025
Validation loss: 2.4468856228550813

Epoch: 6| Step: 9
Training loss: 2.1524787763552773
Validation loss: 2.462119794808314

Epoch: 6| Step: 10
Training loss: 2.415833055387202
Validation loss: 2.4332203870726024

Epoch: 6| Step: 11
Training loss: 1.9289182295645493
Validation loss: 2.4628959960754027

Epoch: 6| Step: 12
Training loss: 2.4075429836092286
Validation loss: 2.460266835488902

Epoch: 6| Step: 13
Training loss: 2.797276302935736
Validation loss: 2.4659511702741836

Epoch: 157| Step: 0
Training loss: 2.189638019414829
Validation loss: 2.4442659117396914

Epoch: 6| Step: 1
Training loss: 1.9330828367384123
Validation loss: 2.455745613233504

Epoch: 6| Step: 2
Training loss: 2.8162823992413495
Validation loss: 2.443679295095483

Epoch: 6| Step: 3
Training loss: 2.907030554517352
Validation loss: 2.431965573784876

Epoch: 6| Step: 4
Training loss: 2.8879791522766185
Validation loss: 2.4300199171205703

Epoch: 6| Step: 5
Training loss: 2.139605536960092
Validation loss: 2.4492723696210743

Epoch: 6| Step: 6
Training loss: 2.83184552866246
Validation loss: 2.424753056884017

Epoch: 6| Step: 7
Training loss: 2.837315248364819
Validation loss: 2.426328952090498

Epoch: 6| Step: 8
Training loss: 2.507089100542029
Validation loss: 2.449104763976069

Epoch: 6| Step: 9
Training loss: 1.9463580282484507
Validation loss: 2.442498678222847

Epoch: 6| Step: 10
Training loss: 2.5334097043455133
Validation loss: 2.4614841773962546

Epoch: 6| Step: 11
Training loss: 2.043081714431829
Validation loss: 2.4420317778537237

Epoch: 6| Step: 12
Training loss: 2.071826309391456
Validation loss: 2.4524997562052375

Epoch: 6| Step: 13
Training loss: 2.5129537675569
Validation loss: 2.446382128961509

Epoch: 158| Step: 0
Training loss: 2.4490729232280066
Validation loss: 2.443090710691553

Epoch: 6| Step: 1
Training loss: 2.3403960580740777
Validation loss: 2.438760179797676

Epoch: 6| Step: 2
Training loss: 2.324601137136723
Validation loss: 2.469772203047939

Epoch: 6| Step: 3
Training loss: 2.136344360803237
Validation loss: 2.434495432458736

Epoch: 6| Step: 4
Training loss: 2.541854872275643
Validation loss: 2.407234187722388

Epoch: 6| Step: 5
Training loss: 2.529006906037651
Validation loss: 2.4334365219022187

Epoch: 6| Step: 6
Training loss: 2.9666017489527725
Validation loss: 2.4590534728716698

Epoch: 6| Step: 7
Training loss: 2.164347605739817
Validation loss: 2.4512901051139537

Epoch: 6| Step: 8
Training loss: 2.3077108950966756
Validation loss: 2.438014157918999

Epoch: 6| Step: 9
Training loss: 2.573149347530622
Validation loss: 2.4312105391108236

Epoch: 6| Step: 10
Training loss: 2.6630096592486225
Validation loss: 2.4382477910326292

Epoch: 6| Step: 11
Training loss: 2.624807259886008
Validation loss: 2.4575767371313555

Epoch: 6| Step: 12
Training loss: 2.0756316177368346
Validation loss: 2.4316184016388096

Epoch: 6| Step: 13
Training loss: 2.442125479996142
Validation loss: 2.4439343324630958

Epoch: 159| Step: 0
Training loss: 2.6853523544608895
Validation loss: 2.4314455281817193

Epoch: 6| Step: 1
Training loss: 2.468815476720215
Validation loss: 2.4529706484326796

Epoch: 6| Step: 2
Training loss: 2.4639087965298527
Validation loss: 2.4349576471833227

Epoch: 6| Step: 3
Training loss: 2.2491103638759133
Validation loss: 2.4375223201363987

Epoch: 6| Step: 4
Training loss: 2.670965385644036
Validation loss: 2.421979067680635

Epoch: 6| Step: 5
Training loss: 2.371961054792612
Validation loss: 2.4256084836968625

Epoch: 6| Step: 6
Training loss: 2.443230763564072
Validation loss: 2.457866030564762

Epoch: 6| Step: 7
Training loss: 2.763861746045055
Validation loss: 2.4619775379526376

Epoch: 6| Step: 8
Training loss: 2.254374807435512
Validation loss: 2.4264209689743583

Epoch: 6| Step: 9
Training loss: 2.5359416855867436
Validation loss: 2.4447917764494678

Epoch: 6| Step: 10
Training loss: 2.237968489546955
Validation loss: 2.4434119538635075

Epoch: 6| Step: 11
Training loss: 2.4368191281625533
Validation loss: 2.447161434200594

Epoch: 6| Step: 12
Training loss: 2.3479832375495095
Validation loss: 2.439509096765175

Epoch: 6| Step: 13
Training loss: 2.433095914763377
Validation loss: 2.447749852501267

Epoch: 160| Step: 0
Training loss: 3.034321595339774
Validation loss: 2.4569443195084317

Epoch: 6| Step: 1
Training loss: 2.0268954036696103
Validation loss: 2.4323819480042674

Epoch: 6| Step: 2
Training loss: 2.4546489477013647
Validation loss: 2.4561182167880276

Epoch: 6| Step: 3
Training loss: 2.4174694722880328
Validation loss: 2.4483260909136404

Epoch: 6| Step: 4
Training loss: 3.2855831054895894
Validation loss: 2.4533253468987177

Epoch: 6| Step: 5
Training loss: 2.779062932798454
Validation loss: 2.4252111199472375

Epoch: 6| Step: 6
Training loss: 2.34290440882213
Validation loss: 2.453895653149209

Epoch: 6| Step: 7
Training loss: 2.4096057825847406
Validation loss: 2.438283768511374

Epoch: 6| Step: 8
Training loss: 2.087688496924977
Validation loss: 2.445468720813016

Epoch: 6| Step: 9
Training loss: 2.5654163048042644
Validation loss: 2.4604634529126312

Epoch: 6| Step: 10
Training loss: 2.193340895889988
Validation loss: 2.463867538146673

Epoch: 6| Step: 11
Training loss: 2.253928886842022
Validation loss: 2.4708015242987083

Epoch: 6| Step: 12
Training loss: 1.4361285426059365
Validation loss: 2.423849124666593

Epoch: 6| Step: 13
Training loss: 2.2265869139286525
Validation loss: 2.4376586344981184

Epoch: 161| Step: 0
Training loss: 2.6246966232103097
Validation loss: 2.4356429496228627

Epoch: 6| Step: 1
Training loss: 2.325978153339367
Validation loss: 2.4317929453395055

Epoch: 6| Step: 2
Training loss: 2.0115267467536375
Validation loss: 2.4264580748071256

Epoch: 6| Step: 3
Training loss: 1.7519872145382214
Validation loss: 2.4478976400592014

Epoch: 6| Step: 4
Training loss: 2.69477109032438
Validation loss: 2.4654280884824646

Epoch: 6| Step: 5
Training loss: 2.3834710883853196
Validation loss: 2.4459561339581732

Epoch: 6| Step: 6
Training loss: 2.3630656498697795
Validation loss: 2.4258773742656756

Epoch: 6| Step: 7
Training loss: 2.5938709644468045
Validation loss: 2.4488543447563207

Epoch: 6| Step: 8
Training loss: 2.749148323650823
Validation loss: 2.4531883789093496

Epoch: 6| Step: 9
Training loss: 2.467284334878277
Validation loss: 2.4648556942774924

Epoch: 6| Step: 10
Training loss: 2.5856962984659257
Validation loss: 2.4442115624126655

Epoch: 6| Step: 11
Training loss: 2.8102229755487813
Validation loss: 2.4319678971159804

Epoch: 6| Step: 12
Training loss: 2.070581497854603
Validation loss: 2.4573227766024766

Epoch: 6| Step: 13
Training loss: 2.6374792739993933
Validation loss: 2.465973403387368

Epoch: 162| Step: 0
Training loss: 2.12297331709766
Validation loss: 2.4507108186675417

Epoch: 6| Step: 1
Training loss: 3.1950981982308293
Validation loss: 2.461651309876345

Epoch: 6| Step: 2
Training loss: 2.16831205931814
Validation loss: 2.4623032829191454

Epoch: 6| Step: 3
Training loss: 2.146070251225099
Validation loss: 2.433610532266203

Epoch: 6| Step: 4
Training loss: 2.124196405493171
Validation loss: 2.4537304528917123

Epoch: 6| Step: 5
Training loss: 2.20563315610818
Validation loss: 2.4532037527311714

Epoch: 6| Step: 6
Training loss: 2.4274528996998543
Validation loss: 2.4484942744215967

Epoch: 6| Step: 7
Training loss: 2.1622022214284438
Validation loss: 2.4278112174991553

Epoch: 6| Step: 8
Training loss: 2.80216794553919
Validation loss: 2.4667627797972607

Epoch: 6| Step: 9
Training loss: 2.3842295951054115
Validation loss: 2.446718050696651

Epoch: 6| Step: 10
Training loss: 2.8746413960923767
Validation loss: 2.4611181247234426

Epoch: 6| Step: 11
Training loss: 2.780572873100885
Validation loss: 2.4392710410491687

Epoch: 6| Step: 12
Training loss: 2.2211449820144407
Validation loss: 2.4511652022531054

Epoch: 6| Step: 13
Training loss: 2.1231241361286695
Validation loss: 2.4220148644895767

Epoch: 163| Step: 0
Training loss: 2.396305889021125
Validation loss: 2.4278420562434144

Epoch: 6| Step: 1
Training loss: 2.688925786286277
Validation loss: 2.4604196102818006

Epoch: 6| Step: 2
Training loss: 2.4406124686140456
Validation loss: 2.43345851637999

Epoch: 6| Step: 3
Training loss: 2.7007159484790133
Validation loss: 2.4617656449181724

Epoch: 6| Step: 4
Training loss: 2.687883926292336
Validation loss: 2.4388724734015614

Epoch: 6| Step: 5
Training loss: 2.773476269947987
Validation loss: 2.4384755237869253

Epoch: 6| Step: 6
Training loss: 2.808860458422621
Validation loss: 2.43824135944249

Epoch: 6| Step: 7
Training loss: 2.3446574171135297
Validation loss: 2.4329714044748414

Epoch: 6| Step: 8
Training loss: 2.899211934317305
Validation loss: 2.433296000651791

Epoch: 6| Step: 9
Training loss: 1.9081550834176022
Validation loss: 2.4498225971373206

Epoch: 6| Step: 10
Training loss: 2.07792157776551
Validation loss: 2.4430271479987544

Epoch: 6| Step: 11
Training loss: 1.7827946173049365
Validation loss: 2.4534103596485437

Epoch: 6| Step: 12
Training loss: 1.8146117174955685
Validation loss: 2.450375814140657

Epoch: 6| Step: 13
Training loss: 2.2399893695715294
Validation loss: 2.4544424659340756

Epoch: 164| Step: 0
Training loss: 2.352468322475768
Validation loss: 2.454003761812999

Epoch: 6| Step: 1
Training loss: 2.553756030762246
Validation loss: 2.4570974062647233

Epoch: 6| Step: 2
Training loss: 1.7255268011230782
Validation loss: 2.4481175909446744

Epoch: 6| Step: 3
Training loss: 2.448959507219192
Validation loss: 2.451594052467616

Epoch: 6| Step: 4
Training loss: 2.205022549330097
Validation loss: 2.4377291376844963

Epoch: 6| Step: 5
Training loss: 2.4676839723963986
Validation loss: 2.4376662823144257

Epoch: 6| Step: 6
Training loss: 2.7225183263184642
Validation loss: 2.4334907110276682

Epoch: 6| Step: 7
Training loss: 2.555316905843252
Validation loss: 2.4472826235847434

Epoch: 6| Step: 8
Training loss: 2.3445381365290086
Validation loss: 2.4529637161636884

Epoch: 6| Step: 9
Training loss: 2.6805937988856168
Validation loss: 2.4388488937083372

Epoch: 6| Step: 10
Training loss: 1.8546104614403753
Validation loss: 2.447352605976445

Epoch: 6| Step: 11
Training loss: 2.8093259066661744
Validation loss: 2.4480260230680595

Epoch: 6| Step: 12
Training loss: 2.9103817026763754
Validation loss: 2.4665405409422423

Epoch: 6| Step: 13
Training loss: 1.9200990115902077
Validation loss: 2.447106131941909

Epoch: 165| Step: 0
Training loss: 2.4278571296524833
Validation loss: 2.4385523221790355

Epoch: 6| Step: 1
Training loss: 1.783889888953361
Validation loss: 2.4181737753052888

Epoch: 6| Step: 2
Training loss: 2.4381646448357723
Validation loss: 2.453639503011966

Epoch: 6| Step: 3
Training loss: 2.526050454874908
Validation loss: 2.4589120337719668

Epoch: 6| Step: 4
Training loss: 2.488407533037158
Validation loss: 2.4347044450972875

Epoch: 6| Step: 5
Training loss: 2.8211214802091407
Validation loss: 2.4384213744728487

Epoch: 6| Step: 6
Training loss: 2.6103865438815346
Validation loss: 2.448677794174237

Epoch: 6| Step: 7
Training loss: 2.27753982877608
Validation loss: 2.437495251344105

Epoch: 6| Step: 8
Training loss: 2.414982987495982
Validation loss: 2.467471411462177

Epoch: 6| Step: 9
Training loss: 2.548014473668885
Validation loss: 2.415362788878199

Epoch: 6| Step: 10
Training loss: 2.5581741105358082
Validation loss: 2.451955277745561

Epoch: 6| Step: 11
Training loss: 1.8197813773633127
Validation loss: 2.4604957518745465

Epoch: 6| Step: 12
Training loss: 2.374937357829314
Validation loss: 2.4553314260268824

Epoch: 6| Step: 13
Training loss: 2.9838043785813295
Validation loss: 2.4382391225236826

Epoch: 166| Step: 0
Training loss: 1.940411318503424
Validation loss: 2.4346157991920228

Epoch: 6| Step: 1
Training loss: 1.8295522481834203
Validation loss: 2.41462360905439

Epoch: 6| Step: 2
Training loss: 2.2998649184323607
Validation loss: 2.4390919550670054

Epoch: 6| Step: 3
Training loss: 3.0352567953101697
Validation loss: 2.4447320718860994

Epoch: 6| Step: 4
Training loss: 2.5758005471818475
Validation loss: 2.4111865401273596

Epoch: 6| Step: 5
Training loss: 2.3308355950008255
Validation loss: 2.425037903907589

Epoch: 6| Step: 6
Training loss: 2.611284573747479
Validation loss: 2.445696669032059

Epoch: 6| Step: 7
Training loss: 2.4773157941623727
Validation loss: 2.4580649282749385

Epoch: 6| Step: 8
Training loss: 2.4879750972188415
Validation loss: 2.4364410479183474

Epoch: 6| Step: 9
Training loss: 2.078079337858888
Validation loss: 2.473956879300703

Epoch: 6| Step: 10
Training loss: 2.653280415829969
Validation loss: 2.428316541803122

Epoch: 6| Step: 11
Training loss: 2.4654522853451204
Validation loss: 2.4628784526008807

Epoch: 6| Step: 12
Training loss: 2.510873607874207
Validation loss: 2.44326416699941

Epoch: 6| Step: 13
Training loss: 2.483314143710485
Validation loss: 2.4590227607452633

Epoch: 167| Step: 0
Training loss: 2.1478779011979685
Validation loss: 2.4431017633985253

Epoch: 6| Step: 1
Training loss: 3.152201860867301
Validation loss: 2.4466814103405565

Epoch: 6| Step: 2
Training loss: 2.7392061986837484
Validation loss: 2.466697324458633

Epoch: 6| Step: 3
Training loss: 2.1990964594662756
Validation loss: 2.4550247366053104

Epoch: 6| Step: 4
Training loss: 2.1419809321134484
Validation loss: 2.4455290258872915

Epoch: 6| Step: 5
Training loss: 2.1917853749935006
Validation loss: 2.4441075802173033

Epoch: 6| Step: 6
Training loss: 2.237546470628361
Validation loss: 2.439599981810142

Epoch: 6| Step: 7
Training loss: 2.854052650420463
Validation loss: 2.4653394481573763

Epoch: 6| Step: 8
Training loss: 2.4989785968891294
Validation loss: 2.4695485418738095

Epoch: 6| Step: 9
Training loss: 2.739804354455953
Validation loss: 2.418444021448403

Epoch: 6| Step: 10
Training loss: 2.0894466985552698
Validation loss: 2.4435458843899722

Epoch: 6| Step: 11
Training loss: 1.7044079349414583
Validation loss: 2.4316260062493753

Epoch: 6| Step: 12
Training loss: 2.4960817148697534
Validation loss: 2.442444475354197

Epoch: 6| Step: 13
Training loss: 2.1211682722794416
Validation loss: 2.444121386936224

Epoch: 168| Step: 0
Training loss: 2.0697834994483415
Validation loss: 2.4562864736791052

Epoch: 6| Step: 1
Training loss: 2.1719546955224125
Validation loss: 2.4353522911213883

Epoch: 6| Step: 2
Training loss: 1.8609689243843954
Validation loss: 2.4451090840024565

Epoch: 6| Step: 3
Training loss: 2.328028939332715
Validation loss: 2.450577377014487

Epoch: 6| Step: 4
Training loss: 2.589970512222274
Validation loss: 2.4445000726380592

Epoch: 6| Step: 5
Training loss: 2.166215727414459
Validation loss: 2.4503045888286543

Epoch: 6| Step: 6
Training loss: 2.3382198959137117
Validation loss: 2.4614992770455943

Epoch: 6| Step: 7
Training loss: 3.1761157620950335
Validation loss: 2.438558121121631

Epoch: 6| Step: 8
Training loss: 2.594365609891105
Validation loss: 2.4406545045588754

Epoch: 6| Step: 9
Training loss: 2.5988295121205716
Validation loss: 2.475158724186055

Epoch: 6| Step: 10
Training loss: 2.319130027866295
Validation loss: 2.479313382193413

Epoch: 6| Step: 11
Training loss: 1.9907394831388117
Validation loss: 2.454486504371286

Epoch: 6| Step: 12
Training loss: 2.9271528749361675
Validation loss: 2.4411610228403235

Epoch: 6| Step: 13
Training loss: 2.283201140964974
Validation loss: 2.469313515020747

Epoch: 169| Step: 0
Training loss: 2.71378662604765
Validation loss: 2.4341153946159966

Epoch: 6| Step: 1
Training loss: 2.6510007264299236
Validation loss: 2.4547866096216167

Epoch: 6| Step: 2
Training loss: 2.7939942937968807
Validation loss: 2.44398788812481

Epoch: 6| Step: 3
Training loss: 1.9921512376065513
Validation loss: 2.4377743382832437

Epoch: 6| Step: 4
Training loss: 2.0847187267830174
Validation loss: 2.433640275707089

Epoch: 6| Step: 5
Training loss: 2.122898633566482
Validation loss: 2.439279598165246

Epoch: 6| Step: 6
Training loss: 2.930854259854093
Validation loss: 2.4439350195455423

Epoch: 6| Step: 7
Training loss: 2.2900165743831873
Validation loss: 2.4417959103944016

Epoch: 6| Step: 8
Training loss: 2.361946372099259
Validation loss: 2.447908512399498

Epoch: 6| Step: 9
Training loss: 1.861717863799031
Validation loss: 2.458168832132257

Epoch: 6| Step: 10
Training loss: 1.8867406113268277
Validation loss: 2.4228404115944198

Epoch: 6| Step: 11
Training loss: 3.0279126229623805
Validation loss: 2.4311405518189

Epoch: 6| Step: 12
Training loss: 2.5043814412037264
Validation loss: 2.428339065645609

Epoch: 6| Step: 13
Training loss: 2.248711853043061
Validation loss: 2.419005314384853

Epoch: 170| Step: 0
Training loss: 2.2669049034954463
Validation loss: 2.4435011645830325

Epoch: 6| Step: 1
Training loss: 2.8722291945916587
Validation loss: 2.4572731896821107

Epoch: 6| Step: 2
Training loss: 1.9214720885180028
Validation loss: 2.42560517240749

Epoch: 6| Step: 3
Training loss: 2.023074555709449
Validation loss: 2.435503589868395

Epoch: 6| Step: 4
Training loss: 2.2027563774199272
Validation loss: 2.4493484908870333

Epoch: 6| Step: 5
Training loss: 2.5159775386226158
Validation loss: 2.453246370261066

Epoch: 6| Step: 6
Training loss: 2.6637444180412646
Validation loss: 2.4361502415495884

Epoch: 6| Step: 7
Training loss: 2.547095353593071
Validation loss: 2.4317914472948337

Epoch: 6| Step: 8
Training loss: 2.648728256244352
Validation loss: 2.4524249688778443

Epoch: 6| Step: 9
Training loss: 2.539528390249901
Validation loss: 2.480311808563989

Epoch: 6| Step: 10
Training loss: 2.431310375415192
Validation loss: 2.4349808929064976

Epoch: 6| Step: 11
Training loss: 2.5076326204715333
Validation loss: 2.446223695467185

Epoch: 6| Step: 12
Training loss: 2.3157314713642947
Validation loss: 2.45046257957692

Epoch: 6| Step: 13
Training loss: 2.064414436317056
Validation loss: 2.434923573620488

Epoch: 171| Step: 0
Training loss: 2.0562406406363505
Validation loss: 2.452644073704016

Epoch: 6| Step: 1
Training loss: 2.257338635833665
Validation loss: 2.4629605084375314

Epoch: 6| Step: 2
Training loss: 2.330585280653066
Validation loss: 2.4372868093649993

Epoch: 6| Step: 3
Training loss: 2.6346589357395236
Validation loss: 2.4298496767919313

Epoch: 6| Step: 4
Training loss: 2.117902909356204
Validation loss: 2.4451796350019066

Epoch: 6| Step: 5
Training loss: 2.2457980019285593
Validation loss: 2.4424623282899116

Epoch: 6| Step: 6
Training loss: 2.1129909464059486
Validation loss: 2.4461544573678666

Epoch: 6| Step: 7
Training loss: 2.1066318335651206
Validation loss: 2.4477207696290932

Epoch: 6| Step: 8
Training loss: 2.1871211132532387
Validation loss: 2.4790970387603597

Epoch: 6| Step: 9
Training loss: 3.682625862866008
Validation loss: 2.465315751411026

Epoch: 6| Step: 10
Training loss: 2.1950451019450044
Validation loss: 2.444269395979307

Epoch: 6| Step: 11
Training loss: 2.6120550588964977
Validation loss: 2.433288053582102

Epoch: 6| Step: 12
Training loss: 2.234266798694055
Validation loss: 2.4426111830430712

Epoch: 6| Step: 13
Training loss: 2.36384744718659
Validation loss: 2.4394292051673188

Epoch: 172| Step: 0
Training loss: 2.6131393781848984
Validation loss: 2.4392451099244408

Epoch: 6| Step: 1
Training loss: 2.1383006152501567
Validation loss: 2.4257709083589662

Epoch: 6| Step: 2
Training loss: 2.1724355509409117
Validation loss: 2.4588687298765337

Epoch: 6| Step: 3
Training loss: 2.741838394939801
Validation loss: 2.432955849592458

Epoch: 6| Step: 4
Training loss: 2.423836190873465
Validation loss: 2.4405413801177493

Epoch: 6| Step: 5
Training loss: 2.7422778340211305
Validation loss: 2.42996406174797

Epoch: 6| Step: 6
Training loss: 2.772614606822428
Validation loss: 2.4529025022181146

Epoch: 6| Step: 7
Training loss: 1.6284555959858207
Validation loss: 2.4310320064234525

Epoch: 6| Step: 8
Training loss: 2.291686861353817
Validation loss: 2.4351385129334164

Epoch: 6| Step: 9
Training loss: 2.3648793263527104
Validation loss: 2.471307304622064

Epoch: 6| Step: 10
Training loss: 2.1229080674206613
Validation loss: 2.460526226814619

Epoch: 6| Step: 11
Training loss: 2.4675351787560067
Validation loss: 2.41094700426339

Epoch: 6| Step: 12
Training loss: 2.359283748655753
Validation loss: 2.42221660077192

Epoch: 6| Step: 13
Training loss: 2.8356085972756113
Validation loss: 2.4211749591719

Epoch: 173| Step: 0
Training loss: 1.6183782791407364
Validation loss: 2.4482983091163106

Epoch: 6| Step: 1
Training loss: 2.3634105804617147
Validation loss: 2.428209245315457

Epoch: 6| Step: 2
Training loss: 3.1059417940127934
Validation loss: 2.433129517656741

Epoch: 6| Step: 3
Training loss: 2.524796536245738
Validation loss: 2.4508473409144385

Epoch: 6| Step: 4
Training loss: 2.6502165543945213
Validation loss: 2.4526340716301216

Epoch: 6| Step: 5
Training loss: 2.3324391377349576
Validation loss: 2.4459257919205357

Epoch: 6| Step: 6
Training loss: 2.4287244844691545
Validation loss: 2.4149167114976673

Epoch: 6| Step: 7
Training loss: 2.0092740806284257
Validation loss: 2.432047726014721

Epoch: 6| Step: 8
Training loss: 1.5689984037538265
Validation loss: 2.4414489621599795

Epoch: 6| Step: 9
Training loss: 2.1429131523260256
Validation loss: 2.446904964659323

Epoch: 6| Step: 10
Training loss: 2.473175331820174
Validation loss: 2.4471930735411243

Epoch: 6| Step: 11
Training loss: 2.636259544793002
Validation loss: 2.4187695470356454

Epoch: 6| Step: 12
Training loss: 2.875500842711674
Validation loss: 2.4335408710412865

Epoch: 6| Step: 13
Training loss: 2.590221164642644
Validation loss: 2.423882503021341

Epoch: 174| Step: 0
Training loss: 2.4518649029627166
Validation loss: 2.4488920497076725

Epoch: 6| Step: 1
Training loss: 2.73878776882912
Validation loss: 2.468520232069599

Epoch: 6| Step: 2
Training loss: 2.708011246138059
Validation loss: 2.42219731001894

Epoch: 6| Step: 3
Training loss: 2.1584580767114514
Validation loss: 2.4167733297971226

Epoch: 6| Step: 4
Training loss: 2.0733746608936925
Validation loss: 2.4484639230027176

Epoch: 6| Step: 5
Training loss: 2.118804089241194
Validation loss: 2.4123046349583808

Epoch: 6| Step: 6
Training loss: 2.578097071640869
Validation loss: 2.444382837674549

Epoch: 6| Step: 7
Training loss: 2.567513840887841
Validation loss: 2.4620151788545814

Epoch: 6| Step: 8
Training loss: 1.6327843184525985
Validation loss: 2.427050366935435

Epoch: 6| Step: 9
Training loss: 2.3800313759987546
Validation loss: 2.4314081926910327

Epoch: 6| Step: 10
Training loss: 2.5155717358370224
Validation loss: 2.4190679122639356

Epoch: 6| Step: 11
Training loss: 2.5967768277594585
Validation loss: 2.452551214027042

Epoch: 6| Step: 12
Training loss: 1.8892818755817278
Validation loss: 2.433939721919201

Epoch: 6| Step: 13
Training loss: 3.0029679558029088
Validation loss: 2.4524672298937493

Epoch: 175| Step: 0
Training loss: 2.8560868832278015
Validation loss: 2.455411356708465

Epoch: 6| Step: 1
Training loss: 2.6873175980525144
Validation loss: 2.418875979833587

Epoch: 6| Step: 2
Training loss: 2.70155324057321
Validation loss: 2.4319514693043107

Epoch: 6| Step: 3
Training loss: 2.4706087478886745
Validation loss: 2.456074853717793

Epoch: 6| Step: 4
Training loss: 1.8670446109764547
Validation loss: 2.433931998142626

Epoch: 6| Step: 5
Training loss: 2.4463521191661037
Validation loss: 2.450109350080031

Epoch: 6| Step: 6
Training loss: 2.7891733697818855
Validation loss: 2.4342838727606178

Epoch: 6| Step: 7
Training loss: 2.198932744293973
Validation loss: 2.452069016256406

Epoch: 6| Step: 8
Training loss: 2.6372721677610227
Validation loss: 2.4701280227964846

Epoch: 6| Step: 9
Training loss: 1.6146679107499522
Validation loss: 2.449709957810876

Epoch: 6| Step: 10
Training loss: 1.5581338533776563
Validation loss: 2.4671307122573607

Epoch: 6| Step: 11
Training loss: 2.6329571149371005
Validation loss: 2.435806908535525

Epoch: 6| Step: 12
Training loss: 2.358678449668514
Validation loss: 2.4531526665230943

Epoch: 6| Step: 13
Training loss: 2.3229443558438243
Validation loss: 2.440925681448872

Epoch: 176| Step: 0
Training loss: 2.2668872342595963
Validation loss: 2.440500099604108

Epoch: 6| Step: 1
Training loss: 2.7044804873433455
Validation loss: 2.4414128150113346

Epoch: 6| Step: 2
Training loss: 2.373565843136976
Validation loss: 2.4437320847572295

Epoch: 6| Step: 3
Training loss: 2.139593836663555
Validation loss: 2.4282226061010026

Epoch: 6| Step: 4
Training loss: 2.8053373896142815
Validation loss: 2.4311864696401324

Epoch: 6| Step: 5
Training loss: 2.244320907854503
Validation loss: 2.427379027329306

Epoch: 6| Step: 6
Training loss: 2.5927346321837113
Validation loss: 2.4092833661041113

Epoch: 6| Step: 7
Training loss: 2.093134775443614
Validation loss: 2.433451005990078

Epoch: 6| Step: 8
Training loss: 2.547061468681928
Validation loss: 2.419185759368523

Epoch: 6| Step: 9
Training loss: 2.363843917070249
Validation loss: 2.4447297680258133

Epoch: 6| Step: 10
Training loss: 2.534534819017055
Validation loss: 2.4429258417683473

Epoch: 6| Step: 11
Training loss: 2.2560323805751037
Validation loss: 2.4049650745372855

Epoch: 6| Step: 12
Training loss: 2.087256882267255
Validation loss: 2.4074330611799497

Epoch: 6| Step: 13
Training loss: 1.880342374833434
Validation loss: 2.4599925758339163

Epoch: 177| Step: 0
Training loss: 2.891854184654748
Validation loss: 2.437179224590637

Epoch: 6| Step: 1
Training loss: 1.6820666120313996
Validation loss: 2.446821224158311

Epoch: 6| Step: 2
Training loss: 2.47031459241244
Validation loss: 2.413778584977286

Epoch: 6| Step: 3
Training loss: 2.012605045965284
Validation loss: 2.4311141659466227

Epoch: 6| Step: 4
Training loss: 2.555953525801263
Validation loss: 2.450065505018691

Epoch: 6| Step: 5
Training loss: 2.585918875912447
Validation loss: 2.423701779414834

Epoch: 6| Step: 6
Training loss: 2.4556139328673963
Validation loss: 2.432627574332869

Epoch: 6| Step: 7
Training loss: 2.5950472241994356
Validation loss: 2.429376366015617

Epoch: 6| Step: 8
Training loss: 1.980825418411809
Validation loss: 2.4366088144643885

Epoch: 6| Step: 9
Training loss: 1.8848358299343855
Validation loss: 2.4615262557994435

Epoch: 6| Step: 10
Training loss: 2.3656016662333776
Validation loss: 2.455506520473158

Epoch: 6| Step: 11
Training loss: 2.3575923829570806
Validation loss: 2.4449774578025076

Epoch: 6| Step: 12
Training loss: 2.606066405052631
Validation loss: 2.4422054030595453

Epoch: 6| Step: 13
Training loss: 3.0952781217034118
Validation loss: 2.4651490056870626

Epoch: 178| Step: 0
Training loss: 1.7663294644308303
Validation loss: 2.44659648860783

Epoch: 6| Step: 1
Training loss: 2.7160515383295483
Validation loss: 2.420972109458357

Epoch: 6| Step: 2
Training loss: 2.572915564985979
Validation loss: 2.424390877923786

Epoch: 6| Step: 3
Training loss: 2.4707170207119122
Validation loss: 2.447946412571868

Epoch: 6| Step: 4
Training loss: 2.120354455070359
Validation loss: 2.4222737979330833

Epoch: 6| Step: 5
Training loss: 2.704529942904432
Validation loss: 2.4408616096964577

Epoch: 6| Step: 6
Training loss: 2.101731644527705
Validation loss: 2.4099724195349976

Epoch: 6| Step: 7
Training loss: 2.4952953894595242
Validation loss: 2.4210854134041875

Epoch: 6| Step: 8
Training loss: 2.183254918541845
Validation loss: 2.428167015036631

Epoch: 6| Step: 9
Training loss: 1.6163687729766083
Validation loss: 2.428723388807791

Epoch: 6| Step: 10
Training loss: 2.621440836045087
Validation loss: 2.4327991756551923

Epoch: 6| Step: 11
Training loss: 2.104920721124199
Validation loss: 2.4386218780933424

Epoch: 6| Step: 12
Training loss: 2.3758414936048187
Validation loss: 2.4268081423119092

Epoch: 6| Step: 13
Training loss: 3.5785756722700564
Validation loss: 2.41721828821386

Epoch: 179| Step: 0
Training loss: 2.484908712387424
Validation loss: 2.4286156695827477

Epoch: 6| Step: 1
Training loss: 2.318231850694451
Validation loss: 2.4224111333410305

Epoch: 6| Step: 2
Training loss: 1.9059875807942952
Validation loss: 2.4596568400428027

Epoch: 6| Step: 3
Training loss: 2.3938995075597727
Validation loss: 2.430658179332107

Epoch: 6| Step: 4
Training loss: 1.760059192485715
Validation loss: 2.4279156801155333

Epoch: 6| Step: 5
Training loss: 2.3225986508215
Validation loss: 2.4515348168279623

Epoch: 6| Step: 6
Training loss: 3.0233392428417836
Validation loss: 2.4141907846865855

Epoch: 6| Step: 7
Training loss: 2.51142513760041
Validation loss: 2.4411767816808285

Epoch: 6| Step: 8
Training loss: 1.7040609885033642
Validation loss: 2.432731465513906

Epoch: 6| Step: 9
Training loss: 2.9681840859157136
Validation loss: 2.426763770620485

Epoch: 6| Step: 10
Training loss: 2.559578509501373
Validation loss: 2.4367761738846454

Epoch: 6| Step: 11
Training loss: 2.2692005225084317
Validation loss: 2.4463241483262355

Epoch: 6| Step: 12
Training loss: 1.7775690292281943
Validation loss: 2.4285322975887547

Epoch: 6| Step: 13
Training loss: 2.890334656026552
Validation loss: 2.4332133405866005

Epoch: 180| Step: 0
Training loss: 1.7668223414419066
Validation loss: 2.451374839148986

Epoch: 6| Step: 1
Training loss: 1.7320700786059866
Validation loss: 2.4317779880442036

Epoch: 6| Step: 2
Training loss: 2.6055109343766905
Validation loss: 2.44148793231133

Epoch: 6| Step: 3
Training loss: 2.8035065016027354
Validation loss: 2.4646618432743623

Epoch: 6| Step: 4
Training loss: 2.201913703537154
Validation loss: 2.452502088307218

Epoch: 6| Step: 5
Training loss: 2.0775258053715877
Validation loss: 2.4173972387276543

Epoch: 6| Step: 6
Training loss: 1.7313714353202339
Validation loss: 2.4531031081748145

Epoch: 6| Step: 7
Training loss: 2.571059283729977
Validation loss: 2.4086794692361013

Epoch: 6| Step: 8
Training loss: 2.6714882375524973
Validation loss: 2.418251587889193

Epoch: 6| Step: 9
Training loss: 2.7337080659863924
Validation loss: 2.4415001011027018

Epoch: 6| Step: 10
Training loss: 2.403300570856799
Validation loss: 2.454534429467612

Epoch: 6| Step: 11
Training loss: 2.3854026849550727
Validation loss: 2.435307805615332

Epoch: 6| Step: 12
Training loss: 2.85287721190914
Validation loss: 2.4373890367970863

Epoch: 6| Step: 13
Training loss: 1.947185426703892
Validation loss: 2.45949617945658

Epoch: 181| Step: 0
Training loss: 2.523836275603278
Validation loss: 2.441361771898271

Epoch: 6| Step: 1
Training loss: 1.7045292795743192
Validation loss: 2.444219816942692

Epoch: 6| Step: 2
Training loss: 2.098727671883315
Validation loss: 2.4620384533758455

Epoch: 6| Step: 3
Training loss: 2.6729090067356527
Validation loss: 2.4444689186222113

Epoch: 6| Step: 4
Training loss: 1.930395266818217
Validation loss: 2.4394426095925823

Epoch: 6| Step: 5
Training loss: 2.4993107799341048
Validation loss: 2.4254935572220986

Epoch: 6| Step: 6
Training loss: 2.95548860128312
Validation loss: 2.4436477781166444

Epoch: 6| Step: 7
Training loss: 2.4890266870866493
Validation loss: 2.437914087184233

Epoch: 6| Step: 8
Training loss: 2.2181066735553987
Validation loss: 2.431428941847408

Epoch: 6| Step: 9
Training loss: 2.4432287143134097
Validation loss: 2.426447129068081

Epoch: 6| Step: 10
Training loss: 2.1061684431365544
Validation loss: 2.441659913632411

Epoch: 6| Step: 11
Training loss: 2.1513738368031605
Validation loss: 2.427472043606029

Epoch: 6| Step: 12
Training loss: 2.5427174715041736
Validation loss: 2.419484060025694

Epoch: 6| Step: 13
Training loss: 2.614154572812059
Validation loss: 2.4316383087361984

Epoch: 182| Step: 0
Training loss: 2.7500372797433177
Validation loss: 2.4305366451701693

Epoch: 6| Step: 1
Training loss: 2.241265296692355
Validation loss: 2.4522700641317545

Epoch: 6| Step: 2
Training loss: 2.586334105903729
Validation loss: 2.4454406738237844

Epoch: 6| Step: 3
Training loss: 2.5243577725832496
Validation loss: 2.441496609760963

Epoch: 6| Step: 4
Training loss: 2.913536208339393
Validation loss: 2.4426508252445664

Epoch: 6| Step: 5
Training loss: 2.274877557498717
Validation loss: 2.452851596298207

Epoch: 6| Step: 6
Training loss: 2.2519389381193413
Validation loss: 2.4300354011227654

Epoch: 6| Step: 7
Training loss: 2.192276671289234
Validation loss: 2.437040276160715

Epoch: 6| Step: 8
Training loss: 2.239474366368606
Validation loss: 2.397420578009075

Epoch: 6| Step: 9
Training loss: 2.071923546776112
Validation loss: 2.45431437887098

Epoch: 6| Step: 10
Training loss: 2.095013706827049
Validation loss: 2.4505675872411823

Epoch: 6| Step: 11
Training loss: 1.650611059150916
Validation loss: 2.452370808734447

Epoch: 6| Step: 12
Training loss: 2.5487489885344097
Validation loss: 2.432313140108925

Epoch: 6| Step: 13
Training loss: 2.384778321878311
Validation loss: 2.435651799463233

Epoch: 183| Step: 0
Training loss: 2.459993696127157
Validation loss: 2.420610584321921

Epoch: 6| Step: 1
Training loss: 2.5994813401744277
Validation loss: 2.4212235436287517

Epoch: 6| Step: 2
Training loss: 2.170068332457621
Validation loss: 2.447060113693692

Epoch: 6| Step: 3
Training loss: 3.211850669933481
Validation loss: 2.466628603369956

Epoch: 6| Step: 4
Training loss: 2.3401917977265208
Validation loss: 2.4418208516827558

Epoch: 6| Step: 5
Training loss: 2.317397318913983
Validation loss: 2.42510936969537

Epoch: 6| Step: 6
Training loss: 2.4009272175044503
Validation loss: 2.4471864852756404

Epoch: 6| Step: 7
Training loss: 2.4886235790628968
Validation loss: 2.4379968518064845

Epoch: 6| Step: 8
Training loss: 2.1927493734135948
Validation loss: 2.4303901942695436

Epoch: 6| Step: 9
Training loss: 1.6723021202319865
Validation loss: 2.435252375762989

Epoch: 6| Step: 10
Training loss: 2.339403317988651
Validation loss: 2.447374463344483

Epoch: 6| Step: 11
Training loss: 2.153515173297726
Validation loss: 2.4448003824018714

Epoch: 6| Step: 12
Training loss: 1.8623424540202433
Validation loss: 2.446270565737301

Epoch: 6| Step: 13
Training loss: 2.6245785329431346
Validation loss: 2.4564536764543057

Epoch: 184| Step: 0
Training loss: 3.00982392667413
Validation loss: 2.429901285627979

Epoch: 6| Step: 1
Training loss: 2.565019810769241
Validation loss: 2.4380995731098456

Epoch: 6| Step: 2
Training loss: 2.511793927481086
Validation loss: 2.440322934635617

Epoch: 6| Step: 3
Training loss: 2.0897972030447156
Validation loss: 2.422999482657324

Epoch: 6| Step: 4
Training loss: 2.163664192424357
Validation loss: 2.4422974116989113

Epoch: 6| Step: 5
Training loss: 1.99827340222556
Validation loss: 2.423435808323202

Epoch: 6| Step: 6
Training loss: 2.211173216854365
Validation loss: 2.4403757559314867

Epoch: 6| Step: 7
Training loss: 1.8169535806969173
Validation loss: 2.440007239448167

Epoch: 6| Step: 8
Training loss: 1.9980091676854923
Validation loss: 2.451093472214468

Epoch: 6| Step: 9
Training loss: 2.2506479813732687
Validation loss: 2.462094973768477

Epoch: 6| Step: 10
Training loss: 3.2106903797849693
Validation loss: 2.4346432527482764

Epoch: 6| Step: 11
Training loss: 2.011409165347602
Validation loss: 2.4506223082037333

Epoch: 6| Step: 12
Training loss: 1.8943895424612187
Validation loss: 2.4244658913446133

Epoch: 6| Step: 13
Training loss: 3.061167680187275
Validation loss: 2.4181917030012667

Epoch: 185| Step: 0
Training loss: 1.5866316605694628
Validation loss: 2.4304098793669824

Epoch: 6| Step: 1
Training loss: 2.463418539463753
Validation loss: 2.4239777739951767

Epoch: 6| Step: 2
Training loss: 2.241094555461361
Validation loss: 2.4296415295812333

Epoch: 6| Step: 3
Training loss: 1.8771334272750393
Validation loss: 2.42942261581611

Epoch: 6| Step: 4
Training loss: 1.9670386975452163
Validation loss: 2.4465032867412044

Epoch: 6| Step: 5
Training loss: 2.7062003221423265
Validation loss: 2.4144677146212556

Epoch: 6| Step: 6
Training loss: 2.861834859406148
Validation loss: 2.404425576228256

Epoch: 6| Step: 7
Training loss: 2.449943861026243
Validation loss: 2.4435925274794807

Epoch: 6| Step: 8
Training loss: 2.757860394026843
Validation loss: 2.4251586258748308

Epoch: 6| Step: 9
Training loss: 2.1176156036995333
Validation loss: 2.4296034620439158

Epoch: 6| Step: 10
Training loss: 2.7273084609262734
Validation loss: 2.434110052716594

Epoch: 6| Step: 11
Training loss: 1.9127985303668125
Validation loss: 2.3984409343073207

Epoch: 6| Step: 12
Training loss: 2.56028018729419
Validation loss: 2.4387072940747383

Epoch: 6| Step: 13
Training loss: 2.1446464243605425
Validation loss: 2.4249749178023237

Epoch: 186| Step: 0
Training loss: 2.311889155360785
Validation loss: 2.4100871075288723

Epoch: 6| Step: 1
Training loss: 2.6514481168587936
Validation loss: 2.4234172603736583

Epoch: 6| Step: 2
Training loss: 2.2383238570333925
Validation loss: 2.451589402219461

Epoch: 6| Step: 3
Training loss: 2.329131043445496
Validation loss: 2.426979429945123

Epoch: 6| Step: 4
Training loss: 2.623612991107056
Validation loss: 2.4198383406697435

Epoch: 6| Step: 5
Training loss: 2.3250952342227977
Validation loss: 2.460335998415854

Epoch: 6| Step: 6
Training loss: 2.967344573786482
Validation loss: 2.444072784590115

Epoch: 6| Step: 7
Training loss: 2.101066105299667
Validation loss: 2.4422430059686784

Epoch: 6| Step: 8
Training loss: 2.1097994907078754
Validation loss: 2.44019779294443

Epoch: 6| Step: 9
Training loss: 2.0576058320907595
Validation loss: 2.4418243205132546

Epoch: 6| Step: 10
Training loss: 2.5730175868536733
Validation loss: 2.4457074106951824

Epoch: 6| Step: 11
Training loss: 2.269650060593591
Validation loss: 2.424395152609121

Epoch: 6| Step: 12
Training loss: 1.9564722294463386
Validation loss: 2.4561954634495815

Epoch: 6| Step: 13
Training loss: 1.8921379782183785
Validation loss: 2.4274142935424865

Epoch: 187| Step: 0
Training loss: 2.816060757973172
Validation loss: 2.438216450933479

Epoch: 6| Step: 1
Training loss: 2.8898852252278524
Validation loss: 2.4453265253182637

Epoch: 6| Step: 2
Training loss: 2.0900447570534983
Validation loss: 2.4221404259313863

Epoch: 6| Step: 3
Training loss: 2.1854213102404705
Validation loss: 2.446263458332139

Epoch: 6| Step: 4
Training loss: 2.133643802263856
Validation loss: 2.457044198429718

Epoch: 6| Step: 5
Training loss: 1.7799203829157761
Validation loss: 2.4360393305213943

Epoch: 6| Step: 6
Training loss: 2.0809657822105
Validation loss: 2.4303067623690433

Epoch: 6| Step: 7
Training loss: 2.357213931642873
Validation loss: 2.4472558827369935

Epoch: 6| Step: 8
Training loss: 2.544286711586974
Validation loss: 2.4347667646503224

Epoch: 6| Step: 9
Training loss: 2.367213384404944
Validation loss: 2.4287883655276516

Epoch: 6| Step: 10
Training loss: 2.046577490231667
Validation loss: 2.423716173066097

Epoch: 6| Step: 11
Training loss: 1.8964564658251504
Validation loss: 2.4385366625471505

Epoch: 6| Step: 12
Training loss: 2.205547110570482
Validation loss: 2.452434756986142

Epoch: 6| Step: 13
Training loss: 3.604141073558691
Validation loss: 2.4381993512892546

Epoch: 188| Step: 0
Training loss: 2.881401398957046
Validation loss: 2.4206433687114455

Epoch: 6| Step: 1
Training loss: 2.154680869774856
Validation loss: 2.4055814279019123

Epoch: 6| Step: 2
Training loss: 2.3232817997227224
Validation loss: 2.4501150547039785

Epoch: 6| Step: 3
Training loss: 1.7080247026484066
Validation loss: 2.4460919206823037

Epoch: 6| Step: 4
Training loss: 2.2522266814008893
Validation loss: 2.4435167614489592

Epoch: 6| Step: 5
Training loss: 2.202211014562667
Validation loss: 2.410967839129307

Epoch: 6| Step: 6
Training loss: 1.8562999269084015
Validation loss: 2.428931018363449

Epoch: 6| Step: 7
Training loss: 2.1807005794216323
Validation loss: 2.43969079779405

Epoch: 6| Step: 8
Training loss: 2.625249759962861
Validation loss: 2.4422245100536784

Epoch: 6| Step: 9
Training loss: 2.7083108363073043
Validation loss: 2.438539479248786

Epoch: 6| Step: 10
Training loss: 2.463634067170904
Validation loss: 2.4403253687201825

Epoch: 6| Step: 11
Training loss: 2.676413713318187
Validation loss: 2.4473568924075333

Epoch: 6| Step: 12
Training loss: 1.9262882826439978
Validation loss: 2.436936708061463

Epoch: 6| Step: 13
Training loss: 1.986439089455998
Validation loss: 2.4289431318528742

Epoch: 189| Step: 0
Training loss: 2.566992380687431
Validation loss: 2.435153709620138

Epoch: 6| Step: 1
Training loss: 2.34697145957156
Validation loss: 2.4420021255978215

Epoch: 6| Step: 2
Training loss: 2.557960956159195
Validation loss: 2.424383761362279

Epoch: 6| Step: 3
Training loss: 2.7503946194581133
Validation loss: 2.427278770561024

Epoch: 6| Step: 4
Training loss: 2.57455141178494
Validation loss: 2.428402753622526

Epoch: 6| Step: 5
Training loss: 1.921822275818647
Validation loss: 2.4497082132817134

Epoch: 6| Step: 6
Training loss: 2.4599732462660993
Validation loss: 2.4719067468431555

Epoch: 6| Step: 7
Training loss: 2.3316294261620616
Validation loss: 2.424387241395189

Epoch: 6| Step: 8
Training loss: 2.3569534708705806
Validation loss: 2.4383004943149413

Epoch: 6| Step: 9
Training loss: 1.7106279066937093
Validation loss: 2.4230592751734585

Epoch: 6| Step: 10
Training loss: 2.6655350807470373
Validation loss: 2.453360504514996

Epoch: 6| Step: 11
Training loss: 2.1141229388273697
Validation loss: 2.4139797484434395

Epoch: 6| Step: 12
Training loss: 1.7366896983405364
Validation loss: 2.4046421387073194

Epoch: 6| Step: 13
Training loss: 2.060533915836026
Validation loss: 2.430217702875221

Epoch: 190| Step: 0
Training loss: 2.3482011362647324
Validation loss: 2.412148367463776

Epoch: 6| Step: 1
Training loss: 2.6972160362419784
Validation loss: 2.4490119391575633

Epoch: 6| Step: 2
Training loss: 2.4825964745467854
Validation loss: 2.4295688190378004

Epoch: 6| Step: 3
Training loss: 1.6333313624052237
Validation loss: 2.437917394373921

Epoch: 6| Step: 4
Training loss: 2.072436010203437
Validation loss: 2.4291509705850114

Epoch: 6| Step: 5
Training loss: 2.1792212640500708
Validation loss: 2.4250181339737362

Epoch: 6| Step: 6
Training loss: 2.6331814923350665
Validation loss: 2.433196462863187

Epoch: 6| Step: 7
Training loss: 2.24887183834208
Validation loss: 2.4220773411913923

Epoch: 6| Step: 8
Training loss: 2.657297802874036
Validation loss: 2.4473618240985298

Epoch: 6| Step: 9
Training loss: 1.9461778301757218
Validation loss: 2.4467263805932458

Epoch: 6| Step: 10
Training loss: 2.6247642047881756
Validation loss: 2.43496593203126

Epoch: 6| Step: 11
Training loss: 2.445082778621518
Validation loss: 2.4425503094799574

Epoch: 6| Step: 12
Training loss: 2.1893180921227717
Validation loss: 2.4188867240178444

Epoch: 6| Step: 13
Training loss: 1.9434057488970726
Validation loss: 2.4424286627649723

Epoch: 191| Step: 0
Training loss: 2.5599657878973847
Validation loss: 2.451821002509956

Epoch: 6| Step: 1
Training loss: 1.9192155875782673
Validation loss: 2.424694869890007

Epoch: 6| Step: 2
Training loss: 2.6281069579168532
Validation loss: 2.4420722818828886

Epoch: 6| Step: 3
Training loss: 2.212017321334264
Validation loss: 2.4419426116132756

Epoch: 6| Step: 4
Training loss: 2.988930625419288
Validation loss: 2.3982482068002327

Epoch: 6| Step: 5
Training loss: 2.516584699024311
Validation loss: 2.4236657388517675

Epoch: 6| Step: 6
Training loss: 1.833393233216587
Validation loss: 2.4255979780265235

Epoch: 6| Step: 7
Training loss: 1.416335665611046
Validation loss: 2.417242683430718

Epoch: 6| Step: 8
Training loss: 2.0763583597457203
Validation loss: 2.428970894387539

Epoch: 6| Step: 9
Training loss: 2.271352119564425
Validation loss: 2.417606741282789

Epoch: 6| Step: 10
Training loss: 2.577153803222436
Validation loss: 2.443948468489924

Epoch: 6| Step: 11
Training loss: 2.170455688410898
Validation loss: 2.45337802931963

Epoch: 6| Step: 12
Training loss: 2.4228039344371473
Validation loss: 2.4277820964105983

Epoch: 6| Step: 13
Training loss: 2.444882291054982
Validation loss: 2.4208631928538797

Epoch: 192| Step: 0
Training loss: 2.4219727527210324
Validation loss: 2.4184076168467703

Epoch: 6| Step: 1
Training loss: 2.1894605297878798
Validation loss: 2.426240151273718

Epoch: 6| Step: 2
Training loss: 1.9611737842229122
Validation loss: 2.449078263893912

Epoch: 6| Step: 3
Training loss: 2.096786574476241
Validation loss: 2.447746237060743

Epoch: 6| Step: 4
Training loss: 2.244675800729009
Validation loss: 2.396077891989755

Epoch: 6| Step: 5
Training loss: 3.3293268603637656
Validation loss: 2.4026054095095444

Epoch: 6| Step: 6
Training loss: 2.0879094664505917
Validation loss: 2.4209139300716447

Epoch: 6| Step: 7
Training loss: 2.400461740581
Validation loss: 2.4354589439680585

Epoch: 6| Step: 8
Training loss: 2.0306639779653968
Validation loss: 2.4581267546602037

Epoch: 6| Step: 9
Training loss: 2.7936076253843725
Validation loss: 2.443958490375708

Epoch: 6| Step: 10
Training loss: 2.2399557351098403
Validation loss: 2.423737653379635

Epoch: 6| Step: 11
Training loss: 1.6110808581584781
Validation loss: 2.4179108227898567

Epoch: 6| Step: 12
Training loss: 2.192802541948562
Validation loss: 2.4280934294043215

Epoch: 6| Step: 13
Training loss: 1.8277206625834732
Validation loss: 2.427823192967648

Epoch: 193| Step: 0
Training loss: 3.069218952839427
Validation loss: 2.4147640241319457

Epoch: 6| Step: 1
Training loss: 1.8640492773746178
Validation loss: 2.436672311017125

Epoch: 6| Step: 2
Training loss: 2.2721618009563804
Validation loss: 2.431723665342545

Epoch: 6| Step: 3
Training loss: 2.5955412780501126
Validation loss: 2.416594858202416

Epoch: 6| Step: 4
Training loss: 2.674189763938731
Validation loss: 2.433318315100867

Epoch: 6| Step: 5
Training loss: 1.4762874932498176
Validation loss: 2.405572236177006

Epoch: 6| Step: 6
Training loss: 2.034673300347736
Validation loss: 2.433474491552253

Epoch: 6| Step: 7
Training loss: 1.8692408169128876
Validation loss: 2.450144214834878

Epoch: 6| Step: 8
Training loss: 2.137329125964013
Validation loss: 2.442906879832775

Epoch: 6| Step: 9
Training loss: 2.669217042458514
Validation loss: 2.4375177513719346

Epoch: 6| Step: 10
Training loss: 2.405194930585413
Validation loss: 2.4243853517516856

Epoch: 6| Step: 11
Training loss: 2.400557286410669
Validation loss: 2.433445164325565

Epoch: 6| Step: 12
Training loss: 2.140120843701816
Validation loss: 2.4212063705614266

Epoch: 6| Step: 13
Training loss: 1.6738515560686795
Validation loss: 2.435221542430613

Epoch: 194| Step: 0
Training loss: 2.828855978564645
Validation loss: 2.4353099099552455

Epoch: 6| Step: 1
Training loss: 2.0338574619893346
Validation loss: 2.463503765858843

Epoch: 6| Step: 2
Training loss: 1.9109749940826104
Validation loss: 2.4195545238206844

Epoch: 6| Step: 3
Training loss: 2.762070866735659
Validation loss: 2.4461625565220197

Epoch: 6| Step: 4
Training loss: 2.188784848670497
Validation loss: 2.4517485022015286

Epoch: 6| Step: 5
Training loss: 2.066301714555193
Validation loss: 2.4121452056201718

Epoch: 6| Step: 6
Training loss: 1.6551668476005663
Validation loss: 2.394818510943042

Epoch: 6| Step: 7
Training loss: 2.1349825037790993
Validation loss: 2.459238842575918

Epoch: 6| Step: 8
Training loss: 2.2680125317370297
Validation loss: 2.4330254854200595

Epoch: 6| Step: 9
Training loss: 2.298495078127431
Validation loss: 2.4465942357516974

Epoch: 6| Step: 10
Training loss: 2.129981093345153
Validation loss: 2.447588852345271

Epoch: 6| Step: 11
Training loss: 2.89382180439987
Validation loss: 2.4129888617000863

Epoch: 6| Step: 12
Training loss: 2.1585619045673927
Validation loss: 2.418459484691663

Epoch: 6| Step: 13
Training loss: 2.70921785631478
Validation loss: 2.4614176620153323

Epoch: 195| Step: 0
Training loss: 2.1956054926395776
Validation loss: 2.434786504914767

Epoch: 6| Step: 1
Training loss: 2.212719741512689
Validation loss: 2.399596950782244

Epoch: 6| Step: 2
Training loss: 2.1302058461617
Validation loss: 2.426779688449354

Epoch: 6| Step: 3
Training loss: 2.6824156106009385
Validation loss: 2.4539785369189318

Epoch: 6| Step: 4
Training loss: 2.3474137217436284
Validation loss: 2.4734421819943244

Epoch: 6| Step: 5
Training loss: 2.194297909035743
Validation loss: 2.4291835864178286

Epoch: 6| Step: 6
Training loss: 2.2443431102215468
Validation loss: 2.458854975208272

Epoch: 6| Step: 7
Training loss: 2.219985295668009
Validation loss: 2.4780273349563338

Epoch: 6| Step: 8
Training loss: 2.0875384298659014
Validation loss: 2.399684234453209

Epoch: 6| Step: 9
Training loss: 2.464025588354784
Validation loss: 2.441854455245918

Epoch: 6| Step: 10
Training loss: 2.097445514685126
Validation loss: 2.4530925457277655

Epoch: 6| Step: 11
Training loss: 2.8133597861156705
Validation loss: 2.4303370810517197

Epoch: 6| Step: 12
Training loss: 2.2357826333891784
Validation loss: 2.4536163462949947

Epoch: 6| Step: 13
Training loss: 1.9001197425855376
Validation loss: 2.42771719941322

Epoch: 196| Step: 0
Training loss: 1.8558721806480425
Validation loss: 2.4391267279426745

Epoch: 6| Step: 1
Training loss: 2.621784420517533
Validation loss: 2.435660947141455

Epoch: 6| Step: 2
Training loss: 2.142484873269807
Validation loss: 2.4412507626478166

Epoch: 6| Step: 3
Training loss: 1.861573530353054
Validation loss: 2.4102869283420296

Epoch: 6| Step: 4
Training loss: 2.392629344158395
Validation loss: 2.4371328495440756

Epoch: 6| Step: 5
Training loss: 2.848420217255492
Validation loss: 2.4253668111126734

Epoch: 6| Step: 6
Training loss: 2.041234054923634
Validation loss: 2.438448123890159

Epoch: 6| Step: 7
Training loss: 2.259579293919612
Validation loss: 2.457678901372846

Epoch: 6| Step: 8
Training loss: 2.7051174339991366
Validation loss: 2.429120523644942

Epoch: 6| Step: 9
Training loss: 2.2410804062274323
Validation loss: 2.4377031470395787

Epoch: 6| Step: 10
Training loss: 1.954973612458474
Validation loss: 2.433781445434904

Epoch: 6| Step: 11
Training loss: 1.9678256574569182
Validation loss: 2.4191985479414115

Epoch: 6| Step: 12
Training loss: 2.612923773020507
Validation loss: 2.4442700913582627

Epoch: 6| Step: 13
Training loss: 2.4404457094812195
Validation loss: 2.4439494975340987

Epoch: 197| Step: 0
Training loss: 2.4376512138217357
Validation loss: 2.4204152249320097

Epoch: 6| Step: 1
Training loss: 2.331795889832208
Validation loss: 2.434066804174682

Epoch: 6| Step: 2
Training loss: 2.381206634206708
Validation loss: 2.436030224254676

Epoch: 6| Step: 3
Training loss: 2.4091147671887314
Validation loss: 2.433506900897657

Epoch: 6| Step: 4
Training loss: 2.6487405879243666
Validation loss: 2.4219041582430325

Epoch: 6| Step: 5
Training loss: 2.093848496582751
Validation loss: 2.460528160594108

Epoch: 6| Step: 6
Training loss: 1.964177953563312
Validation loss: 2.4191395215644427

Epoch: 6| Step: 7
Training loss: 2.03627788658085
Validation loss: 2.4221252904853836

Epoch: 6| Step: 8
Training loss: 2.217290693896548
Validation loss: 2.4224777122718586

Epoch: 6| Step: 9
Training loss: 2.5287448118555433
Validation loss: 2.446865255175893

Epoch: 6| Step: 10
Training loss: 2.170731607153826
Validation loss: 2.4211932188254965

Epoch: 6| Step: 11
Training loss: 2.262365904148339
Validation loss: 2.4230348835007938

Epoch: 6| Step: 12
Training loss: 1.786191677585563
Validation loss: 2.4106940750044883

Epoch: 6| Step: 13
Training loss: 2.7488405210847837
Validation loss: 2.440989476354948

Epoch: 198| Step: 0
Training loss: 1.9201380005555246
Validation loss: 2.4394195177837905

Epoch: 6| Step: 1
Training loss: 1.9080638698028294
Validation loss: 2.415075038604481

Epoch: 6| Step: 2
Training loss: 2.213868372125565
Validation loss: 2.4407052725614378

Epoch: 6| Step: 3
Training loss: 2.6742608198845854
Validation loss: 2.397259248746305

Epoch: 6| Step: 4
Training loss: 2.5725436744652654
Validation loss: 2.41910493482945

Epoch: 6| Step: 5
Training loss: 1.8838515204580752
Validation loss: 2.4220247061641875

Epoch: 6| Step: 6
Training loss: 2.9072004835389764
Validation loss: 2.4059485302703125

Epoch: 6| Step: 7
Training loss: 2.395575490151816
Validation loss: 2.440549180667697

Epoch: 6| Step: 8
Training loss: 1.9984573136600852
Validation loss: 2.407589590004903

Epoch: 6| Step: 9
Training loss: 1.1840229326424354
Validation loss: 2.41778596311773

Epoch: 6| Step: 10
Training loss: 2.6263140159768326
Validation loss: 2.433996923237041

Epoch: 6| Step: 11
Training loss: 2.3573534054045466
Validation loss: 2.426324789113025

Epoch: 6| Step: 12
Training loss: 1.9054999204669136
Validation loss: 2.429280328491526

Epoch: 6| Step: 13
Training loss: 2.748048610185131
Validation loss: 2.417192165056506

Epoch: 199| Step: 0
Training loss: 1.8839628891863611
Validation loss: 2.424357292434351

Epoch: 6| Step: 1
Training loss: 2.386313745877144
Validation loss: 2.4202019222705697

Epoch: 6| Step: 2
Training loss: 2.9818707089862
Validation loss: 2.425665332958048

Epoch: 6| Step: 3
Training loss: 2.628014786050155
Validation loss: 2.4003973545201176

Epoch: 6| Step: 4
Training loss: 1.435636473474088
Validation loss: 2.403765773214953

Epoch: 6| Step: 5
Training loss: 2.2646176959966104
Validation loss: 2.426603054703508

Epoch: 6| Step: 6
Training loss: 2.141403168178875
Validation loss: 2.408645280440962

Epoch: 6| Step: 7
Training loss: 1.8044413609287828
Validation loss: 2.4325248759466613

Epoch: 6| Step: 8
Training loss: 2.4813636427061128
Validation loss: 2.4087289331414894

Epoch: 6| Step: 9
Training loss: 2.564797464743805
Validation loss: 2.4459644412948784

Epoch: 6| Step: 10
Training loss: 2.108759020122961
Validation loss: 2.4194665636223265

Epoch: 6| Step: 11
Training loss: 2.4829026183667535
Validation loss: 2.437684920085309

Epoch: 6| Step: 12
Training loss: 2.0549852278798015
Validation loss: 2.435496095258457

Epoch: 6| Step: 13
Training loss: 1.96453824711261
Validation loss: 2.422847677650311

Epoch: 200| Step: 0
Training loss: 2.408083130754423
Validation loss: 2.42297730912282

Epoch: 6| Step: 1
Training loss: 1.7047773972119644
Validation loss: 2.382147025963923

Epoch: 6| Step: 2
Training loss: 2.0480788090711997
Validation loss: 2.416051519714548

Epoch: 6| Step: 3
Training loss: 2.534142807414685
Validation loss: 2.416653756845155

Epoch: 6| Step: 4
Training loss: 2.0304157598023633
Validation loss: 2.4372242187030286

Epoch: 6| Step: 5
Training loss: 2.9684451298023786
Validation loss: 2.4273614172657223

Epoch: 6| Step: 6
Training loss: 3.056818772264677
Validation loss: 2.4433603875046384

Epoch: 6| Step: 7
Training loss: 2.23903889507195
Validation loss: 2.4297481081270584

Epoch: 6| Step: 8
Training loss: 1.9130079828944253
Validation loss: 2.4334769251125503

Epoch: 6| Step: 9
Training loss: 1.9325070188328255
Validation loss: 2.411024156378587

Epoch: 6| Step: 10
Training loss: 2.2410935979972213
Validation loss: 2.4407414648503756

Epoch: 6| Step: 11
Training loss: 2.224617841669303
Validation loss: 2.423670189873918

Epoch: 6| Step: 12
Training loss: 2.1320077125309616
Validation loss: 2.4440686812055317

Epoch: 6| Step: 13
Training loss: 1.5987773962708312
Validation loss: 2.422741089186972

Epoch: 201| Step: 0
Training loss: 2.5059583232607685
Validation loss: 2.420117424106205

Epoch: 6| Step: 1
Training loss: 2.1219793055295577
Validation loss: 2.4163225496133833

Epoch: 6| Step: 2
Training loss: 2.238932622961471
Validation loss: 2.4290285367299447

Epoch: 6| Step: 3
Training loss: 2.3480441618735366
Validation loss: 2.4355228452260778

Epoch: 6| Step: 4
Training loss: 1.9209927650645058
Validation loss: 2.425333177830233

Epoch: 6| Step: 5
Training loss: 2.423113992079122
Validation loss: 2.420710114875699

Epoch: 6| Step: 6
Training loss: 1.5752101455245509
Validation loss: 2.4578501273565565

Epoch: 6| Step: 7
Training loss: 1.8988212542948109
Validation loss: 2.4297209210710826

Epoch: 6| Step: 8
Training loss: 2.633455554524095
Validation loss: 2.412743130588833

Epoch: 6| Step: 9
Training loss: 1.5469701718424278
Validation loss: 2.4340029784425923

Epoch: 6| Step: 10
Training loss: 2.8099112570654268
Validation loss: 2.4531297361663773

Epoch: 6| Step: 11
Training loss: 2.5926356851942347
Validation loss: 2.411123254913115

Epoch: 6| Step: 12
Training loss: 2.4382622333971864
Validation loss: 2.4224253748585607

Epoch: 6| Step: 13
Training loss: 1.515564828838406
Validation loss: 2.375621136937123

Epoch: 202| Step: 0
Training loss: 1.9079970811785558
Validation loss: 2.4514499570790287

Epoch: 6| Step: 1
Training loss: 1.9462786500521145
Validation loss: 2.42473628415098

Epoch: 6| Step: 2
Training loss: 2.2314735193786164
Validation loss: 2.4301496111852696

Epoch: 6| Step: 3
Training loss: 1.757378147290925
Validation loss: 2.4204937677574394

Epoch: 6| Step: 4
Training loss: 2.6638296254866987
Validation loss: 2.408728171625679

Epoch: 6| Step: 5
Training loss: 2.9420674304093852
Validation loss: 2.4261882320958077

Epoch: 6| Step: 6
Training loss: 2.381833935526014
Validation loss: 2.4506227161898035

Epoch: 6| Step: 7
Training loss: 2.4643409083091004
Validation loss: 2.418977510601952

Epoch: 6| Step: 8
Training loss: 2.2667111654214547
Validation loss: 2.442104482647375

Epoch: 6| Step: 9
Training loss: 2.290499812058077
Validation loss: 2.4471326041426793

Epoch: 6| Step: 10
Training loss: 2.6108239085829625
Validation loss: 2.4303848167567272

Epoch: 6| Step: 11
Training loss: 2.048156337224741
Validation loss: 2.389575406934929

Epoch: 6| Step: 12
Training loss: 1.8864787642160552
Validation loss: 2.448766248769562

Epoch: 6| Step: 13
Training loss: 1.6878704088373635
Validation loss: 2.4505495856939112

Epoch: 203| Step: 0
Training loss: 2.0875621854919433
Validation loss: 2.4271141711156163

Epoch: 6| Step: 1
Training loss: 2.1208785985926357
Validation loss: 2.4398177260234952

Epoch: 6| Step: 2
Training loss: 2.6901079875159417
Validation loss: 2.4067863481342084

Epoch: 6| Step: 3
Training loss: 2.1198634729868817
Validation loss: 2.428854560660253

Epoch: 6| Step: 4
Training loss: 2.427580972061597
Validation loss: 2.4083018169462065

Epoch: 6| Step: 5
Training loss: 2.1885661115798762
Validation loss: 2.4312158367665853

Epoch: 6| Step: 6
Training loss: 2.1498064708104487
Validation loss: 2.42702889323074

Epoch: 6| Step: 7
Training loss: 2.1270997388345934
Validation loss: 2.4509344416321728

Epoch: 6| Step: 8
Training loss: 2.1576276054969927
Validation loss: 2.4643795123004915

Epoch: 6| Step: 9
Training loss: 2.0846288340597847
Validation loss: 2.452125759121738

Epoch: 6| Step: 10
Training loss: 2.8348711178933548
Validation loss: 2.427848117296209

Epoch: 6| Step: 11
Training loss: 2.0005072904004404
Validation loss: 2.431824171085203

Epoch: 6| Step: 12
Training loss: 2.476731544284938
Validation loss: 2.410857174305314

Epoch: 6| Step: 13
Training loss: 1.7081194798045005
Validation loss: 2.442380026734357

Epoch: 204| Step: 0
Training loss: 1.9606364349625198
Validation loss: 2.42819508839815

Epoch: 6| Step: 1
Training loss: 1.946725477719395
Validation loss: 2.4494401312571803

Epoch: 6| Step: 2
Training loss: 2.094268506882166
Validation loss: 2.432933722806392

Epoch: 6| Step: 3
Training loss: 1.8676512074568001
Validation loss: 2.422550770044608

Epoch: 6| Step: 4
Training loss: 1.7492100431320123
Validation loss: 2.413485237032056

Epoch: 6| Step: 5
Training loss: 2.4116479347343382
Validation loss: 2.446660915223929

Epoch: 6| Step: 6
Training loss: 2.3812111398324505
Validation loss: 2.4067499935505183

Epoch: 6| Step: 7
Training loss: 2.0652713074618774
Validation loss: 2.434061886622626

Epoch: 6| Step: 8
Training loss: 2.5903673290037306
Validation loss: 2.4301308301726166

Epoch: 6| Step: 9
Training loss: 2.1606857451048085
Validation loss: 2.427577080523715

Epoch: 6| Step: 10
Training loss: 2.1735794734040366
Validation loss: 2.4367998094043193

Epoch: 6| Step: 11
Training loss: 3.113933346563606
Validation loss: 2.4333367944283455

Epoch: 6| Step: 12
Training loss: 2.366916754318791
Validation loss: 2.3927936126593066

Epoch: 6| Step: 13
Training loss: 2.028018552458283
Validation loss: 2.429736472395548

Epoch: 205| Step: 0
Training loss: 2.5374149552549277
Validation loss: 2.4357262639968074

Epoch: 6| Step: 1
Training loss: 2.1665261907766187
Validation loss: 2.4143974161345683

Epoch: 6| Step: 2
Training loss: 1.812918516050129
Validation loss: 2.4114821822714396

Epoch: 6| Step: 3
Training loss: 2.880618700222113
Validation loss: 2.450758214021522

Epoch: 6| Step: 4
Training loss: 2.595668404994938
Validation loss: 2.3877998724240546

Epoch: 6| Step: 5
Training loss: 2.4853941548413268
Validation loss: 2.4482235986849044

Epoch: 6| Step: 6
Training loss: 2.171709452295686
Validation loss: 2.4173263551815287

Epoch: 6| Step: 7
Training loss: 2.131591894743763
Validation loss: 2.445864824762891

Epoch: 6| Step: 8
Training loss: 1.747789076224091
Validation loss: 2.4288855708665764

Epoch: 6| Step: 9
Training loss: 2.2798185691255966
Validation loss: 2.4464302243480107

Epoch: 6| Step: 10
Training loss: 1.9519468492518122
Validation loss: 2.4378150397688048

Epoch: 6| Step: 11
Training loss: 1.763007392625461
Validation loss: 2.4520491610663195

Epoch: 6| Step: 12
Training loss: 2.1618354437750145
Validation loss: 2.426897507560849

Epoch: 6| Step: 13
Training loss: 2.5252016119207528
Validation loss: 2.4537798878238424

Epoch: 206| Step: 0
Training loss: 2.032229612789037
Validation loss: 2.4105181130946116

Epoch: 6| Step: 1
Training loss: 2.5151101290364286
Validation loss: 2.4235518468112365

Epoch: 6| Step: 2
Training loss: 1.8415391889385255
Validation loss: 2.4080553413908508

Epoch: 6| Step: 3
Training loss: 1.9490599787385239
Validation loss: 2.4252662734931456

Epoch: 6| Step: 4
Training loss: 2.11971545883022
Validation loss: 2.4573744302323153

Epoch: 6| Step: 5
Training loss: 2.207523797361643
Validation loss: 2.4163369670630197

Epoch: 6| Step: 6
Training loss: 2.0504275643670784
Validation loss: 2.4306909489655744

Epoch: 6| Step: 7
Training loss: 2.4228461502672825
Validation loss: 2.4302674810639124

Epoch: 6| Step: 8
Training loss: 2.2972539472356117
Validation loss: 2.4371039029554753

Epoch: 6| Step: 9
Training loss: 2.755343188114604
Validation loss: 2.4580500886055425

Epoch: 6| Step: 10
Training loss: 1.7656247299329162
Validation loss: 2.4470626280309284

Epoch: 6| Step: 11
Training loss: 2.1280950558162
Validation loss: 2.416060159599244

Epoch: 6| Step: 12
Training loss: 2.582397619620246
Validation loss: 2.4439022858839934

Epoch: 6| Step: 13
Training loss: 2.561327317031051
Validation loss: 2.409234753680324

Epoch: 207| Step: 0
Training loss: 2.2183648433305554
Validation loss: 2.465350306490327

Epoch: 6| Step: 1
Training loss: 2.0884653840122143
Validation loss: 2.429405014234389

Epoch: 6| Step: 2
Training loss: 2.244066680407087
Validation loss: 2.4105768619022

Epoch: 6| Step: 3
Training loss: 2.74845591458153
Validation loss: 2.4136868614806652

Epoch: 6| Step: 4
Training loss: 1.2215786411080696
Validation loss: 2.4225772798750596

Epoch: 6| Step: 5
Training loss: 2.1155216659485907
Validation loss: 2.393323543737767

Epoch: 6| Step: 6
Training loss: 2.331171998874425
Validation loss: 2.44070741111135

Epoch: 6| Step: 7
Training loss: 2.0836852984346264
Validation loss: 2.4295154588835484

Epoch: 6| Step: 8
Training loss: 2.229611955417517
Validation loss: 2.4404929186688684

Epoch: 6| Step: 9
Training loss: 2.4710582131198273
Validation loss: 2.3901930189577936

Epoch: 6| Step: 10
Training loss: 2.2283995428451537
Validation loss: 2.4122286354538276

Epoch: 6| Step: 11
Training loss: 2.185742135142078
Validation loss: 2.441105918607229

Epoch: 6| Step: 12
Training loss: 2.301418248645864
Validation loss: 2.4352851567392304

Epoch: 6| Step: 13
Training loss: 2.7712671518719874
Validation loss: 2.461200863701399

Epoch: 208| Step: 0
Training loss: 2.8413696387394225
Validation loss: 2.435457452915179

Epoch: 6| Step: 1
Training loss: 2.29666292418169
Validation loss: 2.4297655531790623

Epoch: 6| Step: 2
Training loss: 1.9642749364978327
Validation loss: 2.4184187282984633

Epoch: 6| Step: 3
Training loss: 2.1084694508073367
Validation loss: 2.409796864509609

Epoch: 6| Step: 4
Training loss: 1.8611160589819782
Validation loss: 2.4105837038987707

Epoch: 6| Step: 5
Training loss: 2.031178751943061
Validation loss: 2.447684796796987

Epoch: 6| Step: 6
Training loss: 1.9673318750851556
Validation loss: 2.4335037104440973

Epoch: 6| Step: 7
Training loss: 2.340263010714836
Validation loss: 2.46435056014386

Epoch: 6| Step: 8
Training loss: 3.135890599590505
Validation loss: 2.4129185116284635

Epoch: 6| Step: 9
Training loss: 2.0205630354343254
Validation loss: 2.4390839932476616

Epoch: 6| Step: 10
Training loss: 2.0028608841333453
Validation loss: 2.457589151722396

Epoch: 6| Step: 11
Training loss: 1.9507989078283234
Validation loss: 2.4098719577460335

Epoch: 6| Step: 12
Training loss: 2.5250230655938584
Validation loss: 2.4479675546007096

Epoch: 6| Step: 13
Training loss: 1.573341901615756
Validation loss: 2.4281611596041093

Epoch: 209| Step: 0
Training loss: 2.0945041493957315
Validation loss: 2.4046670079944787

Epoch: 6| Step: 1
Training loss: 1.6463930731422838
Validation loss: 2.4359941735018715

Epoch: 6| Step: 2
Training loss: 3.3616565142736543
Validation loss: 2.4214506467555674

Epoch: 6| Step: 3
Training loss: 2.231535915146422
Validation loss: 2.4201254419666753

Epoch: 6| Step: 4
Training loss: 2.3690081855758107
Validation loss: 2.434032351610696

Epoch: 6| Step: 5
Training loss: 2.144856079181732
Validation loss: 2.429788761002567

Epoch: 6| Step: 6
Training loss: 2.4903754938568667
Validation loss: 2.4541001501529363

Epoch: 6| Step: 7
Training loss: 1.5585656032076267
Validation loss: 2.4178326731953477

Epoch: 6| Step: 8
Training loss: 1.7003160463396756
Validation loss: 2.4395398286179977

Epoch: 6| Step: 9
Training loss: 2.1456134893395844
Validation loss: 2.411248790250082

Epoch: 6| Step: 10
Training loss: 2.4326435518003797
Validation loss: 2.385752811723631

Epoch: 6| Step: 11
Training loss: 2.2564115302681382
Validation loss: 2.4498249192303088

Epoch: 6| Step: 12
Training loss: 2.0402540912584817
Validation loss: 2.4530059302742564

Epoch: 6| Step: 13
Training loss: 2.277755778550183
Validation loss: 2.4209368182322164

Epoch: 210| Step: 0
Training loss: 1.6251982054508713
Validation loss: 2.4271439339606333

Epoch: 6| Step: 1
Training loss: 2.6269267141156085
Validation loss: 2.394272988916807

Epoch: 6| Step: 2
Training loss: 2.3097576686361463
Validation loss: 2.4231055376324373

Epoch: 6| Step: 3
Training loss: 2.595950560476637
Validation loss: 2.428704080597921

Epoch: 6| Step: 4
Training loss: 1.977240465014584
Validation loss: 2.4019298790226435

Epoch: 6| Step: 5
Training loss: 2.316941609522354
Validation loss: 2.438032758856109

Epoch: 6| Step: 6
Training loss: 2.346097050733401
Validation loss: 2.4065346285140325

Epoch: 6| Step: 7
Training loss: 2.448555839906731
Validation loss: 2.4252856841224517

Epoch: 6| Step: 8
Training loss: 2.1724977766756504
Validation loss: 2.4237519854703455

Epoch: 6| Step: 9
Training loss: 1.8598596277899597
Validation loss: 2.431517275874899

Epoch: 6| Step: 10
Training loss: 1.9485246726009136
Validation loss: 2.444933616129058

Epoch: 6| Step: 11
Training loss: 2.7592486135498833
Validation loss: 2.4529203725776956

Epoch: 6| Step: 12
Training loss: 1.8752066180509497
Validation loss: 2.445541310848471

Epoch: 6| Step: 13
Training loss: 1.9524589928925529
Validation loss: 2.4201458270639757

Epoch: 211| Step: 0
Training loss: 2.204245748946071
Validation loss: 2.408406326360713

Epoch: 6| Step: 1
Training loss: 2.312954213666808
Validation loss: 2.420730596716888

Epoch: 6| Step: 2
Training loss: 1.5354720317463515
Validation loss: 2.4382703903093144

Epoch: 6| Step: 3
Training loss: 1.9822478419992278
Validation loss: 2.4072230092020153

Epoch: 6| Step: 4
Training loss: 1.9688752755164969
Validation loss: 2.395062552042049

Epoch: 6| Step: 5
Training loss: 1.9720147931199852
Validation loss: 2.438102020454757

Epoch: 6| Step: 6
Training loss: 1.8058387420155506
Validation loss: 2.4309391231996598

Epoch: 6| Step: 7
Training loss: 1.9067873588234212
Validation loss: 2.4420819991596887

Epoch: 6| Step: 8
Training loss: 2.307780320983393
Validation loss: 2.4107255017272013

Epoch: 6| Step: 9
Training loss: 2.1537756613576975
Validation loss: 2.419595968320268

Epoch: 6| Step: 10
Training loss: 2.266478594756523
Validation loss: 2.424161182207667

Epoch: 6| Step: 11
Training loss: 2.997316113606921
Validation loss: 2.4544532053568617

Epoch: 6| Step: 12
Training loss: 2.960514249721277
Validation loss: 2.441202501158635

Epoch: 6| Step: 13
Training loss: 2.5818779650273838
Validation loss: 2.427696227397638

Epoch: 212| Step: 0
Training loss: 2.152604490572867
Validation loss: 2.4371595431526427

Epoch: 6| Step: 1
Training loss: 2.061057540023707
Validation loss: 2.4353893956163226

Epoch: 6| Step: 2
Training loss: 2.356447538397726
Validation loss: 2.369588483294473

Epoch: 6| Step: 3
Training loss: 1.8996177740615394
Validation loss: 2.4175445414067873

Epoch: 6| Step: 4
Training loss: 1.7351130384400177
Validation loss: 2.4188119710623344

Epoch: 6| Step: 5
Training loss: 2.2366072168233275
Validation loss: 2.4095862701151227

Epoch: 6| Step: 6
Training loss: 2.135738168720499
Validation loss: 2.4221181881712037

Epoch: 6| Step: 7
Training loss: 2.12784879127151
Validation loss: 2.427831850093232

Epoch: 6| Step: 8
Training loss: 2.6188811785998447
Validation loss: 2.4164450341908417

Epoch: 6| Step: 9
Training loss: 2.517969212071882
Validation loss: 2.400651663098972

Epoch: 6| Step: 10
Training loss: 2.244847013022812
Validation loss: 2.40526086053552

Epoch: 6| Step: 11
Training loss: 2.672773243680389
Validation loss: 2.4378801033156856

Epoch: 6| Step: 12
Training loss: 2.19363013045989
Validation loss: 2.4245809373740363

Epoch: 6| Step: 13
Training loss: 1.9823725050618195
Validation loss: 2.4318270343036668

Epoch: 213| Step: 0
Training loss: 1.735628104943756
Validation loss: 2.421394936215998

Epoch: 6| Step: 1
Training loss: 2.6815008584070403
Validation loss: 2.422804378851552

Epoch: 6| Step: 2
Training loss: 2.879386706484726
Validation loss: 2.414669554307556

Epoch: 6| Step: 3
Training loss: 1.627767773352653
Validation loss: 2.4154678439848785

Epoch: 6| Step: 4
Training loss: 2.3424569186846433
Validation loss: 2.4445278823954086

Epoch: 6| Step: 5
Training loss: 2.2203187366588604
Validation loss: 2.4428280910940745

Epoch: 6| Step: 6
Training loss: 1.9912039928305822
Validation loss: 2.406087184000732

Epoch: 6| Step: 7
Training loss: 2.026817650420338
Validation loss: 2.4429413940346634

Epoch: 6| Step: 8
Training loss: 1.9657021803023742
Validation loss: 2.4224276491334247

Epoch: 6| Step: 9
Training loss: 2.386778485788358
Validation loss: 2.437446061455986

Epoch: 6| Step: 10
Training loss: 2.2989554811525363
Validation loss: 2.409972319541229

Epoch: 6| Step: 11
Training loss: 2.2920904865810896
Validation loss: 2.444050133024082

Epoch: 6| Step: 12
Training loss: 2.158413451289855
Validation loss: 2.4400662022954203

Epoch: 6| Step: 13
Training loss: 2.065338955232288
Validation loss: 2.4380092073192143

Epoch: 214| Step: 0
Training loss: 2.127698307141348
Validation loss: 2.4223961636241493

Epoch: 6| Step: 1
Training loss: 2.333815615630076
Validation loss: 2.4628291024512134

Epoch: 6| Step: 2
Training loss: 1.6473391521237364
Validation loss: 2.440534157286275

Epoch: 6| Step: 3
Training loss: 2.060186533584185
Validation loss: 2.456855234840384

Epoch: 6| Step: 4
Training loss: 2.2149051072437027
Validation loss: 2.4367979125534385

Epoch: 6| Step: 5
Training loss: 1.996293089705543
Validation loss: 2.4578841480183433

Epoch: 6| Step: 6
Training loss: 2.3185712143896486
Validation loss: 2.4585380767885012

Epoch: 6| Step: 7
Training loss: 2.74929826626335
Validation loss: 2.425936240928448

Epoch: 6| Step: 8
Training loss: 2.3154811716650707
Validation loss: 2.426967213698787

Epoch: 6| Step: 9
Training loss: 1.5842893708995334
Validation loss: 2.397176154015658

Epoch: 6| Step: 10
Training loss: 2.3880012425430617
Validation loss: 2.4029319397279445

Epoch: 6| Step: 11
Training loss: 2.098263785755217
Validation loss: 2.4331722718525177

Epoch: 6| Step: 12
Training loss: 2.172899841458023
Validation loss: 2.420995547707368

Epoch: 6| Step: 13
Training loss: 2.854816910306093
Validation loss: 2.412560500352775

Epoch: 215| Step: 0
Training loss: 2.1565892049487236
Validation loss: 2.4239526099780355

Epoch: 6| Step: 1
Training loss: 2.5674435451284756
Validation loss: 2.4172915643325115

Epoch: 6| Step: 2
Training loss: 2.1323855465297714
Validation loss: 2.407366066701652

Epoch: 6| Step: 3
Training loss: 2.7492353936938474
Validation loss: 2.4304517109881605

Epoch: 6| Step: 4
Training loss: 2.0877404582705803
Validation loss: 2.407050059540741

Epoch: 6| Step: 5
Training loss: 1.8712800317468135
Validation loss: 2.425955770894271

Epoch: 6| Step: 6
Training loss: 2.6093117711978238
Validation loss: 2.4181883656536614

Epoch: 6| Step: 7
Training loss: 2.0321770533223242
Validation loss: 2.4227054406708497

Epoch: 6| Step: 8
Training loss: 2.080202827834738
Validation loss: 2.45966866671711

Epoch: 6| Step: 9
Training loss: 2.691297642436285
Validation loss: 2.4232716672359302

Epoch: 6| Step: 10
Training loss: 1.686835546721176
Validation loss: 2.4151476483874053

Epoch: 6| Step: 11
Training loss: 2.257077846660099
Validation loss: 2.4299085326800998

Epoch: 6| Step: 12
Training loss: 1.67130968750512
Validation loss: 2.4373058918078865

Epoch: 6| Step: 13
Training loss: 1.3375425456758077
Validation loss: 2.40675104808617

Epoch: 216| Step: 0
Training loss: 2.253220267007927
Validation loss: 2.4615708527891966

Epoch: 6| Step: 1
Training loss: 2.2008371580996555
Validation loss: 2.423461638858187

Epoch: 6| Step: 2
Training loss: 3.009003638689067
Validation loss: 2.429031324615204

Epoch: 6| Step: 3
Training loss: 2.4175250951338243
Validation loss: 2.425232532052372

Epoch: 6| Step: 4
Training loss: 2.705721011010301
Validation loss: 2.4564237427374906

Epoch: 6| Step: 5
Training loss: 1.860876038478844
Validation loss: 2.4432868544443944

Epoch: 6| Step: 6
Training loss: 1.685387030279246
Validation loss: 2.409478623129376

Epoch: 6| Step: 7
Training loss: 2.088884878774721
Validation loss: 2.4208628635117284

Epoch: 6| Step: 8
Training loss: 1.7820812761843265
Validation loss: 2.377188157592935

Epoch: 6| Step: 9
Training loss: 2.2575601086899426
Validation loss: 2.442937321281373

Epoch: 6| Step: 10
Training loss: 1.964705536305853
Validation loss: 2.436549952078727

Epoch: 6| Step: 11
Training loss: 2.0505233747837814
Validation loss: 2.4293025489696296

Epoch: 6| Step: 12
Training loss: 1.6550020518679158
Validation loss: 2.4229027321027474

Epoch: 6| Step: 13
Training loss: 2.0384622326089814
Validation loss: 2.430923450908268

Epoch: 217| Step: 0
Training loss: 2.121116005796568
Validation loss: 2.4216018856201207

Epoch: 6| Step: 1
Training loss: 2.307216691864944
Validation loss: 2.429417877225374

Epoch: 6| Step: 2
Training loss: 1.724287303258322
Validation loss: 2.4185577061763315

Epoch: 6| Step: 3
Training loss: 2.2326575661275667
Validation loss: 2.421804420059344

Epoch: 6| Step: 4
Training loss: 1.9977720487387753
Validation loss: 2.435036076789735

Epoch: 6| Step: 5
Training loss: 2.28219731140326
Validation loss: 2.426820479786122

Epoch: 6| Step: 6
Training loss: 1.8433067306176307
Validation loss: 2.393548599587332

Epoch: 6| Step: 7
Training loss: 2.550209904427599
Validation loss: 2.429785878500811

Epoch: 6| Step: 8
Training loss: 2.890856594396414
Validation loss: 2.418912106069367

Epoch: 6| Step: 9
Training loss: 2.1934504638671384
Validation loss: 2.4471050534154895

Epoch: 6| Step: 10
Training loss: 1.9625604608054485
Validation loss: 2.4326289285382288

Epoch: 6| Step: 11
Training loss: 2.0609285552529903
Validation loss: 2.4257814555536057

Epoch: 6| Step: 12
Training loss: 2.21851078946798
Validation loss: 2.4335925933245743

Epoch: 6| Step: 13
Training loss: 1.442796982154408
Validation loss: 2.3988363277703577

Epoch: 218| Step: 0
Training loss: 2.1785083712490745
Validation loss: 2.4497129926816834

Epoch: 6| Step: 1
Training loss: 1.7208252602573342
Validation loss: 2.3976699495057665

Epoch: 6| Step: 2
Training loss: 2.306124171517659
Validation loss: 2.4344328858671287

Epoch: 6| Step: 3
Training loss: 2.0416123389457166
Validation loss: 2.423704066242564

Epoch: 6| Step: 4
Training loss: 2.5011236526628235
Validation loss: 2.4450117183927653

Epoch: 6| Step: 5
Training loss: 2.25111658153181
Validation loss: 2.421350985180041

Epoch: 6| Step: 6
Training loss: 2.2234565353382947
Validation loss: 2.434331444189218

Epoch: 6| Step: 7
Training loss: 1.7997520302465524
Validation loss: 2.4523171303675517

Epoch: 6| Step: 8
Training loss: 2.0476245235821913
Validation loss: 2.458792955477819

Epoch: 6| Step: 9
Training loss: 2.6800520846301787
Validation loss: 2.445266783487877

Epoch: 6| Step: 10
Training loss: 2.530963080828346
Validation loss: 2.4397662124175232

Epoch: 6| Step: 11
Training loss: 2.080017375506673
Validation loss: 2.420247734086296

Epoch: 6| Step: 12
Training loss: 2.064597132919288
Validation loss: 2.4293609078882343

Epoch: 6| Step: 13
Training loss: 1.5554176034761897
Validation loss: 2.4271036170373494

Epoch: 219| Step: 0
Training loss: 2.22214452554721
Validation loss: 2.4080431270853486

Epoch: 6| Step: 1
Training loss: 2.1242580240427387
Validation loss: 2.4238973022667825

Epoch: 6| Step: 2
Training loss: 2.3182833754721357
Validation loss: 2.4489217153715024

Epoch: 6| Step: 3
Training loss: 2.301444976354423
Validation loss: 2.4001496207691333

Epoch: 6| Step: 4
Training loss: 2.027757194565539
Validation loss: 2.4459386911843684

Epoch: 6| Step: 5
Training loss: 1.916896543677143
Validation loss: 2.416850793406173

Epoch: 6| Step: 6
Training loss: 1.752619417831774
Validation loss: 2.422805604165131

Epoch: 6| Step: 7
Training loss: 2.6734247007793774
Validation loss: 2.429114601383439

Epoch: 6| Step: 8
Training loss: 1.9252634338853365
Validation loss: 2.402622690988327

Epoch: 6| Step: 9
Training loss: 1.7636637639971298
Validation loss: 2.452206574193514

Epoch: 6| Step: 10
Training loss: 2.3740869071883828
Validation loss: 2.4420352232890807

Epoch: 6| Step: 11
Training loss: 2.492677837673613
Validation loss: 2.429929463446355

Epoch: 6| Step: 12
Training loss: 2.26674608577644
Validation loss: 2.421246419333239

Epoch: 6| Step: 13
Training loss: 2.0053407171236888
Validation loss: 2.4034363029788963

Epoch: 220| Step: 0
Training loss: 1.75616744312362
Validation loss: 2.436766136136434

Epoch: 6| Step: 1
Training loss: 2.55402302631104
Validation loss: 2.41885692740272

Epoch: 6| Step: 2
Training loss: 2.222763943870536
Validation loss: 2.4131657366135557

Epoch: 6| Step: 3
Training loss: 1.6215199840865713
Validation loss: 2.4348807333060756

Epoch: 6| Step: 4
Training loss: 1.9834821599797992
Validation loss: 2.427557145402656

Epoch: 6| Step: 5
Training loss: 2.209465804115756
Validation loss: 2.469270907974262

Epoch: 6| Step: 6
Training loss: 2.113130179768092
Validation loss: 2.4239901977928255

Epoch: 6| Step: 7
Training loss: 1.7971029385827604
Validation loss: 2.387675399256017

Epoch: 6| Step: 8
Training loss: 2.087884915435949
Validation loss: 2.4028053798588207

Epoch: 6| Step: 9
Training loss: 2.78957919936459
Validation loss: 2.439934681250597

Epoch: 6| Step: 10
Training loss: 2.2652657059530332
Validation loss: 2.410858350395661

Epoch: 6| Step: 11
Training loss: 1.6412760578071284
Validation loss: 2.4241631545137476

Epoch: 6| Step: 12
Training loss: 2.341196220175388
Validation loss: 2.4455941965924315

Epoch: 6| Step: 13
Training loss: 2.8753350104151587
Validation loss: 2.423946729558111

Epoch: 221| Step: 0
Training loss: 1.4808511768497519
Validation loss: 2.438296836475195

Epoch: 6| Step: 1
Training loss: 2.2848026360683567
Validation loss: 2.396337706632687

Epoch: 6| Step: 2
Training loss: 2.2041579185653566
Validation loss: 2.437221266104918

Epoch: 6| Step: 3
Training loss: 1.9969339114291191
Validation loss: 2.444789758917069

Epoch: 6| Step: 4
Training loss: 3.0474486764618276
Validation loss: 2.4228116090392127

Epoch: 6| Step: 5
Training loss: 1.7516851486019864
Validation loss: 2.4521205714602807

Epoch: 6| Step: 6
Training loss: 1.7652507824271368
Validation loss: 2.4339614827616263

Epoch: 6| Step: 7
Training loss: 1.7562900307868319
Validation loss: 2.448685434272251

Epoch: 6| Step: 8
Training loss: 2.2919928116344486
Validation loss: 2.429807911826929

Epoch: 6| Step: 9
Training loss: 1.8341389388825602
Validation loss: 2.452968056541848

Epoch: 6| Step: 10
Training loss: 2.443241888037677
Validation loss: 2.435360384092795

Epoch: 6| Step: 11
Training loss: 2.1133355153109643
Validation loss: 2.389806390795282

Epoch: 6| Step: 12
Training loss: 2.646488519081165
Validation loss: 2.409756014797784

Epoch: 6| Step: 13
Training loss: 2.3252365320133714
Validation loss: 2.4433041640082207

Epoch: 222| Step: 0
Training loss: 1.5006278631333154
Validation loss: 2.4705621982265953

Epoch: 6| Step: 1
Training loss: 2.5214544009341098
Validation loss: 2.423147432401172

Epoch: 6| Step: 2
Training loss: 1.9909361256307427
Validation loss: 2.423367367393302

Epoch: 6| Step: 3
Training loss: 1.9240458563734852
Validation loss: 2.4188669991957075

Epoch: 6| Step: 4
Training loss: 1.7105302717958488
Validation loss: 2.452541480739105

Epoch: 6| Step: 5
Training loss: 2.1083369208545344
Validation loss: 2.439273790427983

Epoch: 6| Step: 6
Training loss: 3.2514557145863168
Validation loss: 2.425751660667377

Epoch: 6| Step: 7
Training loss: 2.1091388711513317
Validation loss: 2.4198338508164707

Epoch: 6| Step: 8
Training loss: 1.9951990440332712
Validation loss: 2.4337231540691384

Epoch: 6| Step: 9
Training loss: 1.8326502163091938
Validation loss: 2.4288932019764564

Epoch: 6| Step: 10
Training loss: 1.7000277292570611
Validation loss: 2.432610234114496

Epoch: 6| Step: 11
Training loss: 1.943198836706857
Validation loss: 2.4206465173366216

Epoch: 6| Step: 12
Training loss: 2.473771312403998
Validation loss: 2.425166320509888

Epoch: 6| Step: 13
Training loss: 2.8182301111642136
Validation loss: 2.4208038115279664

Epoch: 223| Step: 0
Training loss: 2.834916196253906
Validation loss: 2.4048706467247305

Epoch: 6| Step: 1
Training loss: 1.9632852186169722
Validation loss: 2.448746143805728

Epoch: 6| Step: 2
Training loss: 1.9416403063293153
Validation loss: 2.4167830909829138

Epoch: 6| Step: 3
Training loss: 2.188529072258824
Validation loss: 2.4540778199185564

Epoch: 6| Step: 4
Training loss: 2.1804784071355474
Validation loss: 2.4368877677983924

Epoch: 6| Step: 5
Training loss: 2.2355259418590636
Validation loss: 2.4374164812048087

Epoch: 6| Step: 6
Training loss: 2.8485419174198316
Validation loss: 2.4213228049382525

Epoch: 6| Step: 7
Training loss: 1.6032339166893035
Validation loss: 2.4454529974928376

Epoch: 6| Step: 8
Training loss: 2.440501980972033
Validation loss: 2.4066722847184945

Epoch: 6| Step: 9
Training loss: 2.053621080639435
Validation loss: 2.4090497482884077

Epoch: 6| Step: 10
Training loss: 2.075594400963148
Validation loss: 2.377961146184129

Epoch: 6| Step: 11
Training loss: 2.174275560421559
Validation loss: 2.436726449751219

Epoch: 6| Step: 12
Training loss: 1.300348891610994
Validation loss: 2.4173627288738126

Epoch: 6| Step: 13
Training loss: 1.6772111958478262
Validation loss: 2.4072615680355436

Epoch: 224| Step: 0
Training loss: 2.0727872057285412
Validation loss: 2.4383485451397497

Epoch: 6| Step: 1
Training loss: 2.277120432038151
Validation loss: 2.4002386253092687

Epoch: 6| Step: 2
Training loss: 2.2265328388580814
Validation loss: 2.455437558746645

Epoch: 6| Step: 3
Training loss: 2.0803541116791795
Validation loss: 2.4565162676563133

Epoch: 6| Step: 4
Training loss: 1.9542044746412506
Validation loss: 2.432127888542614

Epoch: 6| Step: 5
Training loss: 2.2948760592168695
Validation loss: 2.428716342996752

Epoch: 6| Step: 6
Training loss: 2.4525746499618015
Validation loss: 2.459882005070506

Epoch: 6| Step: 7
Training loss: 1.829629002262259
Validation loss: 2.418137080388794

Epoch: 6| Step: 8
Training loss: 1.5497904574360493
Validation loss: 2.373292513193626

Epoch: 6| Step: 9
Training loss: 2.355952123132841
Validation loss: 2.4543165755471232

Epoch: 6| Step: 10
Training loss: 2.7129872073509222
Validation loss: 2.458409160308741

Epoch: 6| Step: 11
Training loss: 2.1012600252092746
Validation loss: 2.4160523781337035

Epoch: 6| Step: 12
Training loss: 1.782538901355303
Validation loss: 2.415973631496801

Epoch: 6| Step: 13
Training loss: 1.6451385898821513
Validation loss: 2.4376007103446344

Epoch: 225| Step: 0
Training loss: 1.9746376284607032
Validation loss: 2.4207089096823338

Epoch: 6| Step: 1
Training loss: 2.36237149973987
Validation loss: 2.4282849093608414

Epoch: 6| Step: 2
Training loss: 2.5427139084215837
Validation loss: 2.4238240455150932

Epoch: 6| Step: 3
Training loss: 2.593252846744497
Validation loss: 2.440055775683224

Epoch: 6| Step: 4
Training loss: 1.475174104792405
Validation loss: 2.420028614646905

Epoch: 6| Step: 5
Training loss: 2.572273781545534
Validation loss: 2.422514389060372

Epoch: 6| Step: 6
Training loss: 2.0785519727752377
Validation loss: 2.4225744184231544

Epoch: 6| Step: 7
Training loss: 1.995320627648537
Validation loss: 2.4101300385972917

Epoch: 6| Step: 8
Training loss: 2.18884432220702
Validation loss: 2.40897105050085

Epoch: 6| Step: 9
Training loss: 1.6023590340110898
Validation loss: 2.4365350197768647

Epoch: 6| Step: 10
Training loss: 1.9093126801904616
Validation loss: 2.430709965064627

Epoch: 6| Step: 11
Training loss: 1.7083989650245341
Validation loss: 2.4291525430781817

Epoch: 6| Step: 12
Training loss: 2.1759196430894163
Validation loss: 2.4243089812166003

Epoch: 6| Step: 13
Training loss: 2.430990574977341
Validation loss: 2.4049933702324067

Epoch: 226| Step: 0
Training loss: 1.8529116065428963
Validation loss: 2.4078552970557245

Epoch: 6| Step: 1
Training loss: 2.0612796294128373
Validation loss: 2.389513459070771

Epoch: 6| Step: 2
Training loss: 2.2219570783217333
Validation loss: 2.452196423972605

Epoch: 6| Step: 3
Training loss: 2.667751588263444
Validation loss: 2.3961749382150197

Epoch: 6| Step: 4
Training loss: 1.5550420155629288
Validation loss: 2.4163000644162853

Epoch: 6| Step: 5
Training loss: 2.1282572745780604
Validation loss: 2.4167270702356367

Epoch: 6| Step: 6
Training loss: 2.095687425311068
Validation loss: 2.4392701004161794

Epoch: 6| Step: 7
Training loss: 2.3805312946893005
Validation loss: 2.41013800033303

Epoch: 6| Step: 8
Training loss: 1.8635828825684213
Validation loss: 2.432368364490875

Epoch: 6| Step: 9
Training loss: 2.1782339848709276
Validation loss: 2.4128681879965095

Epoch: 6| Step: 10
Training loss: 1.9882307664499006
Validation loss: 2.4199992081628907

Epoch: 6| Step: 11
Training loss: 1.92337696962534
Validation loss: 2.436520237318137

Epoch: 6| Step: 12
Training loss: 2.4281778337187507
Validation loss: 2.4287355650821896

Epoch: 6| Step: 13
Training loss: 2.333660942875222
Validation loss: 2.4416780536913443

Epoch: 227| Step: 0
Training loss: 1.6267089660543768
Validation loss: 2.4264311292881993

Epoch: 6| Step: 1
Training loss: 2.666038876386703
Validation loss: 2.4572612862727548

Epoch: 6| Step: 2
Training loss: 2.246119756133413
Validation loss: 2.4567932559335524

Epoch: 6| Step: 3
Training loss: 1.6895145118453656
Validation loss: 2.403270859415429

Epoch: 6| Step: 4
Training loss: 2.0562489889310536
Validation loss: 2.429151720949329

Epoch: 6| Step: 5
Training loss: 2.0554879953548384
Validation loss: 2.440976589796471

Epoch: 6| Step: 6
Training loss: 1.9289130382642425
Validation loss: 2.434107725110861

Epoch: 6| Step: 7
Training loss: 1.9227729498436341
Validation loss: 2.4355534979088476

Epoch: 6| Step: 8
Training loss: 1.8074938599625976
Validation loss: 2.4279188119183726

Epoch: 6| Step: 9
Training loss: 1.743463023645565
Validation loss: 2.428178568546978

Epoch: 6| Step: 10
Training loss: 2.2177376385196887
Validation loss: 2.4190766531800763

Epoch: 6| Step: 11
Training loss: 2.056917670012219
Validation loss: 2.4483161560149393

Epoch: 6| Step: 12
Training loss: 2.377463017285352
Validation loss: 2.415147297036169

Epoch: 6| Step: 13
Training loss: 3.464278354552686
Validation loss: 2.414743911038648

Epoch: 228| Step: 0
Training loss: 1.6749034796846551
Validation loss: 2.417136019092561

Epoch: 6| Step: 1
Training loss: 1.8376123458876046
Validation loss: 2.412982367034262

Epoch: 6| Step: 2
Training loss: 2.365658105495113
Validation loss: 2.4466926207614175

Epoch: 6| Step: 3
Training loss: 1.9865925330639742
Validation loss: 2.4556015062024033

Epoch: 6| Step: 4
Training loss: 2.446239941497848
Validation loss: 2.44308772950569

Epoch: 6| Step: 5
Training loss: 2.8328595232756038
Validation loss: 2.4312047405687234

Epoch: 6| Step: 6
Training loss: 1.7501948111956653
Validation loss: 2.4033933894101502

Epoch: 6| Step: 7
Training loss: 1.826826694200942
Validation loss: 2.4222870813882476

Epoch: 6| Step: 8
Training loss: 1.7894399985960523
Validation loss: 2.3902704001506674

Epoch: 6| Step: 9
Training loss: 2.4919686056887396
Validation loss: 2.4333388298850265

Epoch: 6| Step: 10
Training loss: 2.2334400701874992
Validation loss: 2.4424937702997584

Epoch: 6| Step: 11
Training loss: 1.9700518950777202
Validation loss: 2.467043233572731

Epoch: 6| Step: 12
Training loss: 1.9647691230935425
Validation loss: 2.453588745601827

Epoch: 6| Step: 13
Training loss: 2.4447236250868647
Validation loss: 2.4482334156325

Epoch: 229| Step: 0
Training loss: 1.4515684261139459
Validation loss: 2.4721834557928024

Epoch: 6| Step: 1
Training loss: 1.980448826194931
Validation loss: 2.4268016793476477

Epoch: 6| Step: 2
Training loss: 2.1566280088934895
Validation loss: 2.4028608727165124

Epoch: 6| Step: 3
Training loss: 2.861733053152387
Validation loss: 2.410295652175774

Epoch: 6| Step: 4
Training loss: 2.5880553455831965
Validation loss: 2.4444277358983415

Epoch: 6| Step: 5
Training loss: 2.055666382124582
Validation loss: 2.463026189545955

Epoch: 6| Step: 6
Training loss: 1.9562153286039945
Validation loss: 2.4354856185550964

Epoch: 6| Step: 7
Training loss: 1.805351828631592
Validation loss: 2.4359275767099966

Epoch: 6| Step: 8
Training loss: 1.5840649002246654
Validation loss: 2.4148244685693143

Epoch: 6| Step: 9
Training loss: 2.0279333179804735
Validation loss: 2.4310872166720348

Epoch: 6| Step: 10
Training loss: 2.271055881432545
Validation loss: 2.394008848818612

Epoch: 6| Step: 11
Training loss: 2.0772838754622276
Validation loss: 2.42592707454538

Epoch: 6| Step: 12
Training loss: 1.7550451578269897
Validation loss: 2.43358608622498

Epoch: 6| Step: 13
Training loss: 2.3594163297355353
Validation loss: 2.4249462965361803

Epoch: 230| Step: 0
Training loss: 1.8391925931047162
Validation loss: 2.447464549339697

Epoch: 6| Step: 1
Training loss: 1.4675093747672985
Validation loss: 2.431832310586593

Epoch: 6| Step: 2
Training loss: 2.2649208816284556
Validation loss: 2.4148975296325563

Epoch: 6| Step: 3
Training loss: 2.327784878252844
Validation loss: 2.4043552176382073

Epoch: 6| Step: 4
Training loss: 2.4147090107880507
Validation loss: 2.441456095131288

Epoch: 6| Step: 5
Training loss: 2.164024820929313
Validation loss: 2.4438095424995456

Epoch: 6| Step: 6
Training loss: 2.0419050843002022
Validation loss: 2.459020403551037

Epoch: 6| Step: 7
Training loss: 2.0478143065578642
Validation loss: 2.4098017837052366

Epoch: 6| Step: 8
Training loss: 1.9064436016889927
Validation loss: 2.41871976857637

Epoch: 6| Step: 9
Training loss: 2.293683696069169
Validation loss: 2.4387309224419287

Epoch: 6| Step: 10
Training loss: 2.2452461036416405
Validation loss: 2.458135945415246

Epoch: 6| Step: 11
Training loss: 1.578852419759018
Validation loss: 2.4383098171027235

Epoch: 6| Step: 12
Training loss: 2.3047212242633215
Validation loss: 2.365428338998647

Epoch: 6| Step: 13
Training loss: 2.067087446979022
Validation loss: 2.374432978059045

Epoch: 231| Step: 0
Training loss: 2.3275741847228377
Validation loss: 2.441606974695434

Epoch: 6| Step: 1
Training loss: 2.4283941328422385
Validation loss: 2.4192079506996813

Epoch: 6| Step: 2
Training loss: 1.3443752874412211
Validation loss: 2.4586795634678715

Epoch: 6| Step: 3
Training loss: 2.5683354249715076
Validation loss: 2.448802618192064

Epoch: 6| Step: 4
Training loss: 2.0201091714194868
Validation loss: 2.4020151034394477

Epoch: 6| Step: 5
Training loss: 1.667861970793562
Validation loss: 2.4456288783270925

Epoch: 6| Step: 6
Training loss: 2.2182889647409123
Validation loss: 2.425735074503865

Epoch: 6| Step: 7
Training loss: 2.2778556340048586
Validation loss: 2.4076257945516515

Epoch: 6| Step: 8
Training loss: 1.8041466897588245
Validation loss: 2.412511813694689

Epoch: 6| Step: 9
Training loss: 2.3028149255022043
Validation loss: 2.4294017091749667

Epoch: 6| Step: 10
Training loss: 2.093825381615843
Validation loss: 2.4460826689529163

Epoch: 6| Step: 11
Training loss: 1.8472233400206024
Validation loss: 2.420740177266308

Epoch: 6| Step: 12
Training loss: 1.560771291015332
Validation loss: 2.427936925823512

Epoch: 6| Step: 13
Training loss: 2.8441857643354345
Validation loss: 2.4490028068041245

Epoch: 232| Step: 0
Training loss: 1.4684498256986795
Validation loss: 2.418328319330169

Epoch: 6| Step: 1
Training loss: 1.7420362056162486
Validation loss: 2.4365811273829783

Epoch: 6| Step: 2
Training loss: 1.6404283678204152
Validation loss: 2.4297956443860462

Epoch: 6| Step: 3
Training loss: 2.342278896225609
Validation loss: 2.4391598725338235

Epoch: 6| Step: 4
Training loss: 2.9352837176207833
Validation loss: 2.4606057532840806

Epoch: 6| Step: 5
Training loss: 2.1287817122403934
Validation loss: 2.436857164511958

Epoch: 6| Step: 6
Training loss: 2.057230836636949
Validation loss: 2.4215420412380286

Epoch: 6| Step: 7
Training loss: 2.0435085422308394
Validation loss: 2.4515867022062534

Epoch: 6| Step: 8
Training loss: 2.259395480030148
Validation loss: 2.4425014428612366

Epoch: 6| Step: 9
Training loss: 2.389770355045337
Validation loss: 2.4090175526469015

Epoch: 6| Step: 10
Training loss: 1.9918104824776655
Validation loss: 2.4540324014585453

Epoch: 6| Step: 11
Training loss: 1.365085228016381
Validation loss: 2.427775347233264

Epoch: 6| Step: 12
Training loss: 2.308709827480466
Validation loss: 2.4630493051531417

Epoch: 6| Step: 13
Training loss: 1.8413504163574357
Validation loss: 2.4409011007137864

Epoch: 233| Step: 0
Training loss: 2.1006926257193044
Validation loss: 2.4001642416442865

Epoch: 6| Step: 1
Training loss: 1.6787668943371683
Validation loss: 2.4495650938216906

Epoch: 6| Step: 2
Training loss: 1.4689136170501889
Validation loss: 2.4209417327942253

Epoch: 6| Step: 3
Training loss: 2.055082682039117
Validation loss: 2.412718094847033

Epoch: 6| Step: 4
Training loss: 1.3207460402675395
Validation loss: 2.4585371508263063

Epoch: 6| Step: 5
Training loss: 2.6619436837995307
Validation loss: 2.413937606949885

Epoch: 6| Step: 6
Training loss: 2.3161456265430487
Validation loss: 2.4243126252648874

Epoch: 6| Step: 7
Training loss: 2.483261626656966
Validation loss: 2.3992837215583878

Epoch: 6| Step: 8
Training loss: 2.644673511279267
Validation loss: 2.4044743231983765

Epoch: 6| Step: 9
Training loss: 2.051405689902763
Validation loss: 2.436302355706074

Epoch: 6| Step: 10
Training loss: 2.081512214707275
Validation loss: 2.417004172025178

Epoch: 6| Step: 11
Training loss: 1.8277286849857666
Validation loss: 2.4310978894894224

Epoch: 6| Step: 12
Training loss: 1.8579397352072173
Validation loss: 2.4087912398580213

Epoch: 6| Step: 13
Training loss: 1.8924970579943345
Validation loss: 2.4336135661454246

Epoch: 234| Step: 0
Training loss: 1.8210920375585176
Validation loss: 2.421232740524399

Epoch: 6| Step: 1
Training loss: 2.2346198741403596
Validation loss: 2.4172337099818266

Epoch: 6| Step: 2
Training loss: 2.1012137311520536
Validation loss: 2.416833099204239

Epoch: 6| Step: 3
Training loss: 1.9469030534367142
Validation loss: 2.393532053753491

Epoch: 6| Step: 4
Training loss: 1.662596580740291
Validation loss: 2.4096449730196188

Epoch: 6| Step: 5
Training loss: 1.9963807498771933
Validation loss: 2.4611707070012017

Epoch: 6| Step: 6
Training loss: 1.979738541015111
Validation loss: 2.4386299730920857

Epoch: 6| Step: 7
Training loss: 1.8642467500449345
Validation loss: 2.418858052969797

Epoch: 6| Step: 8
Training loss: 2.371932307218238
Validation loss: 2.42605807106518

Epoch: 6| Step: 9
Training loss: 2.779976199480444
Validation loss: 2.454520001380803

Epoch: 6| Step: 10
Training loss: 2.2290436422560305
Validation loss: 2.3983026592005596

Epoch: 6| Step: 11
Training loss: 1.5105258069124103
Validation loss: 2.4412746761840727

Epoch: 6| Step: 12
Training loss: 2.54077982413187
Validation loss: 2.41483258468706

Epoch: 6| Step: 13
Training loss: 1.6117054630384589
Validation loss: 2.409732356585103

Epoch: 235| Step: 0
Training loss: 1.4066469268106807
Validation loss: 2.391642192766664

Epoch: 6| Step: 1
Training loss: 2.641965266378421
Validation loss: 2.422259029515693

Epoch: 6| Step: 2
Training loss: 1.7876730108229744
Validation loss: 2.437361170304605

Epoch: 6| Step: 3
Training loss: 2.1913844904779767
Validation loss: 2.4340538251439816

Epoch: 6| Step: 4
Training loss: 2.186425190226566
Validation loss: 2.41938543799407

Epoch: 6| Step: 5
Training loss: 1.83312974868716
Validation loss: 2.416820355395075

Epoch: 6| Step: 6
Training loss: 2.24538159566071
Validation loss: 2.391866965230054

Epoch: 6| Step: 7
Training loss: 2.4085331773395224
Validation loss: 2.439297274579075

Epoch: 6| Step: 8
Training loss: 2.385911870692611
Validation loss: 2.3937027414328957

Epoch: 6| Step: 9
Training loss: 1.6597807336102983
Validation loss: 2.4539324187571

Epoch: 6| Step: 10
Training loss: 1.9006800338068124
Validation loss: 2.4551916916942655

Epoch: 6| Step: 11
Training loss: 1.5997863597097135
Validation loss: 2.428509185961463

Epoch: 6| Step: 12
Training loss: 2.0025539780484216
Validation loss: 2.4756203823642653

Epoch: 6| Step: 13
Training loss: 2.6399520829215954
Validation loss: 2.399840297649475

Epoch: 236| Step: 0
Training loss: 2.601341627671187
Validation loss: 2.3921364961583835

Epoch: 6| Step: 1
Training loss: 2.3023719664191815
Validation loss: 2.4569782358503836

Epoch: 6| Step: 2
Training loss: 1.2884887343163243
Validation loss: 2.4006105715350112

Epoch: 6| Step: 3
Training loss: 2.033215085744718
Validation loss: 2.413638529995208

Epoch: 6| Step: 4
Training loss: 1.491135151254453
Validation loss: 2.4374632252836883

Epoch: 6| Step: 5
Training loss: 2.2530537121800407
Validation loss: 2.4274764263955486

Epoch: 6| Step: 6
Training loss: 2.0457672149892336
Validation loss: 2.4324998915119953

Epoch: 6| Step: 7
Training loss: 2.7046610266206925
Validation loss: 2.4303159122333144

Epoch: 6| Step: 8
Training loss: 1.982967327977979
Validation loss: 2.4550710848615336

Epoch: 6| Step: 9
Training loss: 2.2982495405465784
Validation loss: 2.452550382494367

Epoch: 6| Step: 10
Training loss: 2.13617684084472
Validation loss: 2.408391530387997

Epoch: 6| Step: 11
Training loss: 1.8235607716815327
Validation loss: 2.444068634003982

Epoch: 6| Step: 12
Training loss: 1.6893351430986119
Validation loss: 2.43124964068432

Epoch: 6| Step: 13
Training loss: 1.9031019012101718
Validation loss: 2.4449541718608856

Epoch: 237| Step: 0
Training loss: 2.073478379813191
Validation loss: 2.4128650616270315

Epoch: 6| Step: 1
Training loss: 2.168597046133406
Validation loss: 2.4187315272598053

Epoch: 6| Step: 2
Training loss: 2.405052778969498
Validation loss: 2.40296654053919

Epoch: 6| Step: 3
Training loss: 1.9353936343538647
Validation loss: 2.4085876196756772

Epoch: 6| Step: 4
Training loss: 2.270432311412694
Validation loss: 2.442290366734257

Epoch: 6| Step: 5
Training loss: 1.7935512153453133
Validation loss: 2.3891395148183276

Epoch: 6| Step: 6
Training loss: 1.9786374505543163
Validation loss: 2.410523665740024

Epoch: 6| Step: 7
Training loss: 2.659292386090792
Validation loss: 2.4624425017779235

Epoch: 6| Step: 8
Training loss: 2.215381052552317
Validation loss: 2.4212941786181874

Epoch: 6| Step: 9
Training loss: 1.8752898945818226
Validation loss: 2.4237367130645957

Epoch: 6| Step: 10
Training loss: 1.551401624377798
Validation loss: 2.401562336097792

Epoch: 6| Step: 11
Training loss: 1.124562973331896
Validation loss: 2.425358571693957

Epoch: 6| Step: 12
Training loss: 1.8563268343760966
Validation loss: 2.458745395948806

Epoch: 6| Step: 13
Training loss: 2.84395154301692
Validation loss: 2.4003877424399045

Epoch: 238| Step: 0
Training loss: 2.247569997204533
Validation loss: 2.442310035166659

Epoch: 6| Step: 1
Training loss: 2.092744614353252
Validation loss: 2.413334579414196

Epoch: 6| Step: 2
Training loss: 2.0442377237607023
Validation loss: 2.4591556982553606

Epoch: 6| Step: 3
Training loss: 2.227711591849897
Validation loss: 2.411448252213507

Epoch: 6| Step: 4
Training loss: 1.8959503207599278
Validation loss: 2.413095187720178

Epoch: 6| Step: 5
Training loss: 1.9255773966451157
Validation loss: 2.422233391481671

Epoch: 6| Step: 6
Training loss: 1.7331671418088685
Validation loss: 2.432934008102146

Epoch: 6| Step: 7
Training loss: 2.6571528975858127
Validation loss: 2.397701868232814

Epoch: 6| Step: 8
Training loss: 1.6617013719633744
Validation loss: 2.440244583549796

Epoch: 6| Step: 9
Training loss: 2.133685593529687
Validation loss: 2.475598176862533

Epoch: 6| Step: 10
Training loss: 1.6992372709119952
Validation loss: 2.432314989865657

Epoch: 6| Step: 11
Training loss: 1.924056017395271
Validation loss: 2.4254733016274637

Epoch: 6| Step: 12
Training loss: 1.881308180204027
Validation loss: 2.4440524144485516

Epoch: 6| Step: 13
Training loss: 2.7666839468849136
Validation loss: 2.436755655424906

Epoch: 239| Step: 0
Training loss: 1.815512554212494
Validation loss: 2.4327069421405816

Epoch: 6| Step: 1
Training loss: 1.955086417471175
Validation loss: 2.429079082286752

Epoch: 6| Step: 2
Training loss: 2.2609031142102713
Validation loss: 2.3939937261312334

Epoch: 6| Step: 3
Training loss: 1.9181822990045434
Validation loss: 2.4337402862168402

Epoch: 6| Step: 4
Training loss: 2.168687196201486
Validation loss: 2.4223072112244908

Epoch: 6| Step: 5
Training loss: 1.5806465776749794
Validation loss: 2.4246626895587253

Epoch: 6| Step: 6
Training loss: 2.686374251100147
Validation loss: 2.435692012783374

Epoch: 6| Step: 7
Training loss: 1.8051079594669153
Validation loss: 2.440417571148259

Epoch: 6| Step: 8
Training loss: 1.48722405318395
Validation loss: 2.428786825519915

Epoch: 6| Step: 9
Training loss: 2.112849672710161
Validation loss: 2.402777849539956

Epoch: 6| Step: 10
Training loss: 2.234002355698972
Validation loss: 2.454214264548633

Epoch: 6| Step: 11
Training loss: 1.9803279548271908
Validation loss: 2.4382640502523656

Epoch: 6| Step: 12
Training loss: 2.179495197960328
Validation loss: 2.4105540232015055

Epoch: 6| Step: 13
Training loss: 2.0829568777102985
Validation loss: 2.4069002240087065

Epoch: 240| Step: 0
Training loss: 1.7532295671852804
Validation loss: 2.4191517005088885

Epoch: 6| Step: 1
Training loss: 1.6448195832170251
Validation loss: 2.443743150299303

Epoch: 6| Step: 2
Training loss: 2.2473830793305423
Validation loss: 2.403814529299269

Epoch: 6| Step: 3
Training loss: 1.761712389340305
Validation loss: 2.4129334604598616

Epoch: 6| Step: 4
Training loss: 2.160419910199175
Validation loss: 2.4577374559109013

Epoch: 6| Step: 5
Training loss: 2.3800064324043606
Validation loss: 2.415465178950358

Epoch: 6| Step: 6
Training loss: 2.2989219834346684
Validation loss: 2.4132101320543886

Epoch: 6| Step: 7
Training loss: 2.5914231859584693
Validation loss: 2.4267670275088853

Epoch: 6| Step: 8
Training loss: 2.4043692632913634
Validation loss: 2.4095130926908803

Epoch: 6| Step: 9
Training loss: 2.0958687609287727
Validation loss: 2.4284152128445884

Epoch: 6| Step: 10
Training loss: 1.4994553530852448
Validation loss: 2.383719342890021

Epoch: 6| Step: 11
Training loss: 1.4847930319569131
Validation loss: 2.4230757389375976

Epoch: 6| Step: 12
Training loss: 1.9062969014385787
Validation loss: 2.4210467999523875

Epoch: 6| Step: 13
Training loss: 2.2256071483878457
Validation loss: 2.4184625153167496

Epoch: 241| Step: 0
Training loss: 1.930701356256524
Validation loss: 2.4389535794144837

Epoch: 6| Step: 1
Training loss: 1.7172763402309603
Validation loss: 2.4231791583577773

Epoch: 6| Step: 2
Training loss: 1.6648037114871448
Validation loss: 2.420993266792587

Epoch: 6| Step: 3
Training loss: 2.6510947970978824
Validation loss: 2.416974224389675

Epoch: 6| Step: 4
Training loss: 2.0996191406022895
Validation loss: 2.440007462190043

Epoch: 6| Step: 5
Training loss: 1.6107901120032269
Validation loss: 2.4462466475914173

Epoch: 6| Step: 6
Training loss: 2.2123421564210264
Validation loss: 2.4217482730499387

Epoch: 6| Step: 7
Training loss: 2.1356044283560713
Validation loss: 2.413535163815365

Epoch: 6| Step: 8
Training loss: 1.9424384767468583
Validation loss: 2.4206302308618985

Epoch: 6| Step: 9
Training loss: 1.7632292300804393
Validation loss: 2.444301807979973

Epoch: 6| Step: 10
Training loss: 2.3396592107229113
Validation loss: 2.3966859760003185

Epoch: 6| Step: 11
Training loss: 2.0856332164096143
Validation loss: 2.4251917034356993

Epoch: 6| Step: 12
Training loss: 2.196260620855749
Validation loss: 2.408324514670168

Epoch: 6| Step: 13
Training loss: 1.6202814112065425
Validation loss: 2.443896536337077

Epoch: 242| Step: 0
Training loss: 1.7497471899257202
Validation loss: 2.413371783411799

Epoch: 6| Step: 1
Training loss: 1.3694152556595705
Validation loss: 2.442254451951701

Epoch: 6| Step: 2
Training loss: 2.353111795943096
Validation loss: 2.4439787857748563

Epoch: 6| Step: 3
Training loss: 2.1284142161837476
Validation loss: 2.4179152494170735

Epoch: 6| Step: 4
Training loss: 1.6970274377289565
Validation loss: 2.490025569647593

Epoch: 6| Step: 5
Training loss: 2.0486852197838354
Validation loss: 2.4094785784421537

Epoch: 6| Step: 6
Training loss: 2.6893077359485678
Validation loss: 2.431902676447083

Epoch: 6| Step: 7
Training loss: 1.9147117914794753
Validation loss: 2.4830621413404006

Epoch: 6| Step: 8
Training loss: 2.1922611194302064
Validation loss: 2.4652361844975714

Epoch: 6| Step: 9
Training loss: 2.3868279315056373
Validation loss: 2.4657056175417424

Epoch: 6| Step: 10
Training loss: 2.2464304265333666
Validation loss: 2.495416674996063

Epoch: 6| Step: 11
Training loss: 1.8322714707080405
Validation loss: 2.4811724690885346

Epoch: 6| Step: 12
Training loss: 2.121585346390534
Validation loss: 2.394845403761073

Epoch: 6| Step: 13
Training loss: 1.1182466301563434
Validation loss: 2.465977025371856

Epoch: 243| Step: 0
Training loss: 1.9473014988937882
Validation loss: 2.437890567625714

Epoch: 6| Step: 1
Training loss: 1.9362808206369697
Validation loss: 2.4116124167010278

Epoch: 6| Step: 2
Training loss: 2.6500105335817974
Validation loss: 2.436121100703494

Epoch: 6| Step: 3
Training loss: 1.633896609253543
Validation loss: 2.3993774514374273

Epoch: 6| Step: 4
Training loss: 1.8593951312345738
Validation loss: 2.4223524847528655

Epoch: 6| Step: 5
Training loss: 1.7068681093382059
Validation loss: 2.4368876362966088

Epoch: 6| Step: 6
Training loss: 2.0903903709776728
Validation loss: 2.4294792745261433

Epoch: 6| Step: 7
Training loss: 1.843768103559162
Validation loss: 2.4251783375803435

Epoch: 6| Step: 8
Training loss: 2.2842409566854944
Validation loss: 2.4210343282243825

Epoch: 6| Step: 9
Training loss: 2.130644538322064
Validation loss: 2.4379008257817265

Epoch: 6| Step: 10
Training loss: 1.9874956718733583
Validation loss: 2.437220341510759

Epoch: 6| Step: 11
Training loss: 2.282348577317091
Validation loss: 2.423197738281626

Epoch: 6| Step: 12
Training loss: 1.8743041972709422
Validation loss: 2.3762795574869755

Epoch: 6| Step: 13
Training loss: 1.952745324424818
Validation loss: 2.4259434934848363

Epoch: 244| Step: 0
Training loss: 3.0162656429689805
Validation loss: 2.4294323040183974

Epoch: 6| Step: 1
Training loss: 1.6089752589683186
Validation loss: 2.419027974734955

Epoch: 6| Step: 2
Training loss: 2.598523171687643
Validation loss: 2.3818080281087197

Epoch: 6| Step: 3
Training loss: 1.6226817981690467
Validation loss: 2.4228481596196088

Epoch: 6| Step: 4
Training loss: 1.4675585195385783
Validation loss: 2.426788365671532

Epoch: 6| Step: 5
Training loss: 1.9065565894547518
Validation loss: 2.444832621684972

Epoch: 6| Step: 6
Training loss: 1.6925377001712116
Validation loss: 2.445101130243003

Epoch: 6| Step: 7
Training loss: 1.6679493815885498
Validation loss: 2.431298363346902

Epoch: 6| Step: 8
Training loss: 2.2932260814065226
Validation loss: 2.4302443970145635

Epoch: 6| Step: 9
Training loss: 2.236160098764104
Validation loss: 2.4705843338105864

Epoch: 6| Step: 10
Training loss: 1.7375440084249316
Validation loss: 2.4392624218946577

Epoch: 6| Step: 11
Training loss: 1.8216111949119294
Validation loss: 2.440180375196612

Epoch: 6| Step: 12
Training loss: 2.4649111682600915
Validation loss: 2.4259619909456083

Epoch: 6| Step: 13
Training loss: 1.9293330558169433
Validation loss: 2.461568978150936

Epoch: 245| Step: 0
Training loss: 2.3601012470057645
Validation loss: 2.443603298849952

Epoch: 6| Step: 1
Training loss: 1.8339888600059977
Validation loss: 2.4428990815641933

Epoch: 6| Step: 2
Training loss: 1.58397895633321
Validation loss: 2.500116423490391

Epoch: 6| Step: 3
Training loss: 1.9557465316739757
Validation loss: 2.4336308022999726

Epoch: 6| Step: 4
Training loss: 1.3758434396407633
Validation loss: 2.418113628215648

Epoch: 6| Step: 5
Training loss: 1.8919873334125947
Validation loss: 2.430968788595379

Epoch: 6| Step: 6
Training loss: 2.5031882936473973
Validation loss: 2.419030730164791

Epoch: 6| Step: 7
Training loss: 2.2746353402114194
Validation loss: 2.440241789039753

Epoch: 6| Step: 8
Training loss: 1.7135519319205565
Validation loss: 2.4043218651474088

Epoch: 6| Step: 9
Training loss: 2.153540304628276
Validation loss: 2.414255703359968

Epoch: 6| Step: 10
Training loss: 1.900575477885712
Validation loss: 2.4084495811737545

Epoch: 6| Step: 11
Training loss: 2.247245267831868
Validation loss: 2.4549812821666164

Epoch: 6| Step: 12
Training loss: 2.0035426235629714
Validation loss: 2.4465260119983276

Epoch: 6| Step: 13
Training loss: 1.53131835162139
Validation loss: 2.411922502563012

Epoch: 246| Step: 0
Training loss: 2.1749519123593144
Validation loss: 2.4053359653541353

Epoch: 6| Step: 1
Training loss: 1.965961661565526
Validation loss: 2.411159149096393

Epoch: 6| Step: 2
Training loss: 2.0747729349565986
Validation loss: 2.431978573447438

Epoch: 6| Step: 3
Training loss: 2.500717060250857
Validation loss: 2.451179042430309

Epoch: 6| Step: 4
Training loss: 1.8984542657559256
Validation loss: 2.4119669432077724

Epoch: 6| Step: 5
Training loss: 2.513511575539021
Validation loss: 2.414438329599498

Epoch: 6| Step: 6
Training loss: 1.78815700487697
Validation loss: 2.439104873392054

Epoch: 6| Step: 7
Training loss: 1.7708049846698788
Validation loss: 2.4108601570649775

Epoch: 6| Step: 8
Training loss: 1.8002270820217328
Validation loss: 2.4497570868373466

Epoch: 6| Step: 9
Training loss: 1.613889270212665
Validation loss: 2.4524953292821103

Epoch: 6| Step: 10
Training loss: 2.582934338510777
Validation loss: 2.4163860063305744

Epoch: 6| Step: 11
Training loss: 1.6205104283953893
Validation loss: 2.4255981968070435

Epoch: 6| Step: 12
Training loss: 1.7729245422881665
Validation loss: 2.464285318497784

Epoch: 6| Step: 13
Training loss: 1.6620690669227425
Validation loss: 2.4653006387409633

Epoch: 247| Step: 0
Training loss: 2.146782143707247
Validation loss: 2.4167654015891675

Epoch: 6| Step: 1
Training loss: 2.1954575894559225
Validation loss: 2.4225491974991455

Epoch: 6| Step: 2
Training loss: 1.7329472344097887
Validation loss: 2.418848572541462

Epoch: 6| Step: 3
Training loss: 1.6289029567328444
Validation loss: 2.4774265243618165

Epoch: 6| Step: 4
Training loss: 1.7709907760939947
Validation loss: 2.3787580699534923

Epoch: 6| Step: 5
Training loss: 2.276969970598927
Validation loss: 2.4620915897244493

Epoch: 6| Step: 6
Training loss: 2.422027583084102
Validation loss: 2.440067905388564

Epoch: 6| Step: 7
Training loss: 1.8571413873310352
Validation loss: 2.410744134032688

Epoch: 6| Step: 8
Training loss: 2.1635510222358683
Validation loss: 2.4331823349628694

Epoch: 6| Step: 9
Training loss: 1.8921187623798108
Validation loss: 2.4412615989573876

Epoch: 6| Step: 10
Training loss: 2.127733267918119
Validation loss: 2.411208668986664

Epoch: 6| Step: 11
Training loss: 1.3591402662337815
Validation loss: 2.4395293566701888

Epoch: 6| Step: 12
Training loss: 2.1109574775117554
Validation loss: 2.425217432817001

Epoch: 6| Step: 13
Training loss: 2.2358147310878125
Validation loss: 2.406836003794918

Epoch: 248| Step: 0
Training loss: 2.1133945173839166
Validation loss: 2.434990227351123

Epoch: 6| Step: 1
Training loss: 2.708767948980148
Validation loss: 2.434157402685242

Epoch: 6| Step: 2
Training loss: 2.073575424746893
Validation loss: 2.444357485178409

Epoch: 6| Step: 3
Training loss: 1.4688400890235815
Validation loss: 2.4322522886520797

Epoch: 6| Step: 4
Training loss: 1.8391702314145528
Validation loss: 2.381779236855597

Epoch: 6| Step: 5
Training loss: 1.7976048853041744
Validation loss: 2.473461920907013

Epoch: 6| Step: 6
Training loss: 1.9991048955603528
Validation loss: 2.469900071810203

Epoch: 6| Step: 7
Training loss: 1.7874078553464987
Validation loss: 2.4082498346532435

Epoch: 6| Step: 8
Training loss: 1.8091603785961536
Validation loss: 2.4203361319470322

Epoch: 6| Step: 9
Training loss: 2.0965326521496253
Validation loss: 2.4173439471446625

Epoch: 6| Step: 10
Training loss: 2.012071300835837
Validation loss: 2.4863144237711543

Epoch: 6| Step: 11
Training loss: 1.6377193333155642
Validation loss: 2.4190495878184346

Epoch: 6| Step: 12
Training loss: 2.2696496404079327
Validation loss: 2.3954708415444648

Epoch: 6| Step: 13
Training loss: 1.874780514904329
Validation loss: 2.4192313032502537

Epoch: 249| Step: 0
Training loss: 1.756909083168442
Validation loss: 2.4407386898156136

Epoch: 6| Step: 1
Training loss: 2.196867476948301
Validation loss: 2.37375885851892

Epoch: 6| Step: 2
Training loss: 2.1340784361134375
Validation loss: 2.397969366335385

Epoch: 6| Step: 3
Training loss: 1.5103728540138988
Validation loss: 2.388840744822477

Epoch: 6| Step: 4
Training loss: 1.876369484814353
Validation loss: 2.3847604794716464

Epoch: 6| Step: 5
Training loss: 2.0937129914158685
Validation loss: 2.4128398699005045

Epoch: 6| Step: 6
Training loss: 1.5255893475259146
Validation loss: 2.4542384199848515

Epoch: 6| Step: 7
Training loss: 1.6233571624704064
Validation loss: 2.442442130500102

Epoch: 6| Step: 8
Training loss: 2.7651189998521772
Validation loss: 2.4369322339306434

Epoch: 6| Step: 9
Training loss: 1.7640340608478684
Validation loss: 2.4255595716987726

Epoch: 6| Step: 10
Training loss: 2.5433446837738996
Validation loss: 2.461273371493851

Epoch: 6| Step: 11
Training loss: 1.6506171257296325
Validation loss: 2.4125292646331338

Epoch: 6| Step: 12
Training loss: 2.0765177312177046
Validation loss: 2.423061884244755

Epoch: 6| Step: 13
Training loss: 1.4376423806706302
Validation loss: 2.399970660705416

Epoch: 250| Step: 0
Training loss: 1.7260585411902942
Validation loss: 2.4033855898668772

Epoch: 6| Step: 1
Training loss: 1.5112403290015564
Validation loss: 2.460049388126945

Epoch: 6| Step: 2
Training loss: 1.6542657446155964
Validation loss: 2.430852158160706

Epoch: 6| Step: 3
Training loss: 2.144202035117289
Validation loss: 2.427955938151245

Epoch: 6| Step: 4
Training loss: 2.6837351843643074
Validation loss: 2.4073075377201576

Epoch: 6| Step: 5
Training loss: 1.9519532618008257
Validation loss: 2.445809096975697

Epoch: 6| Step: 6
Training loss: 1.803773062089986
Validation loss: 2.448967450017642

Epoch: 6| Step: 7
Training loss: 2.454495672722967
Validation loss: 2.416996700133081

Epoch: 6| Step: 8
Training loss: 1.5255790330337213
Validation loss: 2.434935562540537

Epoch: 6| Step: 9
Training loss: 1.544854125262662
Validation loss: 2.4385365295573314

Epoch: 6| Step: 10
Training loss: 2.0157685931016633
Validation loss: 2.432283042103152

Epoch: 6| Step: 11
Training loss: 2.3169000366274157
Validation loss: 2.4679935563834134

Epoch: 6| Step: 12
Training loss: 2.1110762905573126
Validation loss: 2.410174235737548

Epoch: 6| Step: 13
Training loss: 1.768470564157488
Validation loss: 2.4188429563372678

Epoch: 251| Step: 0
Training loss: 1.8390328793016029
Validation loss: 2.4232232719554885

Epoch: 6| Step: 1
Training loss: 2.8552042242385003
Validation loss: 2.430762608191479

Epoch: 6| Step: 2
Training loss: 2.0272068572821853
Validation loss: 2.418577859632334

Epoch: 6| Step: 3
Training loss: 2.342544652621146
Validation loss: 2.4249957833202167

Epoch: 6| Step: 4
Training loss: 1.426182687760726
Validation loss: 2.4493689169392656

Epoch: 6| Step: 5
Training loss: 1.5449066740076673
Validation loss: 2.4490409145789847

Epoch: 6| Step: 6
Training loss: 1.9384409557694855
Validation loss: 2.396105090579138

Epoch: 6| Step: 7
Training loss: 1.9844303273575399
Validation loss: 2.407585505366117

Epoch: 6| Step: 8
Training loss: 2.3817642657830835
Validation loss: 2.4179059741658833

Epoch: 6| Step: 9
Training loss: 1.6406780415997966
Validation loss: 2.381192125980063

Epoch: 6| Step: 10
Training loss: 1.520029177636633
Validation loss: 2.4068594412346926

Epoch: 6| Step: 11
Training loss: 1.9593235380237877
Validation loss: 2.489532329791853

Epoch: 6| Step: 12
Training loss: 1.601043914945567
Validation loss: 2.401344845177223

Epoch: 6| Step: 13
Training loss: 1.3968818579042455
Validation loss: 2.4482749825084826

Epoch: 252| Step: 0
Training loss: 2.1417053169691407
Validation loss: 2.4004647853847114

Epoch: 6| Step: 1
Training loss: 1.6732406030217488
Validation loss: 2.431520438886316

Epoch: 6| Step: 2
Training loss: 1.5304716039127615
Validation loss: 2.3989613562072636

Epoch: 6| Step: 3
Training loss: 2.0143544532232194
Validation loss: 2.449238090126725

Epoch: 6| Step: 4
Training loss: 1.7844636938496
Validation loss: 2.4625478345606764

Epoch: 6| Step: 5
Training loss: 1.9410154997114886
Validation loss: 2.449532866588544

Epoch: 6| Step: 6
Training loss: 2.0339622582804067
Validation loss: 2.4290530423587398

Epoch: 6| Step: 7
Training loss: 2.208236500278471
Validation loss: 2.4049860481023124

Epoch: 6| Step: 8
Training loss: 2.202381630876552
Validation loss: 2.421573635779397

Epoch: 6| Step: 9
Training loss: 1.9969076449452527
Validation loss: 2.4317865825966054

Epoch: 6| Step: 10
Training loss: 2.5630284206497973
Validation loss: 2.373605123155873

Epoch: 6| Step: 11
Training loss: 1.818280243918801
Validation loss: 2.444004189402171

Epoch: 6| Step: 12
Training loss: 1.5869378003032286
Validation loss: 2.429633554730834

Epoch: 6| Step: 13
Training loss: 1.31738290298948
Validation loss: 2.4228157748787966

Epoch: 253| Step: 0
Training loss: 1.8186607889535364
Validation loss: 2.399019574270322

Epoch: 6| Step: 1
Training loss: 2.224268323629253
Validation loss: 2.4504253078566207

Epoch: 6| Step: 2
Training loss: 2.668758962290096
Validation loss: 2.4215572502020217

Epoch: 6| Step: 3
Training loss: 1.745086106086006
Validation loss: 2.431752589527959

Epoch: 6| Step: 4
Training loss: 2.3702382990791
Validation loss: 2.437181986848097

Epoch: 6| Step: 5
Training loss: 1.6336193372783143
Validation loss: 2.404628523764417

Epoch: 6| Step: 6
Training loss: 2.073974365090664
Validation loss: 2.4205261655597536

Epoch: 6| Step: 7
Training loss: 1.190994741945487
Validation loss: 2.4614315403650697

Epoch: 6| Step: 8
Training loss: 2.0400778628430833
Validation loss: 2.420644910722807

Epoch: 6| Step: 9
Training loss: 2.0462936857170737
Validation loss: 2.4665533105711184

Epoch: 6| Step: 10
Training loss: 1.4788901737747961
Validation loss: 2.405589470765608

Epoch: 6| Step: 11
Training loss: 1.801492546423983
Validation loss: 2.4377208908851915

Epoch: 6| Step: 12
Training loss: 1.913603560253646
Validation loss: 2.4527355412951013

Epoch: 6| Step: 13
Training loss: 1.6781173109166112
Validation loss: 2.4000805403755296

Epoch: 254| Step: 0
Training loss: 1.3565887309440237
Validation loss: 2.4299433190734354

Epoch: 6| Step: 1
Training loss: 1.5578836530010327
Validation loss: 2.3989194093448294

Epoch: 6| Step: 2
Training loss: 1.3352432677972947
Validation loss: 2.3951939158024933

Epoch: 6| Step: 3
Training loss: 1.4317918309901196
Validation loss: 2.4282958146159785

Epoch: 6| Step: 4
Training loss: 2.074675831119102
Validation loss: 2.3804254925330492

Epoch: 6| Step: 5
Training loss: 1.7580208209891173
Validation loss: 2.4541275074425593

Epoch: 6| Step: 6
Training loss: 2.2390377237635546
Validation loss: 2.4459564934612166

Epoch: 6| Step: 7
Training loss: 2.683403974594422
Validation loss: 2.4756627931489064

Epoch: 6| Step: 8
Training loss: 2.39681504633399
Validation loss: 2.438844393652711

Epoch: 6| Step: 9
Training loss: 2.156366980876256
Validation loss: 2.4258053350571496

Epoch: 6| Step: 10
Training loss: 2.2636061519794684
Validation loss: 2.4381598817023855

Epoch: 6| Step: 11
Training loss: 1.4411237072759755
Validation loss: 2.4674055562041413

Epoch: 6| Step: 12
Training loss: 1.7019816069006948
Validation loss: 2.4104715516228694

Epoch: 6| Step: 13
Training loss: 2.405243799458334
Validation loss: 2.4632472795671685

Epoch: 255| Step: 0
Training loss: 1.996821858589951
Validation loss: 2.4504143248000796

Epoch: 6| Step: 1
Training loss: 2.469808906699871
Validation loss: 2.4412672549479106

Epoch: 6| Step: 2
Training loss: 1.9202022561195835
Validation loss: 2.437436252598653

Epoch: 6| Step: 3
Training loss: 1.99735812699107
Validation loss: 2.4612257099031596

Epoch: 6| Step: 4
Training loss: 1.2835925018063012
Validation loss: 2.465386968868725

Epoch: 6| Step: 5
Training loss: 1.4964973562658876
Validation loss: 2.4327818888225416

Epoch: 6| Step: 6
Training loss: 1.6002552931486032
Validation loss: 2.4621455245850967

Epoch: 6| Step: 7
Training loss: 2.877368283277249
Validation loss: 2.443626086746263

Epoch: 6| Step: 8
Training loss: 1.5331595833785434
Validation loss: 2.413761391866589

Epoch: 6| Step: 9
Training loss: 1.8501488806126194
Validation loss: 2.4237833528854873

Epoch: 6| Step: 10
Training loss: 1.956278764799659
Validation loss: 2.4463425356971706

Epoch: 6| Step: 11
Training loss: 2.302223465971118
Validation loss: 2.443411138106294

Epoch: 6| Step: 12
Training loss: 1.7170675192406102
Validation loss: 2.4106674568284054

Epoch: 6| Step: 13
Training loss: 2.0249294833868188
Validation loss: 2.3999820529957185

Epoch: 256| Step: 0
Training loss: 1.3576090512109407
Validation loss: 2.429219248567427

Epoch: 6| Step: 1
Training loss: 1.8505110189526726
Validation loss: 2.3910927574622467

Epoch: 6| Step: 2
Training loss: 1.6942356046932212
Validation loss: 2.4011822709759283

Epoch: 6| Step: 3
Training loss: 2.2644454516349417
Validation loss: 2.398932987760845

Epoch: 6| Step: 4
Training loss: 2.4156248104988607
Validation loss: 2.4378204429559918

Epoch: 6| Step: 5
Training loss: 1.9341996293694848
Validation loss: 2.3938775688850096

Epoch: 6| Step: 6
Training loss: 1.8274857797343391
Validation loss: 2.4254594468893376

Epoch: 6| Step: 7
Training loss: 1.4103663914039177
Validation loss: 2.4426337839311816

Epoch: 6| Step: 8
Training loss: 1.5913244002599825
Validation loss: 2.3626716963297505

Epoch: 6| Step: 9
Training loss: 3.003301552178514
Validation loss: 2.422754711862915

Epoch: 6| Step: 10
Training loss: 1.9017945423087625
Validation loss: 2.4215633248680306

Epoch: 6| Step: 11
Training loss: 1.9131112362336302
Validation loss: 2.404028957518637

Epoch: 6| Step: 12
Training loss: 1.5858893927432722
Validation loss: 2.3974870414725427

Epoch: 6| Step: 13
Training loss: 1.9582322750665158
Validation loss: 2.375503463468113

Epoch: 257| Step: 0
Training loss: 1.578193738592313
Validation loss: 2.4667445168401922

Epoch: 6| Step: 1
Training loss: 2.1967675216668896
Validation loss: 2.4455356374872603

Epoch: 6| Step: 2
Training loss: 2.1237870288694536
Validation loss: 2.4529578394487306

Epoch: 6| Step: 3
Training loss: 1.9469295047092416
Validation loss: 2.4270822636898015

Epoch: 6| Step: 4
Training loss: 2.8889650269606855
Validation loss: 2.4167490635008666

Epoch: 6| Step: 5
Training loss: 1.8027317960478912
Validation loss: 2.429387893724641

Epoch: 6| Step: 6
Training loss: 1.6040543686173698
Validation loss: 2.433276100794843

Epoch: 6| Step: 7
Training loss: 1.5294245524109171
Validation loss: 2.4531892363513594

Epoch: 6| Step: 8
Training loss: 1.2511475064336837
Validation loss: 2.4718548944002854

Epoch: 6| Step: 9
Training loss: 1.696372127310994
Validation loss: 2.440099344631707

Epoch: 6| Step: 10
Training loss: 2.2659634041453054
Validation loss: 2.419132748804918

Epoch: 6| Step: 11
Training loss: 1.8957305572933387
Validation loss: 2.403490974362511

Epoch: 6| Step: 12
Training loss: 2.104046002947543
Validation loss: 2.416060533100471

Epoch: 6| Step: 13
Training loss: 1.4329019067256823
Validation loss: 2.4577988498394405

Epoch: 258| Step: 0
Training loss: 2.168732269830263
Validation loss: 2.416985773596152

Epoch: 6| Step: 1
Training loss: 1.6299764287449559
Validation loss: 2.4319865595825862

Epoch: 6| Step: 2
Training loss: 1.8553354958318202
Validation loss: 2.428980527397855

Epoch: 6| Step: 3
Training loss: 1.429815317912776
Validation loss: 2.3831562054580298

Epoch: 6| Step: 4
Training loss: 1.7080029268887387
Validation loss: 2.4550542707321483

Epoch: 6| Step: 5
Training loss: 2.582662392723842
Validation loss: 2.489030650435601

Epoch: 6| Step: 6
Training loss: 1.9262731825258488
Validation loss: 2.450162284755108

Epoch: 6| Step: 7
Training loss: 2.0594867311306295
Validation loss: 2.428942632622518

Epoch: 6| Step: 8
Training loss: 1.9837626315834254
Validation loss: 2.4291416590827817

Epoch: 6| Step: 9
Training loss: 1.8554414445976042
Validation loss: 2.4294225124019135

Epoch: 6| Step: 10
Training loss: 2.4002716308102223
Validation loss: 2.458663017485665

Epoch: 6| Step: 11
Training loss: 1.9318466153831757
Validation loss: 2.4735476594140797

Epoch: 6| Step: 12
Training loss: 1.3474617195707705
Validation loss: 2.450784411674746

Epoch: 6| Step: 13
Training loss: 1.4244938302781835
Validation loss: 2.45075476829679

Epoch: 259| Step: 0
Training loss: 2.1472637507524337
Validation loss: 2.474783912474176

Epoch: 6| Step: 1
Training loss: 1.4983302200307669
Validation loss: 2.4267173771809225

Epoch: 6| Step: 2
Training loss: 1.9871117050610172
Validation loss: 2.4247919115782066

Epoch: 6| Step: 3
Training loss: 1.395765426274453
Validation loss: 2.4497032392214373

Epoch: 6| Step: 4
Training loss: 1.1782411715352596
Validation loss: 2.4219346223360096

Epoch: 6| Step: 5
Training loss: 1.7932985621606585
Validation loss: 2.45638954425632

Epoch: 6| Step: 6
Training loss: 1.7006183341224073
Validation loss: 2.454586244128682

Epoch: 6| Step: 7
Training loss: 2.0998310202777515
Validation loss: 2.4309367461558407

Epoch: 6| Step: 8
Training loss: 1.9443277831124524
Validation loss: 2.413372326229208

Epoch: 6| Step: 9
Training loss: 1.5087466335812159
Validation loss: 2.45923242105774

Epoch: 6| Step: 10
Training loss: 2.1180656835873233
Validation loss: 2.43496743338714

Epoch: 6| Step: 11
Training loss: 2.9466740625671273
Validation loss: 2.4380988633530745

Epoch: 6| Step: 12
Training loss: 2.187517874508445
Validation loss: 2.457842286798184

Epoch: 6| Step: 13
Training loss: 1.6772696192172911
Validation loss: 2.427014633305632

Epoch: 260| Step: 0
Training loss: 1.9086657366486652
Validation loss: 2.4184534138897997

Epoch: 6| Step: 1
Training loss: 2.262777920508662
Validation loss: 2.443407252894889

Epoch: 6| Step: 2
Training loss: 1.4719456746815989
Validation loss: 2.448472201937132

Epoch: 6| Step: 3
Training loss: 1.301975652692656
Validation loss: 2.431311167290151

Epoch: 6| Step: 4
Training loss: 2.1773649578067666
Validation loss: 2.4121156998398177

Epoch: 6| Step: 5
Training loss: 1.6111384239658613
Validation loss: 2.403447442578851

Epoch: 6| Step: 6
Training loss: 1.5707852235639648
Validation loss: 2.4187446065286498

Epoch: 6| Step: 7
Training loss: 1.4685272697226106
Validation loss: 2.4460437945381432

Epoch: 6| Step: 8
Training loss: 2.099969309627975
Validation loss: 2.449849489957706

Epoch: 6| Step: 9
Training loss: 1.7610322075519107
Validation loss: 2.4354915753238426

Epoch: 6| Step: 10
Training loss: 2.245366517799571
Validation loss: 2.455954053302029

Epoch: 6| Step: 11
Training loss: 2.7331622240736144
Validation loss: 2.42237396869232

Epoch: 6| Step: 12
Training loss: 1.6760765829137976
Validation loss: 2.4364143595906045

Epoch: 6| Step: 13
Training loss: 1.4082487101590442
Validation loss: 2.4353026979252985

Epoch: 261| Step: 0
Training loss: 2.2565179301182856
Validation loss: 2.422528021477126

Epoch: 6| Step: 1
Training loss: 1.2782908436968097
Validation loss: 2.43020520225866

Epoch: 6| Step: 2
Training loss: 1.8784490017054114
Validation loss: 2.4612371394779693

Epoch: 6| Step: 3
Training loss: 1.502923262732978
Validation loss: 2.4404325521774566

Epoch: 6| Step: 4
Training loss: 1.885732705059341
Validation loss: 2.409496336227975

Epoch: 6| Step: 5
Training loss: 1.7181962941997084
Validation loss: 2.413022418434529

Epoch: 6| Step: 6
Training loss: 2.536953187852696
Validation loss: 2.404688449512336

Epoch: 6| Step: 7
Training loss: 1.5071488733500846
Validation loss: 2.4290717251092664

Epoch: 6| Step: 8
Training loss: 2.0566347127541444
Validation loss: 2.405750808320276

Epoch: 6| Step: 9
Training loss: 2.3062424408910247
Validation loss: 2.444375336727613

Epoch: 6| Step: 10
Training loss: 2.0837977718193077
Validation loss: 2.447671547484063

Epoch: 6| Step: 11
Training loss: 1.6520782329517476
Validation loss: 2.4266494482158176

Epoch: 6| Step: 12
Training loss: 1.9904924549188798
Validation loss: 2.4139618462839603

Epoch: 6| Step: 13
Training loss: 1.3345845828416216
Validation loss: 2.438377690381301

Epoch: 262| Step: 0
Training loss: 1.5611635214415982
Validation loss: 2.408712262222856

Epoch: 6| Step: 1
Training loss: 1.5374997332813063
Validation loss: 2.3961202962332004

Epoch: 6| Step: 2
Training loss: 1.5216418516566685
Validation loss: 2.4167273354331975

Epoch: 6| Step: 3
Training loss: 2.2503935151891916
Validation loss: 2.4577913554157003

Epoch: 6| Step: 4
Training loss: 1.8403885798016424
Validation loss: 2.4513732265293666

Epoch: 6| Step: 5
Training loss: 2.1431662518215373
Validation loss: 2.4815587427870116

Epoch: 6| Step: 6
Training loss: 1.7043717746683118
Validation loss: 2.4336496563768986

Epoch: 6| Step: 7
Training loss: 1.901316904148601
Validation loss: 2.4322507914173315

Epoch: 6| Step: 8
Training loss: 1.6707424713061032
Validation loss: 2.3861166964022797

Epoch: 6| Step: 9
Training loss: 2.1650014004251297
Validation loss: 2.4002041998596453

Epoch: 6| Step: 10
Training loss: 1.9406515147291343
Validation loss: 2.444370680087901

Epoch: 6| Step: 11
Training loss: 2.401240894274547
Validation loss: 2.4045446026056227

Epoch: 6| Step: 12
Training loss: 1.5807948426162513
Validation loss: 2.4245392719770646

Epoch: 6| Step: 13
Training loss: 1.676021247519688
Validation loss: 2.4192347864561348

Epoch: 263| Step: 0
Training loss: 1.9450948202756804
Validation loss: 2.411760467062513

Epoch: 6| Step: 1
Training loss: 1.696028527438262
Validation loss: 2.4589238713266703

Epoch: 6| Step: 2
Training loss: 1.9520521956016
Validation loss: 2.3997332155475695

Epoch: 6| Step: 3
Training loss: 1.6270341612565336
Validation loss: 2.422517360641685

Epoch: 6| Step: 4
Training loss: 1.4441374254797446
Validation loss: 2.417367989004436

Epoch: 6| Step: 5
Training loss: 1.894188918813604
Validation loss: 2.41129446065319

Epoch: 6| Step: 6
Training loss: 2.0846464469343045
Validation loss: 2.4106640324951627

Epoch: 6| Step: 7
Training loss: 1.77637389833463
Validation loss: 2.4299602932430795

Epoch: 6| Step: 8
Training loss: 2.144881423126906
Validation loss: 2.419704005910487

Epoch: 6| Step: 9
Training loss: 2.4048645192329396
Validation loss: 2.4437905171349503

Epoch: 6| Step: 10
Training loss: 1.8411128694496104
Validation loss: 2.4636131823786664

Epoch: 6| Step: 11
Training loss: 1.9321347675904588
Validation loss: 2.419427878771034

Epoch: 6| Step: 12
Training loss: 1.6257966363005556
Validation loss: 2.4234971725839465

Epoch: 6| Step: 13
Training loss: 1.7871142444648482
Validation loss: 2.4638565369737075

Epoch: 264| Step: 0
Training loss: 1.8510471061264544
Validation loss: 2.4438091176405177

Epoch: 6| Step: 1
Training loss: 1.4864039959384683
Validation loss: 2.406731249368507

Epoch: 6| Step: 2
Training loss: 2.0146650053850985
Validation loss: 2.4632903280024196

Epoch: 6| Step: 3
Training loss: 2.532419570293375
Validation loss: 2.465368323189711

Epoch: 6| Step: 4
Training loss: 1.73494539246385
Validation loss: 2.4293617389161186

Epoch: 6| Step: 5
Training loss: 2.042261880280412
Validation loss: 2.4173734654669796

Epoch: 6| Step: 6
Training loss: 1.821478997929617
Validation loss: 2.3765704765017954

Epoch: 6| Step: 7
Training loss: 1.5299800355394086
Validation loss: 2.4215523379478876

Epoch: 6| Step: 8
Training loss: 2.008756541803481
Validation loss: 2.419707420628948

Epoch: 6| Step: 9
Training loss: 1.7573852019713578
Validation loss: 2.401118855010535

Epoch: 6| Step: 10
Training loss: 2.013341038459703
Validation loss: 2.4135550033783857

Epoch: 6| Step: 11
Training loss: 1.807491749471615
Validation loss: 2.466792696136377

Epoch: 6| Step: 12
Training loss: 1.8851699316395425
Validation loss: 2.43639419584112

Epoch: 6| Step: 13
Training loss: 1.433516248224393
Validation loss: 2.4796843952861223

Epoch: 265| Step: 0
Training loss: 1.856954586001676
Validation loss: 2.442940527224045

Epoch: 6| Step: 1
Training loss: 2.5333684839353174
Validation loss: 2.464318104945111

Epoch: 6| Step: 2
Training loss: 1.8460596779654728
Validation loss: 2.412941616936705

Epoch: 6| Step: 3
Training loss: 1.501481516675721
Validation loss: 2.4507793014584367

Epoch: 6| Step: 4
Training loss: 2.00351906172022
Validation loss: 2.3888706346644155

Epoch: 6| Step: 5
Training loss: 1.7469820156995006
Validation loss: 2.417663885796303

Epoch: 6| Step: 6
Training loss: 1.7523884142125448
Validation loss: 2.446395888262023

Epoch: 6| Step: 7
Training loss: 2.3839663854123705
Validation loss: 2.429796918928242

Epoch: 6| Step: 8
Training loss: 1.6583251908196655
Validation loss: 2.452344158912326

Epoch: 6| Step: 9
Training loss: 2.1521669512515915
Validation loss: 2.449163396848685

Epoch: 6| Step: 10
Training loss: 1.6280037920858472
Validation loss: 2.414304385644711

Epoch: 6| Step: 11
Training loss: 1.798338981999013
Validation loss: 2.40073093286976

Epoch: 6| Step: 12
Training loss: 1.5109965647185664
Validation loss: 2.4522251338615493

Epoch: 6| Step: 13
Training loss: 1.4735986744823977
Validation loss: 2.4416161289365594

Epoch: 266| Step: 0
Training loss: 2.0040873246802016
Validation loss: 2.4442644674884004

Epoch: 6| Step: 1
Training loss: 1.601413775726063
Validation loss: 2.440268425002725

Epoch: 6| Step: 2
Training loss: 1.78707175293391
Validation loss: 2.427603915639539

Epoch: 6| Step: 3
Training loss: 1.771414253840619
Validation loss: 2.455838141779367

Epoch: 6| Step: 4
Training loss: 2.6708018506873112
Validation loss: 2.4483528472968894

Epoch: 6| Step: 5
Training loss: 1.7179922340803737
Validation loss: 2.4523258824008165

Epoch: 6| Step: 6
Training loss: 1.8263849307534277
Validation loss: 2.4547568049192567

Epoch: 6| Step: 7
Training loss: 1.7441985151673216
Validation loss: 2.44794154489443

Epoch: 6| Step: 8
Training loss: 1.8872317925688
Validation loss: 2.4619763409857356

Epoch: 6| Step: 9
Training loss: 1.3680331857125008
Validation loss: 2.444730038574835

Epoch: 6| Step: 10
Training loss: 1.6431242299214122
Validation loss: 2.460080402149828

Epoch: 6| Step: 11
Training loss: 2.2194659730039263
Validation loss: 2.437138785456224

Epoch: 6| Step: 12
Training loss: 1.8610450233125437
Validation loss: 2.4419363818751716

Epoch: 6| Step: 13
Training loss: 1.8472193388888516
Validation loss: 2.4317406913936175

Epoch: 267| Step: 0
Training loss: 2.777087407682673
Validation loss: 2.4619336350750856

Epoch: 6| Step: 1
Training loss: 1.724605849749547
Validation loss: 2.4349360900221835

Epoch: 6| Step: 2
Training loss: 1.8397253042917752
Validation loss: 2.4540046121797134

Epoch: 6| Step: 3
Training loss: 2.1593314004959887
Validation loss: 2.395467180376412

Epoch: 6| Step: 4
Training loss: 1.6886506572787283
Validation loss: 2.4941030007342815

Epoch: 6| Step: 5
Training loss: 1.6615068753444917
Validation loss: 2.436569960925148

Epoch: 6| Step: 6
Training loss: 1.4026294300378923
Validation loss: 2.419911341463947

Epoch: 6| Step: 7
Training loss: 1.9021572515101521
Validation loss: 2.4278380394676855

Epoch: 6| Step: 8
Training loss: 2.145375125690526
Validation loss: 2.4033871909513342

Epoch: 6| Step: 9
Training loss: 1.7636962077848022
Validation loss: 2.4195616461098575

Epoch: 6| Step: 10
Training loss: 1.637954864224759
Validation loss: 2.462070886562439

Epoch: 6| Step: 11
Training loss: 1.709501456372471
Validation loss: 2.4415321687117943

Epoch: 6| Step: 12
Training loss: 1.6083631575327721
Validation loss: 2.4611313610218666

Epoch: 6| Step: 13
Training loss: 1.5520173726584279
Validation loss: 2.3888530406764605

Epoch: 268| Step: 0
Training loss: 2.5439925469463263
Validation loss: 2.4331891012775153

Epoch: 6| Step: 1
Training loss: 1.3465763796544503
Validation loss: 2.4434445477316253

Epoch: 6| Step: 2
Training loss: 1.5816668809033736
Validation loss: 2.4085288132991067

Epoch: 6| Step: 3
Training loss: 1.6522153980373868
Validation loss: 2.4108451273215135

Epoch: 6| Step: 4
Training loss: 1.6314157599055155
Validation loss: 2.4024963906670056

Epoch: 6| Step: 5
Training loss: 2.463157209811542
Validation loss: 2.4312721125744936

Epoch: 6| Step: 6
Training loss: 1.8240503400874708
Validation loss: 2.4208972774063153

Epoch: 6| Step: 7
Training loss: 1.207508227476282
Validation loss: 2.4305246134564453

Epoch: 6| Step: 8
Training loss: 1.9835241701438684
Validation loss: 2.3911365977960317

Epoch: 6| Step: 9
Training loss: 2.2694863923936643
Validation loss: 2.4406209338432934

Epoch: 6| Step: 10
Training loss: 2.1103371015527213
Validation loss: 2.407863382364806

Epoch: 6| Step: 11
Training loss: 1.5405640998239911
Validation loss: 2.466916824386535

Epoch: 6| Step: 12
Training loss: 1.6567282076303675
Validation loss: 2.4370601757874786

Epoch: 6| Step: 13
Training loss: 1.5664441491771914
Validation loss: 2.416286551765721

Epoch: 269| Step: 0
Training loss: 1.9392965048008297
Validation loss: 2.446297073179209

Epoch: 6| Step: 1
Training loss: 2.4786617395305175
Validation loss: 2.4376330763988623

Epoch: 6| Step: 2
Training loss: 1.6684725355723504
Validation loss: 2.415537660261484

Epoch: 6| Step: 3
Training loss: 1.4612264908334462
Validation loss: 2.440658208233445

Epoch: 6| Step: 4
Training loss: 2.1416561121501183
Validation loss: 2.4382744056701884

Epoch: 6| Step: 5
Training loss: 1.6168534675641886
Validation loss: 2.4566624248177105

Epoch: 6| Step: 6
Training loss: 1.7567636709315118
Validation loss: 2.3986527348795024

Epoch: 6| Step: 7
Training loss: 1.9461786264649523
Validation loss: 2.4481271685121384

Epoch: 6| Step: 8
Training loss: 2.3550603964931285
Validation loss: 2.41277472506494

Epoch: 6| Step: 9
Training loss: 1.352199250098129
Validation loss: 2.3843922403329145

Epoch: 6| Step: 10
Training loss: 1.7484594103383784
Validation loss: 2.358726509048954

Epoch: 6| Step: 11
Training loss: 1.590637908463477
Validation loss: 2.3934996965068134

Epoch: 6| Step: 12
Training loss: 1.9535509789373628
Validation loss: 2.4184591158010473

Epoch: 6| Step: 13
Training loss: 1.49459038242067
Validation loss: 2.4289848789687105

Epoch: 270| Step: 0
Training loss: 1.984033990830303
Validation loss: 2.4751849471143688

Epoch: 6| Step: 1
Training loss: 2.4530073004021853
Validation loss: 2.405157797294982

Epoch: 6| Step: 2
Training loss: 1.9927981170140041
Validation loss: 2.4210789711653917

Epoch: 6| Step: 3
Training loss: 1.9537101174333478
Validation loss: 2.4505596967056493

Epoch: 6| Step: 4
Training loss: 1.4123281306802016
Validation loss: 2.449041734218326

Epoch: 6| Step: 5
Training loss: 1.8080496906904238
Validation loss: 2.4815740095482295

Epoch: 6| Step: 6
Training loss: 2.000542328737341
Validation loss: 2.4257970062410483

Epoch: 6| Step: 7
Training loss: 1.6888608743340718
Validation loss: 2.3909748648984706

Epoch: 6| Step: 8
Training loss: 1.8098468435413024
Validation loss: 2.4859540031934464

Epoch: 6| Step: 9
Training loss: 1.7328050398257537
Validation loss: 2.48765127520024

Epoch: 6| Step: 10
Training loss: 1.3061258759000522
Validation loss: 2.4695956411019204

Epoch: 6| Step: 11
Training loss: 2.3804030947368173
Validation loss: 2.4884100900752246

Epoch: 6| Step: 12
Training loss: 1.766573828231198
Validation loss: 2.412156084470379

Epoch: 6| Step: 13
Training loss: 1.1378422589013217
Validation loss: 2.405712103255628

Epoch: 271| Step: 0
Training loss: 1.499111150604606
Validation loss: 2.4136755105087015

Epoch: 6| Step: 1
Training loss: 1.495208558044516
Validation loss: 2.4063587944538094

Epoch: 6| Step: 2
Training loss: 1.8314289981993723
Validation loss: 2.455166917561638

Epoch: 6| Step: 3
Training loss: 1.461865217250336
Validation loss: 2.505134676776446

Epoch: 6| Step: 4
Training loss: 1.7454061156927088
Validation loss: 2.4336000811553857

Epoch: 6| Step: 5
Training loss: 1.5593246237772669
Validation loss: 2.421247229322979

Epoch: 6| Step: 6
Training loss: 1.6445022544207477
Validation loss: 2.4568494603023696

Epoch: 6| Step: 7
Training loss: 2.1063506874898503
Validation loss: 2.4361630336726745

Epoch: 6| Step: 8
Training loss: 2.1608461792379274
Validation loss: 2.4607683354429977

Epoch: 6| Step: 9
Training loss: 2.321608261867153
Validation loss: 2.45358406256425

Epoch: 6| Step: 10
Training loss: 2.4360771917255435
Validation loss: 2.4359352494309743

Epoch: 6| Step: 11
Training loss: 1.9578394030209016
Validation loss: 2.4493463970382803

Epoch: 6| Step: 12
Training loss: 1.5280607837999858
Validation loss: 2.4354717039328495

Epoch: 6| Step: 13
Training loss: 1.0872976443688045
Validation loss: 2.3957110922625144

Epoch: 272| Step: 0
Training loss: 2.1252929261210247
Validation loss: 2.448464228738494

Epoch: 6| Step: 1
Training loss: 2.5686619801535064
Validation loss: 2.4180805291058785

Epoch: 6| Step: 2
Training loss: 1.580064016687053
Validation loss: 2.448644220908756

Epoch: 6| Step: 3
Training loss: 1.6906939762168138
Validation loss: 2.3987830660216547

Epoch: 6| Step: 4
Training loss: 1.8852134370251712
Validation loss: 2.4464107781901454

Epoch: 6| Step: 5
Training loss: 1.1951005037093616
Validation loss: 2.4074751126098928

Epoch: 6| Step: 6
Training loss: 1.9315392879368274
Validation loss: 2.4039269601572717

Epoch: 6| Step: 7
Training loss: 1.730816050654255
Validation loss: 2.4271740344325456

Epoch: 6| Step: 8
Training loss: 1.6721809321206615
Validation loss: 2.4443782932697085

Epoch: 6| Step: 9
Training loss: 2.0122478493001155
Validation loss: 2.446273439294541

Epoch: 6| Step: 10
Training loss: 1.9965290110118945
Validation loss: 2.4289093866051186

Epoch: 6| Step: 11
Training loss: 1.2160618798673462
Validation loss: 2.446142136708752

Epoch: 6| Step: 12
Training loss: 1.652963364312272
Validation loss: 2.4394182135887323

Epoch: 6| Step: 13
Training loss: 1.990972470030429
Validation loss: 2.4252877205223875

Epoch: 273| Step: 0
Training loss: 2.093592851349488
Validation loss: 2.4672377619788923

Epoch: 6| Step: 1
Training loss: 1.7739657652948064
Validation loss: 2.469199120409659

Epoch: 6| Step: 2
Training loss: 1.746932611214932
Validation loss: 2.447356691284835

Epoch: 6| Step: 3
Training loss: 1.265903112678489
Validation loss: 2.4501109970142805

Epoch: 6| Step: 4
Training loss: 1.571272068157011
Validation loss: 2.459631637686467

Epoch: 6| Step: 5
Training loss: 1.9895254862366383
Validation loss: 2.4430447668660245

Epoch: 6| Step: 6
Training loss: 1.8262784059836303
Validation loss: 2.472445752746658

Epoch: 6| Step: 7
Training loss: 1.3526259191284498
Validation loss: 2.445675991656327

Epoch: 6| Step: 8
Training loss: 1.8660465090190066
Validation loss: 2.4475885538320523

Epoch: 6| Step: 9
Training loss: 2.3202656442554392
Validation loss: 2.428099134017626

Epoch: 6| Step: 10
Training loss: 1.795310093651496
Validation loss: 2.4082333238236826

Epoch: 6| Step: 11
Training loss: 2.1374269528762464
Validation loss: 2.4418866966778316

Epoch: 6| Step: 12
Training loss: 1.6963145024089028
Validation loss: 2.408227589184763

Epoch: 6| Step: 13
Training loss: 1.5677624394235516
Validation loss: 2.418644617219622

Epoch: 274| Step: 0
Training loss: 1.9222044003431602
Validation loss: 2.402084004396081

Epoch: 6| Step: 1
Training loss: 1.9838798686197268
Validation loss: 2.4099950797180076

Epoch: 6| Step: 2
Training loss: 2.404073647518239
Validation loss: 2.451178875089405

Epoch: 6| Step: 3
Training loss: 1.3894422408978795
Validation loss: 2.4452941101257073

Epoch: 6| Step: 4
Training loss: 1.4876319890808087
Validation loss: 2.4329080642284455

Epoch: 6| Step: 5
Training loss: 1.953518270953392
Validation loss: 2.3839137262214094

Epoch: 6| Step: 6
Training loss: 1.6546787510281276
Validation loss: 2.427442710395351

Epoch: 6| Step: 7
Training loss: 1.805075467505415
Validation loss: 2.4370026376820477

Epoch: 6| Step: 8
Training loss: 1.8372477948721488
Validation loss: 2.4329878570108088

Epoch: 6| Step: 9
Training loss: 1.3106949974072277
Validation loss: 2.425194745732566

Epoch: 6| Step: 10
Training loss: 1.932542919950595
Validation loss: 2.42246587758578

Epoch: 6| Step: 11
Training loss: 1.9352187601280098
Validation loss: 2.430283079788589

Epoch: 6| Step: 12
Training loss: 1.8852711054074953
Validation loss: 2.43239155275035

Epoch: 6| Step: 13
Training loss: 1.9460454578755457
Validation loss: 2.4414272318276824

Epoch: 275| Step: 0
Training loss: 1.756799906371241
Validation loss: 2.4481616489108045

Epoch: 6| Step: 1
Training loss: 1.8215628983148207
Validation loss: 2.452831316830442

Epoch: 6| Step: 2
Training loss: 1.369270655923539
Validation loss: 2.4358405045517335

Epoch: 6| Step: 3
Training loss: 2.4168498419257967
Validation loss: 2.433492435578419

Epoch: 6| Step: 4
Training loss: 1.2837231190661271
Validation loss: 2.398301750601745

Epoch: 6| Step: 5
Training loss: 1.996052840498562
Validation loss: 2.474066196199479

Epoch: 6| Step: 6
Training loss: 1.3478829897997784
Validation loss: 2.463410071402248

Epoch: 6| Step: 7
Training loss: 1.5459699198521841
Validation loss: 2.422224540243024

Epoch: 6| Step: 8
Training loss: 2.3453682970986978
Validation loss: 2.4412681538564494

Epoch: 6| Step: 9
Training loss: 1.0596017577959214
Validation loss: 2.447638477305049

Epoch: 6| Step: 10
Training loss: 2.084456929165167
Validation loss: 2.3900411752047623

Epoch: 6| Step: 11
Training loss: 2.0147485527869304
Validation loss: 2.4593947562696323

Epoch: 6| Step: 12
Training loss: 1.661152188627074
Validation loss: 2.444084146482033

Epoch: 6| Step: 13
Training loss: 2.0989285096983323
Validation loss: 2.459133842915754

Epoch: 276| Step: 0
Training loss: 1.507049367428924
Validation loss: 2.465495924363668

Epoch: 6| Step: 1
Training loss: 1.6884551700540789
Validation loss: 2.4112755125804157

Epoch: 6| Step: 2
Training loss: 1.613928861154037
Validation loss: 2.4319014346336383

Epoch: 6| Step: 3
Training loss: 1.7631686518206884
Validation loss: 2.4481754641813316

Epoch: 6| Step: 4
Training loss: 1.5213539939322194
Validation loss: 2.4854475541179366

Epoch: 6| Step: 5
Training loss: 1.4940471944082834
Validation loss: 2.4254006743540204

Epoch: 6| Step: 6
Training loss: 2.346149183006511
Validation loss: 2.39773345936182

Epoch: 6| Step: 7
Training loss: 1.9720664776242178
Validation loss: 2.4273590546728046

Epoch: 6| Step: 8
Training loss: 2.364145470856869
Validation loss: 2.4255008660637287

Epoch: 6| Step: 9
Training loss: 2.3981801245952443
Validation loss: 2.4456014474585044

Epoch: 6| Step: 10
Training loss: 1.7745284031593815
Validation loss: 2.369543007659523

Epoch: 6| Step: 11
Training loss: 1.8154774906293754
Validation loss: 2.4024300012279385

Epoch: 6| Step: 12
Training loss: 1.4901236596733052
Validation loss: 2.414851689570219

Epoch: 6| Step: 13
Training loss: 0.9099179066319044
Validation loss: 2.4546559775621617

Epoch: 277| Step: 0
Training loss: 1.5060955807369696
Validation loss: 2.419184882986384

Epoch: 6| Step: 1
Training loss: 1.4604864393138184
Validation loss: 2.4369908493376284

Epoch: 6| Step: 2
Training loss: 2.0592866777342462
Validation loss: 2.426816119052339

Epoch: 6| Step: 3
Training loss: 2.778170820615699
Validation loss: 2.4650333018916455

Epoch: 6| Step: 4
Training loss: 1.599886803795158
Validation loss: 2.4480737583824133

Epoch: 6| Step: 5
Training loss: 1.3070048236626572
Validation loss: 2.358309946480864

Epoch: 6| Step: 6
Training loss: 1.8879738497094947
Validation loss: 2.421890338130655

Epoch: 6| Step: 7
Training loss: 1.958559212610264
Validation loss: 2.452198924679813

Epoch: 6| Step: 8
Training loss: 1.6022941592841111
Validation loss: 2.444865246420996

Epoch: 6| Step: 9
Training loss: 1.4133311535410595
Validation loss: 2.395052270965618

Epoch: 6| Step: 10
Training loss: 1.6698135073116518
Validation loss: 2.4891630492372285

Epoch: 6| Step: 11
Training loss: 1.6787093042140468
Validation loss: 2.432329442161558

Epoch: 6| Step: 12
Training loss: 1.5774138708526992
Validation loss: 2.3723747708411422

Epoch: 6| Step: 13
Training loss: 2.035185771588906
Validation loss: 2.410549153930628

Epoch: 278| Step: 0
Training loss: 1.4313616513342813
Validation loss: 2.4983699929910994

Epoch: 6| Step: 1
Training loss: 1.7586663778958915
Validation loss: 2.457504864586068

Epoch: 6| Step: 2
Training loss: 1.6429599676473399
Validation loss: 2.4414271105459595

Epoch: 6| Step: 3
Training loss: 1.8051733378609716
Validation loss: 2.436086267298244

Epoch: 6| Step: 4
Training loss: 1.6004871014376487
Validation loss: 2.424206591372313

Epoch: 6| Step: 5
Training loss: 1.4704581534129832
Validation loss: 2.413202961273954

Epoch: 6| Step: 6
Training loss: 1.834608270477247
Validation loss: 2.4911361298937873

Epoch: 6| Step: 7
Training loss: 1.5609718479352492
Validation loss: 2.514926206223385

Epoch: 6| Step: 8
Training loss: 1.5758723431698944
Validation loss: 2.4737924606769046

Epoch: 6| Step: 9
Training loss: 1.7146114809020976
Validation loss: 2.4329640817223526

Epoch: 6| Step: 10
Training loss: 2.6363396718242464
Validation loss: 2.4281135987367968

Epoch: 6| Step: 11
Training loss: 1.4141914772520288
Validation loss: 2.4052410111805758

Epoch: 6| Step: 12
Training loss: 2.160121151740743
Validation loss: 2.4008512796280224

Epoch: 6| Step: 13
Training loss: 2.431439911551908
Validation loss: 2.4406743673649633

Epoch: 279| Step: 0
Training loss: 1.5925406561292432
Validation loss: 2.426671095893849

Epoch: 6| Step: 1
Training loss: 1.772897377611504
Validation loss: 2.4269515220963056

Epoch: 6| Step: 2
Training loss: 1.5379058054241885
Validation loss: 2.447582133694215

Epoch: 6| Step: 3
Training loss: 1.8430191143118928
Validation loss: 2.4222890954377543

Epoch: 6| Step: 4
Training loss: 1.7597327022881053
Validation loss: 2.4381120910823486

Epoch: 6| Step: 5
Training loss: 2.4644214975767653
Validation loss: 2.4412158191860573

Epoch: 6| Step: 6
Training loss: 1.6491855171646501
Validation loss: 2.4297433095024252

Epoch: 6| Step: 7
Training loss: 1.7850530748998334
Validation loss: 2.4375347075030422

Epoch: 6| Step: 8
Training loss: 1.3892020757213168
Validation loss: 2.48651762273884

Epoch: 6| Step: 9
Training loss: 1.5999821006250527
Validation loss: 2.3458479703478865

Epoch: 6| Step: 10
Training loss: 1.6326982376054542
Validation loss: 2.429376041784819

Epoch: 6| Step: 11
Training loss: 1.7532273913723098
Validation loss: 2.3644524805912077

Epoch: 6| Step: 12
Training loss: 2.112850011236697
Validation loss: 2.4320685129329807

Epoch: 6| Step: 13
Training loss: 1.4514468768073627
Validation loss: 2.44089667060967

Epoch: 280| Step: 0
Training loss: 1.8443037591591533
Validation loss: 2.417361595186903

Epoch: 6| Step: 1
Training loss: 1.6292132996164046
Validation loss: 2.4398821834851017

Epoch: 6| Step: 2
Training loss: 1.6234175973650682
Validation loss: 2.410297592219367

Epoch: 6| Step: 3
Training loss: 1.1125715168457422
Validation loss: 2.412129552041967

Epoch: 6| Step: 4
Training loss: 1.6388132900467305
Validation loss: 2.4711955927177076

Epoch: 6| Step: 5
Training loss: 2.4272499736723416
Validation loss: 2.4785278674790536

Epoch: 6| Step: 6
Training loss: 1.961031664528974
Validation loss: 2.4241057507614334

Epoch: 6| Step: 7
Training loss: 1.530631894290424
Validation loss: 2.4714665013874795

Epoch: 6| Step: 8
Training loss: 1.9031075387538903
Validation loss: 2.4642696346121062

Epoch: 6| Step: 9
Training loss: 1.4738023583297921
Validation loss: 2.478874438186977

Epoch: 6| Step: 10
Training loss: 2.1450593780977685
Validation loss: 2.472280320587948

Epoch: 6| Step: 11
Training loss: 1.2613074515105438
Validation loss: 2.4921544280127157

Epoch: 6| Step: 12
Training loss: 1.536999011409841
Validation loss: 2.4565702236973355

Epoch: 6| Step: 13
Training loss: 2.8979370014090615
Validation loss: 2.4630242676158103

Epoch: 281| Step: 0
Training loss: 2.0443470027526085
Validation loss: 2.4736148342311606

Epoch: 6| Step: 1
Training loss: 2.541938068929051
Validation loss: 2.4402979444202533

Epoch: 6| Step: 2
Training loss: 1.6798832269230537
Validation loss: 2.420904207779727

Epoch: 6| Step: 3
Training loss: 1.579854338728068
Validation loss: 2.399538459865159

Epoch: 6| Step: 4
Training loss: 1.4317368791184475
Validation loss: 2.4226554023440214

Epoch: 6| Step: 5
Training loss: 1.6890387407267429
Validation loss: 2.468106232240071

Epoch: 6| Step: 6
Training loss: 2.257539409238549
Validation loss: 2.4076501751603643

Epoch: 6| Step: 7
Training loss: 1.8111193429854735
Validation loss: 2.4758391108764926

Epoch: 6| Step: 8
Training loss: 1.4175668362262348
Validation loss: 2.401792722732569

Epoch: 6| Step: 9
Training loss: 1.5481029992201611
Validation loss: 2.4382996521396194

Epoch: 6| Step: 10
Training loss: 1.6400225305172633
Validation loss: 2.4246413007048075

Epoch: 6| Step: 11
Training loss: 1.7863152746042408
Validation loss: 2.461030666699219

Epoch: 6| Step: 12
Training loss: 1.7238992717418087
Validation loss: 2.4471899779280517

Epoch: 6| Step: 13
Training loss: 1.6243435927756655
Validation loss: 2.4327089517787295

Epoch: 282| Step: 0
Training loss: 1.8818328968255145
Validation loss: 2.4319348213264482

Epoch: 6| Step: 1
Training loss: 2.522623692665992
Validation loss: 2.4067141609001066

Epoch: 6| Step: 2
Training loss: 1.616844988685602
Validation loss: 2.4521369185158988

Epoch: 6| Step: 3
Training loss: 1.6090125259044616
Validation loss: 2.4308975973650977

Epoch: 6| Step: 4
Training loss: 1.5503150373675314
Validation loss: 2.444351199191192

Epoch: 6| Step: 5
Training loss: 1.7574472005409463
Validation loss: 2.4749306875504296

Epoch: 6| Step: 6
Training loss: 1.2196724164197714
Validation loss: 2.4846048050820606

Epoch: 6| Step: 7
Training loss: 1.6028287766333555
Validation loss: 2.473907497814182

Epoch: 6| Step: 8
Training loss: 2.156357472270721
Validation loss: 2.47930430975253

Epoch: 6| Step: 9
Training loss: 1.7559740413102618
Validation loss: 2.5119634023145627

Epoch: 6| Step: 10
Training loss: 1.866197778644411
Validation loss: 2.4826395850325578

Epoch: 6| Step: 11
Training loss: 1.6753479012689438
Validation loss: 2.4640624681217704

Epoch: 6| Step: 12
Training loss: 1.625409074791835
Validation loss: 2.46574749342284

Epoch: 6| Step: 13
Training loss: 1.326804323474808
Validation loss: 2.494316703419437

Epoch: 283| Step: 0
Training loss: 1.6583332419595103
Validation loss: 2.4429892423432524

Epoch: 6| Step: 1
Training loss: 1.785506399860519
Validation loss: 2.441506665861678

Epoch: 6| Step: 2
Training loss: 1.8094696494532536
Validation loss: 2.449158839332544

Epoch: 6| Step: 3
Training loss: 1.798511058850791
Validation loss: 2.499310222957745

Epoch: 6| Step: 4
Training loss: 1.4228287736249838
Validation loss: 2.442347344658671

Epoch: 6| Step: 5
Training loss: 1.6313034458101325
Validation loss: 2.455610853089864

Epoch: 6| Step: 6
Training loss: 1.7229816017076323
Validation loss: 2.432500655071063

Epoch: 6| Step: 7
Training loss: 1.5573675164810588
Validation loss: 2.356874258332488

Epoch: 6| Step: 8
Training loss: 1.6682116579519903
Validation loss: 2.4474605333443424

Epoch: 6| Step: 9
Training loss: 1.2927467178601098
Validation loss: 2.416582096163229

Epoch: 6| Step: 10
Training loss: 2.6092759530462675
Validation loss: 2.4214965185842963

Epoch: 6| Step: 11
Training loss: 1.556717740282273
Validation loss: 2.4162064217654184

Epoch: 6| Step: 12
Training loss: 1.9059347923948837
Validation loss: 2.4038254437181568

Epoch: 6| Step: 13
Training loss: 1.5622932297269405
Validation loss: 2.4435963274170964

Epoch: 284| Step: 0
Training loss: 1.9661969782427642
Validation loss: 2.429615104215827

Epoch: 6| Step: 1
Training loss: 1.662137489663806
Validation loss: 2.5129166453281986

Epoch: 6| Step: 2
Training loss: 1.9688965879090767
Validation loss: 2.4437746912253293

Epoch: 6| Step: 3
Training loss: 2.214494734888112
Validation loss: 2.436950640618434

Epoch: 6| Step: 4
Training loss: 1.6682315235278102
Validation loss: 2.4167211966326043

Epoch: 6| Step: 5
Training loss: 1.2049603025933284
Validation loss: 2.4713451120334393

Epoch: 6| Step: 6
Training loss: 1.8238098862602712
Validation loss: 2.3790144096359884

Epoch: 6| Step: 7
Training loss: 2.0929144715222887
Validation loss: 2.443891662691204

Epoch: 6| Step: 8
Training loss: 1.8782402650623247
Validation loss: 2.405480623932154

Epoch: 6| Step: 9
Training loss: 1.7549880330039116
Validation loss: 2.4559512443077463

Epoch: 6| Step: 10
Training loss: 1.5232503922808023
Validation loss: 2.4821578250281906

Epoch: 6| Step: 11
Training loss: 1.307443186982591
Validation loss: 2.451549471627983

Epoch: 6| Step: 12
Training loss: 1.8525507096571463
Validation loss: 2.4895445180956246

Epoch: 6| Step: 13
Training loss: 1.6688967408087096
Validation loss: 2.423402065727524

Epoch: 285| Step: 0
Training loss: 1.7520468866440955
Validation loss: 2.46982153383411

Epoch: 6| Step: 1
Training loss: 1.2995378663203185
Validation loss: 2.4479407133668087

Epoch: 6| Step: 2
Training loss: 1.4544410898415858
Validation loss: 2.4673050265046217

Epoch: 6| Step: 3
Training loss: 1.2680532449620228
Validation loss: 2.4254043231040647

Epoch: 6| Step: 4
Training loss: 2.0794236563931205
Validation loss: 2.459571699233719

Epoch: 6| Step: 5
Training loss: 1.9432895053590944
Validation loss: 2.446165611514324

Epoch: 6| Step: 6
Training loss: 1.6428816035327434
Validation loss: 2.4780946107628425

Epoch: 6| Step: 7
Training loss: 2.338347043871591
Validation loss: 2.431095794685121

Epoch: 6| Step: 8
Training loss: 1.833700432292752
Validation loss: 2.4516435566201786

Epoch: 6| Step: 9
Training loss: 1.9649053909006484
Validation loss: 2.410923483212377

Epoch: 6| Step: 10
Training loss: 1.444049510191573
Validation loss: 2.450023179554651

Epoch: 6| Step: 11
Training loss: 1.5116395757084904
Validation loss: 2.423232148904019

Epoch: 6| Step: 12
Training loss: 1.8680989104025625
Validation loss: 2.4285145433477764

Epoch: 6| Step: 13
Training loss: 1.5183447591531065
Validation loss: 2.445859655266667

Epoch: 286| Step: 0
Training loss: 1.3484922607901346
Validation loss: 2.3920521035139646

Epoch: 6| Step: 1
Training loss: 1.7335823928577891
Validation loss: 2.3967974438122908

Epoch: 6| Step: 2
Training loss: 1.667915718611366
Validation loss: 2.466629465493882

Epoch: 6| Step: 3
Training loss: 1.481858137494137
Validation loss: 2.475662709270401

Epoch: 6| Step: 4
Training loss: 1.4206683729660645
Validation loss: 2.390086790697102

Epoch: 6| Step: 5
Training loss: 1.5335817294784098
Validation loss: 2.453290470400856

Epoch: 6| Step: 6
Training loss: 1.5023605528242456
Validation loss: 2.429983630027105

Epoch: 6| Step: 7
Training loss: 2.4704404427429814
Validation loss: 2.447653211992479

Epoch: 6| Step: 8
Training loss: 2.179980405316965
Validation loss: 2.4251568129437975

Epoch: 6| Step: 9
Training loss: 1.9155570287298058
Validation loss: 2.4212963406651977

Epoch: 6| Step: 10
Training loss: 1.6520975709600714
Validation loss: 2.432933547624772

Epoch: 6| Step: 11
Training loss: 1.6162991502550617
Validation loss: 2.454196466808575

Epoch: 6| Step: 12
Training loss: 1.7887157120740582
Validation loss: 2.431738783216735

Epoch: 6| Step: 13
Training loss: 1.1125125305670225
Validation loss: 2.461880942049625

Epoch: 287| Step: 0
Training loss: 2.535721020910272
Validation loss: 2.4791913522918527

Epoch: 6| Step: 1
Training loss: 1.7177465110346972
Validation loss: 2.42996321826593

Epoch: 6| Step: 2
Training loss: 1.664843380523884
Validation loss: 2.419839503919657

Epoch: 6| Step: 3
Training loss: 1.5471541027701494
Validation loss: 2.469304421412529

Epoch: 6| Step: 4
Training loss: 1.8801169192704354
Validation loss: 2.533756218082268

Epoch: 6| Step: 5
Training loss: 1.2891381443832757
Validation loss: 2.4439018489776463

Epoch: 6| Step: 6
Training loss: 1.7275825352695058
Validation loss: 2.4005087151393285

Epoch: 6| Step: 7
Training loss: 1.9353566158027364
Validation loss: 2.49207364616693

Epoch: 6| Step: 8
Training loss: 1.248555540918725
Validation loss: 2.4478430299455094

Epoch: 6| Step: 9
Training loss: 1.9421595871408759
Validation loss: 2.4664237549107493

Epoch: 6| Step: 10
Training loss: 1.6331427573265314
Validation loss: 2.468272773512869

Epoch: 6| Step: 11
Training loss: 1.8622304964615133
Validation loss: 2.42960572590652

Epoch: 6| Step: 12
Training loss: 1.5445219696645986
Validation loss: 2.432689580620976

Epoch: 6| Step: 13
Training loss: 1.2120666653739514
Validation loss: 2.427024154719736

Epoch: 288| Step: 0
Training loss: 1.5200972495841703
Validation loss: 2.395526934519895

Epoch: 6| Step: 1
Training loss: 1.3067801134497865
Validation loss: 2.4317788735928647

Epoch: 6| Step: 2
Training loss: 1.896776390969069
Validation loss: 2.4533428949435705

Epoch: 6| Step: 3
Training loss: 2.120890626964104
Validation loss: 2.445401671263704

Epoch: 6| Step: 4
Training loss: 1.8181773749210512
Validation loss: 2.465885488582241

Epoch: 6| Step: 5
Training loss: 1.7462526799524778
Validation loss: 2.4864812440874045

Epoch: 6| Step: 6
Training loss: 1.3651274064797914
Validation loss: 2.456307834592616

Epoch: 6| Step: 7
Training loss: 1.1979794637833603
Validation loss: 2.408486029318276

Epoch: 6| Step: 8
Training loss: 1.559072626493518
Validation loss: 2.455774238828832

Epoch: 6| Step: 9
Training loss: 2.3422533470094877
Validation loss: 2.4434827233061696

Epoch: 6| Step: 10
Training loss: 1.3500427786795615
Validation loss: 2.40586626977503

Epoch: 6| Step: 11
Training loss: 2.507527367850409
Validation loss: 2.414279362907311

Epoch: 6| Step: 12
Training loss: 0.9480499481289679
Validation loss: 2.3935722549613225

Epoch: 6| Step: 13
Training loss: 1.831840391323452
Validation loss: 2.4835756811150804

Epoch: 289| Step: 0
Training loss: 1.9747997158238093
Validation loss: 2.447978103554446

Epoch: 6| Step: 1
Training loss: 1.7107775887786267
Validation loss: 2.4026412596899083

Epoch: 6| Step: 2
Training loss: 1.66059069166252
Validation loss: 2.3881848620530794

Epoch: 6| Step: 3
Training loss: 1.8583263357170428
Validation loss: 2.3864731434431343

Epoch: 6| Step: 4
Training loss: 1.2688742008396487
Validation loss: 2.3950340630228006

Epoch: 6| Step: 5
Training loss: 1.5012730123898526
Validation loss: 2.3748012701372065

Epoch: 6| Step: 6
Training loss: 1.4773675247934106
Validation loss: 2.41751914075514

Epoch: 6| Step: 7
Training loss: 1.8210600926362732
Validation loss: 2.4669570549324913

Epoch: 6| Step: 8
Training loss: 1.7484403199419423
Validation loss: 2.3622708747901693

Epoch: 6| Step: 9
Training loss: 2.2989697927221924
Validation loss: 2.478548287336181

Epoch: 6| Step: 10
Training loss: 1.2586479492641172
Validation loss: 2.4769298099538624

Epoch: 6| Step: 11
Training loss: 1.7171542996641218
Validation loss: 2.4797448390358654

Epoch: 6| Step: 12
Training loss: 1.6214644777992802
Validation loss: 2.3984236665218344

Epoch: 6| Step: 13
Training loss: 2.1102993670517702
Validation loss: 2.434237696892287

Epoch: 290| Step: 0
Training loss: 1.6859442992687559
Validation loss: 2.4151693864208292

Epoch: 6| Step: 1
Training loss: 1.8363635279057124
Validation loss: 2.486313410198923

Epoch: 6| Step: 2
Training loss: 1.4467037618659764
Validation loss: 2.444849404399329

Epoch: 6| Step: 3
Training loss: 2.0178960972436712
Validation loss: 2.4803848951352694

Epoch: 6| Step: 4
Training loss: 1.7939001253154907
Validation loss: 2.4640438446731423

Epoch: 6| Step: 5
Training loss: 1.3160307034415337
Validation loss: 2.386620694093675

Epoch: 6| Step: 6
Training loss: 1.7413833199074253
Validation loss: 2.4477328225985997

Epoch: 6| Step: 7
Training loss: 1.6224220073746003
Validation loss: 2.4609847327779906

Epoch: 6| Step: 8
Training loss: 1.2794847190335
Validation loss: 2.4798733563257613

Epoch: 6| Step: 9
Training loss: 2.4121798485719697
Validation loss: 2.4170929324542487

Epoch: 6| Step: 10
Training loss: 1.6622840798496452
Validation loss: 2.39711829918399

Epoch: 6| Step: 11
Training loss: 1.5782393612357284
Validation loss: 2.4446054937249007

Epoch: 6| Step: 12
Training loss: 1.8508836491647338
Validation loss: 2.431769070340365

Epoch: 6| Step: 13
Training loss: 2.0695988414724296
Validation loss: 2.3747386572697997

Epoch: 291| Step: 0
Training loss: 1.710660171676837
Validation loss: 2.4395611312479577

Epoch: 6| Step: 1
Training loss: 2.178083588522559
Validation loss: 2.439972304444705

Epoch: 6| Step: 2
Training loss: 1.6353416020686757
Validation loss: 2.459641901059357

Epoch: 6| Step: 3
Training loss: 1.654002121717575
Validation loss: 2.491845906433665

Epoch: 6| Step: 4
Training loss: 1.8913514814361096
Validation loss: 2.400757041865083

Epoch: 6| Step: 5
Training loss: 2.1036187645182065
Validation loss: 2.4119013506925464

Epoch: 6| Step: 6
Training loss: 1.3298154058921745
Validation loss: 2.4448232923124618

Epoch: 6| Step: 7
Training loss: 1.61439073295769
Validation loss: 2.449560690898954

Epoch: 6| Step: 8
Training loss: 1.5808826939677694
Validation loss: 2.401753950146142

Epoch: 6| Step: 9
Training loss: 1.0346904354347612
Validation loss: 2.4278842562734013

Epoch: 6| Step: 10
Training loss: 1.4009394082493138
Validation loss: 2.4755572681175053

Epoch: 6| Step: 11
Training loss: 1.4235876479450909
Validation loss: 2.474535326335384

Epoch: 6| Step: 12
Training loss: 2.203919395994447
Validation loss: 2.3570800922805577

Epoch: 6| Step: 13
Training loss: 1.7151717652144471
Validation loss: 2.4686875777415658

Epoch: 292| Step: 0
Training loss: 1.8568561065339215
Validation loss: 2.3807019124741027

Epoch: 6| Step: 1
Training loss: 2.455655390472986
Validation loss: 2.437257714715664

Epoch: 6| Step: 2
Training loss: 1.9365143268349732
Validation loss: 2.427153347131694

Epoch: 6| Step: 3
Training loss: 1.8104885384092277
Validation loss: 2.4297902128030353

Epoch: 6| Step: 4
Training loss: 1.2066154381027265
Validation loss: 2.410499655588183

Epoch: 6| Step: 5
Training loss: 2.21783686370389
Validation loss: 2.448103832943247

Epoch: 6| Step: 6
Training loss: 1.3765943127354074
Validation loss: 2.417515141292016

Epoch: 6| Step: 7
Training loss: 1.4904228281276437
Validation loss: 2.4030289001166287

Epoch: 6| Step: 8
Training loss: 1.5199112993008208
Validation loss: 2.4408166437740073

Epoch: 6| Step: 9
Training loss: 1.2939313088864877
Validation loss: 2.4691839744038218

Epoch: 6| Step: 10
Training loss: 1.6983789232079145
Validation loss: 2.45432583331946

Epoch: 6| Step: 11
Training loss: 1.5366900597954902
Validation loss: 2.4604042310132064

Epoch: 6| Step: 12
Training loss: 1.667780773996848
Validation loss: 2.4518945211564334

Epoch: 6| Step: 13
Training loss: 1.5910127358301474
Validation loss: 2.4610962914983223

Epoch: 293| Step: 0
Training loss: 1.6388844294226943
Validation loss: 2.427313559788686

Epoch: 6| Step: 1
Training loss: 2.3487958379620255
Validation loss: 2.4491991679268437

Epoch: 6| Step: 2
Training loss: 1.5480762787884548
Validation loss: 2.4144330057491596

Epoch: 6| Step: 3
Training loss: 1.4880836335592562
Validation loss: 2.4433937023455172

Epoch: 6| Step: 4
Training loss: 1.8564182141055505
Validation loss: 2.4321399260278733

Epoch: 6| Step: 5
Training loss: 1.9567315334678343
Validation loss: 2.3858958489047426

Epoch: 6| Step: 6
Training loss: 1.5203956949772715
Validation loss: 2.4305797835479015

Epoch: 6| Step: 7
Training loss: 1.7513547830322116
Validation loss: 2.4274312431522107

Epoch: 6| Step: 8
Training loss: 1.4500017133242251
Validation loss: 2.4315256399224774

Epoch: 6| Step: 9
Training loss: 1.577406389146172
Validation loss: 2.4513025253978653

Epoch: 6| Step: 10
Training loss: 1.6389512016102754
Validation loss: 2.371015341811573

Epoch: 6| Step: 11
Training loss: 1.5129124859235832
Validation loss: 2.4163793001193556

Epoch: 6| Step: 12
Training loss: 1.284069819518873
Validation loss: 2.39838719052172

Epoch: 6| Step: 13
Training loss: 1.9171713358128497
Validation loss: 2.4305373508066546

Epoch: 294| Step: 0
Training loss: 1.517738677458738
Validation loss: 2.4305426615320767

Epoch: 6| Step: 1
Training loss: 1.4091595960891232
Validation loss: 2.402401500867806

Epoch: 6| Step: 2
Training loss: 1.5709724368051585
Validation loss: 2.494579069694219

Epoch: 6| Step: 3
Training loss: 1.9405449351627346
Validation loss: 2.472832852597006

Epoch: 6| Step: 4
Training loss: 2.7416132572927707
Validation loss: 2.4513601372896248

Epoch: 6| Step: 5
Training loss: 1.6904911799185243
Validation loss: 2.498448761231223

Epoch: 6| Step: 6
Training loss: 1.7760708117587394
Validation loss: 2.4659659473221853

Epoch: 6| Step: 7
Training loss: 1.7845050450384898
Validation loss: 2.4925170993200916

Epoch: 6| Step: 8
Training loss: 2.181235252702151
Validation loss: 2.4710813708244905

Epoch: 6| Step: 9
Training loss: 1.6944314099767641
Validation loss: 2.5006207556833506

Epoch: 6| Step: 10
Training loss: 1.7346563712412444
Validation loss: 2.476623256987863

Epoch: 6| Step: 11
Training loss: 1.0907680734609841
Validation loss: 2.4386565286307693

Epoch: 6| Step: 12
Training loss: 1.3792068110651856
Validation loss: 2.460119907702599

Epoch: 6| Step: 13
Training loss: 1.721297924452217
Validation loss: 2.4401778485149848

Epoch: 295| Step: 0
Training loss: 1.4070678875615452
Validation loss: 2.458560026578496

Epoch: 6| Step: 1
Training loss: 2.0451669336658216
Validation loss: 2.384417103641728

Epoch: 6| Step: 2
Training loss: 1.9649519236461233
Validation loss: 2.445024280663661

Epoch: 6| Step: 3
Training loss: 1.4719615481578896
Validation loss: 2.4172155540506575

Epoch: 6| Step: 4
Training loss: 1.536065140753537
Validation loss: 2.4450675545243055

Epoch: 6| Step: 5
Training loss: 2.5325841331251806
Validation loss: 2.4276733501645706

Epoch: 6| Step: 6
Training loss: 1.905591069135549
Validation loss: 2.4932069964292363

Epoch: 6| Step: 7
Training loss: 1.4822233969362693
Validation loss: 2.4142483976407623

Epoch: 6| Step: 8
Training loss: 1.465706777019596
Validation loss: 2.447740767806556

Epoch: 6| Step: 9
Training loss: 1.3884911614075932
Validation loss: 2.467697886148167

Epoch: 6| Step: 10
Training loss: 1.5010501046862375
Validation loss: 2.4465356680991497

Epoch: 6| Step: 11
Training loss: 1.4268229820203642
Validation loss: 2.370206547529644

Epoch: 6| Step: 12
Training loss: 1.5835253030280887
Validation loss: 2.414135950488837

Epoch: 6| Step: 13
Training loss: 1.8622130845039668
Validation loss: 2.4404909511561548

Epoch: 296| Step: 0
Training loss: 2.006015552357775
Validation loss: 2.3750358464418446

Epoch: 6| Step: 1
Training loss: 1.6637529971857394
Validation loss: 2.4450579073045478

Epoch: 6| Step: 2
Training loss: 1.6023626794166572
Validation loss: 2.408354013141806

Epoch: 6| Step: 3
Training loss: 1.508560548532563
Validation loss: 2.4653440703898037

Epoch: 6| Step: 4
Training loss: 1.4297106798304475
Validation loss: 2.4379034116083984

Epoch: 6| Step: 5
Training loss: 1.328927100823664
Validation loss: 2.409512663912439

Epoch: 6| Step: 6
Training loss: 2.0147911535278253
Validation loss: 2.4298103195172667

Epoch: 6| Step: 7
Training loss: 1.5588488836057668
Validation loss: 2.423800710771773

Epoch: 6| Step: 8
Training loss: 1.8292770016470667
Validation loss: 2.5046916274714563

Epoch: 6| Step: 9
Training loss: 1.6257029260175764
Validation loss: 2.4706615888898034

Epoch: 6| Step: 10
Training loss: 1.3786166484046107
Validation loss: 2.403933468623576

Epoch: 6| Step: 11
Training loss: 2.5242338547864187
Validation loss: 2.489867486405602

Epoch: 6| Step: 12
Training loss: 1.3137288471700386
Validation loss: 2.4673733915929223

Epoch: 6| Step: 13
Training loss: 1.6035423880607638
Validation loss: 2.468814216091158

Epoch: 297| Step: 0
Training loss: 1.320097053601179
Validation loss: 2.4402294385277203

Epoch: 6| Step: 1
Training loss: 1.4530021861690658
Validation loss: 2.469356838715611

Epoch: 6| Step: 2
Training loss: 2.13509350324011
Validation loss: 2.4147306041367798

Epoch: 6| Step: 3
Training loss: 1.717077238866143
Validation loss: 2.3840525412465796

Epoch: 6| Step: 4
Training loss: 1.7805850477680658
Validation loss: 2.396150935140447

Epoch: 6| Step: 5
Training loss: 1.2701835013155225
Validation loss: 2.4548198665176364

Epoch: 6| Step: 6
Training loss: 1.56487261878365
Validation loss: 2.4130285517710726

Epoch: 6| Step: 7
Training loss: 1.5112810314390732
Validation loss: 2.4617007013414045

Epoch: 6| Step: 8
Training loss: 1.8276226951230279
Validation loss: 2.4417744120298828

Epoch: 6| Step: 9
Training loss: 1.989554606391736
Validation loss: 2.5017774948907783

Epoch: 6| Step: 10
Training loss: 1.4521998259758224
Validation loss: 2.447472837415693

Epoch: 6| Step: 11
Training loss: 2.235930108378713
Validation loss: 2.4308228478096625

Epoch: 6| Step: 12
Training loss: 1.3652670314741453
Validation loss: 2.443558779955357

Epoch: 6| Step: 13
Training loss: 1.0318109547213379
Validation loss: 2.395799813341488

Epoch: 298| Step: 0
Training loss: 1.512395662854707
Validation loss: 2.4194037673131747

Epoch: 6| Step: 1
Training loss: 1.2440594657165274
Validation loss: 2.4095915025366024

Epoch: 6| Step: 2
Training loss: 1.5949789059000476
Validation loss: 2.426099273964654

Epoch: 6| Step: 3
Training loss: 1.3539269112817112
Validation loss: 2.4606467360900863

Epoch: 6| Step: 4
Training loss: 1.5116025894839378
Validation loss: 2.46022769179717

Epoch: 6| Step: 5
Training loss: 1.3192916625504931
Validation loss: 2.405233643972413

Epoch: 6| Step: 6
Training loss: 1.5370041303461255
Validation loss: 2.4668849215222033

Epoch: 6| Step: 7
Training loss: 2.2328184881857465
Validation loss: 2.46022941115249

Epoch: 6| Step: 8
Training loss: 1.7325619680708584
Validation loss: 2.421683563700697

Epoch: 6| Step: 9
Training loss: 1.2852648657262014
Validation loss: 2.4302667194404104

Epoch: 6| Step: 10
Training loss: 1.683257031678595
Validation loss: 2.436631213256641

Epoch: 6| Step: 11
Training loss: 2.4978447206734433
Validation loss: 2.474720743226671

Epoch: 6| Step: 12
Training loss: 1.8913992565329842
Validation loss: 2.446548515945886

Epoch: 6| Step: 13
Training loss: 1.6032731015688224
Validation loss: 2.443485369323725

Epoch: 299| Step: 0
Training loss: 1.8513974144330638
Validation loss: 2.4824587355138297

Epoch: 6| Step: 1
Training loss: 1.8723907753597981
Validation loss: 2.3946983074237

Epoch: 6| Step: 2
Training loss: 1.575629801699363
Validation loss: 2.427354237067292

Epoch: 6| Step: 3
Training loss: 1.6030565689680971
Validation loss: 2.4258817166079782

Epoch: 6| Step: 4
Training loss: 1.2776202914493922
Validation loss: 2.457914063949607

Epoch: 6| Step: 5
Training loss: 1.8430813368899621
Validation loss: 2.431107472945636

Epoch: 6| Step: 6
Training loss: 1.7291790222584464
Validation loss: 2.4685695992982346

Epoch: 6| Step: 7
Training loss: 1.533485804454472
Validation loss: 2.3928475645736693

Epoch: 6| Step: 8
Training loss: 1.6681430555833607
Validation loss: 2.3850428629622074

Epoch: 6| Step: 9
Training loss: 1.3027879512356202
Validation loss: 2.41228704025308

Epoch: 6| Step: 10
Training loss: 1.4662808705598083
Validation loss: 2.479101171030812

Epoch: 6| Step: 11
Training loss: 2.241693209617436
Validation loss: 2.4625933666361615

Epoch: 6| Step: 12
Training loss: 1.5194636234248509
Validation loss: 2.399737939575915

Epoch: 6| Step: 13
Training loss: 2.1339483904331487
Validation loss: 2.441432833356617

Epoch: 300| Step: 0
Training loss: 1.7598836268618545
Validation loss: 2.4344954424626923

Epoch: 6| Step: 1
Training loss: 2.342379665316978
Validation loss: 2.5009478874234947

Epoch: 6| Step: 2
Training loss: 1.4195838326439383
Validation loss: 2.440246907403078

Epoch: 6| Step: 3
Training loss: 1.8637922374050777
Validation loss: 2.4518091264795165

Epoch: 6| Step: 4
Training loss: 1.440742319092208
Validation loss: 2.432913644803163

Epoch: 6| Step: 5
Training loss: 1.559286551556744
Validation loss: 2.4447515219591365

Epoch: 6| Step: 6
Training loss: 1.537411651554075
Validation loss: 2.5269802116256748

Epoch: 6| Step: 7
Training loss: 1.8829070894532816
Validation loss: 2.4823865232774867

Epoch: 6| Step: 8
Training loss: 1.8225444159308632
Validation loss: 2.428277792598397

Epoch: 6| Step: 9
Training loss: 1.7037120822149154
Validation loss: 2.446602393176735

Epoch: 6| Step: 10
Training loss: 1.429565090921756
Validation loss: 2.4509837488685897

Epoch: 6| Step: 11
Training loss: 1.4785161893936754
Validation loss: 2.452284620451137

Epoch: 6| Step: 12
Training loss: 1.4287312128762535
Validation loss: 2.4577771957427084

Epoch: 6| Step: 13
Training loss: 1.3286257529102719
Validation loss: 2.4391630009353458

Epoch: 301| Step: 0
Training loss: 1.5131164713150045
Validation loss: 2.4693364871594152

Epoch: 6| Step: 1
Training loss: 1.602066779412844
Validation loss: 2.4532834888763837

Epoch: 6| Step: 2
Training loss: 1.4766501748833927
Validation loss: 2.4212683567243602

Epoch: 6| Step: 3
Training loss: 1.5834500955728532
Validation loss: 2.4878909858008558

Epoch: 6| Step: 4
Training loss: 1.678024533352743
Validation loss: 2.4556698359001725

Epoch: 6| Step: 5
Training loss: 0.8620159490906556
Validation loss: 2.457829104757413

Epoch: 6| Step: 6
Training loss: 1.31093549580472
Validation loss: 2.4646940817570626

Epoch: 6| Step: 7
Training loss: 1.801570562127925
Validation loss: 2.527929924237693

Epoch: 6| Step: 8
Training loss: 1.4864965436159376
Validation loss: 2.4629251714274623

Epoch: 6| Step: 9
Training loss: 1.2660097079093153
Validation loss: 2.4702187049597057

Epoch: 6| Step: 10
Training loss: 1.831725593234566
Validation loss: 2.487522023775913

Epoch: 6| Step: 11
Training loss: 2.6651612642031597
Validation loss: 2.4788128583231295

Epoch: 6| Step: 12
Training loss: 1.9633412617241057
Validation loss: 2.496656169966498

Epoch: 6| Step: 13
Training loss: 1.93157391100273
Validation loss: 2.408771406823458

Epoch: 302| Step: 0
Training loss: 2.587260020456419
Validation loss: 2.435294040513602

Epoch: 6| Step: 1
Training loss: 1.902449775263437
Validation loss: 2.4243946297073866

Epoch: 6| Step: 2
Training loss: 1.4712731623224038
Validation loss: 2.4347357208970513

Epoch: 6| Step: 3
Training loss: 1.7084835343118676
Validation loss: 2.435419457337683

Epoch: 6| Step: 4
Training loss: 1.3988926322697723
Validation loss: 2.433792852210741

Epoch: 6| Step: 5
Training loss: 1.7569734054141979
Validation loss: 2.444583513021088

Epoch: 6| Step: 6
Training loss: 1.133859295439901
Validation loss: 2.430867319421221

Epoch: 6| Step: 7
Training loss: 1.2865511388418358
Validation loss: 2.443271562496388

Epoch: 6| Step: 8
Training loss: 2.0602383784913085
Validation loss: 2.4432975951601787

Epoch: 6| Step: 9
Training loss: 1.5824132387504244
Validation loss: 2.498237070315567

Epoch: 6| Step: 10
Training loss: 1.8001534449553243
Validation loss: 2.4441293134659663

Epoch: 6| Step: 11
Training loss: 1.0089713833836829
Validation loss: 2.40528564348773

Epoch: 6| Step: 12
Training loss: 1.4341836905628118
Validation loss: 2.4974446085607944

Epoch: 6| Step: 13
Training loss: 1.2773998376507265
Validation loss: 2.4274851222489686

Epoch: 303| Step: 0
Training loss: 1.4711764157934013
Validation loss: 2.428265246099758

Epoch: 6| Step: 1
Training loss: 1.337739498763767
Validation loss: 2.405757377921285

Epoch: 6| Step: 2
Training loss: 2.0643683554172556
Validation loss: 2.417684123049729

Epoch: 6| Step: 3
Training loss: 1.1242597051587122
Validation loss: 2.460525284930093

Epoch: 6| Step: 4
Training loss: 1.9511346059300378
Validation loss: 2.4937098176638286

Epoch: 6| Step: 5
Training loss: 1.630814201049128
Validation loss: 2.427850788800737

Epoch: 6| Step: 6
Training loss: 1.792547438245185
Validation loss: 2.4797252013110787

Epoch: 6| Step: 7
Training loss: 1.8610331090393513
Validation loss: 2.4106611356330565

Epoch: 6| Step: 8
Training loss: 1.127698205751705
Validation loss: 2.43702594069164

Epoch: 6| Step: 9
Training loss: 1.106049455902806
Validation loss: 2.440358567941535

Epoch: 6| Step: 10
Training loss: 1.8291395583638657
Validation loss: 2.455739757790908

Epoch: 6| Step: 11
Training loss: 1.4179494977332403
Validation loss: 2.466058600742464

Epoch: 6| Step: 12
Training loss: 2.258105513095051
Validation loss: 2.4036462741794917

Epoch: 6| Step: 13
Training loss: 1.1682499575738392
Validation loss: 2.482246977089103

Epoch: 304| Step: 0
Training loss: 1.137556468693824
Validation loss: 2.3996411741934196

Epoch: 6| Step: 1
Training loss: 1.5159565671068853
Validation loss: 2.4090893138375122

Epoch: 6| Step: 2
Training loss: 1.5980432316848823
Validation loss: 2.4990273685808537

Epoch: 6| Step: 3
Training loss: 1.6119223129114935
Validation loss: 2.4842985985936266

Epoch: 6| Step: 4
Training loss: 1.1655881983288507
Validation loss: 2.514639161209597

Epoch: 6| Step: 5
Training loss: 1.655787997317086
Validation loss: 2.4164392670548516

Epoch: 6| Step: 6
Training loss: 1.8128428956948905
Validation loss: 2.4622876160817353

Epoch: 6| Step: 7
Training loss: 1.5366531334789304
Validation loss: 2.490867418145113

Epoch: 6| Step: 8
Training loss: 1.858763009021337
Validation loss: 2.387416744450279

Epoch: 6| Step: 9
Training loss: 1.4934297353986072
Validation loss: 2.3969545858921624

Epoch: 6| Step: 10
Training loss: 1.5709331291870967
Validation loss: 2.4577171004525775

Epoch: 6| Step: 11
Training loss: 1.819581634099068
Validation loss: 2.422581077854635

Epoch: 6| Step: 12
Training loss: 2.2515451635769397
Validation loss: 2.411900661925003

Epoch: 6| Step: 13
Training loss: 1.7598799013212763
Validation loss: 2.4301038204103684

Epoch: 305| Step: 0
Training loss: 1.6268876922381974
Validation loss: 2.468768256688348

Epoch: 6| Step: 1
Training loss: 1.3630659048081735
Validation loss: 2.461398592566477

Epoch: 6| Step: 2
Training loss: 2.2224335517003952
Validation loss: 2.4186237700472173

Epoch: 6| Step: 3
Training loss: 1.4628479242140795
Validation loss: 2.446517782015356

Epoch: 6| Step: 4
Training loss: 1.2224151081027854
Validation loss: 2.4377999532664414

Epoch: 6| Step: 5
Training loss: 2.2070959571197455
Validation loss: 2.4881789271305825

Epoch: 6| Step: 6
Training loss: 1.3849981244621936
Validation loss: 2.426841131102885

Epoch: 6| Step: 7
Training loss: 1.2591963553741863
Validation loss: 2.449952871628187

Epoch: 6| Step: 8
Training loss: 1.7812101125433955
Validation loss: 2.3648096010398003

Epoch: 6| Step: 9
Training loss: 1.5783398925714778
Validation loss: 2.440202492216577

Epoch: 6| Step: 10
Training loss: 1.329441181323566
Validation loss: 2.4440209295538295

Epoch: 6| Step: 11
Training loss: 1.7413006907558588
Validation loss: 2.4101761460960143

Epoch: 6| Step: 12
Training loss: 1.6922612308913423
Validation loss: 2.4566042662583487

Epoch: 6| Step: 13
Training loss: 1.4785999591515215
Validation loss: 2.4769035361521476

Epoch: 306| Step: 0
Training loss: 1.4876964150908347
Validation loss: 2.450751923007385

Epoch: 6| Step: 1
Training loss: 1.3998441813813483
Validation loss: 2.4427699232524116

Epoch: 6| Step: 2
Training loss: 1.6378405966602365
Validation loss: 2.4549245645764293

Epoch: 6| Step: 3
Training loss: 1.527731063398314
Validation loss: 2.421570574641188

Epoch: 6| Step: 4
Training loss: 2.0012435623246487
Validation loss: 2.4868728083218703

Epoch: 6| Step: 5
Training loss: 1.5062105830563215
Validation loss: 2.4852200571863

Epoch: 6| Step: 6
Training loss: 2.002838742754888
Validation loss: 2.404154444220727

Epoch: 6| Step: 7
Training loss: 1.4589476063702715
Validation loss: 2.4222329638965707

Epoch: 6| Step: 8
Training loss: 1.9154377881619136
Validation loss: 2.4086998202899195

Epoch: 6| Step: 9
Training loss: 1.8872441099405692
Validation loss: 2.4941216716055363

Epoch: 6| Step: 10
Training loss: 1.3968862102152597
Validation loss: 2.4702790876617557

Epoch: 6| Step: 11
Training loss: 2.0945061983447997
Validation loss: 2.452299431762407

Epoch: 6| Step: 12
Training loss: 1.3042594070285438
Validation loss: 2.4755042483798193

Epoch: 6| Step: 13
Training loss: 1.4001592341194242
Validation loss: 2.46617329123894

Epoch: 307| Step: 0
Training loss: 1.6386881703599787
Validation loss: 2.442607410960301

Epoch: 6| Step: 1
Training loss: 1.4037196812875543
Validation loss: 2.4484952628152787

Epoch: 6| Step: 2
Training loss: 2.1431106281215806
Validation loss: 2.4150106695434546

Epoch: 6| Step: 3
Training loss: 1.8415953120336843
Validation loss: 2.4262206193704685

Epoch: 6| Step: 4
Training loss: 1.5286609014215788
Validation loss: 2.464094297246409

Epoch: 6| Step: 5
Training loss: 1.4211401245536393
Validation loss: 2.4435465159768284

Epoch: 6| Step: 6
Training loss: 1.6302279226407854
Validation loss: 2.4099923501250506

Epoch: 6| Step: 7
Training loss: 1.8916963426500064
Validation loss: 2.4224915253293844

Epoch: 6| Step: 8
Training loss: 1.5205464636876547
Validation loss: 2.5016873069824928

Epoch: 6| Step: 9
Training loss: 1.5009918907043045
Validation loss: 2.455817487158015

Epoch: 6| Step: 10
Training loss: 1.3459000353429331
Validation loss: 2.434197886083245

Epoch: 6| Step: 11
Training loss: 1.9963762117066546
Validation loss: 2.4151448184693494

Epoch: 6| Step: 12
Training loss: 1.214423005573204
Validation loss: 2.471095687170722

Epoch: 6| Step: 13
Training loss: 1.5186156036817235
Validation loss: 2.3918124091872537

Epoch: 308| Step: 0
Training loss: 1.8468058203635438
Validation loss: 2.443418611586314

Epoch: 6| Step: 1
Training loss: 1.2839965225541035
Validation loss: 2.484625838444407

Epoch: 6| Step: 2
Training loss: 2.1497333849227025
Validation loss: 2.4656170131878863

Epoch: 6| Step: 3
Training loss: 1.5201414790314658
Validation loss: 2.459059913622666

Epoch: 6| Step: 4
Training loss: 1.1344564151184235
Validation loss: 2.5001416412344883

Epoch: 6| Step: 5
Training loss: 1.4893086409102765
Validation loss: 2.4188194961698732

Epoch: 6| Step: 6
Training loss: 1.42918737450251
Validation loss: 2.496074423204113

Epoch: 6| Step: 7
Training loss: 1.905668576481407
Validation loss: 2.464181139880859

Epoch: 6| Step: 8
Training loss: 1.6154880901005095
Validation loss: 2.4313534863576725

Epoch: 6| Step: 9
Training loss: 1.7537455665711792
Validation loss: 2.429614330781022

Epoch: 6| Step: 10
Training loss: 1.3061533020586438
Validation loss: 2.3945249054786943

Epoch: 6| Step: 11
Training loss: 1.8928995243376419
Validation loss: 2.373642450614244

Epoch: 6| Step: 12
Training loss: 1.5163752478487005
Validation loss: 2.3825963635580343

Epoch: 6| Step: 13
Training loss: 1.2567332595581397
Validation loss: 2.4606530341041744

Epoch: 309| Step: 0
Training loss: 1.7657250570117728
Validation loss: 2.4426327270446784

Epoch: 6| Step: 1
Training loss: 1.4372286333110609
Validation loss: 2.4715280547625533

Epoch: 6| Step: 2
Training loss: 1.5065944673461686
Validation loss: 2.419171126818371

Epoch: 6| Step: 3
Training loss: 1.6754100895376003
Validation loss: 2.421251553498916

Epoch: 6| Step: 4
Training loss: 2.5361309323250634
Validation loss: 2.4301417276716557

Epoch: 6| Step: 5
Training loss: 1.4787719988053207
Validation loss: 2.473212745805347

Epoch: 6| Step: 6
Training loss: 1.6987163634124431
Validation loss: 2.411992294979385

Epoch: 6| Step: 7
Training loss: 1.3716926679468227
Validation loss: 2.43313454667144

Epoch: 6| Step: 8
Training loss: 1.6709355361895546
Validation loss: 2.4508615887408998

Epoch: 6| Step: 9
Training loss: 1.0516506979969795
Validation loss: 2.4499134229238724

Epoch: 6| Step: 10
Training loss: 1.5059865064181113
Validation loss: 2.4891322585365168

Epoch: 6| Step: 11
Training loss: 1.6645966151745624
Validation loss: 2.4728195120201657

Epoch: 6| Step: 12
Training loss: 1.1046071283652295
Validation loss: 2.406298663133763

Epoch: 6| Step: 13
Training loss: 1.5852232579055814
Validation loss: 2.430909494352972

Epoch: 310| Step: 0
Training loss: 0.9248987168200782
Validation loss: 2.46184039633027

Epoch: 6| Step: 1
Training loss: 1.3123476303303012
Validation loss: 2.4023211670461144

Epoch: 6| Step: 2
Training loss: 1.9678902338166817
Validation loss: 2.481235841906136

Epoch: 6| Step: 3
Training loss: 1.3694706626499031
Validation loss: 2.4638828583401406

Epoch: 6| Step: 4
Training loss: 1.856837616977191
Validation loss: 2.4689102152016997

Epoch: 6| Step: 5
Training loss: 1.7750024822378936
Validation loss: 2.423267485253236

Epoch: 6| Step: 6
Training loss: 1.711141495758273
Validation loss: 2.432473996231286

Epoch: 6| Step: 7
Training loss: 1.6596525258319117
Validation loss: 2.438898647098624

Epoch: 6| Step: 8
Training loss: 1.786253944323211
Validation loss: 2.3886644341503818

Epoch: 6| Step: 9
Training loss: 2.3715265875075335
Validation loss: 2.4739967052201917

Epoch: 6| Step: 10
Training loss: 1.2663415834647311
Validation loss: 2.4360729875265914

Epoch: 6| Step: 11
Training loss: 1.5033757054235362
Validation loss: 2.4178668497723708

Epoch: 6| Step: 12
Training loss: 1.444817205568692
Validation loss: 2.4299920953584655

Epoch: 6| Step: 13
Training loss: 1.2216565124606675
Validation loss: 2.4638619517253404

Epoch: 311| Step: 0
Training loss: 1.1831508097223924
Validation loss: 2.4386214039722622

Epoch: 6| Step: 1
Training loss: 2.233503691974882
Validation loss: 2.4248184032504168

Epoch: 6| Step: 2
Training loss: 1.3880722103188905
Validation loss: 2.3848612933624365

Epoch: 6| Step: 3
Training loss: 2.279889262672384
Validation loss: 2.4990020616266952

Epoch: 6| Step: 4
Training loss: 1.7643223911486379
Validation loss: 2.3922598220282536

Epoch: 6| Step: 5
Training loss: 1.6658039562286908
Validation loss: 2.4446116673727154

Epoch: 6| Step: 6
Training loss: 1.5401226594305106
Validation loss: 2.532172436687371

Epoch: 6| Step: 7
Training loss: 1.4243082877350473
Validation loss: 2.448827794854427

Epoch: 6| Step: 8
Training loss: 1.6347469570320021
Validation loss: 2.4291055108448862

Epoch: 6| Step: 9
Training loss: 1.2792949647379583
Validation loss: 2.4357633691099334

Epoch: 6| Step: 10
Training loss: 1.4810549901403325
Validation loss: 2.4422330106340517

Epoch: 6| Step: 11
Training loss: 1.8098489512859761
Validation loss: 2.429407014996145

Epoch: 6| Step: 12
Training loss: 1.4476815268321632
Validation loss: 2.4182959747713717

Epoch: 6| Step: 13
Training loss: 0.8165677654623611
Validation loss: 2.404457636108634

Epoch: 312| Step: 0
Training loss: 1.0983865826500607
Validation loss: 2.439206556927624

Epoch: 6| Step: 1
Training loss: 1.5084800230883944
Validation loss: 2.4499861517601245

Epoch: 6| Step: 2
Training loss: 1.2298125924414116
Validation loss: 2.457206704289287

Epoch: 6| Step: 3
Training loss: 1.4780062928227116
Validation loss: 2.4545559011948095

Epoch: 6| Step: 4
Training loss: 2.1157494197079743
Validation loss: 2.4415954175285552

Epoch: 6| Step: 5
Training loss: 1.4135720261209246
Validation loss: 2.465786253698897

Epoch: 6| Step: 6
Training loss: 1.7985514905450568
Validation loss: 2.4859449127060556

Epoch: 6| Step: 7
Training loss: 1.1953563806794418
Validation loss: 2.4131313245388686

Epoch: 6| Step: 8
Training loss: 2.107923672446966
Validation loss: 2.3851255769545157

Epoch: 6| Step: 9
Training loss: 0.9545375175476373
Validation loss: 2.4287208692070004

Epoch: 6| Step: 10
Training loss: 1.8361204015650987
Validation loss: 2.470426277740501

Epoch: 6| Step: 11
Training loss: 1.7656359376821753
Validation loss: 2.455610362413087

Epoch: 6| Step: 12
Training loss: 1.7544112466153328
Validation loss: 2.4880423451512987

Epoch: 6| Step: 13
Training loss: 1.8679668763142134
Validation loss: 2.4093390970699424

Epoch: 313| Step: 0
Training loss: 1.2994917242734092
Validation loss: 2.432943052197302

Epoch: 6| Step: 1
Training loss: 1.6970463337819288
Validation loss: 2.43694937205316

Epoch: 6| Step: 2
Training loss: 1.7062567518610687
Validation loss: 2.4269562037078805

Epoch: 6| Step: 3
Training loss: 1.0997972886831295
Validation loss: 2.429588180520471

Epoch: 6| Step: 4
Training loss: 1.6467127160854824
Validation loss: 2.4661489335660987

Epoch: 6| Step: 5
Training loss: 1.3094981242629253
Validation loss: 2.46573818132143

Epoch: 6| Step: 6
Training loss: 1.8035285167634052
Validation loss: 2.414471617732199

Epoch: 6| Step: 7
Training loss: 1.79373265699981
Validation loss: 2.4278108584770557

Epoch: 6| Step: 8
Training loss: 1.6215147643709564
Validation loss: 2.4696801633354335

Epoch: 6| Step: 9
Training loss: 1.390297025944689
Validation loss: 2.4050575074722484

Epoch: 6| Step: 10
Training loss: 1.7432565872897279
Validation loss: 2.3452463821741474

Epoch: 6| Step: 11
Training loss: 1.4335952467741675
Validation loss: 2.422368013532723

Epoch: 6| Step: 12
Training loss: 2.3750486870844836
Validation loss: 2.4585369485327173

Epoch: 6| Step: 13
Training loss: 1.3841438134863944
Validation loss: 2.465254579518015

Epoch: 314| Step: 0
Training loss: 1.2012499776119743
Validation loss: 2.388092245710067

Epoch: 6| Step: 1
Training loss: 1.4270823773383212
Validation loss: 2.4351265097473194

Epoch: 6| Step: 2
Training loss: 1.438579237122976
Validation loss: 2.4448250791254638

Epoch: 6| Step: 3
Training loss: 1.2906849678646093
Validation loss: 2.4163936355382667

Epoch: 6| Step: 4
Training loss: 1.7431777397922807
Validation loss: 2.4002844913189243

Epoch: 6| Step: 5
Training loss: 1.4783366207070483
Validation loss: 2.4017509373977997

Epoch: 6| Step: 6
Training loss: 1.7413846890401294
Validation loss: 2.4690975942963513

Epoch: 6| Step: 7
Training loss: 1.7202696584413464
Validation loss: 2.418432358360957

Epoch: 6| Step: 8
Training loss: 2.2606784885734483
Validation loss: 2.419439671628828

Epoch: 6| Step: 9
Training loss: 1.5659769663864567
Validation loss: 2.502969290043166

Epoch: 6| Step: 10
Training loss: 1.3846382114778468
Validation loss: 2.4655798182278112

Epoch: 6| Step: 11
Training loss: 1.8012234027071603
Validation loss: 2.4123027953633445

Epoch: 6| Step: 12
Training loss: 1.7178776000832532
Validation loss: 2.3891796214722785

Epoch: 6| Step: 13
Training loss: 1.546788454042979
Validation loss: 2.4520492028866983

Epoch: 315| Step: 0
Training loss: 2.3437591552555563
Validation loss: 2.4142217910439507

Epoch: 6| Step: 1
Training loss: 1.748191921247497
Validation loss: 2.4055111041850075

Epoch: 6| Step: 2
Training loss: 1.7771104596636493
Validation loss: 2.417702241000362

Epoch: 6| Step: 3
Training loss: 1.5402583399743284
Validation loss: 2.3862977402164613

Epoch: 6| Step: 4
Training loss: 1.4636004652201373
Validation loss: 2.376838627599564

Epoch: 6| Step: 5
Training loss: 1.8797662555180954
Validation loss: 2.402458018925018

Epoch: 6| Step: 6
Training loss: 1.041933038350181
Validation loss: 2.424124112072664

Epoch: 6| Step: 7
Training loss: 1.4755904616078892
Validation loss: 2.4795731166246626

Epoch: 6| Step: 8
Training loss: 1.4081255802808599
Validation loss: 2.4015836147893537

Epoch: 6| Step: 9
Training loss: 0.980680921478408
Validation loss: 2.4580326664679872

Epoch: 6| Step: 10
Training loss: 1.77907241762239
Validation loss: 2.430094030444681

Epoch: 6| Step: 11
Training loss: 1.652857923657051
Validation loss: 2.481742207336318

Epoch: 6| Step: 12
Training loss: 1.418218081072928
Validation loss: 2.438143889913419

Epoch: 6| Step: 13
Training loss: 1.4199844199655665
Validation loss: 2.464220756550705

Epoch: 316| Step: 0
Training loss: 1.7652625327957263
Validation loss: 2.3940525158186245

Epoch: 6| Step: 1
Training loss: 1.444578407058407
Validation loss: 2.5074697970883775

Epoch: 6| Step: 2
Training loss: 1.639934285405735
Validation loss: 2.4335546924116294

Epoch: 6| Step: 3
Training loss: 1.4572285781885268
Validation loss: 2.465311990150325

Epoch: 6| Step: 4
Training loss: 1.2424440898635107
Validation loss: 2.503018720389564

Epoch: 6| Step: 5
Training loss: 2.335693448691627
Validation loss: 2.4046117167384513

Epoch: 6| Step: 6
Training loss: 1.2240757608559711
Validation loss: 2.457782664567515

Epoch: 6| Step: 7
Training loss: 1.1274526140358903
Validation loss: 2.4609444973128807

Epoch: 6| Step: 8
Training loss: 1.2431895215228672
Validation loss: 2.3616896007725545

Epoch: 6| Step: 9
Training loss: 1.3806878270661749
Validation loss: 2.485100502269108

Epoch: 6| Step: 10
Training loss: 2.0763059987250907
Validation loss: 2.4143071082388134

Epoch: 6| Step: 11
Training loss: 1.7804964713683242
Validation loss: 2.471160705443003

Epoch: 6| Step: 12
Training loss: 1.410752442518192
Validation loss: 2.4362334101949448

Epoch: 6| Step: 13
Training loss: 1.3090085411288541
Validation loss: 2.459213678676894

Epoch: 317| Step: 0
Training loss: 1.5049528369293956
Validation loss: 2.4684345848138434

Epoch: 6| Step: 1
Training loss: 1.1685380345668557
Validation loss: 2.398509772266244

Epoch: 6| Step: 2
Training loss: 1.7109857143071032
Validation loss: 2.4383791255028786

Epoch: 6| Step: 3
Training loss: 1.8059838993246178
Validation loss: 2.407882306183297

Epoch: 6| Step: 4
Training loss: 1.6533325699578851
Validation loss: 2.4274451985835235

Epoch: 6| Step: 5
Training loss: 2.2704393470860187
Validation loss: 2.4170955808452455

Epoch: 6| Step: 6
Training loss: 1.4235639497135175
Validation loss: 2.4709378235875437

Epoch: 6| Step: 7
Training loss: 1.797339205281394
Validation loss: 2.447022408801693

Epoch: 6| Step: 8
Training loss: 1.219772643416843
Validation loss: 2.4383261453008402

Epoch: 6| Step: 9
Training loss: 1.0178060733919048
Validation loss: 2.4693010410194307

Epoch: 6| Step: 10
Training loss: 1.2043772534209285
Validation loss: 2.46671202220752

Epoch: 6| Step: 11
Training loss: 1.714943641759761
Validation loss: 2.4633162110284332

Epoch: 6| Step: 12
Training loss: 1.5547715360846253
Validation loss: 2.439886810865362

Epoch: 6| Step: 13
Training loss: 1.3856663108521177
Validation loss: 2.4243197790465945

Epoch: 318| Step: 0
Training loss: 1.6395956534181724
Validation loss: 2.4787544830925277

Epoch: 6| Step: 1
Training loss: 1.5703244185114007
Validation loss: 2.3842626921170655

Epoch: 6| Step: 2
Training loss: 2.4826915483440044
Validation loss: 2.4641248879010753

Epoch: 6| Step: 3
Training loss: 0.9676624777242532
Validation loss: 2.440988493324033

Epoch: 6| Step: 4
Training loss: 1.2809819196903633
Validation loss: 2.4683495047806034

Epoch: 6| Step: 5
Training loss: 1.2494109196196255
Validation loss: 2.4206717220765155

Epoch: 6| Step: 6
Training loss: 1.6326287271123987
Validation loss: 2.4170565409134706

Epoch: 6| Step: 7
Training loss: 1.3460394407221559
Validation loss: 2.4295269848773984

Epoch: 6| Step: 8
Training loss: 1.5044562584960812
Validation loss: 2.418074162617212

Epoch: 6| Step: 9
Training loss: 1.728451761046542
Validation loss: 2.4696370478646963

Epoch: 6| Step: 10
Training loss: 1.2332787293297587
Validation loss: 2.369915850086804

Epoch: 6| Step: 11
Training loss: 1.5576108352388105
Validation loss: 2.506877410107277

Epoch: 6| Step: 12
Training loss: 1.6795943833201123
Validation loss: 2.4391457760213537

Epoch: 6| Step: 13
Training loss: 1.684814081660452
Validation loss: 2.4549531120265566

Epoch: 319| Step: 0
Training loss: 1.2901460197517136
Validation loss: 2.461891351203528

Epoch: 6| Step: 1
Training loss: 1.849482917692319
Validation loss: 2.4318253170055155

Epoch: 6| Step: 2
Training loss: 1.356012856279041
Validation loss: 2.501803535134931

Epoch: 6| Step: 3
Training loss: 1.4551118782788166
Validation loss: 2.4598617835624816

Epoch: 6| Step: 4
Training loss: 1.9136565108732722
Validation loss: 2.4128522894226783

Epoch: 6| Step: 5
Training loss: 1.3136353350686616
Validation loss: 2.475102682335949

Epoch: 6| Step: 6
Training loss: 1.1866018512701744
Validation loss: 2.4306681473803384

Epoch: 6| Step: 7
Training loss: 1.2892531745225053
Validation loss: 2.3882315241887784

Epoch: 6| Step: 8
Training loss: 2.4987271883497195
Validation loss: 2.3932552250308197

Epoch: 6| Step: 9
Training loss: 1.4323402350311745
Validation loss: 2.4246344251567526

Epoch: 6| Step: 10
Training loss: 1.295479724797517
Validation loss: 2.4441307976551943

Epoch: 6| Step: 11
Training loss: 1.3567935065524572
Validation loss: 2.4628251219193515

Epoch: 6| Step: 12
Training loss: 1.7366973861911013
Validation loss: 2.361022019037519

Epoch: 6| Step: 13
Training loss: 1.1977050373171163
Validation loss: 2.409326781803659

Epoch: 320| Step: 0
Training loss: 1.696376624781976
Validation loss: 2.4208030135684093

Epoch: 6| Step: 1
Training loss: 1.7003829300380102
Validation loss: 2.418029225650563

Epoch: 6| Step: 2
Training loss: 1.5989602137584584
Validation loss: 2.4620613122152477

Epoch: 6| Step: 3
Training loss: 1.2498623772201307
Validation loss: 2.4269922545609135

Epoch: 6| Step: 4
Training loss: 1.6287023476153295
Validation loss: 2.408397509462161

Epoch: 6| Step: 5
Training loss: 1.7474836241209943
Validation loss: 2.4092799153300546

Epoch: 6| Step: 6
Training loss: 1.196599429605008
Validation loss: 2.4308348295340836

Epoch: 6| Step: 7
Training loss: 1.390602197352988
Validation loss: 2.5092510403379515

Epoch: 6| Step: 8
Training loss: 2.3010184355208216
Validation loss: 2.470856298286567

Epoch: 6| Step: 9
Training loss: 1.3081557266701973
Validation loss: 2.438398166805266

Epoch: 6| Step: 10
Training loss: 1.6263229413574571
Validation loss: 2.4314248202876265

Epoch: 6| Step: 11
Training loss: 1.4199097854540355
Validation loss: 2.3963956118685745

Epoch: 6| Step: 12
Training loss: 1.223715180397502
Validation loss: 2.436326083159712

Epoch: 6| Step: 13
Training loss: 1.9090978268295722
Validation loss: 2.4919559590951073

Epoch: 321| Step: 0
Training loss: 1.8803244332126179
Validation loss: 2.4764521297219573

Epoch: 6| Step: 1
Training loss: 1.6315169601938395
Validation loss: 2.457502935729909

Epoch: 6| Step: 2
Training loss: 1.681004065922274
Validation loss: 2.4599379945292723

Epoch: 6| Step: 3
Training loss: 1.7095905732904857
Validation loss: 2.472743764419627

Epoch: 6| Step: 4
Training loss: 1.4531312347606502
Validation loss: 2.4983959527999606

Epoch: 6| Step: 5
Training loss: 1.2100903408752293
Validation loss: 2.472452146168112

Epoch: 6| Step: 6
Training loss: 1.3997074945601167
Validation loss: 2.416537539887035

Epoch: 6| Step: 7
Training loss: 1.3897590941646083
Validation loss: 2.5323351143633355

Epoch: 6| Step: 8
Training loss: 1.347409742726167
Validation loss: 2.4747548696756367

Epoch: 6| Step: 9
Training loss: 1.2978823323043158
Validation loss: 2.4935096599617

Epoch: 6| Step: 10
Training loss: 1.5303642669578046
Validation loss: 2.404361100125113

Epoch: 6| Step: 11
Training loss: 1.1843446672324751
Validation loss: 2.392915522091083

Epoch: 6| Step: 12
Training loss: 1.6862408214005402
Validation loss: 2.4258986092918207

Epoch: 6| Step: 13
Training loss: 2.5941093839290152
Validation loss: 2.4324507128498127

Epoch: 322| Step: 0
Training loss: 1.510755996295771
Validation loss: 2.4584664992994916

Epoch: 6| Step: 1
Training loss: 1.4069250817622925
Validation loss: 2.4288690156031714

Epoch: 6| Step: 2
Training loss: 1.4979374533507737
Validation loss: 2.4479662664795474

Epoch: 6| Step: 3
Training loss: 1.3831032054095855
Validation loss: 2.3936670208478805

Epoch: 6| Step: 4
Training loss: 1.649730518760758
Validation loss: 2.4526005666327095

Epoch: 6| Step: 5
Training loss: 1.1542722954368
Validation loss: 2.376812869589305

Epoch: 6| Step: 6
Training loss: 1.5189274468388463
Validation loss: 2.4544228252653464

Epoch: 6| Step: 7
Training loss: 2.0060600024422093
Validation loss: 2.4214969378298314

Epoch: 6| Step: 8
Training loss: 1.3667820792584335
Validation loss: 2.4198389244136225

Epoch: 6| Step: 9
Training loss: 1.778602573507273
Validation loss: 2.384886588212098

Epoch: 6| Step: 10
Training loss: 1.71921775695112
Validation loss: 2.436564814846935

Epoch: 6| Step: 11
Training loss: 1.5257647613556387
Validation loss: 2.4751540426007823

Epoch: 6| Step: 12
Training loss: 1.62610918483628
Validation loss: 2.429065166849068

Epoch: 6| Step: 13
Training loss: 1.4380521957623154
Validation loss: 2.4833703202739343

Epoch: 323| Step: 0
Training loss: 1.4893004764636806
Validation loss: 2.4141260522296495

Epoch: 6| Step: 1
Training loss: 1.235502476577407
Validation loss: 2.394837495021637

Epoch: 6| Step: 2
Training loss: 1.2967095326952052
Validation loss: 2.432609618657774

Epoch: 6| Step: 3
Training loss: 1.4724231808739052
Validation loss: 2.4470935122625583

Epoch: 6| Step: 4
Training loss: 1.4227313303107094
Validation loss: 2.4960509273497906

Epoch: 6| Step: 5
Training loss: 1.2756577309909436
Validation loss: 2.432336079100937

Epoch: 6| Step: 6
Training loss: 1.446526095215923
Validation loss: 2.499602941545522

Epoch: 6| Step: 7
Training loss: 0.8084330376028938
Validation loss: 2.4562379487041643

Epoch: 6| Step: 8
Training loss: 0.9976719041759724
Validation loss: 2.526820078193706

Epoch: 6| Step: 9
Training loss: 1.8478370239343904
Validation loss: 2.4215003341394703

Epoch: 6| Step: 10
Training loss: 2.3908620479965066
Validation loss: 2.362820338368565

Epoch: 6| Step: 11
Training loss: 2.0334257943857192
Validation loss: 2.4290055126754013

Epoch: 6| Step: 12
Training loss: 1.4515152084810066
Validation loss: 2.476132156581047

Epoch: 6| Step: 13
Training loss: 1.7821907102558268
Validation loss: 2.4135666895036034

Epoch: 324| Step: 0
Training loss: 1.4906863505855763
Validation loss: 2.4147722285697193

Epoch: 6| Step: 1
Training loss: 1.1680451435124501
Validation loss: 2.4137296637345957

Epoch: 6| Step: 2
Training loss: 1.3782073673191433
Validation loss: 2.463490967934656

Epoch: 6| Step: 3
Training loss: 1.4371407930797564
Validation loss: 2.4439564239027267

Epoch: 6| Step: 4
Training loss: 2.059036120490216
Validation loss: 2.4479798597890285

Epoch: 6| Step: 5
Training loss: 1.5170729494704243
Validation loss: 2.413700759365132

Epoch: 6| Step: 6
Training loss: 1.2762374520128643
Validation loss: 2.422289878619979

Epoch: 6| Step: 7
Training loss: 1.6111060896974265
Validation loss: 2.4173181848652656

Epoch: 6| Step: 8
Training loss: 1.7410249808686804
Validation loss: 2.395569460882617

Epoch: 6| Step: 9
Training loss: 1.49326321638777
Validation loss: 2.4722490598605984

Epoch: 6| Step: 10
Training loss: 1.1896460365743402
Validation loss: 2.4183877026061222

Epoch: 6| Step: 11
Training loss: 1.2743037735143818
Validation loss: 2.481214340688124

Epoch: 6| Step: 12
Training loss: 1.566976771539759
Validation loss: 2.466900466153197

Epoch: 6| Step: 13
Training loss: 2.1580157582694928
Validation loss: 2.4319746984336583

Epoch: 325| Step: 0
Training loss: 1.4626077498170278
Validation loss: 2.4582234527185993

Epoch: 6| Step: 1
Training loss: 1.2780478866930385
Validation loss: 2.449390121001451

Epoch: 6| Step: 2
Training loss: 1.5553966036072406
Validation loss: 2.457906327896994

Epoch: 6| Step: 3
Training loss: 1.2937431206266892
Validation loss: 2.4605317437084437

Epoch: 6| Step: 4
Training loss: 1.3547264507110295
Validation loss: 2.4495682513204775

Epoch: 6| Step: 5
Training loss: 1.1574930262510017
Validation loss: 2.4201321452123805

Epoch: 6| Step: 6
Training loss: 1.3552179021983752
Validation loss: 2.4533757471626676

Epoch: 6| Step: 7
Training loss: 1.5851831004283212
Validation loss: 2.4426989463455944

Epoch: 6| Step: 8
Training loss: 1.3843086898457109
Validation loss: 2.400839349014813

Epoch: 6| Step: 9
Training loss: 1.3170899107271106
Validation loss: 2.456821561496142

Epoch: 6| Step: 10
Training loss: 1.5535524912088694
Validation loss: 2.415533260055298

Epoch: 6| Step: 11
Training loss: 2.6096489128664975
Validation loss: 2.410671132132213

Epoch: 6| Step: 12
Training loss: 1.2700126322170602
Validation loss: 2.462372984691249

Epoch: 6| Step: 13
Training loss: 1.9760238456291142
Validation loss: 2.3973076185084943

Epoch: 326| Step: 0
Training loss: 1.8509043880027494
Validation loss: 2.4306275946454194

Epoch: 6| Step: 1
Training loss: 1.1220389711204388
Validation loss: 2.46567775603802

Epoch: 6| Step: 2
Training loss: 1.7309255578282863
Validation loss: 2.463581693562988

Epoch: 6| Step: 3
Training loss: 1.3125234329311641
Validation loss: 2.490855705124726

Epoch: 6| Step: 4
Training loss: 1.4777644679458863
Validation loss: 2.4478999409380195

Epoch: 6| Step: 5
Training loss: 1.915103862625138
Validation loss: 2.4351976141944793

Epoch: 6| Step: 6
Training loss: 1.3988399246259302
Validation loss: 2.391743841516467

Epoch: 6| Step: 7
Training loss: 2.0123550741956833
Validation loss: 2.4030607503303116

Epoch: 6| Step: 8
Training loss: 1.3441878204352415
Validation loss: 2.4847553932205013

Epoch: 6| Step: 9
Training loss: 1.164373266737872
Validation loss: 2.447411649542393

Epoch: 6| Step: 10
Training loss: 2.2739256239766696
Validation loss: 2.438256901634385

Epoch: 6| Step: 11
Training loss: 1.2454684610956326
Validation loss: 2.4375788915428807

Epoch: 6| Step: 12
Training loss: 1.045885614909581
Validation loss: 2.443475085301277

Epoch: 6| Step: 13
Training loss: 1.4707780188226418
Validation loss: 2.42285978981125

Epoch: 327| Step: 0
Training loss: 0.7300633003929995
Validation loss: 2.41579300919763

Epoch: 6| Step: 1
Training loss: 1.3737201803370862
Validation loss: 2.4180648434470404

Epoch: 6| Step: 2
Training loss: 1.2390613685785543
Validation loss: 2.4595975182041077

Epoch: 6| Step: 3
Training loss: 1.922112923138085
Validation loss: 2.489151280305175

Epoch: 6| Step: 4
Training loss: 1.016575764412097
Validation loss: 2.430888597335764

Epoch: 6| Step: 5
Training loss: 1.5681495763708482
Validation loss: 2.5113395428011454

Epoch: 6| Step: 6
Training loss: 1.4692914248915243
Validation loss: 2.447350860290665

Epoch: 6| Step: 7
Training loss: 2.2983554558338195
Validation loss: 2.4926778829262264

Epoch: 6| Step: 8
Training loss: 1.5558616000309693
Validation loss: 2.4807873174524477

Epoch: 6| Step: 9
Training loss: 1.5735348713965174
Validation loss: 2.463304349829885

Epoch: 6| Step: 10
Training loss: 1.7884523109090709
Validation loss: 2.4770853087217968

Epoch: 6| Step: 11
Training loss: 1.4801608044668924
Validation loss: 2.503279225262364

Epoch: 6| Step: 12
Training loss: 1.5887129977859773
Validation loss: 2.4316008686667603

Epoch: 6| Step: 13
Training loss: 0.9312598131930068
Validation loss: 2.450634473482264

Epoch: 328| Step: 0
Training loss: 1.5253899216497657
Validation loss: 2.4058524971267023

Epoch: 6| Step: 1
Training loss: 1.2194008189898884
Validation loss: 2.4661136162543897

Epoch: 6| Step: 2
Training loss: 1.1755462107400139
Validation loss: 2.469371031654379

Epoch: 6| Step: 3
Training loss: 1.5858907457798121
Validation loss: 2.427616570103255

Epoch: 6| Step: 4
Training loss: 1.9486090369684417
Validation loss: 2.3837501406519412

Epoch: 6| Step: 5
Training loss: 1.317815643082458
Validation loss: 2.3734575226975765

Epoch: 6| Step: 6
Training loss: 1.4236708817172117
Validation loss: 2.4329457570949145

Epoch: 6| Step: 7
Training loss: 2.2117488167786434
Validation loss: 2.448124997697868

Epoch: 6| Step: 8
Training loss: 1.4669293421271867
Validation loss: 2.3770807404392675

Epoch: 6| Step: 9
Training loss: 1.0838644425312745
Validation loss: 2.454249583874534

Epoch: 6| Step: 10
Training loss: 1.1111374944627475
Validation loss: 2.3573892178577442

Epoch: 6| Step: 11
Training loss: 1.448219468908961
Validation loss: 2.3962511157586244

Epoch: 6| Step: 12
Training loss: 1.118118165252761
Validation loss: 2.440638588988077

Epoch: 6| Step: 13
Training loss: 1.6114344336379884
Validation loss: 2.457386901137041

Epoch: 329| Step: 0
Training loss: 1.6560350674496005
Validation loss: 2.4342925637792843

Epoch: 6| Step: 1
Training loss: 1.5095971175064684
Validation loss: 2.393756612346989

Epoch: 6| Step: 2
Training loss: 1.6290243641136042
Validation loss: 2.406491391481014

Epoch: 6| Step: 3
Training loss: 0.8504492456069822
Validation loss: 2.484559314216545

Epoch: 6| Step: 4
Training loss: 1.1592918283905516
Validation loss: 2.395821784706335

Epoch: 6| Step: 5
Training loss: 1.4480810095008168
Validation loss: 2.4279637854709235

Epoch: 6| Step: 6
Training loss: 1.7401836828861215
Validation loss: 2.482586726359611

Epoch: 6| Step: 7
Training loss: 1.5347733736024651
Validation loss: 2.41129820198157

Epoch: 6| Step: 8
Training loss: 1.2607652113959587
Validation loss: 2.4650655219965016

Epoch: 6| Step: 9
Training loss: 1.5421672042856187
Validation loss: 2.480265700446577

Epoch: 6| Step: 10
Training loss: 1.592767449981082
Validation loss: 2.459839512927157

Epoch: 6| Step: 11
Training loss: 1.7267791474034746
Validation loss: 2.4570437602083937

Epoch: 6| Step: 12
Training loss: 1.4808246114399204
Validation loss: 2.512811526296234

Epoch: 6| Step: 13
Training loss: 2.4768401270107256
Validation loss: 2.441536381360511

Epoch: 330| Step: 0
Training loss: 0.9830086322843914
Validation loss: 2.4064683861694878

Epoch: 6| Step: 1
Training loss: 1.2671072486461172
Validation loss: 2.468669731690911

Epoch: 6| Step: 2
Training loss: 1.185037468909366
Validation loss: 2.4539966621796436

Epoch: 6| Step: 3
Training loss: 1.2725756952821228
Validation loss: 2.3333821738386273

Epoch: 6| Step: 4
Training loss: 2.426536356532742
Validation loss: 2.409872585392566

Epoch: 6| Step: 5
Training loss: 1.532668177102965
Validation loss: 2.3903227241066256

Epoch: 6| Step: 6
Training loss: 1.6521536354734476
Validation loss: 2.4461147220763326

Epoch: 6| Step: 7
Training loss: 1.5296257123459958
Validation loss: 2.4610476566680974

Epoch: 6| Step: 8
Training loss: 1.5570031178369097
Validation loss: 2.461523781231806

Epoch: 6| Step: 9
Training loss: 1.307677400782359
Validation loss: 2.4059588002142904

Epoch: 6| Step: 10
Training loss: 0.9104237961362648
Validation loss: 2.389140593222599

Epoch: 6| Step: 11
Training loss: 1.6913847536478612
Validation loss: 2.4109657635194237

Epoch: 6| Step: 12
Training loss: 1.543768026269849
Validation loss: 2.4183888676138574

Epoch: 6| Step: 13
Training loss: 1.4935303881746098
Validation loss: 2.4436386257162916

Epoch: 331| Step: 0
Training loss: 1.3414328357548082
Validation loss: 2.3653106141998017

Epoch: 6| Step: 1
Training loss: 1.3269981540589477
Validation loss: 2.389128250025011

Epoch: 6| Step: 2
Training loss: 1.3793086688570002
Validation loss: 2.3889221640369023

Epoch: 6| Step: 3
Training loss: 1.5808435573592468
Validation loss: 2.401027028534313

Epoch: 6| Step: 4
Training loss: 1.65341418788974
Validation loss: 2.379924272988901

Epoch: 6| Step: 5
Training loss: 1.472853912930345
Validation loss: 2.428768857283466

Epoch: 6| Step: 6
Training loss: 1.5256984268265377
Validation loss: 2.4696379217844413

Epoch: 6| Step: 7
Training loss: 1.0550870915483486
Validation loss: 2.489276112397576

Epoch: 6| Step: 8
Training loss: 2.356662833477322
Validation loss: 2.467052363572821

Epoch: 6| Step: 9
Training loss: 1.4622209592489748
Validation loss: 2.4937350611291036

Epoch: 6| Step: 10
Training loss: 1.4488243532890208
Validation loss: 2.4583788499603774

Epoch: 6| Step: 11
Training loss: 1.038309957711608
Validation loss: 2.45006265369705

Epoch: 6| Step: 12
Training loss: 1.826668313830856
Validation loss: 2.481553137306247

Epoch: 6| Step: 13
Training loss: 1.0700286711657305
Validation loss: 2.4137131043581026

Epoch: 332| Step: 0
Training loss: 1.50848784665177
Validation loss: 2.4590121205131554

Epoch: 6| Step: 1
Training loss: 1.2651462355814864
Validation loss: 2.4675703510495066

Epoch: 6| Step: 2
Training loss: 1.2136820546862979
Validation loss: 2.4533084915454095

Epoch: 6| Step: 3
Training loss: 1.1799646519361187
Validation loss: 2.3881874426693694

Epoch: 6| Step: 4
Training loss: 1.474393351312509
Validation loss: 2.4533950869127747

Epoch: 6| Step: 5
Training loss: 1.1009416927590228
Validation loss: 2.3868046550363218

Epoch: 6| Step: 6
Training loss: 1.61719686164542
Validation loss: 2.460745062973048

Epoch: 6| Step: 7
Training loss: 1.5600550023188315
Validation loss: 2.4642090864489705

Epoch: 6| Step: 8
Training loss: 2.1849531333663257
Validation loss: 2.4280433775259835

Epoch: 6| Step: 9
Training loss: 1.3468240573391954
Validation loss: 2.3970003992329056

Epoch: 6| Step: 10
Training loss: 1.8169218254550918
Validation loss: 2.3861007415285

Epoch: 6| Step: 11
Training loss: 1.6469110589902434
Validation loss: 2.38349327988058

Epoch: 6| Step: 12
Training loss: 1.040427780937337
Validation loss: 2.3769613995496806

Epoch: 6| Step: 13
Training loss: 1.726492073383358
Validation loss: 2.435699384697288

Epoch: 333| Step: 0
Training loss: 1.4115103774194309
Validation loss: 2.399489395198614

Epoch: 6| Step: 1
Training loss: 1.3087292501413255
Validation loss: 2.402603027908008

Epoch: 6| Step: 2
Training loss: 1.4490196728789215
Validation loss: 2.45969332776102

Epoch: 6| Step: 3
Training loss: 1.0093427174605207
Validation loss: 2.4309947405104935

Epoch: 6| Step: 4
Training loss: 1.4497899988625946
Validation loss: 2.439445677204126

Epoch: 6| Step: 5
Training loss: 1.7453611744485613
Validation loss: 2.4602746162198694

Epoch: 6| Step: 6
Training loss: 1.312330961695369
Validation loss: 2.494658264899836

Epoch: 6| Step: 7
Training loss: 1.6501845372205237
Validation loss: 2.495177556386773

Epoch: 6| Step: 8
Training loss: 2.3221880079280917
Validation loss: 2.5039293194278986

Epoch: 6| Step: 9
Training loss: 1.4993558136196228
Validation loss: 2.515509539893141

Epoch: 6| Step: 10
Training loss: 1.9272198053098446
Validation loss: 2.481252012641768

Epoch: 6| Step: 11
Training loss: 1.3502228552934916
Validation loss: 2.439372588392217

Epoch: 6| Step: 12
Training loss: 1.3143675097489262
Validation loss: 2.44619067802751

Epoch: 6| Step: 13
Training loss: 1.0879077190925848
Validation loss: 2.453953498766543

Epoch: 334| Step: 0
Training loss: 1.7125990651010627
Validation loss: 2.4875163925701775

Epoch: 6| Step: 1
Training loss: 1.447633765962657
Validation loss: 2.4293273652549807

Epoch: 6| Step: 2
Training loss: 1.2260555021315087
Validation loss: 2.440384331234568

Epoch: 6| Step: 3
Training loss: 1.2807465005916554
Validation loss: 2.4947443118034616

Epoch: 6| Step: 4
Training loss: 1.201564321528965
Validation loss: 2.381962312469326

Epoch: 6| Step: 5
Training loss: 1.3371372747115513
Validation loss: 2.4209997516161677

Epoch: 6| Step: 6
Training loss: 1.3127703615293824
Validation loss: 2.317710624454956

Epoch: 6| Step: 7
Training loss: 2.40855812246852
Validation loss: 2.48933938189996

Epoch: 6| Step: 8
Training loss: 1.231397974252452
Validation loss: 2.4185264151465864

Epoch: 6| Step: 9
Training loss: 1.7225177043121216
Validation loss: 2.442134919401378

Epoch: 6| Step: 10
Training loss: 1.335418109426845
Validation loss: 2.4247793925051333

Epoch: 6| Step: 11
Training loss: 1.1061461297533646
Validation loss: 2.345484403990224

Epoch: 6| Step: 12
Training loss: 1.3012320622243914
Validation loss: 2.416088022950584

Epoch: 6| Step: 13
Training loss: 1.1679372623753854
Validation loss: 2.4054786331105937

Epoch: 335| Step: 0
Training loss: 1.6547331431778436
Validation loss: 2.4268525232275193

Epoch: 6| Step: 1
Training loss: 1.2698416462492763
Validation loss: 2.3970796151550515

Epoch: 6| Step: 2
Training loss: 1.397857631037503
Validation loss: 2.4332816942219457

Epoch: 6| Step: 3
Training loss: 1.2856730433691552
Validation loss: 2.4248871066480633

Epoch: 6| Step: 4
Training loss: 1.5404811459247747
Validation loss: 2.4545744263880382

Epoch: 6| Step: 5
Training loss: 1.5003854733125157
Validation loss: 2.4404247538809423

Epoch: 6| Step: 6
Training loss: 2.224427923316252
Validation loss: 2.506325625301352

Epoch: 6| Step: 7
Training loss: 1.5619927155035431
Validation loss: 2.4439920960161854

Epoch: 6| Step: 8
Training loss: 1.6421873373944378
Validation loss: 2.545630369263747

Epoch: 6| Step: 9
Training loss: 1.4935457927987235
Validation loss: 2.4641270893565244

Epoch: 6| Step: 10
Training loss: 1.064981591867026
Validation loss: 2.4388635406433896

Epoch: 6| Step: 11
Training loss: 1.296017466686425
Validation loss: 2.405829429229312

Epoch: 6| Step: 12
Training loss: 1.10017079847978
Validation loss: 2.3602398267527813

Epoch: 6| Step: 13
Training loss: 1.3364323374399607
Validation loss: 2.401389226426282

Epoch: 336| Step: 0
Training loss: 1.3294583527726234
Validation loss: 2.368613225663707

Epoch: 6| Step: 1
Training loss: 0.7590334779696551
Validation loss: 2.3972991896148237

Epoch: 6| Step: 2
Training loss: 1.498625363853793
Validation loss: 2.467492230871031

Epoch: 6| Step: 3
Training loss: 1.4591113422100674
Validation loss: 2.4240027241146156

Epoch: 6| Step: 4
Training loss: 1.619162565112584
Validation loss: 2.428906389068884

Epoch: 6| Step: 5
Training loss: 1.7863239500996753
Validation loss: 2.439317236717964

Epoch: 6| Step: 6
Training loss: 1.4036652440396282
Validation loss: 2.3848429501019024

Epoch: 6| Step: 7
Training loss: 1.4780185524030334
Validation loss: 2.4555450002579877

Epoch: 6| Step: 8
Training loss: 1.449214554855156
Validation loss: 2.4167870073267483

Epoch: 6| Step: 9
Training loss: 1.3801263269017794
Validation loss: 2.41370515866351

Epoch: 6| Step: 10
Training loss: 1.0622894976161656
Validation loss: 2.3689339462246393

Epoch: 6| Step: 11
Training loss: 1.202833313696214
Validation loss: 2.4519991046981704

Epoch: 6| Step: 12
Training loss: 2.0385717042462037
Validation loss: 2.4727559608285286

Epoch: 6| Step: 13
Training loss: 1.0247921895827632
Validation loss: 2.478779773368385

Epoch: 337| Step: 0
Training loss: 1.210237509927992
Validation loss: 2.42006999647229

Epoch: 6| Step: 1
Training loss: 1.6304749909570753
Validation loss: 2.4430901052204486

Epoch: 6| Step: 2
Training loss: 1.7356628585274503
Validation loss: 2.4650211525532635

Epoch: 6| Step: 3
Training loss: 1.4637207609492788
Validation loss: 2.466340176122426

Epoch: 6| Step: 4
Training loss: 1.4400688935065031
Validation loss: 2.3835544753646976

Epoch: 6| Step: 5
Training loss: 1.242629638294834
Validation loss: 2.445007910169693

Epoch: 6| Step: 6
Training loss: 1.1896437318414774
Validation loss: 2.3905475975769783

Epoch: 6| Step: 7
Training loss: 1.2638241235443664
Validation loss: 2.4221505369916754

Epoch: 6| Step: 8
Training loss: 1.7289249603596704
Validation loss: 2.4338354156872835

Epoch: 6| Step: 9
Training loss: 2.0657123633765635
Validation loss: 2.458885794733225

Epoch: 6| Step: 10
Training loss: 1.4519525535650106
Validation loss: 2.405396156976961

Epoch: 6| Step: 11
Training loss: 1.2718536731328456
Validation loss: 2.4625109040009687

Epoch: 6| Step: 12
Training loss: 1.250850054667049
Validation loss: 2.393707076811602

Epoch: 6| Step: 13
Training loss: 1.5717637676827094
Validation loss: 2.4419286980896846

Epoch: 338| Step: 0
Training loss: 0.9941689238052347
Validation loss: 2.431259414397759

Epoch: 6| Step: 1
Training loss: 1.4609095932850182
Validation loss: 2.4578669526076515

Epoch: 6| Step: 2
Training loss: 2.1723047284161967
Validation loss: 2.4214787979831565

Epoch: 6| Step: 3
Training loss: 1.308136863089699
Validation loss: 2.4680959121393986

Epoch: 6| Step: 4
Training loss: 1.1390272472562126
Validation loss: 2.492263429153505

Epoch: 6| Step: 5
Training loss: 1.051712927750468
Validation loss: 2.4603639839709315

Epoch: 6| Step: 6
Training loss: 1.361050154603403
Validation loss: 2.41932612371324

Epoch: 6| Step: 7
Training loss: 1.6456166217270491
Validation loss: 2.4024988966882073

Epoch: 6| Step: 8
Training loss: 1.4858702507004116
Validation loss: 2.4783868787830325

Epoch: 6| Step: 9
Training loss: 1.0926039004294477
Validation loss: 2.417812467669327

Epoch: 6| Step: 10
Training loss: 1.2733359267090223
Validation loss: 2.4418438966356137

Epoch: 6| Step: 11
Training loss: 1.6171283803260057
Validation loss: 2.4370361446298454

Epoch: 6| Step: 12
Training loss: 1.7088676020373037
Validation loss: 2.4462253313934914

Epoch: 6| Step: 13
Training loss: 1.8264411931672995
Validation loss: 2.4990277553282967

Epoch: 339| Step: 0
Training loss: 1.316538456014313
Validation loss: 2.4177145459449267

Epoch: 6| Step: 1
Training loss: 1.2167928092484492
Validation loss: 2.4785161183825912

Epoch: 6| Step: 2
Training loss: 1.422575055172013
Validation loss: 2.4321971949710175

Epoch: 6| Step: 3
Training loss: 1.0707159465368652
Validation loss: 2.372623317656798

Epoch: 6| Step: 4
Training loss: 1.6283332676856588
Validation loss: 2.368337647402649

Epoch: 6| Step: 5
Training loss: 0.9116350856334513
Validation loss: 2.38236458487239

Epoch: 6| Step: 6
Training loss: 2.0935632423121464
Validation loss: 2.459509135756099

Epoch: 6| Step: 7
Training loss: 1.462455328234647
Validation loss: 2.394717124380421

Epoch: 6| Step: 8
Training loss: 1.3183645290697863
Validation loss: 2.3816237813251333

Epoch: 6| Step: 9
Training loss: 1.4189841257918523
Validation loss: 2.390066904886482

Epoch: 6| Step: 10
Training loss: 1.852756935865365
Validation loss: 2.4058789586566056

Epoch: 6| Step: 11
Training loss: 1.4930316873855536
Validation loss: 2.4076797995516874

Epoch: 6| Step: 12
Training loss: 1.544730269827586
Validation loss: 2.3893649465244

Epoch: 6| Step: 13
Training loss: 1.627700542394036
Validation loss: 2.4342757282922416

Epoch: 340| Step: 0
Training loss: 1.520485546461087
Validation loss: 2.4522700996758746

Epoch: 6| Step: 1
Training loss: 1.644584310586254
Validation loss: 2.4482001530369213

Epoch: 6| Step: 2
Training loss: 1.5543793799473216
Validation loss: 2.477762970831928

Epoch: 6| Step: 3
Training loss: 1.4721316103771036
Validation loss: 2.436093614341059

Epoch: 6| Step: 4
Training loss: 2.020215979067906
Validation loss: 2.417806870529826

Epoch: 6| Step: 5
Training loss: 1.6078675256030628
Validation loss: 2.470479978754995

Epoch: 6| Step: 6
Training loss: 1.2921444204176842
Validation loss: 2.433133511999665

Epoch: 6| Step: 7
Training loss: 1.2939982853248708
Validation loss: 2.4687044418033763

Epoch: 6| Step: 8
Training loss: 1.3749967054847783
Validation loss: 2.4433942489854714

Epoch: 6| Step: 9
Training loss: 1.1253814050733046
Validation loss: 2.399365623013519

Epoch: 6| Step: 10
Training loss: 1.5661887305621855
Validation loss: 2.4158050405278053

Epoch: 6| Step: 11
Training loss: 1.10781982376411
Validation loss: 2.37647491235642

Epoch: 6| Step: 12
Training loss: 1.1281050640680002
Validation loss: 2.434710354288367

Epoch: 6| Step: 13
Training loss: 0.9954231248637839
Validation loss: 2.3853109869837823

Epoch: 341| Step: 0
Training loss: 1.520324186337006
Validation loss: 2.399910474546527

Epoch: 6| Step: 1
Training loss: 1.5446572637791778
Validation loss: 2.443408921133867

Epoch: 6| Step: 2
Training loss: 1.155226899190757
Validation loss: 2.443062855717392

Epoch: 6| Step: 3
Training loss: 2.1837485707217748
Validation loss: 2.372158213471172

Epoch: 6| Step: 4
Training loss: 1.595167240475258
Validation loss: 2.424953220623693

Epoch: 6| Step: 5
Training loss: 1.3543283023714183
Validation loss: 2.4353905630176373

Epoch: 6| Step: 6
Training loss: 0.9674025362785551
Validation loss: 2.363201785262236

Epoch: 6| Step: 7
Training loss: 1.4578331589129376
Validation loss: 2.492317922793134

Epoch: 6| Step: 8
Training loss: 1.5839285317394998
Validation loss: 2.442592899827422

Epoch: 6| Step: 9
Training loss: 1.483471806452742
Validation loss: 2.4454860579141537

Epoch: 6| Step: 10
Training loss: 1.095141479375164
Validation loss: 2.4808750410570877

Epoch: 6| Step: 11
Training loss: 1.3539045471427233
Validation loss: 2.4241463290521517

Epoch: 6| Step: 12
Training loss: 1.435798882403047
Validation loss: 2.4472029323355464

Epoch: 6| Step: 13
Training loss: 1.2587228170147498
Validation loss: 2.4441500406376067

Epoch: 342| Step: 0
Training loss: 1.4624984480368701
Validation loss: 2.4588253032309515

Epoch: 6| Step: 1
Training loss: 0.9727132389884209
Validation loss: 2.479572854013025

Epoch: 6| Step: 2
Training loss: 1.3428252830900087
Validation loss: 2.422278352586282

Epoch: 6| Step: 3
Training loss: 1.3727525637103728
Validation loss: 2.3872410776482575

Epoch: 6| Step: 4
Training loss: 1.1781418128799706
Validation loss: 2.4202540927388845

Epoch: 6| Step: 5
Training loss: 1.4856537781697619
Validation loss: 2.445851394741202

Epoch: 6| Step: 6
Training loss: 1.6454206585089042
Validation loss: 2.474016790989277

Epoch: 6| Step: 7
Training loss: 1.2517269602720473
Validation loss: 2.3866513453890255

Epoch: 6| Step: 8
Training loss: 0.9096783869295728
Validation loss: 2.435294104728466

Epoch: 6| Step: 9
Training loss: 1.2119767190503874
Validation loss: 2.461157831321877

Epoch: 6| Step: 10
Training loss: 1.8002048322904547
Validation loss: 2.448667006912012

Epoch: 6| Step: 11
Training loss: 1.0894333808562378
Validation loss: 2.4376277905861907

Epoch: 6| Step: 12
Training loss: 1.037459894347319
Validation loss: 2.366982288306269

Epoch: 6| Step: 13
Training loss: 2.695112757261378
Validation loss: 2.4386273961831257

Epoch: 343| Step: 0
Training loss: 1.4919943160186577
Validation loss: 2.424355530719251

Epoch: 6| Step: 1
Training loss: 1.9626646908218002
Validation loss: 2.377881858829656

Epoch: 6| Step: 2
Training loss: 1.1693299185841837
Validation loss: 2.462237035905628

Epoch: 6| Step: 3
Training loss: 1.52534029556455
Validation loss: 2.3698154059276604

Epoch: 6| Step: 4
Training loss: 1.130279866897862
Validation loss: 2.4170503371887886

Epoch: 6| Step: 5
Training loss: 1.236154119169623
Validation loss: 2.458152455314492

Epoch: 6| Step: 6
Training loss: 1.238254101572959
Validation loss: 2.4186158648643845

Epoch: 6| Step: 7
Training loss: 2.2161514754322518
Validation loss: 2.443562362248775

Epoch: 6| Step: 8
Training loss: 1.3537312125384349
Validation loss: 2.4115510205716997

Epoch: 6| Step: 9
Training loss: 0.7122818529230828
Validation loss: 2.4046808274115286

Epoch: 6| Step: 10
Training loss: 1.059247817785641
Validation loss: 2.397296227410949

Epoch: 6| Step: 11
Training loss: 1.2626985223881282
Validation loss: 2.3529263426147526

Epoch: 6| Step: 12
Training loss: 1.5214561685045889
Validation loss: 2.3996616745459525

Epoch: 6| Step: 13
Training loss: 1.24179344404766
Validation loss: 2.3910690711250004

Epoch: 344| Step: 0
Training loss: 1.4219109666907541
Validation loss: 2.4438466969226806

Epoch: 6| Step: 1
Training loss: 1.217989953561826
Validation loss: 2.4110834925420486

Epoch: 6| Step: 2
Training loss: 1.6539497236431444
Validation loss: 2.4517744877288257

Epoch: 6| Step: 3
Training loss: 0.9074656127425665
Validation loss: 2.4063961355972503

Epoch: 6| Step: 4
Training loss: 1.1372217592601728
Validation loss: 2.3782056828338054

Epoch: 6| Step: 5
Training loss: 1.6606962873945568
Validation loss: 2.4199341617721126

Epoch: 6| Step: 6
Training loss: 2.1581621399176827
Validation loss: 2.4260836760781723

Epoch: 6| Step: 7
Training loss: 1.4485904946124502
Validation loss: 2.4386586447985446

Epoch: 6| Step: 8
Training loss: 1.2476452582728483
Validation loss: 2.4696223995742606

Epoch: 6| Step: 9
Training loss: 1.7353965568827499
Validation loss: 2.402647225865157

Epoch: 6| Step: 10
Training loss: 1.5576895861407176
Validation loss: 2.4206118695253753

Epoch: 6| Step: 11
Training loss: 1.0645508887516
Validation loss: 2.4262403742228558

Epoch: 6| Step: 12
Training loss: 1.5446507810457133
Validation loss: 2.4356210464454335

Epoch: 6| Step: 13
Training loss: 1.0597144806694236
Validation loss: 2.4947107742830963

Epoch: 345| Step: 0
Training loss: 1.3546549088056685
Validation loss: 2.423390630142382

Epoch: 6| Step: 1
Training loss: 1.7159848251027485
Validation loss: 2.390174957944554

Epoch: 6| Step: 2
Training loss: 1.8671144606857282
Validation loss: 2.4526516716572266

Epoch: 6| Step: 3
Training loss: 1.234155466379622
Validation loss: 2.5016911288392136

Epoch: 6| Step: 4
Training loss: 1.300128578283071
Validation loss: 2.4481264857477996

Epoch: 6| Step: 5
Training loss: 1.3642537493088875
Validation loss: 2.4673590448171443

Epoch: 6| Step: 6
Training loss: 0.9805708144360193
Validation loss: 2.4927386749568243

Epoch: 6| Step: 7
Training loss: 1.5083137430144742
Validation loss: 2.400071622393374

Epoch: 6| Step: 8
Training loss: 2.0659686889048334
Validation loss: 2.4069860382349306

Epoch: 6| Step: 9
Training loss: 0.8666012130987646
Validation loss: 2.4777541006814063

Epoch: 6| Step: 10
Training loss: 1.2970255109473672
Validation loss: 2.44187253401725

Epoch: 6| Step: 11
Training loss: 1.3598727487888562
Validation loss: 2.4859800797656004

Epoch: 6| Step: 12
Training loss: 0.8890162879987905
Validation loss: 2.4506570830187164

Epoch: 6| Step: 13
Training loss: 2.0042453055177507
Validation loss: 2.413181823813931

Epoch: 346| Step: 0
Training loss: 1.1475907921869433
Validation loss: 2.4375744107028945

Epoch: 6| Step: 1
Training loss: 1.2762216661616508
Validation loss: 2.357231500220736

Epoch: 6| Step: 2
Training loss: 1.566639946987017
Validation loss: 2.3854070601373096

Epoch: 6| Step: 3
Training loss: 1.1750678245773187
Validation loss: 2.4414987822686345

Epoch: 6| Step: 4
Training loss: 1.0186226256143103
Validation loss: 2.3811602833653933

Epoch: 6| Step: 5
Training loss: 1.9212188841286206
Validation loss: 2.4107592197034373

Epoch: 6| Step: 6
Training loss: 1.254513792409904
Validation loss: 2.368391036098466

Epoch: 6| Step: 7
Training loss: 1.2774639947972055
Validation loss: 2.3860032522462014

Epoch: 6| Step: 8
Training loss: 2.0959630629000263
Validation loss: 2.392204772334309

Epoch: 6| Step: 9
Training loss: 1.0083484850814364
Validation loss: 2.416911653428452

Epoch: 6| Step: 10
Training loss: 1.2525163594622308
Validation loss: 2.39992650532223

Epoch: 6| Step: 11
Training loss: 1.1474284195857798
Validation loss: 2.4134036028221804

Epoch: 6| Step: 12
Training loss: 1.5259678880305092
Validation loss: 2.4739133879762183

Epoch: 6| Step: 13
Training loss: 1.5888548078564664
Validation loss: 2.462792772572839

Epoch: 347| Step: 0
Training loss: 1.1605850095335295
Validation loss: 2.521757364478118

Epoch: 6| Step: 1
Training loss: 1.3407654997644374
Validation loss: 2.4440979061323462

Epoch: 6| Step: 2
Training loss: 1.1859649474092644
Validation loss: 2.4700232540598823

Epoch: 6| Step: 3
Training loss: 1.787882586530501
Validation loss: 2.450308501814968

Epoch: 6| Step: 4
Training loss: 1.2714132122042787
Validation loss: 2.4195584272022326

Epoch: 6| Step: 5
Training loss: 1.2530649755851968
Validation loss: 2.4032523739836873

Epoch: 6| Step: 6
Training loss: 1.5526993657609867
Validation loss: 2.3467096140060097

Epoch: 6| Step: 7
Training loss: 1.54086260404511
Validation loss: 2.4061041400086403

Epoch: 6| Step: 8
Training loss: 1.0169244522796603
Validation loss: 2.40622285269041

Epoch: 6| Step: 9
Training loss: 1.1283014914970273
Validation loss: 2.421008072580877

Epoch: 6| Step: 10
Training loss: 1.4593294647105106
Validation loss: 2.407194579966837

Epoch: 6| Step: 11
Training loss: 1.5123199134995253
Validation loss: 2.399112298785241

Epoch: 6| Step: 12
Training loss: 1.0820785126537709
Validation loss: 2.3787877179094035

Epoch: 6| Step: 13
Training loss: 2.7719673666030866
Validation loss: 2.386709014624062

Epoch: 348| Step: 0
Training loss: 0.9603440848263638
Validation loss: 2.4916139047306847

Epoch: 6| Step: 1
Training loss: 1.6068269873337706
Validation loss: 2.428788042537762

Epoch: 6| Step: 2
Training loss: 1.2785334748147676
Validation loss: 2.451640383494737

Epoch: 6| Step: 3
Training loss: 1.1692562088196938
Validation loss: 2.4307198221587036

Epoch: 6| Step: 4
Training loss: 1.623316993683366
Validation loss: 2.380369671043137

Epoch: 6| Step: 5
Training loss: 1.5914979618933136
Validation loss: 2.448829998545973

Epoch: 6| Step: 6
Training loss: 1.345966462832724
Validation loss: 2.3534778200984494

Epoch: 6| Step: 7
Training loss: 1.0080855834974507
Validation loss: 2.4285279013980596

Epoch: 6| Step: 8
Training loss: 1.4260426738875709
Validation loss: 2.4411453132565217

Epoch: 6| Step: 9
Training loss: 0.7407167418111148
Validation loss: 2.448592128695633

Epoch: 6| Step: 10
Training loss: 1.6023634977718693
Validation loss: 2.4724068703096997

Epoch: 6| Step: 11
Training loss: 2.183797918884644
Validation loss: 2.4360447865827246

Epoch: 6| Step: 12
Training loss: 1.4667138128216846
Validation loss: 2.4116106222887197

Epoch: 6| Step: 13
Training loss: 1.518537731014655
Validation loss: 2.4192064904292403

Epoch: 349| Step: 0
Training loss: 0.8002158797574586
Validation loss: 2.4535502455851503

Epoch: 6| Step: 1
Training loss: 0.8697023441036162
Validation loss: 2.433740254615597

Epoch: 6| Step: 2
Training loss: 1.2350257413706585
Validation loss: 2.5065818999950733

Epoch: 6| Step: 3
Training loss: 1.2926232374751232
Validation loss: 2.3711755461429544

Epoch: 6| Step: 4
Training loss: 1.4147251325876509
Validation loss: 2.4649174855397837

Epoch: 6| Step: 5
Training loss: 1.4238159011713794
Validation loss: 2.4524706523058746

Epoch: 6| Step: 6
Training loss: 1.6565201736912072
Validation loss: 2.399794663512065

Epoch: 6| Step: 7
Training loss: 1.4682153580922783
Validation loss: 2.411894398170396

Epoch: 6| Step: 8
Training loss: 1.0133264206558488
Validation loss: 2.4401547815242446

Epoch: 6| Step: 9
Training loss: 2.2860299812012905
Validation loss: 2.3747147230651

Epoch: 6| Step: 10
Training loss: 1.6770228341446862
Validation loss: 2.444775302682473

Epoch: 6| Step: 11
Training loss: 1.4206163473742663
Validation loss: 2.502030589824176

Epoch: 6| Step: 12
Training loss: 1.5855426766658818
Validation loss: 2.4129110414279062

Epoch: 6| Step: 13
Training loss: 1.1701961953568925
Validation loss: 2.455887796298225

Epoch: 350| Step: 0
Training loss: 1.3644615245159757
Validation loss: 2.402160053781663

Epoch: 6| Step: 1
Training loss: 0.8873601601801658
Validation loss: 2.4660185010813307

Epoch: 6| Step: 2
Training loss: 0.987026397997507
Validation loss: 2.405727611570968

Epoch: 6| Step: 3
Training loss: 1.3969586187335394
Validation loss: 2.4148014555911135

Epoch: 6| Step: 4
Training loss: 1.4527493883563927
Validation loss: 2.4020519074987887

Epoch: 6| Step: 5
Training loss: 1.3361345558506432
Validation loss: 2.396748488826535

Epoch: 6| Step: 6
Training loss: 1.29090772400062
Validation loss: 2.4428355170335547

Epoch: 6| Step: 7
Training loss: 2.361818576612219
Validation loss: 2.4058301836706963

Epoch: 6| Step: 8
Training loss: 1.2037717393791707
Validation loss: 2.393134293813733

Epoch: 6| Step: 9
Training loss: 1.3857711778206538
Validation loss: 2.4355634101340398

Epoch: 6| Step: 10
Training loss: 1.3405068316543467
Validation loss: 2.4084571956052296

Epoch: 6| Step: 11
Training loss: 1.6364253470797077
Validation loss: 2.461541145853621

Epoch: 6| Step: 12
Training loss: 1.3529672984494203
Validation loss: 2.3515319865846513

Epoch: 6| Step: 13
Training loss: 1.2748678868231187
Validation loss: 2.4366902904118075

Epoch: 351| Step: 0
Training loss: 0.6714409601668692
Validation loss: 2.4220516980587785

Epoch: 6| Step: 1
Training loss: 2.165845006030885
Validation loss: 2.4275902150990913

Epoch: 6| Step: 2
Training loss: 1.4065790427217635
Validation loss: 2.4382868118212975

Epoch: 6| Step: 3
Training loss: 1.076641776345384
Validation loss: 2.4060788604472805

Epoch: 6| Step: 4
Training loss: 1.1992604997058751
Validation loss: 2.443223260129436

Epoch: 6| Step: 5
Training loss: 1.7084529028505717
Validation loss: 2.4021771762476294

Epoch: 6| Step: 6
Training loss: 1.5932467544979916
Validation loss: 2.44544035408164

Epoch: 6| Step: 7
Training loss: 1.3016047806300908
Validation loss: 2.353715770845198

Epoch: 6| Step: 8
Training loss: 1.1260356374762102
Validation loss: 2.4632391543677143

Epoch: 6| Step: 9
Training loss: 1.3512199717527855
Validation loss: 2.398345631255606

Epoch: 6| Step: 10
Training loss: 1.1921294471935364
Validation loss: 2.385304347097421

Epoch: 6| Step: 11
Training loss: 1.129076670946545
Validation loss: 2.414343371327937

Epoch: 6| Step: 12
Training loss: 1.7022050245183762
Validation loss: 2.4152334614770243

Epoch: 6| Step: 13
Training loss: 1.5365954925179048
Validation loss: 2.4392772555237037

Epoch: 352| Step: 0
Training loss: 1.2031384752187746
Validation loss: 2.373501077425433

Epoch: 6| Step: 1
Training loss: 1.5059850024354242
Validation loss: 2.3815190546594107

Epoch: 6| Step: 2
Training loss: 1.225277756322688
Validation loss: 2.4148432550313577

Epoch: 6| Step: 3
Training loss: 0.7827793411267548
Validation loss: 2.4815750694782257

Epoch: 6| Step: 4
Training loss: 1.4957939624475298
Validation loss: 2.460723067038783

Epoch: 6| Step: 5
Training loss: 1.246651264663316
Validation loss: 2.296691375997896

Epoch: 6| Step: 6
Training loss: 1.2414260065656457
Validation loss: 2.40732343617271

Epoch: 6| Step: 7
Training loss: 1.468052962457361
Validation loss: 2.35196000819702

Epoch: 6| Step: 8
Training loss: 2.2293580825715615
Validation loss: 2.4611708288724503

Epoch: 6| Step: 9
Training loss: 1.082030588969225
Validation loss: 2.476331497215135

Epoch: 6| Step: 10
Training loss: 1.2620031550015822
Validation loss: 2.461771789069589

Epoch: 6| Step: 11
Training loss: 1.267415087637686
Validation loss: 2.3878827609276

Epoch: 6| Step: 12
Training loss: 1.2374977978773465
Validation loss: 2.3511872999812957

Epoch: 6| Step: 13
Training loss: 1.5640772678771777
Validation loss: 2.3925900603769534

Epoch: 353| Step: 0
Training loss: 1.070443305494226
Validation loss: 2.42329968305429

Epoch: 6| Step: 1
Training loss: 1.4616291224588653
Validation loss: 2.3938811666229873

Epoch: 6| Step: 2
Training loss: 1.4032456411990266
Validation loss: 2.425239621810728

Epoch: 6| Step: 3
Training loss: 1.6600509789693507
Validation loss: 2.4126215557334514

Epoch: 6| Step: 4
Training loss: 1.0160535055136561
Validation loss: 2.4149826690290426

Epoch: 6| Step: 5
Training loss: 1.2839422086146464
Validation loss: 2.4335086112150215

Epoch: 6| Step: 6
Training loss: 2.147848263479837
Validation loss: 2.4835303757858993

Epoch: 6| Step: 7
Training loss: 1.2095294272228325
Validation loss: 2.437022993113083

Epoch: 6| Step: 8
Training loss: 1.2893767002850784
Validation loss: 2.4014711201255534

Epoch: 6| Step: 9
Training loss: 1.276624984799479
Validation loss: 2.356328105026406

Epoch: 6| Step: 10
Training loss: 1.3680454287124595
Validation loss: 2.433655801986454

Epoch: 6| Step: 11
Training loss: 1.757568478070952
Validation loss: 2.4696454165905175

Epoch: 6| Step: 12
Training loss: 1.1850472266206478
Validation loss: 2.4294856596677095

Epoch: 6| Step: 13
Training loss: 1.2925557286480016
Validation loss: 2.3839831008705157

Epoch: 354| Step: 0
Training loss: 1.0348334618894628
Validation loss: 2.4176364181061794

Epoch: 6| Step: 1
Training loss: 1.3958910128314725
Validation loss: 2.3752427627419355

Epoch: 6| Step: 2
Training loss: 1.2686300512279622
Validation loss: 2.4130294983837253

Epoch: 6| Step: 3
Training loss: 1.4361489622799963
Validation loss: 2.4446722232462577

Epoch: 6| Step: 4
Training loss: 0.9324557658997287
Validation loss: 2.535152431570927

Epoch: 6| Step: 5
Training loss: 1.0771796463208902
Validation loss: 2.4671727837197808

Epoch: 6| Step: 6
Training loss: 1.6208723905249194
Validation loss: 2.5194202334725286

Epoch: 6| Step: 7
Training loss: 1.7051675430045536
Validation loss: 2.470508501074687

Epoch: 6| Step: 8
Training loss: 1.2776084882204617
Validation loss: 2.4225014285632156

Epoch: 6| Step: 9
Training loss: 1.2889965618493133
Validation loss: 2.419150731388254

Epoch: 6| Step: 10
Training loss: 2.0960635029149173
Validation loss: 2.4070926368668193

Epoch: 6| Step: 11
Training loss: 1.198541704842372
Validation loss: 2.4045801653332144

Epoch: 6| Step: 12
Training loss: 1.371513541532691
Validation loss: 2.3541539302840397

Epoch: 6| Step: 13
Training loss: 1.1649517784453163
Validation loss: 2.4502453607280414

Epoch: 355| Step: 0
Training loss: 1.7926289687320558
Validation loss: 2.437269914620218

Epoch: 6| Step: 1
Training loss: 1.1663996640713787
Validation loss: 2.365827352352279

Epoch: 6| Step: 2
Training loss: 1.3641992664267515
Validation loss: 2.354600385815801

Epoch: 6| Step: 3
Training loss: 1.7018553874958737
Validation loss: 2.377154407759983

Epoch: 6| Step: 4
Training loss: 1.207278575063735
Validation loss: 2.4281778421650535

Epoch: 6| Step: 5
Training loss: 1.3291718788802136
Validation loss: 2.418243872312202

Epoch: 6| Step: 6
Training loss: 0.8273592953756921
Validation loss: 2.4294647240226865

Epoch: 6| Step: 7
Training loss: 1.526119043604022
Validation loss: 2.4519150969487233

Epoch: 6| Step: 8
Training loss: 1.0001690244879442
Validation loss: 2.404378934624287

Epoch: 6| Step: 9
Training loss: 2.100503534166486
Validation loss: 2.419457115247

Epoch: 6| Step: 10
Training loss: 1.5693085151180275
Validation loss: 2.40140997981272

Epoch: 6| Step: 11
Training loss: 1.4503520636822356
Validation loss: 2.4392379210906023

Epoch: 6| Step: 12
Training loss: 1.8018138514955657
Validation loss: 2.4223305381298945

Epoch: 6| Step: 13
Training loss: 1.0977499165058213
Validation loss: 2.3654074021441436

Epoch: 356| Step: 0
Training loss: 1.1637480650331533
Validation loss: 2.430836177355739

Epoch: 6| Step: 1
Training loss: 1.6342556794995582
Validation loss: 2.378159898739541

Epoch: 6| Step: 2
Training loss: 1.150171748065839
Validation loss: 2.419364729659395

Epoch: 6| Step: 3
Training loss: 1.1463941704325655
Validation loss: 2.4176231000849064

Epoch: 6| Step: 4
Training loss: 2.3600616466423388
Validation loss: 2.4735719141744834

Epoch: 6| Step: 5
Training loss: 1.638627643920339
Validation loss: 2.4595721411738873

Epoch: 6| Step: 6
Training loss: 1.4095006459597663
Validation loss: 2.4023434159846975

Epoch: 6| Step: 7
Training loss: 1.3819791362418654
Validation loss: 2.3954973695952773

Epoch: 6| Step: 8
Training loss: 1.2882850845862808
Validation loss: 2.4509025221463916

Epoch: 6| Step: 9
Training loss: 1.2428389466493033
Validation loss: 2.4169549496026637

Epoch: 6| Step: 10
Training loss: 1.1497588049843224
Validation loss: 2.431056685891718

Epoch: 6| Step: 11
Training loss: 1.134465452008631
Validation loss: 2.448166448084716

Epoch: 6| Step: 12
Training loss: 1.376305307356259
Validation loss: 2.3989799078313805

Epoch: 6| Step: 13
Training loss: 1.130244376081023
Validation loss: 2.3956379211972294

Epoch: 357| Step: 0
Training loss: 1.1609923564123708
Validation loss: 2.448630923391769

Epoch: 6| Step: 1
Training loss: 1.3154532947984903
Validation loss: 2.4161946762578506

Epoch: 6| Step: 2
Training loss: 1.797688242110785
Validation loss: 2.4255144425881747

Epoch: 6| Step: 3
Training loss: 1.2292810914826726
Validation loss: 2.3717787507064703

Epoch: 6| Step: 4
Training loss: 2.263359778993667
Validation loss: 2.4107517343045215

Epoch: 6| Step: 5
Training loss: 1.0047044957267388
Validation loss: 2.407249442354571

Epoch: 6| Step: 6
Training loss: 1.1415525871324732
Validation loss: 2.4146354450174163

Epoch: 6| Step: 7
Training loss: 1.5084543393880223
Validation loss: 2.390292018000673

Epoch: 6| Step: 8
Training loss: 1.3784496642903274
Validation loss: 2.508686561339312

Epoch: 6| Step: 9
Training loss: 1.2760197488368634
Validation loss: 2.4534506298525147

Epoch: 6| Step: 10
Training loss: 1.209456886062407
Validation loss: 2.4542553718417013

Epoch: 6| Step: 11
Training loss: 1.3347729967118602
Validation loss: 2.4659431922532487

Epoch: 6| Step: 12
Training loss: 1.0871168360452397
Validation loss: 2.4443467674739625

Epoch: 6| Step: 13
Training loss: 0.7806713631684402
Validation loss: 2.427885060880884

Epoch: 358| Step: 0
Training loss: 0.7362108213042352
Validation loss: 2.458602161284183

Epoch: 6| Step: 1
Training loss: 1.4013408591957306
Validation loss: 2.4890853569840834

Epoch: 6| Step: 2
Training loss: 1.1260112879510853
Validation loss: 2.428660707288189

Epoch: 6| Step: 3
Training loss: 1.2497035628724726
Validation loss: 2.485393063532577

Epoch: 6| Step: 4
Training loss: 1.2883111787168453
Validation loss: 2.4971373524569778

Epoch: 6| Step: 5
Training loss: 1.4914774378656734
Validation loss: 2.4921533293774263

Epoch: 6| Step: 6
Training loss: 1.14924997667201
Validation loss: 2.4563673214590014

Epoch: 6| Step: 7
Training loss: 1.2302219688355394
Validation loss: 2.419999699704016

Epoch: 6| Step: 8
Training loss: 1.1413766135167904
Validation loss: 2.447155492219352

Epoch: 6| Step: 9
Training loss: 0.9544259869758724
Validation loss: 2.4400682321385623

Epoch: 6| Step: 10
Training loss: 1.6331350199658081
Validation loss: 2.413391471352985

Epoch: 6| Step: 11
Training loss: 1.1921367469473632
Validation loss: 2.418793605462151

Epoch: 6| Step: 12
Training loss: 2.530294638353143
Validation loss: 2.4033406865335123

Epoch: 6| Step: 13
Training loss: 0.9144490394680267
Validation loss: 2.3640781969083755

Epoch: 359| Step: 0
Training loss: 1.1879597827834343
Validation loss: 2.356167625601308

Epoch: 6| Step: 1
Training loss: 1.0928415067606674
Validation loss: 2.384970845827908

Epoch: 6| Step: 2
Training loss: 2.15160832242021
Validation loss: 2.349808163603035

Epoch: 6| Step: 3
Training loss: 1.2358293295495548
Validation loss: 2.390461429708051

Epoch: 6| Step: 4
Training loss: 1.31915747327045
Validation loss: 2.4445257477121314

Epoch: 6| Step: 5
Training loss: 1.2613593850466405
Validation loss: 2.4192203730299666

Epoch: 6| Step: 6
Training loss: 1.3702440373054867
Validation loss: 2.4307592712286215

Epoch: 6| Step: 7
Training loss: 1.7773788951710638
Validation loss: 2.4781768879466957

Epoch: 6| Step: 8
Training loss: 1.293261814614321
Validation loss: 2.3789205860036207

Epoch: 6| Step: 9
Training loss: 1.5456648437448666
Validation loss: 2.453776133955007

Epoch: 6| Step: 10
Training loss: 1.342320546848948
Validation loss: 2.4550322029262794

Epoch: 6| Step: 11
Training loss: 1.1931395382842183
Validation loss: 2.4254138645806242

Epoch: 6| Step: 12
Training loss: 1.2494108719134265
Validation loss: 2.352187457684119

Epoch: 6| Step: 13
Training loss: 1.3851826931515847
Validation loss: 2.4239679539993944

Epoch: 360| Step: 0
Training loss: 0.9712948444377693
Validation loss: 2.3964447083188904

Epoch: 6| Step: 1
Training loss: 1.3293128591916594
Validation loss: 2.378194417993139

Epoch: 6| Step: 2
Training loss: 1.0595580491441823
Validation loss: 2.4424910686287347

Epoch: 6| Step: 3
Training loss: 1.5896684329683732
Validation loss: 2.4063806624855095

Epoch: 6| Step: 4
Training loss: 1.113102520432436
Validation loss: 2.494468798748675

Epoch: 6| Step: 5
Training loss: 0.9366942121713606
Validation loss: 2.4777885919690514

Epoch: 6| Step: 6
Training loss: 1.5237708093913673
Validation loss: 2.4750122174421043

Epoch: 6| Step: 7
Training loss: 1.003046758814993
Validation loss: 2.4607842208336193

Epoch: 6| Step: 8
Training loss: 2.0558077583015923
Validation loss: 2.4062347624708735

Epoch: 6| Step: 9
Training loss: 1.2982071618281779
Validation loss: 2.4748579215889137

Epoch: 6| Step: 10
Training loss: 0.8462813517230005
Validation loss: 2.4363700292154613

Epoch: 6| Step: 11
Training loss: 1.1620607510179477
Validation loss: 2.352955881331602

Epoch: 6| Step: 12
Training loss: 1.7298498144724856
Validation loss: 2.4115832892271722

Epoch: 6| Step: 13
Training loss: 1.5998478340270414
Validation loss: 2.4112774050553805

Epoch: 361| Step: 0
Training loss: 1.3663860042548723
Validation loss: 2.3932576550331732

Epoch: 6| Step: 1
Training loss: 1.209492467256754
Validation loss: 2.4231551529952573

Epoch: 6| Step: 2
Training loss: 1.4626409218213894
Validation loss: 2.4237293756331364

Epoch: 6| Step: 3
Training loss: 1.4625771852649918
Validation loss: 2.4248541835174247

Epoch: 6| Step: 4
Training loss: 1.1696630328486053
Validation loss: 2.41604832902411

Epoch: 6| Step: 5
Training loss: 1.3051458227598947
Validation loss: 2.3979313685032757

Epoch: 6| Step: 6
Training loss: 1.309390471738027
Validation loss: 2.39341700841942

Epoch: 6| Step: 7
Training loss: 1.3085217356438077
Validation loss: 2.4171470335109184

Epoch: 6| Step: 8
Training loss: 1.2105779790929045
Validation loss: 2.4697400671826584

Epoch: 6| Step: 9
Training loss: 2.2893808813954215
Validation loss: 2.421919747057315

Epoch: 6| Step: 10
Training loss: 1.287256536334185
Validation loss: 2.413942986055506

Epoch: 6| Step: 11
Training loss: 1.1227429318661053
Validation loss: 2.4157447840535022

Epoch: 6| Step: 12
Training loss: 1.2042480280667776
Validation loss: 2.417150939189341

Epoch: 6| Step: 13
Training loss: 1.0381998482304466
Validation loss: 2.455103729130458

Epoch: 362| Step: 0
Training loss: 1.7293439873774294
Validation loss: 2.4750286277142046

Epoch: 6| Step: 1
Training loss: 1.4126287114737908
Validation loss: 2.3637856862000026

Epoch: 6| Step: 2
Training loss: 1.288643508788571
Validation loss: 2.416191759501005

Epoch: 6| Step: 3
Training loss: 0.9535299285228417
Validation loss: 2.415320268180283

Epoch: 6| Step: 4
Training loss: 1.7084558334469366
Validation loss: 2.3968325364189194

Epoch: 6| Step: 5
Training loss: 1.20546786591948
Validation loss: 2.373614151376746

Epoch: 6| Step: 6
Training loss: 0.914818605880444
Validation loss: 2.4227753372569425

Epoch: 6| Step: 7
Training loss: 0.968605122961753
Validation loss: 2.458577377722736

Epoch: 6| Step: 8
Training loss: 1.5446096459243257
Validation loss: 2.4746726682966425

Epoch: 6| Step: 9
Training loss: 1.031464236576511
Validation loss: 2.3704610455043786

Epoch: 6| Step: 10
Training loss: 1.3419647333909257
Validation loss: 2.42085045755208

Epoch: 6| Step: 11
Training loss: 1.2385481297116077
Validation loss: 2.432417194380376

Epoch: 6| Step: 12
Training loss: 1.4179988469064002
Validation loss: 2.4266885958154805

Epoch: 6| Step: 13
Training loss: 2.6111161139510184
Validation loss: 2.4009022187179023

Epoch: 363| Step: 0
Training loss: 1.3222844673290512
Validation loss: 2.454175743006714

Epoch: 6| Step: 1
Training loss: 1.1685073274212108
Validation loss: 2.4822884980108433

Epoch: 6| Step: 2
Training loss: 1.1423735084878752
Validation loss: 2.4315171251045853

Epoch: 6| Step: 3
Training loss: 1.313509779726351
Validation loss: 2.574168973903298

Epoch: 6| Step: 4
Training loss: 1.0187895550684054
Validation loss: 2.387117810920183

Epoch: 6| Step: 5
Training loss: 1.017714829881302
Validation loss: 2.4600003772328125

Epoch: 6| Step: 6
Training loss: 2.192953885812534
Validation loss: 2.4240960380982144

Epoch: 6| Step: 7
Training loss: 1.5933764150745946
Validation loss: 2.3896961347282506

Epoch: 6| Step: 8
Training loss: 1.1256727220584961
Validation loss: 2.4530223968411655

Epoch: 6| Step: 9
Training loss: 0.8832838774877688
Validation loss: 2.3762777115800757

Epoch: 6| Step: 10
Training loss: 1.1016860784377662
Validation loss: 2.414033710061024

Epoch: 6| Step: 11
Training loss: 1.3231897547845313
Validation loss: 2.3609952784417296

Epoch: 6| Step: 12
Training loss: 1.5864969403718
Validation loss: 2.378654957714662

Epoch: 6| Step: 13
Training loss: 1.1158732439918073
Validation loss: 2.434007755503588

Epoch: 364| Step: 0
Training loss: 1.3879893754420554
Validation loss: 2.37781921117959

Epoch: 6| Step: 1
Training loss: 1.0598792684824296
Validation loss: 2.372818876307755

Epoch: 6| Step: 2
Training loss: 0.9648877956205645
Validation loss: 2.359477656939316

Epoch: 6| Step: 3
Training loss: 1.2951696742776435
Validation loss: 2.4458579095634776

Epoch: 6| Step: 4
Training loss: 1.9464239292914354
Validation loss: 2.406539855852458

Epoch: 6| Step: 5
Training loss: 1.6738907970326573
Validation loss: 2.4384482395376725

Epoch: 6| Step: 6
Training loss: 1.200918676470529
Validation loss: 2.4552563595021004

Epoch: 6| Step: 7
Training loss: 1.358994792515628
Validation loss: 2.384197787950747

Epoch: 6| Step: 8
Training loss: 1.1130526659347573
Validation loss: 2.4403634575727313

Epoch: 6| Step: 9
Training loss: 1.289870038102561
Validation loss: 2.4048633050325563

Epoch: 6| Step: 10
Training loss: 1.3928658507846925
Validation loss: 2.4239652739850195

Epoch: 6| Step: 11
Training loss: 1.216742696520313
Validation loss: 2.346544826679405

Epoch: 6| Step: 12
Training loss: 1.1503294845939664
Validation loss: 2.4779470154105465

Epoch: 6| Step: 13
Training loss: 1.68876812228426
Validation loss: 2.458961747157006

Epoch: 365| Step: 0
Training loss: 1.7432952916946687
Validation loss: 2.426239412688514

Epoch: 6| Step: 1
Training loss: 1.3859633416451371
Validation loss: 2.4333807575961006

Epoch: 6| Step: 2
Training loss: 1.3469433654286438
Validation loss: 2.3874138596482255

Epoch: 6| Step: 3
Training loss: 1.96034821550601
Validation loss: 2.3701890242907893

Epoch: 6| Step: 4
Training loss: 1.3077419868155187
Validation loss: 2.4173616916934804

Epoch: 6| Step: 5
Training loss: 1.2232313662103182
Validation loss: 2.3990254831981144

Epoch: 6| Step: 6
Training loss: 1.31671392541085
Validation loss: 2.464207461941459

Epoch: 6| Step: 7
Training loss: 1.2154103518637907
Validation loss: 2.3785613009758513

Epoch: 6| Step: 8
Training loss: 1.2750219305807702
Validation loss: 2.408623315358159

Epoch: 6| Step: 9
Training loss: 1.225948495924949
Validation loss: 2.45666676283526

Epoch: 6| Step: 10
Training loss: 1.318658458551743
Validation loss: 2.392045546643869

Epoch: 6| Step: 11
Training loss: 1.2345735414399714
Validation loss: 2.5062839287575702

Epoch: 6| Step: 12
Training loss: 1.5281909826968445
Validation loss: 2.4646911974317036

Epoch: 6| Step: 13
Training loss: 1.20897352863925
Validation loss: 2.4170777378249118

Epoch: 366| Step: 0
Training loss: 0.9566823518001095
Validation loss: 2.406370236935639

Epoch: 6| Step: 1
Training loss: 2.0690392375560767
Validation loss: 2.450288244196332

Epoch: 6| Step: 2
Training loss: 1.702728505309337
Validation loss: 2.444581299209286

Epoch: 6| Step: 3
Training loss: 1.199539092081624
Validation loss: 2.3989106270417535

Epoch: 6| Step: 4
Training loss: 1.3585119028647559
Validation loss: 2.4333049369916098

Epoch: 6| Step: 5
Training loss: 0.8779620036286729
Validation loss: 2.3909827311955443

Epoch: 6| Step: 6
Training loss: 1.303129030582772
Validation loss: 2.3993143831099792

Epoch: 6| Step: 7
Training loss: 1.0915390556432265
Validation loss: 2.347767896701685

Epoch: 6| Step: 8
Training loss: 1.4967208623667108
Validation loss: 2.4596041112694307

Epoch: 6| Step: 9
Training loss: 1.3008851705743532
Validation loss: 2.460499754929338

Epoch: 6| Step: 10
Training loss: 1.2031783054977998
Validation loss: 2.4150985776056055

Epoch: 6| Step: 11
Training loss: 1.2211517730223944
Validation loss: 2.4131857884961185

Epoch: 6| Step: 12
Training loss: 1.116780880643053
Validation loss: 2.3952655998783112

Epoch: 6| Step: 13
Training loss: 0.6658218415103722
Validation loss: 2.376794362824285

Epoch: 367| Step: 0
Training loss: 1.1094018637399954
Validation loss: 2.402876265003851

Epoch: 6| Step: 1
Training loss: 2.1364893258343924
Validation loss: 2.487980945833307

Epoch: 6| Step: 2
Training loss: 1.097025625640704
Validation loss: 2.497831829796279

Epoch: 6| Step: 3
Training loss: 1.3267347801317406
Validation loss: 2.4272110157385787

Epoch: 6| Step: 4
Training loss: 1.3682282764251372
Validation loss: 2.4620192273375805

Epoch: 6| Step: 5
Training loss: 1.3808332168281305
Validation loss: 2.3869921836095256

Epoch: 6| Step: 6
Training loss: 1.2895919637232063
Validation loss: 2.514867829786735

Epoch: 6| Step: 7
Training loss: 1.0665858190911734
Validation loss: 2.4736087842712786

Epoch: 6| Step: 8
Training loss: 1.4035566180108867
Validation loss: 2.400578419695642

Epoch: 6| Step: 9
Training loss: 1.1619014265431693
Validation loss: 2.38436865838731

Epoch: 6| Step: 10
Training loss: 1.0994291818527575
Validation loss: 2.4116206573735814

Epoch: 6| Step: 11
Training loss: 1.4404349013411994
Validation loss: 2.371333415294461

Epoch: 6| Step: 12
Training loss: 1.2199414615970352
Validation loss: 2.460452223703332

Epoch: 6| Step: 13
Training loss: 1.129895314878566
Validation loss: 2.3655863879543215

Epoch: 368| Step: 0
Training loss: 1.0705160796638449
Validation loss: 2.4712150689581844

Epoch: 6| Step: 1
Training loss: 1.277176125636553
Validation loss: 2.459065007412818

Epoch: 6| Step: 2
Training loss: 1.0107748569976878
Validation loss: 2.377011437743568

Epoch: 6| Step: 3
Training loss: 1.3450678196368417
Validation loss: 2.3801772622996866

Epoch: 6| Step: 4
Training loss: 1.1112188677723218
Validation loss: 2.389609367557146

Epoch: 6| Step: 5
Training loss: 1.5639858810148493
Validation loss: 2.391902802192306

Epoch: 6| Step: 6
Training loss: 1.2114949573722051
Validation loss: 2.427967227640283

Epoch: 6| Step: 7
Training loss: 1.381738795448125
Validation loss: 2.3588427528893496

Epoch: 6| Step: 8
Training loss: 1.234047278829344
Validation loss: 2.3859352783624295

Epoch: 6| Step: 9
Training loss: 1.1397149623096556
Validation loss: 2.394490281183335

Epoch: 6| Step: 10
Training loss: 2.248572638548205
Validation loss: 2.367803668250702

Epoch: 6| Step: 11
Training loss: 1.1407543788326775
Validation loss: 2.395246350546588

Epoch: 6| Step: 12
Training loss: 1.463510379479461
Validation loss: 2.3937576940260716

Epoch: 6| Step: 13
Training loss: 1.430365729880236
Validation loss: 2.4209958092605968

Epoch: 369| Step: 0
Training loss: 1.0486445488275646
Validation loss: 2.4190301774894043

Epoch: 6| Step: 1
Training loss: 1.6565851556207052
Validation loss: 2.3919518408117417

Epoch: 6| Step: 2
Training loss: 1.4346141042445995
Validation loss: 2.450043240555482

Epoch: 6| Step: 3
Training loss: 0.8861967054088444
Validation loss: 2.484460330941596

Epoch: 6| Step: 4
Training loss: 1.3044289886751106
Validation loss: 2.461827154471844

Epoch: 6| Step: 5
Training loss: 1.2299653976504459
Validation loss: 2.429287844388373

Epoch: 6| Step: 6
Training loss: 1.255405658496832
Validation loss: 2.4032477059336577

Epoch: 6| Step: 7
Training loss: 2.078648551442749
Validation loss: 2.3637529835775677

Epoch: 6| Step: 8
Training loss: 1.3168535689396577
Validation loss: 2.3292852894967813

Epoch: 6| Step: 9
Training loss: 1.029048650876017
Validation loss: 2.4671930216789457

Epoch: 6| Step: 10
Training loss: 1.2670810000895616
Validation loss: 2.462569765266911

Epoch: 6| Step: 11
Training loss: 1.1624510190755901
Validation loss: 2.4191033144748357

Epoch: 6| Step: 12
Training loss: 1.2622322478440957
Validation loss: 2.399401505573758

Epoch: 6| Step: 13
Training loss: 1.2846852746868602
Validation loss: 2.407155990772543

Epoch: 370| Step: 0
Training loss: 1.4847836383709405
Validation loss: 2.4011073181033225

Epoch: 6| Step: 1
Training loss: 1.196588819667122
Validation loss: 2.4378842938823744

Epoch: 6| Step: 2
Training loss: 1.3963834712780878
Validation loss: 2.3961176439170115

Epoch: 6| Step: 3
Training loss: 1.0582527089885208
Validation loss: 2.4776616238754974

Epoch: 6| Step: 4
Training loss: 1.3664609886097494
Validation loss: 2.446862539472525

Epoch: 6| Step: 5
Training loss: 1.7417588326679323
Validation loss: 2.444505612067019

Epoch: 6| Step: 6
Training loss: 1.1499632995388396
Validation loss: 2.410433396708477

Epoch: 6| Step: 7
Training loss: 1.6951938007480816
Validation loss: 2.504303613004059

Epoch: 6| Step: 8
Training loss: 1.4554227484878048
Validation loss: 2.4415435991270837

Epoch: 6| Step: 9
Training loss: 1.1288049777847828
Validation loss: 2.410609132963033

Epoch: 6| Step: 10
Training loss: 2.189844020009237
Validation loss: 2.455306092610395

Epoch: 6| Step: 11
Training loss: 0.8241847243675587
Validation loss: 2.415185235244084

Epoch: 6| Step: 12
Training loss: 0.9341094057386122
Validation loss: 2.43581902887725

Epoch: 6| Step: 13
Training loss: 1.0778594864900422
Validation loss: 2.3628629667684153

Epoch: 371| Step: 0
Training loss: 1.4600930450785885
Validation loss: 2.4007776149126663

Epoch: 6| Step: 1
Training loss: 1.296689767133261
Validation loss: 2.3890891651369057

Epoch: 6| Step: 2
Training loss: 1.486097922023981
Validation loss: 2.4003673273218507

Epoch: 6| Step: 3
Training loss: 1.232831932079108
Validation loss: 2.4331079548349916

Epoch: 6| Step: 4
Training loss: 0.9277462607174483
Validation loss: 2.3832201644782307

Epoch: 6| Step: 5
Training loss: 1.1931318450139896
Validation loss: 2.3690304194851928

Epoch: 6| Step: 6
Training loss: 1.367345005227063
Validation loss: 2.3966595204727277

Epoch: 6| Step: 7
Training loss: 1.073884336263794
Validation loss: 2.396013914546088

Epoch: 6| Step: 8
Training loss: 0.9072658173082865
Validation loss: 2.3813370505906817

Epoch: 6| Step: 9
Training loss: 2.2531070449261827
Validation loss: 2.448812536460696

Epoch: 6| Step: 10
Training loss: 1.427360934617064
Validation loss: 2.444879749309658

Epoch: 6| Step: 11
Training loss: 1.0157485886718198
Validation loss: 2.3680486172462265

Epoch: 6| Step: 12
Training loss: 1.43466753334837
Validation loss: 2.4005773304106515

Epoch: 6| Step: 13
Training loss: 1.116311590240571
Validation loss: 2.4188471841245787

Epoch: 372| Step: 0
Training loss: 1.420393874519953
Validation loss: 2.398865614294958

Epoch: 6| Step: 1
Training loss: 1.0077233090226738
Validation loss: 2.3898016728806057

Epoch: 6| Step: 2
Training loss: 1.2034962069075639
Validation loss: 2.4481254301853794

Epoch: 6| Step: 3
Training loss: 1.0281042033124135
Validation loss: 2.459660606824417

Epoch: 6| Step: 4
Training loss: 2.318821386179237
Validation loss: 2.407678726256835

Epoch: 6| Step: 5
Training loss: 1.048400223320883
Validation loss: 2.3983705679706007

Epoch: 6| Step: 6
Training loss: 1.0200381717832114
Validation loss: 2.4415755758653597

Epoch: 6| Step: 7
Training loss: 1.263246727107806
Validation loss: 2.4306217409215947

Epoch: 6| Step: 8
Training loss: 1.3594808427668172
Validation loss: 2.3735152365362797

Epoch: 6| Step: 9
Training loss: 1.2573841384387232
Validation loss: 2.365509084721873

Epoch: 6| Step: 10
Training loss: 0.9676175112171486
Validation loss: 2.373140296732795

Epoch: 6| Step: 11
Training loss: 1.2151656138415063
Validation loss: 2.366695684763192

Epoch: 6| Step: 12
Training loss: 1.2118868644176866
Validation loss: 2.4146707402196745

Epoch: 6| Step: 13
Training loss: 0.9556992272339863
Validation loss: 2.504026141747162

Epoch: 373| Step: 0
Training loss: 1.0169164809269777
Validation loss: 2.4566037564739287

Epoch: 6| Step: 1
Training loss: 1.2811166647406267
Validation loss: 2.431481707528233

Epoch: 6| Step: 2
Training loss: 1.113917493545394
Validation loss: 2.4464902919530407

Epoch: 6| Step: 3
Training loss: 1.6288603632110292
Validation loss: 2.446783801623351

Epoch: 6| Step: 4
Training loss: 1.1532664597331295
Validation loss: 2.3812459184545256

Epoch: 6| Step: 5
Training loss: 1.2943046560287874
Validation loss: 2.442199541395956

Epoch: 6| Step: 6
Training loss: 1.5968125780898328
Validation loss: 2.436501678495242

Epoch: 6| Step: 7
Training loss: 0.7983498482266871
Validation loss: 2.4327322917020595

Epoch: 6| Step: 8
Training loss: 0.8153407248205896
Validation loss: 2.399527549451291

Epoch: 6| Step: 9
Training loss: 0.9789223805869648
Validation loss: 2.4280905058244016

Epoch: 6| Step: 10
Training loss: 1.1965569394755284
Validation loss: 2.446158576118089

Epoch: 6| Step: 11
Training loss: 1.386028967143187
Validation loss: 2.460786030436472

Epoch: 6| Step: 12
Training loss: 1.4895654779533365
Validation loss: 2.341918277663147

Epoch: 6| Step: 13
Training loss: 2.7692067718892526
Validation loss: 2.3615165997644207

Epoch: 374| Step: 0
Training loss: 2.1091750438719257
Validation loss: 2.431930098435847

Epoch: 6| Step: 1
Training loss: 1.3037171552988431
Validation loss: 2.3760774302547922

Epoch: 6| Step: 2
Training loss: 1.287301403765512
Validation loss: 2.4128204866482

Epoch: 6| Step: 3
Training loss: 1.3679744962160911
Validation loss: 2.418827616900505

Epoch: 6| Step: 4
Training loss: 0.9485803034707017
Validation loss: 2.41328483013502

Epoch: 6| Step: 5
Training loss: 0.9351147507818609
Validation loss: 2.399409452691997

Epoch: 6| Step: 6
Training loss: 1.1885627709046562
Validation loss: 2.4237616825888915

Epoch: 6| Step: 7
Training loss: 1.2700115997055048
Validation loss: 2.383693827008804

Epoch: 6| Step: 8
Training loss: 1.3290022253042266
Validation loss: 2.379130932649279

Epoch: 6| Step: 9
Training loss: 0.9639579629715296
Validation loss: 2.371776896162433

Epoch: 6| Step: 10
Training loss: 1.0677358980419873
Validation loss: 2.3903942915050087

Epoch: 6| Step: 11
Training loss: 1.3320016270361235
Validation loss: 2.4444559906273247

Epoch: 6| Step: 12
Training loss: 1.2403397162448424
Validation loss: 2.393840630581995

Epoch: 6| Step: 13
Training loss: 1.4510213740514306
Validation loss: 2.39537850584068

Epoch: 375| Step: 0
Training loss: 1.2630082382150936
Validation loss: 2.3723098586037477

Epoch: 6| Step: 1
Training loss: 0.9687811323516332
Validation loss: 2.4113943326739564

Epoch: 6| Step: 2
Training loss: 2.0517224867556263
Validation loss: 2.385965602154908

Epoch: 6| Step: 3
Training loss: 1.5811752452444054
Validation loss: 2.3629113934639037

Epoch: 6| Step: 4
Training loss: 1.5095674253898352
Validation loss: 2.3841501651341144

Epoch: 6| Step: 5
Training loss: 1.0275887316888188
Validation loss: 2.359829526986143

Epoch: 6| Step: 6
Training loss: 1.2501054719296634
Validation loss: 2.382159376277882

Epoch: 6| Step: 7
Training loss: 0.9479301717166432
Validation loss: 2.420760781170268

Epoch: 6| Step: 8
Training loss: 1.0411651675687423
Validation loss: 2.4257176205461506

Epoch: 6| Step: 9
Training loss: 1.5545275428567498
Validation loss: 2.4867653327288033

Epoch: 6| Step: 10
Training loss: 1.2122205274527134
Validation loss: 2.349374152099911

Epoch: 6| Step: 11
Training loss: 0.8104732617880896
Validation loss: 2.4358567493186585

Epoch: 6| Step: 12
Training loss: 0.8678369925109055
Validation loss: 2.37715191654067

Epoch: 6| Step: 13
Training loss: 1.4241594679940515
Validation loss: 2.4175727010040267

Epoch: 376| Step: 0
Training loss: 1.5265465726773149
Validation loss: 2.349974423934568

Epoch: 6| Step: 1
Training loss: 1.2468008110136761
Validation loss: 2.393102936568678

Epoch: 6| Step: 2
Training loss: 2.14870770229142
Validation loss: 2.32267708087524

Epoch: 6| Step: 3
Training loss: 1.2111595688515626
Validation loss: 2.3404101326660105

Epoch: 6| Step: 4
Training loss: 1.037588579923538
Validation loss: 2.4003052959109232

Epoch: 6| Step: 5
Training loss: 1.4600318100481713
Validation loss: 2.4131009952509963

Epoch: 6| Step: 6
Training loss: 1.234613902477085
Validation loss: 2.449386279813218

Epoch: 6| Step: 7
Training loss: 1.1441089254554764
Validation loss: 2.3727785568569026

Epoch: 6| Step: 8
Training loss: 1.3180595452601447
Validation loss: 2.324362726078912

Epoch: 6| Step: 9
Training loss: 1.0362947357239858
Validation loss: 2.4000160757247664

Epoch: 6| Step: 10
Training loss: 1.1427155240903977
Validation loss: 2.3722650251838315

Epoch: 6| Step: 11
Training loss: 1.2611751743649928
Validation loss: 2.3794979082606313

Epoch: 6| Step: 12
Training loss: 1.1064714393325545
Validation loss: 2.481421833613555

Epoch: 6| Step: 13
Training loss: 1.3306625359483208
Validation loss: 2.4478925879626656

Epoch: 377| Step: 0
Training loss: 0.96955982322916
Validation loss: 2.365690472934219

Epoch: 6| Step: 1
Training loss: 1.1260180105899882
Validation loss: 2.3872222071321136

Epoch: 6| Step: 2
Training loss: 1.6810737744401563
Validation loss: 2.400913625807968

Epoch: 6| Step: 3
Training loss: 0.9978505518175115
Validation loss: 2.3634898402245126

Epoch: 6| Step: 4
Training loss: 0.9494320978971883
Validation loss: 2.427178950096304

Epoch: 6| Step: 5
Training loss: 0.6489597882845893
Validation loss: 2.4355520705956217

Epoch: 6| Step: 6
Training loss: 1.259159291159747
Validation loss: 2.3869934423426096

Epoch: 6| Step: 7
Training loss: 1.3665396763177728
Validation loss: 2.4395944364965207

Epoch: 6| Step: 8
Training loss: 1.3435627119265838
Validation loss: 2.380697792471717

Epoch: 6| Step: 9
Training loss: 1.1211677553426682
Validation loss: 2.4121597415640457

Epoch: 6| Step: 10
Training loss: 2.0713451185469247
Validation loss: 2.4968206318582356

Epoch: 6| Step: 11
Training loss: 1.1614485713166454
Validation loss: 2.408333724099552

Epoch: 6| Step: 12
Training loss: 1.269306855544316
Validation loss: 2.374540687191631

Epoch: 6| Step: 13
Training loss: 1.2526403198523508
Validation loss: 2.4451328581028378

Epoch: 378| Step: 0
Training loss: 1.146264336183309
Validation loss: 2.414256719575263

Epoch: 6| Step: 1
Training loss: 1.0331968945493855
Validation loss: 2.3910148764345758

Epoch: 6| Step: 2
Training loss: 1.383124364826041
Validation loss: 2.4349771684889014

Epoch: 6| Step: 3
Training loss: 2.146553017626844
Validation loss: 2.3987339150994673

Epoch: 6| Step: 4
Training loss: 1.3857314772726306
Validation loss: 2.3902757445698612

Epoch: 6| Step: 5
Training loss: 1.1923798132256505
Validation loss: 2.5202285873779924

Epoch: 6| Step: 6
Training loss: 1.0119231028724536
Validation loss: 2.4109931758870586

Epoch: 6| Step: 7
Training loss: 1.1069917465839594
Validation loss: 2.44398411239759

Epoch: 6| Step: 8
Training loss: 1.3226607167708742
Validation loss: 2.367644152880291

Epoch: 6| Step: 9
Training loss: 1.3179657072836006
Validation loss: 2.3602337007007654

Epoch: 6| Step: 10
Training loss: 1.0114787048949339
Validation loss: 2.3604546597305274

Epoch: 6| Step: 11
Training loss: 1.0625566579634453
Validation loss: 2.366210569131369

Epoch: 6| Step: 12
Training loss: 1.088009291910716
Validation loss: 2.423839789094748

Epoch: 6| Step: 13
Training loss: 1.26434661916351
Validation loss: 2.4300263171938066

Epoch: 379| Step: 0
Training loss: 1.7435754285270766
Validation loss: 2.392316967605194

Epoch: 6| Step: 1
Training loss: 1.0480152581756712
Validation loss: 2.4490380097247044

Epoch: 6| Step: 2
Training loss: 1.4097088555807353
Validation loss: 2.438038762503161

Epoch: 6| Step: 3
Training loss: 1.0489087064962321
Validation loss: 2.4306274163971002

Epoch: 6| Step: 4
Training loss: 0.8714072172376036
Validation loss: 2.4753549782178355

Epoch: 6| Step: 5
Training loss: 1.2358306800023253
Validation loss: 2.4718045608185295

Epoch: 6| Step: 6
Training loss: 1.065242089976961
Validation loss: 2.3845500870310143

Epoch: 6| Step: 7
Training loss: 0.7678901484673574
Validation loss: 2.398136418369251

Epoch: 6| Step: 8
Training loss: 2.0695987262720434
Validation loss: 2.460198687654868

Epoch: 6| Step: 9
Training loss: 1.4103452180752214
Validation loss: 2.4414147786309366

Epoch: 6| Step: 10
Training loss: 1.2458435094326343
Validation loss: 2.3758053043073857

Epoch: 6| Step: 11
Training loss: 1.245207181184025
Validation loss: 2.436251463332054

Epoch: 6| Step: 12
Training loss: 1.1350249685154254
Validation loss: 2.312380558976845

Epoch: 6| Step: 13
Training loss: 0.8516392454509376
Validation loss: 2.3669902836188252

Epoch: 380| Step: 0
Training loss: 0.6786931975536808
Validation loss: 2.3787971090460034

Epoch: 6| Step: 1
Training loss: 1.1714004573040213
Validation loss: 2.4242173166899907

Epoch: 6| Step: 2
Training loss: 1.2824895956498572
Validation loss: 2.455049295494603

Epoch: 6| Step: 3
Training loss: 1.1745216491639727
Validation loss: 2.463258518671051

Epoch: 6| Step: 4
Training loss: 1.3834918233935207
Validation loss: 2.462071113555754

Epoch: 6| Step: 5
Training loss: 1.1731761575314859
Validation loss: 2.351768802119609

Epoch: 6| Step: 6
Training loss: 1.9217767457734791
Validation loss: 2.4371264539323145

Epoch: 6| Step: 7
Training loss: 0.9884092828496093
Validation loss: 2.439770650878938

Epoch: 6| Step: 8
Training loss: 1.2305818536032715
Validation loss: 2.553373709140164

Epoch: 6| Step: 9
Training loss: 1.1599821737169345
Validation loss: 2.427763843018466

Epoch: 6| Step: 10
Training loss: 1.3126820029361717
Validation loss: 2.444830181601883

Epoch: 6| Step: 11
Training loss: 1.1703495523981644
Validation loss: 2.4074682383516026

Epoch: 6| Step: 12
Training loss: 1.2164037568465538
Validation loss: 2.425416341109282

Epoch: 6| Step: 13
Training loss: 1.0490824073264005
Validation loss: 2.4076514017975605

Epoch: 381| Step: 0
Training loss: 1.0247433317795298
Validation loss: 2.4512845224498427

Epoch: 6| Step: 1
Training loss: 1.5108098099412035
Validation loss: 2.3965129157764724

Epoch: 6| Step: 2
Training loss: 1.1939574395937822
Validation loss: 2.367425592064496

Epoch: 6| Step: 3
Training loss: 1.2895853080590596
Validation loss: 2.431863773019052

Epoch: 6| Step: 4
Training loss: 1.9866096949675747
Validation loss: 2.4093982316034275

Epoch: 6| Step: 5
Training loss: 1.0781941046198213
Validation loss: 2.3870645274645144

Epoch: 6| Step: 6
Training loss: 1.1963141240200137
Validation loss: 2.3881527468873722

Epoch: 6| Step: 7
Training loss: 1.0218643444567312
Validation loss: 2.413859939400028

Epoch: 6| Step: 8
Training loss: 1.1308003938938045
Validation loss: 2.3670447521853757

Epoch: 6| Step: 9
Training loss: 1.300026431181782
Validation loss: 2.4361683942215575

Epoch: 6| Step: 10
Training loss: 1.0308757449661177
Validation loss: 2.4009529506494487

Epoch: 6| Step: 11
Training loss: 1.2538707882629125
Validation loss: 2.474992278033048

Epoch: 6| Step: 12
Training loss: 1.24456645678706
Validation loss: 2.4318421262345224

Epoch: 6| Step: 13
Training loss: 0.9064781296454161
Validation loss: 2.4929177637139572

Epoch: 382| Step: 0
Training loss: 1.1384730484444072
Validation loss: 2.4469516469162267

Epoch: 6| Step: 1
Training loss: 1.1881672339881943
Validation loss: 2.368413067974958

Epoch: 6| Step: 2
Training loss: 1.0212591152648158
Validation loss: 2.533493338713451

Epoch: 6| Step: 3
Training loss: 1.0300933246554387
Validation loss: 2.443486250629491

Epoch: 6| Step: 4
Training loss: 1.068796797056881
Validation loss: 2.5560404168727415

Epoch: 6| Step: 5
Training loss: 1.750505033915652
Validation loss: 2.54141041828806

Epoch: 6| Step: 6
Training loss: 1.587931915159273
Validation loss: 2.5095499454122536

Epoch: 6| Step: 7
Training loss: 1.0543440648161013
Validation loss: 2.466833800632018

Epoch: 6| Step: 8
Training loss: 0.835246790089929
Validation loss: 2.4312448249886454

Epoch: 6| Step: 9
Training loss: 1.142457143785292
Validation loss: 2.3252051168919863

Epoch: 6| Step: 10
Training loss: 2.3221256865230204
Validation loss: 2.406374850987449

Epoch: 6| Step: 11
Training loss: 1.2030460777654135
Validation loss: 2.4130324444609066

Epoch: 6| Step: 12
Training loss: 1.2711111244556972
Validation loss: 2.4791091863335657

Epoch: 6| Step: 13
Training loss: 0.9499168183902508
Validation loss: 2.4293186482945353

Epoch: 383| Step: 0
Training loss: 1.720700423101064
Validation loss: 2.37831350837471

Epoch: 6| Step: 1
Training loss: 1.2388953963328824
Validation loss: 2.423859064131567

Epoch: 6| Step: 2
Training loss: 1.4000098909301135
Validation loss: 2.321926454025754

Epoch: 6| Step: 3
Training loss: 1.5676623704156414
Validation loss: 2.3784850629158454

Epoch: 6| Step: 4
Training loss: 1.1777337676848558
Validation loss: 2.3688688428422418

Epoch: 6| Step: 5
Training loss: 1.2146713772374282
Validation loss: 2.3446889209404196

Epoch: 6| Step: 6
Training loss: 0.8555447618689874
Validation loss: 2.4424900358213066

Epoch: 6| Step: 7
Training loss: 0.7991638224381745
Validation loss: 2.4090936300399224

Epoch: 6| Step: 8
Training loss: 1.0440560720155079
Validation loss: 2.3774077187814107

Epoch: 6| Step: 9
Training loss: 1.3621872061658884
Validation loss: 2.415212538156813

Epoch: 6| Step: 10
Training loss: 0.8860637245210122
Validation loss: 2.355287137314889

Epoch: 6| Step: 11
Training loss: 2.03196445518103
Validation loss: 2.3913948802768368

Epoch: 6| Step: 12
Training loss: 1.3553283354837038
Validation loss: 2.381148452193368

Epoch: 6| Step: 13
Training loss: 0.8066581373184145
Validation loss: 2.39806940737955

Epoch: 384| Step: 0
Training loss: 0.9222213611700897
Validation loss: 2.357030693598315

Epoch: 6| Step: 1
Training loss: 1.0901165145755485
Validation loss: 2.4034347931263347

Epoch: 6| Step: 2
Training loss: 1.2206648431497311
Validation loss: 2.386816678358353

Epoch: 6| Step: 3
Training loss: 1.1081331851525686
Validation loss: 2.436168545756337

Epoch: 6| Step: 4
Training loss: 1.0974408138539475
Validation loss: 2.4016653300019293

Epoch: 6| Step: 5
Training loss: 1.4474721907874526
Validation loss: 2.4865875824086183

Epoch: 6| Step: 6
Training loss: 1.6114811865039496
Validation loss: 2.3969080925043027

Epoch: 6| Step: 7
Training loss: 0.8852574074324034
Validation loss: 2.4314106852561945

Epoch: 6| Step: 8
Training loss: 1.1613119514948136
Validation loss: 2.4242316226797826

Epoch: 6| Step: 9
Training loss: 0.9649820267283333
Validation loss: 2.3751032984386162

Epoch: 6| Step: 10
Training loss: 1.1140943268540675
Validation loss: 2.3750407858230194

Epoch: 6| Step: 11
Training loss: 2.207621969653042
Validation loss: 2.4304340472419965

Epoch: 6| Step: 12
Training loss: 1.2552534810200107
Validation loss: 2.3896509028179307

Epoch: 6| Step: 13
Training loss: 0.7956307364689268
Validation loss: 2.3778304551567806

Epoch: 385| Step: 0
Training loss: 1.3372215658557018
Validation loss: 2.4168023034951176

Epoch: 6| Step: 1
Training loss: 2.174467666199628
Validation loss: 2.378289423393781

Epoch: 6| Step: 2
Training loss: 1.157919734874356
Validation loss: 2.4250659130641763

Epoch: 6| Step: 3
Training loss: 1.0707674938895273
Validation loss: 2.4579928603652887

Epoch: 6| Step: 4
Training loss: 1.224109845895298
Validation loss: 2.4634731185802026

Epoch: 6| Step: 5
Training loss: 1.0555885139696173
Validation loss: 2.4381920100659644

Epoch: 6| Step: 6
Training loss: 1.004766607655569
Validation loss: 2.337757588577921

Epoch: 6| Step: 7
Training loss: 1.1408549560344263
Validation loss: 2.345188078689438

Epoch: 6| Step: 8
Training loss: 1.0265585796217473
Validation loss: 2.361144556954343

Epoch: 6| Step: 9
Training loss: 1.2928088224680054
Validation loss: 2.33834354652086

Epoch: 6| Step: 10
Training loss: 1.2463156284357861
Validation loss: 2.440651375443167

Epoch: 6| Step: 11
Training loss: 1.3414435442015322
Validation loss: 2.4201489996408445

Epoch: 6| Step: 12
Training loss: 1.0316858815410248
Validation loss: 2.436053888059323

Epoch: 6| Step: 13
Training loss: 1.1759856797241712
Validation loss: 2.4274567798196984

Epoch: 386| Step: 0
Training loss: 1.1084095151910638
Validation loss: 2.430127069310928

Epoch: 6| Step: 1
Training loss: 1.3048381147421695
Validation loss: 2.407367205628153

Epoch: 6| Step: 2
Training loss: 1.434402611826164
Validation loss: 2.458486409024708

Epoch: 6| Step: 3
Training loss: 0.7314016739136356
Validation loss: 2.453448979935506

Epoch: 6| Step: 4
Training loss: 1.6937006306227422
Validation loss: 2.5255699320246583

Epoch: 6| Step: 5
Training loss: 1.0629106737718323
Validation loss: 2.426414383474987

Epoch: 6| Step: 6
Training loss: 1.0892125424503822
Validation loss: 2.3582936523791105

Epoch: 6| Step: 7
Training loss: 0.9286096559767284
Validation loss: 2.4229186742393702

Epoch: 6| Step: 8
Training loss: 1.313208116518141
Validation loss: 2.3941990950313277

Epoch: 6| Step: 9
Training loss: 1.0869926431085815
Validation loss: 2.4244114767091878

Epoch: 6| Step: 10
Training loss: 2.049632537286338
Validation loss: 2.483102821651696

Epoch: 6| Step: 11
Training loss: 1.3390827297609977
Validation loss: 2.461570031072935

Epoch: 6| Step: 12
Training loss: 1.0117690615129713
Validation loss: 2.3938938515646195

Epoch: 6| Step: 13
Training loss: 1.3016945322027844
Validation loss: 2.3770205252870102

Epoch: 387| Step: 0
Training loss: 1.1841917636009578
Validation loss: 2.3427249014816214

Epoch: 6| Step: 1
Training loss: 1.366711997040232
Validation loss: 2.4057609669512092

Epoch: 6| Step: 2
Training loss: 2.108653192293572
Validation loss: 2.421660067534314

Epoch: 6| Step: 3
Training loss: 0.9864443266752675
Validation loss: 2.396454788724592

Epoch: 6| Step: 4
Training loss: 1.1143759180943444
Validation loss: 2.371500754504327

Epoch: 6| Step: 5
Training loss: 0.9640341076000903
Validation loss: 2.486609617606138

Epoch: 6| Step: 6
Training loss: 1.2903259097044824
Validation loss: 2.4446475962883554

Epoch: 6| Step: 7
Training loss: 1.4353292079611704
Validation loss: 2.4460871687930417

Epoch: 6| Step: 8
Training loss: 0.8307788359682468
Validation loss: 2.3347200815582307

Epoch: 6| Step: 9
Training loss: 0.8754389887824533
Validation loss: 2.392170771397008

Epoch: 6| Step: 10
Training loss: 1.4579906424286213
Validation loss: 2.374623365389871

Epoch: 6| Step: 11
Training loss: 1.2369836211542602
Validation loss: 2.4108266361635926

Epoch: 6| Step: 12
Training loss: 1.0234106511678325
Validation loss: 2.3557004162147432

Epoch: 6| Step: 13
Training loss: 1.4451702975863705
Validation loss: 2.3641605404880757

Epoch: 388| Step: 0
Training loss: 1.147192611163378
Validation loss: 2.336169783993003

Epoch: 6| Step: 1
Training loss: 1.1127877195534925
Validation loss: 2.39452862483055

Epoch: 6| Step: 2
Training loss: 0.9087618514052953
Validation loss: 2.41169107772584

Epoch: 6| Step: 3
Training loss: 1.2043338004064794
Validation loss: 2.449912662175752

Epoch: 6| Step: 4
Training loss: 1.2880123600396343
Validation loss: 2.3994750720392766

Epoch: 6| Step: 5
Training loss: 1.0666851754867555
Validation loss: 2.3976529573749876

Epoch: 6| Step: 6
Training loss: 0.9041238705809839
Validation loss: 2.3911891622508117

Epoch: 6| Step: 7
Training loss: 1.188694904867738
Validation loss: 2.39173201767929

Epoch: 6| Step: 8
Training loss: 1.1124957609631647
Validation loss: 2.4302506503947394

Epoch: 6| Step: 9
Training loss: 1.325216047199269
Validation loss: 2.394546506331559

Epoch: 6| Step: 10
Training loss: 0.6900710451826833
Validation loss: 2.4290641030034528

Epoch: 6| Step: 11
Training loss: 1.4305440702666583
Validation loss: 2.3510316284889488

Epoch: 6| Step: 12
Training loss: 2.070149886744645
Validation loss: 2.399558402866641

Epoch: 6| Step: 13
Training loss: 1.3314393370042261
Validation loss: 2.403698076595371

Epoch: 389| Step: 0
Training loss: 0.9534380664404902
Validation loss: 2.373212883521987

Epoch: 6| Step: 1
Training loss: 1.0238639583669893
Validation loss: 2.409715362274593

Epoch: 6| Step: 2
Training loss: 1.1668364480775337
Validation loss: 2.401795756776196

Epoch: 6| Step: 3
Training loss: 1.2710787687256981
Validation loss: 2.3422341600139958

Epoch: 6| Step: 4
Training loss: 0.879973344453339
Validation loss: 2.3791843194337003

Epoch: 6| Step: 5
Training loss: 1.2074057482626979
Validation loss: 2.4485786256854523

Epoch: 6| Step: 6
Training loss: 1.1391620398880697
Validation loss: 2.4124879221566315

Epoch: 6| Step: 7
Training loss: 1.1420487179961867
Validation loss: 2.455720739250445

Epoch: 6| Step: 8
Training loss: 1.3083425707804817
Validation loss: 2.375573256931261

Epoch: 6| Step: 9
Training loss: 1.2872955696988062
Validation loss: 2.384417819701181

Epoch: 6| Step: 10
Training loss: 1.2342616161953408
Validation loss: 2.408399274334695

Epoch: 6| Step: 11
Training loss: 2.1671547951186736
Validation loss: 2.379913330017112

Epoch: 6| Step: 12
Training loss: 1.118406151297302
Validation loss: 2.3715860433162264

Epoch: 6| Step: 13
Training loss: 1.0311167659812275
Validation loss: 2.401212076055907

Epoch: 390| Step: 0
Training loss: 1.5055578897293096
Validation loss: 2.411622005303409

Epoch: 6| Step: 1
Training loss: 1.3886867259501692
Validation loss: 2.453945601880659

Epoch: 6| Step: 2
Training loss: 1.2908956728798373
Validation loss: 2.467731937265138

Epoch: 6| Step: 3
Training loss: 1.0908049033364968
Validation loss: 2.5464304632880235

Epoch: 6| Step: 4
Training loss: 2.1154778253253705
Validation loss: 2.4273639572881756

Epoch: 6| Step: 5
Training loss: 1.098089329547833
Validation loss: 2.4250356246806133

Epoch: 6| Step: 6
Training loss: 1.0054225528659089
Validation loss: 2.424854378048651

Epoch: 6| Step: 7
Training loss: 1.0584031950552788
Validation loss: 2.41288681809964

Epoch: 6| Step: 8
Training loss: 1.1615637259570517
Validation loss: 2.4682766278935815

Epoch: 6| Step: 9
Training loss: 1.2113712641400862
Validation loss: 2.5032215726728286

Epoch: 6| Step: 10
Training loss: 0.9846227424947291
Validation loss: 2.4118697309575574

Epoch: 6| Step: 11
Training loss: 1.2171721882279407
Validation loss: 2.400091434389735

Epoch: 6| Step: 12
Training loss: 1.2180835173087108
Validation loss: 2.3826350793763322

Epoch: 6| Step: 13
Training loss: 1.2506238334379614
Validation loss: 2.42851002836506

Epoch: 391| Step: 0
Training loss: 1.023100469874249
Validation loss: 2.403875377565739

Epoch: 6| Step: 1
Training loss: 1.398038071857544
Validation loss: 2.399733758245102

Epoch: 6| Step: 2
Training loss: 1.241364548344644
Validation loss: 2.4854266432340397

Epoch: 6| Step: 3
Training loss: 1.1324372294800553
Validation loss: 2.381649784394652

Epoch: 6| Step: 4
Training loss: 1.29709467118983
Validation loss: 2.3846415970988435

Epoch: 6| Step: 5
Training loss: 1.9299388521024738
Validation loss: 2.378416530054019

Epoch: 6| Step: 6
Training loss: 1.2502674770281677
Validation loss: 2.4067982055960377

Epoch: 6| Step: 7
Training loss: 0.8694994582184941
Validation loss: 2.3368684567543068

Epoch: 6| Step: 8
Training loss: 0.8753409402647012
Validation loss: 2.3288768185631885

Epoch: 6| Step: 9
Training loss: 1.4330109703192428
Validation loss: 2.377913662601112

Epoch: 6| Step: 10
Training loss: 1.061476494980342
Validation loss: 2.3336637925092996

Epoch: 6| Step: 11
Training loss: 1.1768780532124723
Validation loss: 2.4248351151525647

Epoch: 6| Step: 12
Training loss: 0.9835022584572147
Validation loss: 2.429154956694913

Epoch: 6| Step: 13
Training loss: 1.1978015291471429
Validation loss: 2.46477290428833

Epoch: 392| Step: 0
Training loss: 2.110398333947809
Validation loss: 2.4122377284840706

Epoch: 6| Step: 1
Training loss: 0.9846274037183493
Validation loss: 2.392571670292478

Epoch: 6| Step: 2
Training loss: 1.0667036710717985
Validation loss: 2.510529281533708

Epoch: 6| Step: 3
Training loss: 1.0518923419286685
Validation loss: 2.4060607897559296

Epoch: 6| Step: 4
Training loss: 0.9515849319094034
Validation loss: 2.442625955403521

Epoch: 6| Step: 5
Training loss: 1.2141948573798285
Validation loss: 2.4268247982570106

Epoch: 6| Step: 6
Training loss: 1.239729506692282
Validation loss: 2.4444664655910397

Epoch: 6| Step: 7
Training loss: 1.255847889327095
Validation loss: 2.4223579996877183

Epoch: 6| Step: 8
Training loss: 1.0493613367060222
Validation loss: 2.351922127059507

Epoch: 6| Step: 9
Training loss: 1.3099496222411584
Validation loss: 2.3969376410979675

Epoch: 6| Step: 10
Training loss: 1.5668254491140143
Validation loss: 2.4169302295587998

Epoch: 6| Step: 11
Training loss: 0.957532852445901
Validation loss: 2.39396348261164

Epoch: 6| Step: 12
Training loss: 1.0167276119246371
Validation loss: 2.4714035917375425

Epoch: 6| Step: 13
Training loss: 0.8131569260729694
Validation loss: 2.4383351115694363

Epoch: 393| Step: 0
Training loss: 1.136274532812853
Validation loss: 2.3491104266275804

Epoch: 6| Step: 1
Training loss: 1.035300190832562
Validation loss: 2.401351691058678

Epoch: 6| Step: 2
Training loss: 1.3971774855433772
Validation loss: 2.4043793541889773

Epoch: 6| Step: 3
Training loss: 0.9539841703665085
Validation loss: 2.4075147524875042

Epoch: 6| Step: 4
Training loss: 2.040429019133673
Validation loss: 2.465196112016171

Epoch: 6| Step: 5
Training loss: 1.2126982654616065
Validation loss: 2.476228746816595

Epoch: 6| Step: 6
Training loss: 1.0944571252810085
Validation loss: 2.495312065992458

Epoch: 6| Step: 7
Training loss: 1.0019361111570209
Validation loss: 2.4278760190625572

Epoch: 6| Step: 8
Training loss: 1.219090194172443
Validation loss: 2.442924035726146

Epoch: 6| Step: 9
Training loss: 1.4358119174971204
Validation loss: 2.3761743827397246

Epoch: 6| Step: 10
Training loss: 1.1199203890367169
Validation loss: 2.4402703422681675

Epoch: 6| Step: 11
Training loss: 0.9449377657061545
Validation loss: 2.354933865705447

Epoch: 6| Step: 12
Training loss: 1.006901647308666
Validation loss: 2.4326346678313313

Epoch: 6| Step: 13
Training loss: 0.9934668215456077
Validation loss: 2.3949577258089594

Epoch: 394| Step: 0
Training loss: 1.1466268161753892
Validation loss: 2.3994502440300183

Epoch: 6| Step: 1
Training loss: 1.229828392401094
Validation loss: 2.3864057630487308

Epoch: 6| Step: 2
Training loss: 1.1217739155317545
Validation loss: 2.3856256370794293

Epoch: 6| Step: 3
Training loss: 1.833012234860808
Validation loss: 2.410378217518559

Epoch: 6| Step: 4
Training loss: 0.8612889564241085
Validation loss: 2.367212152516851

Epoch: 6| Step: 5
Training loss: 1.3008441165246611
Validation loss: 2.43176159795618

Epoch: 6| Step: 6
Training loss: 1.341619488180829
Validation loss: 2.4495643235462614

Epoch: 6| Step: 7
Training loss: 1.173342485301854
Validation loss: 2.3530482142606446

Epoch: 6| Step: 8
Training loss: 1.2904173233643141
Validation loss: 2.4094324767466366

Epoch: 6| Step: 9
Training loss: 1.2969225219844074
Validation loss: 2.3237712922638507

Epoch: 6| Step: 10
Training loss: 1.0435292884324547
Validation loss: 2.382576696064422

Epoch: 6| Step: 11
Training loss: 1.1149597364263557
Validation loss: 2.449165106700107

Epoch: 6| Step: 12
Training loss: 1.0811959909169295
Validation loss: 2.3976303965320023

Epoch: 6| Step: 13
Training loss: 1.0449679070431699
Validation loss: 2.3908581234988824

Epoch: 395| Step: 0
Training loss: 1.1539394903334725
Validation loss: 2.389146711682194

Epoch: 6| Step: 1
Training loss: 1.163868727973473
Validation loss: 2.412433877079482

Epoch: 6| Step: 2
Training loss: 1.3443848197149206
Validation loss: 2.4123188628129872

Epoch: 6| Step: 3
Training loss: 1.1144745437911738
Validation loss: 2.4662938806035166

Epoch: 6| Step: 4
Training loss: 1.0013062766805412
Validation loss: 2.4356268139486543

Epoch: 6| Step: 5
Training loss: 1.0696904957646047
Validation loss: 2.4149932187548497

Epoch: 6| Step: 6
Training loss: 0.9841812185255505
Validation loss: 2.419473862591506

Epoch: 6| Step: 7
Training loss: 1.238078777715583
Validation loss: 2.4291736597687184

Epoch: 6| Step: 8
Training loss: 1.508278572114128
Validation loss: 2.44622539008141

Epoch: 6| Step: 9
Training loss: 1.4457003511218238
Validation loss: 2.423441893090281

Epoch: 6| Step: 10
Training loss: 2.136481960642742
Validation loss: 2.3345704179635365

Epoch: 6| Step: 11
Training loss: 0.9658398756431551
Validation loss: 2.4210702046528163

Epoch: 6| Step: 12
Training loss: 0.8421360403557155
Validation loss: 2.415686999313623

Epoch: 6| Step: 13
Training loss: 1.6773743070991438
Validation loss: 2.3869045324831166

Epoch: 396| Step: 0
Training loss: 1.314512390342407
Validation loss: 2.376312402738493

Epoch: 6| Step: 1
Training loss: 0.7665579425040245
Validation loss: 2.4087475165005503

Epoch: 6| Step: 2
Training loss: 0.9829380507095006
Validation loss: 2.3594157484273994

Epoch: 6| Step: 3
Training loss: 0.9041277601657982
Validation loss: 2.408818335872231

Epoch: 6| Step: 4
Training loss: 1.0436134203333405
Validation loss: 2.327111885356207

Epoch: 6| Step: 5
Training loss: 1.2237950101062123
Validation loss: 2.4360593603998146

Epoch: 6| Step: 6
Training loss: 1.5397061004351327
Validation loss: 2.352236121054863

Epoch: 6| Step: 7
Training loss: 2.0152582825619576
Validation loss: 2.3911172948535127

Epoch: 6| Step: 8
Training loss: 1.268865886337956
Validation loss: 2.417450609731792

Epoch: 6| Step: 9
Training loss: 1.3592189830828505
Validation loss: 2.4530974387162123

Epoch: 6| Step: 10
Training loss: 0.9950067310968195
Validation loss: 2.4385165063592305

Epoch: 6| Step: 11
Training loss: 1.1544360804650011
Validation loss: 2.411363014604063

Epoch: 6| Step: 12
Training loss: 0.907822461492147
Validation loss: 2.4816633788586295

Epoch: 6| Step: 13
Training loss: 0.8549490268749257
Validation loss: 2.426193480488779

Epoch: 397| Step: 0
Training loss: 1.0040297970282643
Validation loss: 2.3867750690713283

Epoch: 6| Step: 1
Training loss: 1.4998561472260685
Validation loss: 2.468427000129833

Epoch: 6| Step: 2
Training loss: 0.9869201092258297
Validation loss: 2.442286355351799

Epoch: 6| Step: 3
Training loss: 0.8827826570851223
Validation loss: 2.456580115822715

Epoch: 6| Step: 4
Training loss: 1.018213114242006
Validation loss: 2.4205071827815723

Epoch: 6| Step: 5
Training loss: 2.287015136028154
Validation loss: 2.4198561315519735

Epoch: 6| Step: 6
Training loss: 1.0544341736782261
Validation loss: 2.4086586582139065

Epoch: 6| Step: 7
Training loss: 0.9645734400616045
Validation loss: 2.4188150054852757

Epoch: 6| Step: 8
Training loss: 1.0427046309236132
Validation loss: 2.404756407157004

Epoch: 6| Step: 9
Training loss: 0.9479098302294238
Validation loss: 2.3960861422219253

Epoch: 6| Step: 10
Training loss: 1.200893611776041
Validation loss: 2.4571963358028492

Epoch: 6| Step: 11
Training loss: 1.0886923337395809
Validation loss: 2.393901293829819

Epoch: 6| Step: 12
Training loss: 1.1889268434314966
Validation loss: 2.3804614575874266

Epoch: 6| Step: 13
Training loss: 1.3393925833070817
Validation loss: 2.485472578767545

Epoch: 398| Step: 0
Training loss: 0.9821945139688822
Validation loss: 2.4203911624997225

Epoch: 6| Step: 1
Training loss: 1.1096778778544192
Validation loss: 2.4109135818658753

Epoch: 6| Step: 2
Training loss: 1.0346732686272946
Validation loss: 2.383472688864555

Epoch: 6| Step: 3
Training loss: 0.9989304783623314
Validation loss: 2.3772569714732135

Epoch: 6| Step: 4
Training loss: 0.9585970156488856
Validation loss: 2.368076738600348

Epoch: 6| Step: 5
Training loss: 1.365907691310892
Validation loss: 2.3902429067164555

Epoch: 6| Step: 6
Training loss: 1.3225137091865355
Validation loss: 2.364977396436616

Epoch: 6| Step: 7
Training loss: 1.1499153023088835
Validation loss: 2.383108295039726

Epoch: 6| Step: 8
Training loss: 1.1187583177140112
Validation loss: 2.381141522925635

Epoch: 6| Step: 9
Training loss: 1.315587907209343
Validation loss: 2.3725487451624323

Epoch: 6| Step: 10
Training loss: 0.9014793979154642
Validation loss: 2.470432412805026

Epoch: 6| Step: 11
Training loss: 1.0035571370758087
Validation loss: 2.391414309620987

Epoch: 6| Step: 12
Training loss: 2.0533305862127644
Validation loss: 2.4958263156829257

Epoch: 6| Step: 13
Training loss: 1.2065651990756079
Validation loss: 2.3566975251016777

Epoch: 399| Step: 0
Training loss: 0.960351129283113
Validation loss: 2.447219228434418

Epoch: 6| Step: 1
Training loss: 0.99147593897347
Validation loss: 2.3653641525057374

Epoch: 6| Step: 2
Training loss: 0.784274578885228
Validation loss: 2.37499148222125

Epoch: 6| Step: 3
Training loss: 1.6255987971451582
Validation loss: 2.4234983118633093

Epoch: 6| Step: 4
Training loss: 1.0645943364260928
Validation loss: 2.475492753155304

Epoch: 6| Step: 5
Training loss: 0.8077996819252092
Validation loss: 2.3942535806293166

Epoch: 6| Step: 6
Training loss: 1.0864558457918787
Validation loss: 2.4416379457849686

Epoch: 6| Step: 7
Training loss: 1.6397525465756912
Validation loss: 2.358215469780036

Epoch: 6| Step: 8
Training loss: 0.9080465530464515
Validation loss: 2.427187727288097

Epoch: 6| Step: 9
Training loss: 1.0311924889451518
Validation loss: 2.3975629629383186

Epoch: 6| Step: 10
Training loss: 2.2555646959859788
Validation loss: 2.368804799358733

Epoch: 6| Step: 11
Training loss: 1.1505978046375738
Validation loss: 2.4318415959733812

Epoch: 6| Step: 12
Training loss: 1.2232400396219467
Validation loss: 2.3375889382017947

Epoch: 6| Step: 13
Training loss: 0.8259693736270682
Validation loss: 2.3892747203848677

Epoch: 400| Step: 0
Training loss: 1.070721847331522
Validation loss: 2.265703264864124

Epoch: 6| Step: 1
Training loss: 0.9274222722348717
Validation loss: 2.3980893588563514

Epoch: 6| Step: 2
Training loss: 1.5257589796621795
Validation loss: 2.4199057181916928

Epoch: 6| Step: 3
Training loss: 0.6789992344505028
Validation loss: 2.3468472815052475

Epoch: 6| Step: 4
Training loss: 1.063201504420959
Validation loss: 2.4510031514230053

Epoch: 6| Step: 5
Training loss: 1.8719585546527264
Validation loss: 2.3587394151096297

Epoch: 6| Step: 6
Training loss: 0.855188193105372
Validation loss: 2.50659930021118

Epoch: 6| Step: 7
Training loss: 1.1635871274986844
Validation loss: 2.3961152002314052

Epoch: 6| Step: 8
Training loss: 1.3513433025094632
Validation loss: 2.454871581166356

Epoch: 6| Step: 9
Training loss: 1.011543347092239
Validation loss: 2.4007015804671377

Epoch: 6| Step: 10
Training loss: 1.052787821869144
Validation loss: 2.355110376964589

Epoch: 6| Step: 11
Training loss: 0.8486869627924679
Validation loss: 2.4268979512256372

Epoch: 6| Step: 12
Training loss: 1.083648299622943
Validation loss: 2.3718880632877273

Epoch: 6| Step: 13
Training loss: 1.5219343545920434
Validation loss: 2.4316988956516634

Epoch: 401| Step: 0
Training loss: 1.049917099722775
Validation loss: 2.3413488457976626

Epoch: 6| Step: 1
Training loss: 0.887782798627433
Validation loss: 2.4476748352056363

Epoch: 6| Step: 2
Training loss: 1.4121225021406396
Validation loss: 2.4005562590563825

Epoch: 6| Step: 3
Training loss: 1.2111602578316203
Validation loss: 2.440025018808851

Epoch: 6| Step: 4
Training loss: 1.0717320738944558
Validation loss: 2.436806284777095

Epoch: 6| Step: 5
Training loss: 1.031339179142234
Validation loss: 2.4118051445431266

Epoch: 6| Step: 6
Training loss: 0.9265758468412858
Validation loss: 2.409904232395383

Epoch: 6| Step: 7
Training loss: 1.3903741503144211
Validation loss: 2.4549836401062946

Epoch: 6| Step: 8
Training loss: 1.3923495882254586
Validation loss: 2.3874033442924114

Epoch: 6| Step: 9
Training loss: 0.8683275169743985
Validation loss: 2.4631648690068344

Epoch: 6| Step: 10
Training loss: 0.9772797048976918
Validation loss: 2.3451551790382497

Epoch: 6| Step: 11
Training loss: 1.999986529304916
Validation loss: 2.488290019776582

Epoch: 6| Step: 12
Training loss: 1.568999391466926
Validation loss: 2.396513652825756

Epoch: 6| Step: 13
Training loss: 0.934110235256047
Validation loss: 2.4201700434127167

Epoch: 402| Step: 0
Training loss: 1.9410399431013061
Validation loss: 2.382901524885068

Epoch: 6| Step: 1
Training loss: 1.0449526202946158
Validation loss: 2.432356801897458

Epoch: 6| Step: 2
Training loss: 1.6313029342773702
Validation loss: 2.400008552012195

Epoch: 6| Step: 3
Training loss: 1.007234156063823
Validation loss: 2.3984636874043748

Epoch: 6| Step: 4
Training loss: 1.3534221754525504
Validation loss: 2.3994935865709324

Epoch: 6| Step: 5
Training loss: 1.2441923648729345
Validation loss: 2.3869266995755436

Epoch: 6| Step: 6
Training loss: 0.8690385737138134
Validation loss: 2.361884234689467

Epoch: 6| Step: 7
Training loss: 1.0332447757510421
Validation loss: 2.390114278955202

Epoch: 6| Step: 8
Training loss: 1.2078107767228519
Validation loss: 2.2698282371520957

Epoch: 6| Step: 9
Training loss: 1.024443968708188
Validation loss: 2.398598359899017

Epoch: 6| Step: 10
Training loss: 1.0708824923224167
Validation loss: 2.400627514965681

Epoch: 6| Step: 11
Training loss: 0.9777682680663374
Validation loss: 2.4003941691878

Epoch: 6| Step: 12
Training loss: 0.77730955115766
Validation loss: 2.4113200512658937

Epoch: 6| Step: 13
Training loss: 1.2785267615831233
Validation loss: 2.331154961922251

Epoch: 403| Step: 0
Training loss: 0.8698523189999018
Validation loss: 2.3794476357645133

Epoch: 6| Step: 1
Training loss: 0.997021441331449
Validation loss: 2.40064178105789

Epoch: 6| Step: 2
Training loss: 1.1127502781377618
Validation loss: 2.435782969736196

Epoch: 6| Step: 3
Training loss: 1.3445566107371338
Validation loss: 2.4252919777713355

Epoch: 6| Step: 4
Training loss: 1.191454476803117
Validation loss: 2.493158062035307

Epoch: 6| Step: 5
Training loss: 1.3870880494859266
Validation loss: 2.3823840017758364

Epoch: 6| Step: 6
Training loss: 1.258226314734828
Validation loss: 2.4159233752169302

Epoch: 6| Step: 7
Training loss: 0.9257779664572902
Validation loss: 2.3603804652381983

Epoch: 6| Step: 8
Training loss: 0.768407708234713
Validation loss: 2.3780718196590733

Epoch: 6| Step: 9
Training loss: 1.0102308961175455
Validation loss: 2.3768139600580254

Epoch: 6| Step: 10
Training loss: 0.9918188777013957
Validation loss: 2.402676799907246

Epoch: 6| Step: 11
Training loss: 0.959298884450804
Validation loss: 2.4413271482061143

Epoch: 6| Step: 12
Training loss: 0.8330452341526661
Validation loss: 2.487881831805117

Epoch: 6| Step: 13
Training loss: 2.5273080908781704
Validation loss: 2.4312532954187476

Epoch: 404| Step: 0
Training loss: 2.144798387242429
Validation loss: 2.3768638153005868

Epoch: 6| Step: 1
Training loss: 1.391520436917127
Validation loss: 2.408824562394144

Epoch: 6| Step: 2
Training loss: 0.9204740385759347
Validation loss: 2.448426402022636

Epoch: 6| Step: 3
Training loss: 0.8249285927126973
Validation loss: 2.387877318285597

Epoch: 6| Step: 4
Training loss: 0.9946165613111536
Validation loss: 2.3937034124103755

Epoch: 6| Step: 5
Training loss: 1.2661777749132728
Validation loss: 2.3892462776989434

Epoch: 6| Step: 6
Training loss: 1.034986028530893
Validation loss: 2.4016216359637106

Epoch: 6| Step: 7
Training loss: 1.0619029443217396
Validation loss: 2.326661560562957

Epoch: 6| Step: 8
Training loss: 1.0997456386555127
Validation loss: 2.3885361973981936

Epoch: 6| Step: 9
Training loss: 0.822410153986443
Validation loss: 2.383170813872303

Epoch: 6| Step: 10
Training loss: 1.2861214581497427
Validation loss: 2.4319946142100184

Epoch: 6| Step: 11
Training loss: 0.909910176947824
Validation loss: 2.3117973969746473

Epoch: 6| Step: 12
Training loss: 1.0864495915579047
Validation loss: 2.4243435164437526

Epoch: 6| Step: 13
Training loss: 0.9957807460504104
Validation loss: 2.392318570739376

Epoch: 405| Step: 0
Training loss: 0.9783861756120869
Validation loss: 2.398662255584658

Epoch: 6| Step: 1
Training loss: 0.8342474850715863
Validation loss: 2.3838562028343193

Epoch: 6| Step: 2
Training loss: 1.198634897062103
Validation loss: 2.3812581743956964

Epoch: 6| Step: 3
Training loss: 1.6475476217840086
Validation loss: 2.369346366044074

Epoch: 6| Step: 4
Training loss: 0.8912844642406524
Validation loss: 2.467160529056823

Epoch: 6| Step: 5
Training loss: 1.175154509429596
Validation loss: 2.3967473908482835

Epoch: 6| Step: 6
Training loss: 0.9457465507309302
Validation loss: 2.3945966513350103

Epoch: 6| Step: 7
Training loss: 0.8128798403888384
Validation loss: 2.3873195435465115

Epoch: 6| Step: 8
Training loss: 1.0054960020413581
Validation loss: 2.3759792254309575

Epoch: 6| Step: 9
Training loss: 0.9409601254563458
Validation loss: 2.3410480864908156

Epoch: 6| Step: 10
Training loss: 1.0017388246625483
Validation loss: 2.4358137580726287

Epoch: 6| Step: 11
Training loss: 1.4467794860556193
Validation loss: 2.393895107204194

Epoch: 6| Step: 12
Training loss: 2.005998318771312
Validation loss: 2.3606741949951684

Epoch: 6| Step: 13
Training loss: 1.4715009858014365
Validation loss: 2.3529873002001067

Epoch: 406| Step: 0
Training loss: 0.9679560022384487
Validation loss: 2.425201841943886

Epoch: 6| Step: 1
Training loss: 1.0010720705197782
Validation loss: 2.4159444473064866

Epoch: 6| Step: 2
Training loss: 1.0606895055807546
Validation loss: 2.4684266636322896

Epoch: 6| Step: 3
Training loss: 1.8808810509118974
Validation loss: 2.3947705415930134

Epoch: 6| Step: 4
Training loss: 1.2754803052044899
Validation loss: 2.381872820878793

Epoch: 6| Step: 5
Training loss: 1.0074393594444102
Validation loss: 2.440675101581932

Epoch: 6| Step: 6
Training loss: 1.2260983797804847
Validation loss: 2.4231104001860304

Epoch: 6| Step: 7
Training loss: 1.058785171374975
Validation loss: 2.465548859344727

Epoch: 6| Step: 8
Training loss: 1.0932903413829367
Validation loss: 2.3714543739526053

Epoch: 6| Step: 9
Training loss: 1.0478329048024397
Validation loss: 2.412502673878358

Epoch: 6| Step: 10
Training loss: 1.17351544320697
Validation loss: 2.428429138340724

Epoch: 6| Step: 11
Training loss: 1.1901139050954075
Validation loss: 2.402392602172544

Epoch: 6| Step: 12
Training loss: 1.3859679432721874
Validation loss: 2.316124843006971

Epoch: 6| Step: 13
Training loss: 1.4057900418299931
Validation loss: 2.420675922840983

Epoch: 407| Step: 0
Training loss: 1.4033900530959096
Validation loss: 2.4623814125921233

Epoch: 6| Step: 1
Training loss: 0.8793940567955758
Validation loss: 2.3890141880501403

Epoch: 6| Step: 2
Training loss: 1.3673528080865693
Validation loss: 2.4688539819300557

Epoch: 6| Step: 3
Training loss: 1.2403077111376415
Validation loss: 2.461231140858749

Epoch: 6| Step: 4
Training loss: 1.2015118373711586
Validation loss: 2.285983297508191

Epoch: 6| Step: 5
Training loss: 1.3254656926985142
Validation loss: 2.401310255161969

Epoch: 6| Step: 6
Training loss: 0.998582192504642
Validation loss: 2.395276657069746

Epoch: 6| Step: 7
Training loss: 1.2006886572496425
Validation loss: 2.394121714463945

Epoch: 6| Step: 8
Training loss: 1.023961871979589
Validation loss: 2.3674834886820997

Epoch: 6| Step: 9
Training loss: 1.188691996574271
Validation loss: 2.36432383439099

Epoch: 6| Step: 10
Training loss: 0.9234194345530586
Validation loss: 2.400337831628578

Epoch: 6| Step: 11
Training loss: 2.123264277047383
Validation loss: 2.448200303826978

Epoch: 6| Step: 12
Training loss: 0.9883328149181977
Validation loss: 2.3920546049369498

Epoch: 6| Step: 13
Training loss: 1.2382217537338285
Validation loss: 2.4693500085099465

Epoch: 408| Step: 0
Training loss: 1.0942036913911821
Validation loss: 2.317844115802592

Epoch: 6| Step: 1
Training loss: 1.3852132012051317
Validation loss: 2.4692892355623943

Epoch: 6| Step: 2
Training loss: 1.338099732033469
Validation loss: 2.389039873528563

Epoch: 6| Step: 3
Training loss: 0.8789724367439881
Validation loss: 2.378236908261997

Epoch: 6| Step: 4
Training loss: 1.2472537390491734
Validation loss: 2.4072104695805643

Epoch: 6| Step: 5
Training loss: 1.0044817629307896
Validation loss: 2.427981622401786

Epoch: 6| Step: 6
Training loss: 1.3387446663943487
Validation loss: 2.307532270695572

Epoch: 6| Step: 7
Training loss: 1.0908443000908565
Validation loss: 2.3498492939419293

Epoch: 6| Step: 8
Training loss: 1.9854448693411548
Validation loss: 2.3725956618700583

Epoch: 6| Step: 9
Training loss: 1.0557380248069668
Validation loss: 2.438137429133635

Epoch: 6| Step: 10
Training loss: 0.913453771581333
Validation loss: 2.430702858566484

Epoch: 6| Step: 11
Training loss: 0.6666830527755477
Validation loss: 2.4034551411231693

Epoch: 6| Step: 12
Training loss: 1.0426204256900207
Validation loss: 2.2915515385978216

Epoch: 6| Step: 13
Training loss: 0.7764777338749729
Validation loss: 2.4111634977437015

Epoch: 409| Step: 0
Training loss: 1.2126309274989255
Validation loss: 2.396944978188237

Epoch: 6| Step: 1
Training loss: 1.032801991927208
Validation loss: 2.409625686417672

Epoch: 6| Step: 2
Training loss: 0.8878644356177643
Validation loss: 2.4071268658197527

Epoch: 6| Step: 3
Training loss: 1.2296873487692985
Validation loss: 2.3787840849500115

Epoch: 6| Step: 4
Training loss: 0.9148039785547147
Validation loss: 2.3890277948637157

Epoch: 6| Step: 5
Training loss: 1.2606721204084632
Validation loss: 2.4132486472794468

Epoch: 6| Step: 6
Training loss: 1.5060111240264888
Validation loss: 2.475101329618097

Epoch: 6| Step: 7
Training loss: 1.1735511998993036
Validation loss: 2.41153164556379

Epoch: 6| Step: 8
Training loss: 2.041156147039089
Validation loss: 2.4070560387519317

Epoch: 6| Step: 9
Training loss: 0.8551078278883775
Validation loss: 2.3283750085025874

Epoch: 6| Step: 10
Training loss: 1.0483518972001524
Validation loss: 2.440659073753862

Epoch: 6| Step: 11
Training loss: 0.954079946938807
Validation loss: 2.401365891463064

Epoch: 6| Step: 12
Training loss: 0.7542208474720614
Validation loss: 2.4009811510834362

Epoch: 6| Step: 13
Training loss: 1.0872760454410224
Validation loss: 2.4856669876234907

Epoch: 410| Step: 0
Training loss: 1.1731163062788152
Validation loss: 2.3547230820805902

Epoch: 6| Step: 1
Training loss: 0.9908751872767385
Validation loss: 2.412900349789289

Epoch: 6| Step: 2
Training loss: 1.086661666807908
Validation loss: 2.388830533554591

Epoch: 6| Step: 3
Training loss: 0.9734541902289988
Validation loss: 2.394620394849437

Epoch: 6| Step: 4
Training loss: 1.0544131451972565
Validation loss: 2.434599432420581

Epoch: 6| Step: 5
Training loss: 1.2639976682882894
Validation loss: 2.4397863052174493

Epoch: 6| Step: 6
Training loss: 1.0578315496490267
Validation loss: 2.3490299662949017

Epoch: 6| Step: 7
Training loss: 1.1680107491893483
Validation loss: 2.392735015968794

Epoch: 6| Step: 8
Training loss: 1.2619734940957001
Validation loss: 2.411125309653953

Epoch: 6| Step: 9
Training loss: 0.9776502121148596
Validation loss: 2.3063147910732127

Epoch: 6| Step: 10
Training loss: 0.8948699776276348
Validation loss: 2.3968174454523856

Epoch: 6| Step: 11
Training loss: 2.1091690528079425
Validation loss: 2.3866231378332583

Epoch: 6| Step: 12
Training loss: 0.8365638739168828
Validation loss: 2.401634343001711

Epoch: 6| Step: 13
Training loss: 1.564956717334421
Validation loss: 2.4153882705822323

Epoch: 411| Step: 0
Training loss: 0.9209437435004524
Validation loss: 2.439653676229302

Epoch: 6| Step: 1
Training loss: 1.4712843436719096
Validation loss: 2.459604076352445

Epoch: 6| Step: 2
Training loss: 0.6673590348015475
Validation loss: 2.406999665937191

Epoch: 6| Step: 3
Training loss: 1.1706252491263853
Validation loss: 2.464479563200266

Epoch: 6| Step: 4
Training loss: 0.6473158361634966
Validation loss: 2.448405329921076

Epoch: 6| Step: 5
Training loss: 0.8372212472730108
Validation loss: 2.403947159486983

Epoch: 6| Step: 6
Training loss: 1.230318090509954
Validation loss: 2.4410980463223586

Epoch: 6| Step: 7
Training loss: 0.8791223557019017
Validation loss: 2.3868796446044014

Epoch: 6| Step: 8
Training loss: 0.8837956043654638
Validation loss: 2.4233152163434966

Epoch: 6| Step: 9
Training loss: 1.5027842113539707
Validation loss: 2.382843496146918

Epoch: 6| Step: 10
Training loss: 1.3206854299213415
Validation loss: 2.4640381650135095

Epoch: 6| Step: 11
Training loss: 1.1079757354950792
Validation loss: 2.3328056669044837

Epoch: 6| Step: 12
Training loss: 1.938987530066697
Validation loss: 2.3975426798818704

Epoch: 6| Step: 13
Training loss: 1.0722006967477895
Validation loss: 2.4378928884649937

Epoch: 412| Step: 0
Training loss: 1.2620841521727175
Validation loss: 2.443542494066707

Epoch: 6| Step: 1
Training loss: 1.1051297156547537
Validation loss: 2.3731452681463536

Epoch: 6| Step: 2
Training loss: 1.8716624755450115
Validation loss: 2.382746802113057

Epoch: 6| Step: 3
Training loss: 1.0090093086047691
Validation loss: 2.409592230265733

Epoch: 6| Step: 4
Training loss: 1.321446264914398
Validation loss: 2.3649960038027067

Epoch: 6| Step: 5
Training loss: 0.9678408140253928
Validation loss: 2.3926640350273884

Epoch: 6| Step: 6
Training loss: 0.978000436718381
Validation loss: 2.360301702788397

Epoch: 6| Step: 7
Training loss: 1.266205925132037
Validation loss: 2.3633678778718696

Epoch: 6| Step: 8
Training loss: 1.3309903818495188
Validation loss: 2.3947021828060655

Epoch: 6| Step: 9
Training loss: 0.8945207886729648
Validation loss: 2.4147962811707417

Epoch: 6| Step: 10
Training loss: 0.6244103272594502
Validation loss: 2.421077103294133

Epoch: 6| Step: 11
Training loss: 0.9313300872774383
Validation loss: 2.4467808081730222

Epoch: 6| Step: 12
Training loss: 1.2561439203672233
Validation loss: 2.3628035892911536

Epoch: 6| Step: 13
Training loss: 1.1155099077455854
Validation loss: 2.3733092174132073

Epoch: 413| Step: 0
Training loss: 1.2700323905719124
Validation loss: 2.381111061255147

Epoch: 6| Step: 1
Training loss: 1.3546600127813924
Validation loss: 2.430938477791364

Epoch: 6| Step: 2
Training loss: 0.9081413330058563
Validation loss: 2.4120007203561435

Epoch: 6| Step: 3
Training loss: 1.104770723091989
Validation loss: 2.318611745624058

Epoch: 6| Step: 4
Training loss: 0.7450079081582851
Validation loss: 2.3340211171773784

Epoch: 6| Step: 5
Training loss: 0.9054491516572741
Validation loss: 2.375937715522382

Epoch: 6| Step: 6
Training loss: 1.0003834823597695
Validation loss: 2.3782525774148

Epoch: 6| Step: 7
Training loss: 1.0400972878361248
Validation loss: 2.3465090967241515

Epoch: 6| Step: 8
Training loss: 1.2510323076535996
Validation loss: 2.4077384360741614

Epoch: 6| Step: 9
Training loss: 1.1602229346431225
Validation loss: 2.4425690110046316

Epoch: 6| Step: 10
Training loss: 1.03986259002012
Validation loss: 2.4082475991510313

Epoch: 6| Step: 11
Training loss: 1.1947369155821854
Validation loss: 2.3943432808068232

Epoch: 6| Step: 12
Training loss: 0.859316459742637
Validation loss: 2.4292993973170174

Epoch: 6| Step: 13
Training loss: 2.4270194267623983
Validation loss: 2.36949856331689

Epoch: 414| Step: 0
Training loss: 0.9216372619810717
Validation loss: 2.436372947069129

Epoch: 6| Step: 1
Training loss: 1.3266928187545064
Validation loss: 2.35783743487602

Epoch: 6| Step: 2
Training loss: 1.230398606011602
Validation loss: 2.4044421164034993

Epoch: 6| Step: 3
Training loss: 0.9557809564484923
Validation loss: 2.418250387831294

Epoch: 6| Step: 4
Training loss: 0.7061542108442765
Validation loss: 2.417878465224109

Epoch: 6| Step: 5
Training loss: 0.963250361904113
Validation loss: 2.3413909962964015

Epoch: 6| Step: 6
Training loss: 1.316996365726818
Validation loss: 2.42033585125676

Epoch: 6| Step: 7
Training loss: 0.7363384863329352
Validation loss: 2.3620489015467308

Epoch: 6| Step: 8
Training loss: 0.889428321918083
Validation loss: 2.34906319364912

Epoch: 6| Step: 9
Training loss: 1.0216696809990762
Validation loss: 2.3935423895577177

Epoch: 6| Step: 10
Training loss: 0.8774332885706333
Validation loss: 2.3749491319676186

Epoch: 6| Step: 11
Training loss: 1.2303495803527824
Validation loss: 2.324848459046274

Epoch: 6| Step: 12
Training loss: 0.7157496980859012
Validation loss: 2.3980431974955714

Epoch: 6| Step: 13
Training loss: 2.563080233499473
Validation loss: 2.3670248996963736

Epoch: 415| Step: 0
Training loss: 0.9755921692978516
Validation loss: 2.4532758254783094

Epoch: 6| Step: 1
Training loss: 1.1116892357002701
Validation loss: 2.4204334754886885

Epoch: 6| Step: 2
Training loss: 1.0536678330140345
Validation loss: 2.433544529708926

Epoch: 6| Step: 3
Training loss: 0.8074316252113732
Validation loss: 2.395546639629529

Epoch: 6| Step: 4
Training loss: 0.9645190290983524
Validation loss: 2.4910921918685247

Epoch: 6| Step: 5
Training loss: 2.2453372112446064
Validation loss: 2.3878895842084775

Epoch: 6| Step: 6
Training loss: 1.2500798199917909
Validation loss: 2.4257960265649485

Epoch: 6| Step: 7
Training loss: 0.8495929584890259
Validation loss: 2.4136988900326357

Epoch: 6| Step: 8
Training loss: 1.139517782349575
Validation loss: 2.379639299281184

Epoch: 6| Step: 9
Training loss: 0.8816526778060234
Validation loss: 2.387937921530474

Epoch: 6| Step: 10
Training loss: 1.1111775113504399
Validation loss: 2.3869119541160346

Epoch: 6| Step: 11
Training loss: 0.9134128576890156
Validation loss: 2.437439063998319

Epoch: 6| Step: 12
Training loss: 1.5634611606732793
Validation loss: 2.428434122194208

Epoch: 6| Step: 13
Training loss: 0.8973282642280367
Validation loss: 2.3748056972362566

Epoch: 416| Step: 0
Training loss: 1.045795111445347
Validation loss: 2.4055506469417045

Epoch: 6| Step: 1
Training loss: 0.8913219134515292
Validation loss: 2.3534676590970296

Epoch: 6| Step: 2
Training loss: 0.9731322812669776
Validation loss: 2.4373351189375074

Epoch: 6| Step: 3
Training loss: 0.8421656250103275
Validation loss: 2.3900018049035845

Epoch: 6| Step: 4
Training loss: 1.2253657048141458
Validation loss: 2.3804930120461383

Epoch: 6| Step: 5
Training loss: 1.939644457396512
Validation loss: 2.425162096339028

Epoch: 6| Step: 6
Training loss: 1.2427254237843461
Validation loss: 2.3976981190540543

Epoch: 6| Step: 7
Training loss: 0.8155954523690337
Validation loss: 2.3389129115608434

Epoch: 6| Step: 8
Training loss: 1.240913553576046
Validation loss: 2.418665852150403

Epoch: 6| Step: 9
Training loss: 1.3319647540277821
Validation loss: 2.4789762236806663

Epoch: 6| Step: 10
Training loss: 1.2150384188884729
Validation loss: 2.3878347413558187

Epoch: 6| Step: 11
Training loss: 0.9229399139254932
Validation loss: 2.4089459159603623

Epoch: 6| Step: 12
Training loss: 1.2098732486258543
Validation loss: 2.4018752035922564

Epoch: 6| Step: 13
Training loss: 1.0189658749512593
Validation loss: 2.3501993352671033

Epoch: 417| Step: 0
Training loss: 0.9091507756505
Validation loss: 2.386644635114567

Epoch: 6| Step: 1
Training loss: 0.771975976308286
Validation loss: 2.4309448664822764

Epoch: 6| Step: 2
Training loss: 0.901878468169102
Validation loss: 2.360930224355627

Epoch: 6| Step: 3
Training loss: 1.093401117539938
Validation loss: 2.403071981817295

Epoch: 6| Step: 4
Training loss: 1.1355712447095594
Validation loss: 2.355144089466904

Epoch: 6| Step: 5
Training loss: 1.2731115942180393
Validation loss: 2.390676989128456

Epoch: 6| Step: 6
Training loss: 1.1972163378479201
Validation loss: 2.3504352434450655

Epoch: 6| Step: 7
Training loss: 1.8845971857416888
Validation loss: 2.422893977479353

Epoch: 6| Step: 8
Training loss: 0.8947945419697569
Validation loss: 2.442265855893177

Epoch: 6| Step: 9
Training loss: 1.1287806351941112
Validation loss: 2.4034690837721477

Epoch: 6| Step: 10
Training loss: 1.1861020442716361
Validation loss: 2.4295886490181124

Epoch: 6| Step: 11
Training loss: 1.1041014610086688
Validation loss: 2.425173229698418

Epoch: 6| Step: 12
Training loss: 0.9940146495691321
Validation loss: 2.311413345291364

Epoch: 6| Step: 13
Training loss: 0.876799232216659
Validation loss: 2.485151598657605

Epoch: 418| Step: 0
Training loss: 1.0585984796509886
Validation loss: 2.3546759714863605

Epoch: 6| Step: 1
Training loss: 0.6934038604649769
Validation loss: 2.405285332263524

Epoch: 6| Step: 2
Training loss: 1.0305336284675362
Validation loss: 2.398904427152438

Epoch: 6| Step: 3
Training loss: 0.9200303323555282
Validation loss: 2.3722066703338416

Epoch: 6| Step: 4
Training loss: 0.8094344997260564
Validation loss: 2.423403330937884

Epoch: 6| Step: 5
Training loss: 1.0484155735048273
Validation loss: 2.4543997678555685

Epoch: 6| Step: 6
Training loss: 1.453306043278248
Validation loss: 2.4200789339807645

Epoch: 6| Step: 7
Training loss: 0.9834601071368169
Validation loss: 2.4796341865157965

Epoch: 6| Step: 8
Training loss: 1.079081788032901
Validation loss: 2.4438468280500016

Epoch: 6| Step: 9
Training loss: 1.4871512701467435
Validation loss: 2.4171083963863125

Epoch: 6| Step: 10
Training loss: 1.1104899431758277
Validation loss: 2.393006049121448

Epoch: 6| Step: 11
Training loss: 1.8136313623475417
Validation loss: 2.3765208432583567

Epoch: 6| Step: 12
Training loss: 1.078588303241795
Validation loss: 2.4306004401036003

Epoch: 6| Step: 13
Training loss: 1.256596895974269
Validation loss: 2.421586322284828

Epoch: 419| Step: 0
Training loss: 1.0446813573950526
Validation loss: 2.425400291721166

Epoch: 6| Step: 1
Training loss: 1.1684309131143842
Validation loss: 2.4082766903242825

Epoch: 6| Step: 2
Training loss: 1.2688867899249552
Validation loss: 2.4104988292246072

Epoch: 6| Step: 3
Training loss: 0.7788871510267559
Validation loss: 2.3404405287418353

Epoch: 6| Step: 4
Training loss: 1.2482766669687388
Validation loss: 2.327030807611644

Epoch: 6| Step: 5
Training loss: 0.9146199930848267
Validation loss: 2.449489045746209

Epoch: 6| Step: 6
Training loss: 1.9397863618471376
Validation loss: 2.4280582057862525

Epoch: 6| Step: 7
Training loss: 0.9123793208653239
Validation loss: 2.3220677376302734

Epoch: 6| Step: 8
Training loss: 0.763649825536363
Validation loss: 2.275957884644699

Epoch: 6| Step: 9
Training loss: 0.8904566689411562
Validation loss: 2.4119285313435785

Epoch: 6| Step: 10
Training loss: 0.9326015930469772
Validation loss: 2.362189405192602

Epoch: 6| Step: 11
Training loss: 1.1670978578106104
Validation loss: 2.4286887369427226

Epoch: 6| Step: 12
Training loss: 1.2374502576598767
Validation loss: 2.3976908067219047

Epoch: 6| Step: 13
Training loss: 1.1415948272062595
Validation loss: 2.4155750861002576

Epoch: 420| Step: 0
Training loss: 0.974678082996997
Validation loss: 2.3986923858878675

Epoch: 6| Step: 1
Training loss: 1.0207916887054094
Validation loss: 2.363019345146991

Epoch: 6| Step: 2
Training loss: 0.7539598910366669
Validation loss: 2.3841369401686374

Epoch: 6| Step: 3
Training loss: 0.9167086129272566
Validation loss: 2.40320688784483

Epoch: 6| Step: 4
Training loss: 2.0285291789200923
Validation loss: 2.414340596744624

Epoch: 6| Step: 5
Training loss: 0.9087125272515164
Validation loss: 2.422196301368644

Epoch: 6| Step: 6
Training loss: 1.0078072362954535
Validation loss: 2.3398596455793546

Epoch: 6| Step: 7
Training loss: 1.0986079641287176
Validation loss: 2.445704013934306

Epoch: 6| Step: 8
Training loss: 0.791964566916835
Validation loss: 2.451703739089107

Epoch: 6| Step: 9
Training loss: 1.2113522219360042
Validation loss: 2.3895741618996293

Epoch: 6| Step: 10
Training loss: 0.9898126972147947
Validation loss: 2.4266497736032617

Epoch: 6| Step: 11
Training loss: 1.0628721483020285
Validation loss: 2.4700835180325966

Epoch: 6| Step: 12
Training loss: 0.9329874152656441
Validation loss: 2.272582340662692

Epoch: 6| Step: 13
Training loss: 1.7119804930867983
Validation loss: 2.478510905278551

Epoch: 421| Step: 0
Training loss: 0.9321511906897023
Validation loss: 2.4516305545701447

Epoch: 6| Step: 1
Training loss: 0.9273775719610702
Validation loss: 2.3919156074845933

Epoch: 6| Step: 2
Training loss: 0.969287415611492
Validation loss: 2.3904385543268725

Epoch: 6| Step: 3
Training loss: 0.9894847553075403
Validation loss: 2.428905057063919

Epoch: 6| Step: 4
Training loss: 1.0727169011383166
Validation loss: 2.3787520788876417

Epoch: 6| Step: 5
Training loss: 0.9503342467118228
Validation loss: 2.387520749088325

Epoch: 6| Step: 6
Training loss: 1.3273552851992425
Validation loss: 2.3719748053655314

Epoch: 6| Step: 7
Training loss: 0.7492298702174492
Validation loss: 2.389324948130967

Epoch: 6| Step: 8
Training loss: 0.9313251913040632
Validation loss: 2.4220916894572087

Epoch: 6| Step: 9
Training loss: 1.0721598922212652
Validation loss: 2.378207084197812

Epoch: 6| Step: 10
Training loss: 0.8747920742943954
Validation loss: 2.370657528693555

Epoch: 6| Step: 11
Training loss: 0.7059298203089859
Validation loss: 2.3971047650318202

Epoch: 6| Step: 12
Training loss: 2.1942446680785426
Validation loss: 2.4819881804274893

Epoch: 6| Step: 13
Training loss: 1.5519833457879073
Validation loss: 2.4617838523893862

Epoch: 422| Step: 0
Training loss: 1.9271371644895534
Validation loss: 2.469257629134834

Epoch: 6| Step: 1
Training loss: 0.93548606085574
Validation loss: 2.3874151654068174

Epoch: 6| Step: 2
Training loss: 1.1212811994517782
Validation loss: 2.4118237015422834

Epoch: 6| Step: 3
Training loss: 1.2188716729879328
Validation loss: 2.4586886854245624

Epoch: 6| Step: 4
Training loss: 0.6708871099190412
Validation loss: 2.46523281568465

Epoch: 6| Step: 5
Training loss: 0.9040650962583973
Validation loss: 2.4066434670910257

Epoch: 6| Step: 6
Training loss: 1.3787280175539498
Validation loss: 2.366729666061899

Epoch: 6| Step: 7
Training loss: 0.7931355268111975
Validation loss: 2.3954111245300056

Epoch: 6| Step: 8
Training loss: 0.8802633362387935
Validation loss: 2.366753052225793

Epoch: 6| Step: 9
Training loss: 1.1475473184740148
Validation loss: 2.4133939644675646

Epoch: 6| Step: 10
Training loss: 1.2637632357605104
Validation loss: 2.3833449106632982

Epoch: 6| Step: 11
Training loss: 1.0915307554908817
Validation loss: 2.386095868018511

Epoch: 6| Step: 12
Training loss: 0.9860451471775209
Validation loss: 2.3791843485269895

Epoch: 6| Step: 13
Training loss: 0.4770980077538425
Validation loss: 2.388291207111839

Epoch: 423| Step: 0
Training loss: 1.0434242996701537
Validation loss: 2.3535352908030096

Epoch: 6| Step: 1
Training loss: 0.9770451993082211
Validation loss: 2.310133665898579

Epoch: 6| Step: 2
Training loss: 0.8473477483391622
Validation loss: 2.4105234498454116

Epoch: 6| Step: 3
Training loss: 0.8317940602237459
Validation loss: 2.3905679040586922

Epoch: 6| Step: 4
Training loss: 1.2323044903889524
Validation loss: 2.336829809872478

Epoch: 6| Step: 5
Training loss: 1.0123606527065225
Validation loss: 2.401969285418433

Epoch: 6| Step: 6
Training loss: 0.7472444618047945
Validation loss: 2.375451475192026

Epoch: 6| Step: 7
Training loss: 1.240402570718502
Validation loss: 2.3576830201662626

Epoch: 6| Step: 8
Training loss: 1.2652479952449778
Validation loss: 2.326664900279107

Epoch: 6| Step: 9
Training loss: 2.009977012616701
Validation loss: 2.3197359774999744

Epoch: 6| Step: 10
Training loss: 1.10306743871489
Validation loss: 2.405599213390239

Epoch: 6| Step: 11
Training loss: 0.9669839389043168
Validation loss: 2.4200457928937853

Epoch: 6| Step: 12
Training loss: 0.925354646021153
Validation loss: 2.4785736583243625

Epoch: 6| Step: 13
Training loss: 1.1632407443319663
Validation loss: 2.4572363165207642

Epoch: 424| Step: 0
Training loss: 1.1370988452860225
Validation loss: 2.4358483001589444

Epoch: 6| Step: 1
Training loss: 1.0363426463421457
Validation loss: 2.3633026819046337

Epoch: 6| Step: 2
Training loss: 1.1382843981027106
Validation loss: 2.3609802168391054

Epoch: 6| Step: 3
Training loss: 0.7356229689058771
Validation loss: 2.4394261212458077

Epoch: 6| Step: 4
Training loss: 1.1873363080891508
Validation loss: 2.453015744804563

Epoch: 6| Step: 5
Training loss: 0.9982646547766065
Validation loss: 2.278264575664315

Epoch: 6| Step: 6
Training loss: 0.941905320710381
Validation loss: 2.371142934629071

Epoch: 6| Step: 7
Training loss: 1.3406292361746064
Validation loss: 2.4715851879427624

Epoch: 6| Step: 8
Training loss: 1.213866696468877
Validation loss: 2.427426337504391

Epoch: 6| Step: 9
Training loss: 1.337857834908396
Validation loss: 2.4768702166169985

Epoch: 6| Step: 10
Training loss: 0.7762430343683971
Validation loss: 2.3951332381982486

Epoch: 6| Step: 11
Training loss: 0.9877020001538626
Validation loss: 2.3958986166895917

Epoch: 6| Step: 12
Training loss: 1.963198327386512
Validation loss: 2.359205560834954

Epoch: 6| Step: 13
Training loss: 0.8937921260696043
Validation loss: 2.3631318135526502

Epoch: 425| Step: 0
Training loss: 2.145516702445169
Validation loss: 2.3773617521746018

Epoch: 6| Step: 1
Training loss: 1.1272421851243637
Validation loss: 2.3612718134976185

Epoch: 6| Step: 2
Training loss: 0.9685527846880571
Validation loss: 2.3894271954349917

Epoch: 6| Step: 3
Training loss: 1.1773892683052973
Validation loss: 2.372979098243844

Epoch: 6| Step: 4
Training loss: 1.1695591741679825
Validation loss: 2.3467023099374273

Epoch: 6| Step: 5
Training loss: 0.8905616536952622
Validation loss: 2.3518545557891386

Epoch: 6| Step: 6
Training loss: 1.2428938099192528
Validation loss: 2.414137730280949

Epoch: 6| Step: 7
Training loss: 0.8934319083488145
Validation loss: 2.354914293229464

Epoch: 6| Step: 8
Training loss: 1.401142338913893
Validation loss: 2.3832713588565393

Epoch: 6| Step: 9
Training loss: 1.1028401966243642
Validation loss: 2.3478603080864797

Epoch: 6| Step: 10
Training loss: 0.8356182522668925
Validation loss: 2.3430917500514554

Epoch: 6| Step: 11
Training loss: 0.8865507865833857
Validation loss: 2.433826537122122

Epoch: 6| Step: 12
Training loss: 1.142955958828695
Validation loss: 2.4145188898931997

Epoch: 6| Step: 13
Training loss: 1.1511134417265623
Validation loss: 2.422367915108956

Epoch: 426| Step: 0
Training loss: 1.0558294824792438
Validation loss: 2.455640194338913

Epoch: 6| Step: 1
Training loss: 1.1485016993010608
Validation loss: 2.4387530757335734

Epoch: 6| Step: 2
Training loss: 1.1444678175081593
Validation loss: 2.417756802924334

Epoch: 6| Step: 3
Training loss: 0.8980101190837986
Validation loss: 2.4067787076456866

Epoch: 6| Step: 4
Training loss: 0.8914974690870473
Validation loss: 2.4476150847067992

Epoch: 6| Step: 5
Training loss: 0.9884950308590428
Validation loss: 2.500388907874595

Epoch: 6| Step: 6
Training loss: 1.4352067817011056
Validation loss: 2.3844528138881973

Epoch: 6| Step: 7
Training loss: 0.7850519746837559
Validation loss: 2.3786710697681386

Epoch: 6| Step: 8
Training loss: 1.761823765232019
Validation loss: 2.3635336551036867

Epoch: 6| Step: 9
Training loss: 1.3501178760635522
Validation loss: 2.3706601024357874

Epoch: 6| Step: 10
Training loss: 0.7959521316483481
Validation loss: 2.3905448420248963

Epoch: 6| Step: 11
Training loss: 0.888806578100139
Validation loss: 2.3572127875165094

Epoch: 6| Step: 12
Training loss: 1.0431597245495252
Validation loss: 2.3350186070408343

Epoch: 6| Step: 13
Training loss: 0.9228274387657989
Validation loss: 2.3822578783940758

Epoch: 427| Step: 0
Training loss: 1.2706705937646767
Validation loss: 2.419564120681916

Epoch: 6| Step: 1
Training loss: 1.3264272272628617
Validation loss: 2.341464739777727

Epoch: 6| Step: 2
Training loss: 1.3176895361402716
Validation loss: 2.3831786118028817

Epoch: 6| Step: 3
Training loss: 0.6183698411105203
Validation loss: 2.359849389491364

Epoch: 6| Step: 4
Training loss: 0.9269676815004039
Validation loss: 2.4322034607220675

Epoch: 6| Step: 5
Training loss: 0.5903812510983111
Validation loss: 2.41501968628329

Epoch: 6| Step: 6
Training loss: 0.9990485552690707
Validation loss: 2.5020611131874815

Epoch: 6| Step: 7
Training loss: 0.9485798322033295
Validation loss: 2.3144022471340038

Epoch: 6| Step: 8
Training loss: 0.787760727727319
Validation loss: 2.352054657688587

Epoch: 6| Step: 9
Training loss: 0.7822747947881563
Validation loss: 2.376323523307408

Epoch: 6| Step: 10
Training loss: 1.792998336514639
Validation loss: 2.350726321447318

Epoch: 6| Step: 11
Training loss: 0.9846615449952556
Validation loss: 2.3777587284730943

Epoch: 6| Step: 12
Training loss: 1.2061846087821515
Validation loss: 2.3931528788253638

Epoch: 6| Step: 13
Training loss: 0.7969407447172688
Validation loss: 2.4152481476034615

Epoch: 428| Step: 0
Training loss: 1.953810426603735
Validation loss: 2.3520967700162854

Epoch: 6| Step: 1
Training loss: 0.8571206782514244
Validation loss: 2.4298712590323652

Epoch: 6| Step: 2
Training loss: 1.1875064247359095
Validation loss: 2.3438668389405932

Epoch: 6| Step: 3
Training loss: 1.162646821707552
Validation loss: 2.346002219891682

Epoch: 6| Step: 4
Training loss: 0.7694740467788561
Validation loss: 2.2769590076836126

Epoch: 6| Step: 5
Training loss: 1.1476801236800624
Validation loss: 2.347030435297728

Epoch: 6| Step: 6
Training loss: 0.6927407312106958
Validation loss: 2.427140424080617

Epoch: 6| Step: 7
Training loss: 0.9406765844451734
Validation loss: 2.336167781293457

Epoch: 6| Step: 8
Training loss: 1.151973445036585
Validation loss: 2.3537760207257343

Epoch: 6| Step: 9
Training loss: 1.074182350235572
Validation loss: 2.3257380745800016

Epoch: 6| Step: 10
Training loss: 1.0357610123527932
Validation loss: 2.4670130729498343

Epoch: 6| Step: 11
Training loss: 0.9237637971252898
Validation loss: 2.4353343229023365

Epoch: 6| Step: 12
Training loss: 0.739269825927197
Validation loss: 2.382183828117886

Epoch: 6| Step: 13
Training loss: 1.2360855515417555
Validation loss: 2.3807302494118265

Epoch: 429| Step: 0
Training loss: 1.135699782231787
Validation loss: 2.387848155733871

Epoch: 6| Step: 1
Training loss: 1.0507978133133469
Validation loss: 2.353919722396865

Epoch: 6| Step: 2
Training loss: 0.8408812745575985
Validation loss: 2.3471745980134657

Epoch: 6| Step: 3
Training loss: 1.0930411630437213
Validation loss: 2.3217024570713978

Epoch: 6| Step: 4
Training loss: 0.985969946761126
Validation loss: 2.3475578063195894

Epoch: 6| Step: 5
Training loss: 0.8940681024807193
Validation loss: 2.4213483525605057

Epoch: 6| Step: 6
Training loss: 1.1938751155137086
Validation loss: 2.448800598729659

Epoch: 6| Step: 7
Training loss: 0.834904397756746
Validation loss: 2.433069370973309

Epoch: 6| Step: 8
Training loss: 0.7623898801863473
Validation loss: 2.4610474733312295

Epoch: 6| Step: 9
Training loss: 0.8864355433246852
Validation loss: 2.463173747981652

Epoch: 6| Step: 10
Training loss: 0.9094445388791048
Validation loss: 2.37771957421615

Epoch: 6| Step: 11
Training loss: 0.888256571216364
Validation loss: 2.371205030509568

Epoch: 6| Step: 12
Training loss: 1.8864687167520318
Validation loss: 2.353171493689117

Epoch: 6| Step: 13
Training loss: 1.2317898394655376
Validation loss: 2.3410603864243966

Epoch: 430| Step: 0
Training loss: 0.9306194538901665
Validation loss: 2.3598676456624688

Epoch: 6| Step: 1
Training loss: 0.7813828927500253
Validation loss: 2.321647474629824

Epoch: 6| Step: 2
Training loss: 1.0571589582369587
Validation loss: 2.402887755542931

Epoch: 6| Step: 3
Training loss: 1.0574238072896607
Validation loss: 2.325887232945735

Epoch: 6| Step: 4
Training loss: 1.0649779539557633
Validation loss: 2.4035356839645816

Epoch: 6| Step: 5
Training loss: 1.8432834487543641
Validation loss: 2.4053704271356473

Epoch: 6| Step: 6
Training loss: 0.8864944443181674
Validation loss: 2.2818689409912998

Epoch: 6| Step: 7
Training loss: 0.9157992434788229
Validation loss: 2.3240093293687822

Epoch: 6| Step: 8
Training loss: 1.1306590691827036
Validation loss: 2.3359485757243967

Epoch: 6| Step: 9
Training loss: 1.1969668838649363
Validation loss: 2.430564679559868

Epoch: 6| Step: 10
Training loss: 1.286198526729736
Validation loss: 2.3692598604634325

Epoch: 6| Step: 11
Training loss: 1.0517558856687899
Validation loss: 2.4576336355213986

Epoch: 6| Step: 12
Training loss: 0.9180129020299536
Validation loss: 2.3886523192427935

Epoch: 6| Step: 13
Training loss: 1.1123171195255643
Validation loss: 2.366995116318358

Epoch: 431| Step: 0
Training loss: 1.259809720945787
Validation loss: 2.275405577705056

Epoch: 6| Step: 1
Training loss: 0.8032843197977428
Validation loss: 2.351849210174575

Epoch: 6| Step: 2
Training loss: 1.0382288980596885
Validation loss: 2.3533154686689506

Epoch: 6| Step: 3
Training loss: 0.8232226748433569
Validation loss: 2.4258236327770524

Epoch: 6| Step: 4
Training loss: 1.0163373356414325
Validation loss: 2.3052794683279707

Epoch: 6| Step: 5
Training loss: 0.7012407274364145
Validation loss: 2.349047216289872

Epoch: 6| Step: 6
Training loss: 1.3250016230447292
Validation loss: 2.392921517871841

Epoch: 6| Step: 7
Training loss: 0.8350480240585753
Validation loss: 2.490837256787214

Epoch: 6| Step: 8
Training loss: 0.9795124207800077
Validation loss: 2.4698723136723113

Epoch: 6| Step: 9
Training loss: 2.046638766335712
Validation loss: 2.414790375268697

Epoch: 6| Step: 10
Training loss: 0.6748218009755043
Validation loss: 2.427650144294548

Epoch: 6| Step: 11
Training loss: 1.0467751298780115
Validation loss: 2.3657935878222918

Epoch: 6| Step: 12
Training loss: 1.1502809326516334
Validation loss: 2.3472916116166576

Epoch: 6| Step: 13
Training loss: 1.0478267613415146
Validation loss: 2.4484621723505495

Epoch: 432| Step: 0
Training loss: 1.2845194900061612
Validation loss: 2.454912855504146

Epoch: 6| Step: 1
Training loss: 1.3658570273630701
Validation loss: 2.3768959276818458

Epoch: 6| Step: 2
Training loss: 0.960559522523025
Validation loss: 2.451900523797552

Epoch: 6| Step: 3
Training loss: 0.4674957343024187
Validation loss: 2.3714322751989356

Epoch: 6| Step: 4
Training loss: 1.0263065570668295
Validation loss: 2.4096500159384027

Epoch: 6| Step: 5
Training loss: 1.8442001439828282
Validation loss: 2.3216723771674292

Epoch: 6| Step: 6
Training loss: 0.7816764049357212
Validation loss: 2.4003104203984873

Epoch: 6| Step: 7
Training loss: 1.063259414347739
Validation loss: 2.349648368132124

Epoch: 6| Step: 8
Training loss: 0.766179253951176
Validation loss: 2.339848656298008

Epoch: 6| Step: 9
Training loss: 1.017011019490425
Validation loss: 2.3840462215301623

Epoch: 6| Step: 10
Training loss: 0.9996042064370639
Validation loss: 2.3579910762498013

Epoch: 6| Step: 11
Training loss: 0.8360589197696267
Validation loss: 2.454050080252916

Epoch: 6| Step: 12
Training loss: 1.0153346893900956
Validation loss: 2.3425616756841423

Epoch: 6| Step: 13
Training loss: 0.6141814652924094
Validation loss: 2.392685704377361

Epoch: 433| Step: 0
Training loss: 0.9072693977878641
Validation loss: 2.401205210558753

Epoch: 6| Step: 1
Training loss: 1.0452547202798628
Validation loss: 2.3937126807696023

Epoch: 6| Step: 2
Training loss: 1.0858372703787296
Validation loss: 2.377789992115578

Epoch: 6| Step: 3
Training loss: 0.9921516351900994
Validation loss: 2.341938841052728

Epoch: 6| Step: 4
Training loss: 1.1440865235253748
Validation loss: 2.477682032247309

Epoch: 6| Step: 5
Training loss: 1.9481723705966139
Validation loss: 2.3901749643800008

Epoch: 6| Step: 6
Training loss: 1.0070493899206852
Validation loss: 2.4180345171980244

Epoch: 6| Step: 7
Training loss: 0.8153251900787408
Validation loss: 2.3695251754936537

Epoch: 6| Step: 8
Training loss: 1.0529998274764076
Validation loss: 2.3238031244757806

Epoch: 6| Step: 9
Training loss: 0.7305770222596631
Validation loss: 2.393245643181316

Epoch: 6| Step: 10
Training loss: 0.7445535790536528
Validation loss: 2.366496997432093

Epoch: 6| Step: 11
Training loss: 1.000366680152136
Validation loss: 2.417295881267234

Epoch: 6| Step: 12
Training loss: 0.7939267690071948
Validation loss: 2.4260959961026516

Epoch: 6| Step: 13
Training loss: 0.7976321942534481
Validation loss: 2.358294652487338

Epoch: 434| Step: 0
Training loss: 0.8278746676403301
Validation loss: 2.4115822474350943

Epoch: 6| Step: 1
Training loss: 1.1032339090936851
Validation loss: 2.359128169411647

Epoch: 6| Step: 2
Training loss: 0.9119506959303564
Validation loss: 2.343708252893907

Epoch: 6| Step: 3
Training loss: 0.9452959169556897
Validation loss: 2.381117874332872

Epoch: 6| Step: 4
Training loss: 0.9416218111163223
Validation loss: 2.3540710885736282

Epoch: 6| Step: 5
Training loss: 1.0450926453986893
Validation loss: 2.327219660754435

Epoch: 6| Step: 6
Training loss: 0.8735060881570107
Validation loss: 2.322642192372607

Epoch: 6| Step: 7
Training loss: 1.2066998566933191
Validation loss: 2.3799296061714355

Epoch: 6| Step: 8
Training loss: 0.7537757879245682
Validation loss: 2.4043871675683506

Epoch: 6| Step: 9
Training loss: 0.9529010947461485
Validation loss: 2.3256323007194095

Epoch: 6| Step: 10
Training loss: 1.781287008871463
Validation loss: 2.4250744209333983

Epoch: 6| Step: 11
Training loss: 0.9410168487426858
Validation loss: 2.3372822876261634

Epoch: 6| Step: 12
Training loss: 1.4091570582063193
Validation loss: 2.4370845880325436

Epoch: 6| Step: 13
Training loss: 0.8669740912604249
Validation loss: 2.4317476472655084

Epoch: 435| Step: 0
Training loss: 0.9596029489201581
Validation loss: 2.425500700122088

Epoch: 6| Step: 1
Training loss: 1.262512429808813
Validation loss: 2.3713165414777535

Epoch: 6| Step: 2
Training loss: 1.163500605410495
Validation loss: 2.3490997960162425

Epoch: 6| Step: 3
Training loss: 1.1456626533776155
Validation loss: 2.4047131722662303

Epoch: 6| Step: 4
Training loss: 1.0701536074569677
Validation loss: 2.3658077735564635

Epoch: 6| Step: 5
Training loss: 1.7506241366606616
Validation loss: 2.34181637976383

Epoch: 6| Step: 6
Training loss: 1.3911383035109195
Validation loss: 2.3396991881816196

Epoch: 6| Step: 7
Training loss: 0.9306830517331642
Validation loss: 2.3837428694197444

Epoch: 6| Step: 8
Training loss: 1.1508924235026352
Validation loss: 2.2964206313387368

Epoch: 6| Step: 9
Training loss: 0.8205895818779304
Validation loss: 2.3882447586836335

Epoch: 6| Step: 10
Training loss: 0.731298495583778
Validation loss: 2.393837790468534

Epoch: 6| Step: 11
Training loss: 1.0437931988393867
Validation loss: 2.401458880871648

Epoch: 6| Step: 12
Training loss: 0.8544462878297329
Validation loss: 2.388205370576025

Epoch: 6| Step: 13
Training loss: 0.7067285174129828
Validation loss: 2.3041947488950676

Epoch: 436| Step: 0
Training loss: 1.0406307919086188
Validation loss: 2.392729544185413

Epoch: 6| Step: 1
Training loss: 0.9437909136360431
Validation loss: 2.405819964592859

Epoch: 6| Step: 2
Training loss: 1.2003735874703592
Validation loss: 2.378683797561179

Epoch: 6| Step: 3
Training loss: 1.0720473659712355
Validation loss: 2.4926330176419254

Epoch: 6| Step: 4
Training loss: 1.2814728612835458
Validation loss: 2.4627483267903325

Epoch: 6| Step: 5
Training loss: 0.9959731683487351
Validation loss: 2.4058168072193653

Epoch: 6| Step: 6
Training loss: 1.019632911729065
Validation loss: 2.4500550424831404

Epoch: 6| Step: 7
Training loss: 1.9180365587356156
Validation loss: 2.3687134112651034

Epoch: 6| Step: 8
Training loss: 1.2464082613963807
Validation loss: 2.371199345788742

Epoch: 6| Step: 9
Training loss: 0.9221225341540515
Validation loss: 2.370179156663371

Epoch: 6| Step: 10
Training loss: 1.0043698439023616
Validation loss: 2.3713123100315405

Epoch: 6| Step: 11
Training loss: 0.8474138678046435
Validation loss: 2.3721799488275894

Epoch: 6| Step: 12
Training loss: 0.8128757341625894
Validation loss: 2.3905416451729864

Epoch: 6| Step: 13
Training loss: 1.34640949462698
Validation loss: 2.3220692380113523

Epoch: 437| Step: 0
Training loss: 0.7749069588709449
Validation loss: 2.3164820034515228

Epoch: 6| Step: 1
Training loss: 0.9033295831977826
Validation loss: 2.4088847663530024

Epoch: 6| Step: 2
Training loss: 0.779778429741652
Validation loss: 2.3648612671426954

Epoch: 6| Step: 3
Training loss: 1.0889356651498692
Validation loss: 2.4441885675783728

Epoch: 6| Step: 4
Training loss: 1.021181896931883
Validation loss: 2.407078482494986

Epoch: 6| Step: 5
Training loss: 0.9184664087460703
Validation loss: 2.3704451561336066

Epoch: 6| Step: 6
Training loss: 1.1331690786113189
Validation loss: 2.3651440499368075

Epoch: 6| Step: 7
Training loss: 0.7147571949071299
Validation loss: 2.4524665755162993

Epoch: 6| Step: 8
Training loss: 0.6041309466709642
Validation loss: 2.431558634033016

Epoch: 6| Step: 9
Training loss: 1.2142013863124734
Validation loss: 2.4244619303049055

Epoch: 6| Step: 10
Training loss: 0.9669987323302961
Validation loss: 2.381307685215142

Epoch: 6| Step: 11
Training loss: 0.9214375961480643
Validation loss: 2.423319007877007

Epoch: 6| Step: 12
Training loss: 1.0526905510721223
Validation loss: 2.437927972092948

Epoch: 6| Step: 13
Training loss: 2.780173446952834
Validation loss: 2.4412072468037693

Epoch: 438| Step: 0
Training loss: 1.0662969735856849
Validation loss: 2.3857544719222

Epoch: 6| Step: 1
Training loss: 0.9951082328415951
Validation loss: 2.3941597534850616

Epoch: 6| Step: 2
Training loss: 0.6999298826931153
Validation loss: 2.3896023598321965

Epoch: 6| Step: 3
Training loss: 1.207305531371416
Validation loss: 2.376759099476997

Epoch: 6| Step: 4
Training loss: 1.2366876305468109
Validation loss: 2.406499185219477

Epoch: 6| Step: 5
Training loss: 1.1907489902284623
Validation loss: 2.4046541293457078

Epoch: 6| Step: 6
Training loss: 1.16093043945137
Validation loss: 2.3530400849594564

Epoch: 6| Step: 7
Training loss: 1.0968955448324118
Validation loss: 2.3682480036011473

Epoch: 6| Step: 8
Training loss: 1.049155924628191
Validation loss: 2.38254163181902

Epoch: 6| Step: 9
Training loss: 1.2016054936965332
Validation loss: 2.399663152051696

Epoch: 6| Step: 10
Training loss: 0.8565108340525149
Validation loss: 2.348830974307519

Epoch: 6| Step: 11
Training loss: 1.848972488850596
Validation loss: 2.3816545496736667

Epoch: 6| Step: 12
Training loss: 0.7666826533295525
Validation loss: 2.381159555559984

Epoch: 6| Step: 13
Training loss: 0.4955368520657354
Validation loss: 2.3758800497392016

Epoch: 439| Step: 0
Training loss: 0.7740457628309472
Validation loss: 2.3686439443880256

Epoch: 6| Step: 1
Training loss: 1.1787450196048703
Validation loss: 2.428220565299876

Epoch: 6| Step: 2
Training loss: 1.1801299219213688
Validation loss: 2.3482590199566933

Epoch: 6| Step: 3
Training loss: 0.9190938345124473
Validation loss: 2.4051644079537042

Epoch: 6| Step: 4
Training loss: 0.7173813767682339
Validation loss: 2.4191923518290652

Epoch: 6| Step: 5
Training loss: 0.9204334691178867
Validation loss: 2.4107351810582585

Epoch: 6| Step: 6
Training loss: 2.0217405295133095
Validation loss: 2.4288030309122353

Epoch: 6| Step: 7
Training loss: 0.8462304636222975
Validation loss: 2.446531526930681

Epoch: 6| Step: 8
Training loss: 0.8735276163798238
Validation loss: 2.4233770988451537

Epoch: 6| Step: 9
Training loss: 0.7642144424607217
Validation loss: 2.3801249124188457

Epoch: 6| Step: 10
Training loss: 1.0308229544776777
Validation loss: 2.4222298956537465

Epoch: 6| Step: 11
Training loss: 1.2736728193355276
Validation loss: 2.44307147930295

Epoch: 6| Step: 12
Training loss: 0.9372370669087451
Validation loss: 2.3950774335677925

Epoch: 6| Step: 13
Training loss: 0.8907933996175289
Validation loss: 2.3988348005950386

Epoch: 440| Step: 0
Training loss: 1.0904279120893885
Validation loss: 2.4162863671545507

Epoch: 6| Step: 1
Training loss: 0.8066044538391512
Validation loss: 2.3591818135178375

Epoch: 6| Step: 2
Training loss: 0.8191364031725186
Validation loss: 2.331476154380476

Epoch: 6| Step: 3
Training loss: 1.004812818337943
Validation loss: 2.372859002221826

Epoch: 6| Step: 4
Training loss: 1.1837834876539248
Validation loss: 2.388736096843607

Epoch: 6| Step: 5
Training loss: 1.1262190889272115
Validation loss: 2.3776147176334153

Epoch: 6| Step: 6
Training loss: 1.770602207434362
Validation loss: 2.340822207176187

Epoch: 6| Step: 7
Training loss: 0.8289037677465263
Validation loss: 2.377102570448138

Epoch: 6| Step: 8
Training loss: 0.9114708963164145
Validation loss: 2.4405387792285995

Epoch: 6| Step: 9
Training loss: 0.9496505132102272
Validation loss: 2.3640089343407267

Epoch: 6| Step: 10
Training loss: 1.0897915735368076
Validation loss: 2.338203227178845

Epoch: 6| Step: 11
Training loss: 1.0006331585105335
Validation loss: 2.4093024511469774

Epoch: 6| Step: 12
Training loss: 0.9598882265388065
Validation loss: 2.380038486227102

Epoch: 6| Step: 13
Training loss: 1.2124267280698287
Validation loss: 2.341735723551069

Epoch: 441| Step: 0
Training loss: 0.7286838204382317
Validation loss: 2.3942774753075606

Epoch: 6| Step: 1
Training loss: 1.1529045162978377
Validation loss: 2.377972970574375

Epoch: 6| Step: 2
Training loss: 1.0711463965367762
Validation loss: 2.3570581855969532

Epoch: 6| Step: 3
Training loss: 0.883166318225186
Validation loss: 2.313863049361112

Epoch: 6| Step: 4
Training loss: 0.852991986647394
Validation loss: 2.3620485151634765

Epoch: 6| Step: 5
Training loss: 0.8757205448669263
Validation loss: 2.358883416774305

Epoch: 6| Step: 6
Training loss: 0.9292927072053943
Validation loss: 2.4075693349840703

Epoch: 6| Step: 7
Training loss: 2.0434498557781726
Validation loss: 2.3991497617982676

Epoch: 6| Step: 8
Training loss: 1.1339270534869956
Validation loss: 2.3811990117666855

Epoch: 6| Step: 9
Training loss: 0.5823376764216686
Validation loss: 2.3755164165171445

Epoch: 6| Step: 10
Training loss: 0.8694277856901224
Validation loss: 2.42781485206695

Epoch: 6| Step: 11
Training loss: 1.3768010914516169
Validation loss: 2.364669923623046

Epoch: 6| Step: 12
Training loss: 0.5683261560124833
Validation loss: 2.4257115943306764

Epoch: 6| Step: 13
Training loss: 1.2627047533241422
Validation loss: 2.3044351374587206

Epoch: 442| Step: 0
Training loss: 1.046617846433639
Validation loss: 2.3663156439585706

Epoch: 6| Step: 1
Training loss: 0.7745842957007586
Validation loss: 2.374941954148971

Epoch: 6| Step: 2
Training loss: 1.01275746404025
Validation loss: 2.387945477369378

Epoch: 6| Step: 3
Training loss: 0.9956634788955965
Validation loss: 2.404968677008328

Epoch: 6| Step: 4
Training loss: 1.2482278659782688
Validation loss: 2.354313052983294

Epoch: 6| Step: 5
Training loss: 0.6404649488043609
Validation loss: 2.425785156043944

Epoch: 6| Step: 6
Training loss: 0.9920351707487965
Validation loss: 2.3265222705171222

Epoch: 6| Step: 7
Training loss: 1.873800720688804
Validation loss: 2.3677257953425745

Epoch: 6| Step: 8
Training loss: 0.5722855704415319
Validation loss: 2.3377356954776474

Epoch: 6| Step: 9
Training loss: 0.7860792817081095
Validation loss: 2.366208017635306

Epoch: 6| Step: 10
Training loss: 1.103520162117332
Validation loss: 2.391123398605738

Epoch: 6| Step: 11
Training loss: 1.4714066847709117
Validation loss: 2.3326750473493316

Epoch: 6| Step: 12
Training loss: 0.9327758654073146
Validation loss: 2.3623389696230777

Epoch: 6| Step: 13
Training loss: 1.0139740069178387
Validation loss: 2.3952864191648753

Epoch: 443| Step: 0
Training loss: 0.9172686565307812
Validation loss: 2.4738270880314746

Epoch: 6| Step: 1
Training loss: 1.2203213270114792
Validation loss: 2.4532615352434197

Epoch: 6| Step: 2
Training loss: 0.6378722244851176
Validation loss: 2.3650761074084143

Epoch: 6| Step: 3
Training loss: 1.1071807222000065
Validation loss: 2.358178900188703

Epoch: 6| Step: 4
Training loss: 0.9086823542419235
Validation loss: 2.303464692705191

Epoch: 6| Step: 5
Training loss: 0.9412512433979794
Validation loss: 2.3644253987609694

Epoch: 6| Step: 6
Training loss: 0.9600071008240824
Validation loss: 2.3533611876166787

Epoch: 6| Step: 7
Training loss: 1.0144319422658166
Validation loss: 2.3585371874074657

Epoch: 6| Step: 8
Training loss: 0.9222576511010878
Validation loss: 2.3559166830243057

Epoch: 6| Step: 9
Training loss: 2.019462658069628
Validation loss: 2.4320309582631134

Epoch: 6| Step: 10
Training loss: 0.7826052545561673
Validation loss: 2.3893051477181544

Epoch: 6| Step: 11
Training loss: 0.857532746048423
Validation loss: 2.4375872558255978

Epoch: 6| Step: 12
Training loss: 0.6435312084493817
Validation loss: 2.3359410876536946

Epoch: 6| Step: 13
Training loss: 0.9876039317522084
Validation loss: 2.387616084796039

Epoch: 444| Step: 0
Training loss: 0.8447489300010116
Validation loss: 2.326741445788071

Epoch: 6| Step: 1
Training loss: 0.8123229640877537
Validation loss: 2.3404552181109657

Epoch: 6| Step: 2
Training loss: 1.2070243366129887
Validation loss: 2.3553787394101717

Epoch: 6| Step: 3
Training loss: 1.2148210823912673
Validation loss: 2.3468841429119203

Epoch: 6| Step: 4
Training loss: 1.1431256408856463
Validation loss: 2.3705898306996485

Epoch: 6| Step: 5
Training loss: 1.0494886197531315
Validation loss: 2.352260813107191

Epoch: 6| Step: 6
Training loss: 0.9393364086333165
Validation loss: 2.3000965926738517

Epoch: 6| Step: 7
Training loss: 0.9516320652581075
Validation loss: 2.3937083909181722

Epoch: 6| Step: 8
Training loss: 1.2397841710256299
Validation loss: 2.3666679997883078

Epoch: 6| Step: 9
Training loss: 0.7337891697217199
Validation loss: 2.428173084780393

Epoch: 6| Step: 10
Training loss: 1.235440916667179
Validation loss: 2.39830009801996

Epoch: 6| Step: 11
Training loss: 1.0442268698452397
Validation loss: 2.356089246235242

Epoch: 6| Step: 12
Training loss: 1.813362705516415
Validation loss: 2.40576918610794

Epoch: 6| Step: 13
Training loss: 0.8244248263648919
Validation loss: 2.362198045103411

Epoch: 445| Step: 0
Training loss: 0.9604814889564773
Validation loss: 2.4482343988958024

Epoch: 6| Step: 1
Training loss: 1.080807320706516
Validation loss: 2.3759491410430265

Epoch: 6| Step: 2
Training loss: 1.0869295816607425
Validation loss: 2.3131655827465

Epoch: 6| Step: 3
Training loss: 0.8857331364851608
Validation loss: 2.3621585189623677

Epoch: 6| Step: 4
Training loss: 0.9128191389856507
Validation loss: 2.3666945268059068

Epoch: 6| Step: 5
Training loss: 0.693735004812857
Validation loss: 2.380811305298026

Epoch: 6| Step: 6
Training loss: 0.7131424968421859
Validation loss: 2.294591890557389

Epoch: 6| Step: 7
Training loss: 0.8166978306241379
Validation loss: 2.319219967389289

Epoch: 6| Step: 8
Training loss: 1.0796294289193664
Validation loss: 2.4076108904959126

Epoch: 6| Step: 9
Training loss: 1.820868869612218
Validation loss: 2.2726952603025574

Epoch: 6| Step: 10
Training loss: 1.460918405989445
Validation loss: 2.3272103545081197

Epoch: 6| Step: 11
Training loss: 1.0096727103422611
Validation loss: 2.403862853142102

Epoch: 6| Step: 12
Training loss: 1.2648388811268676
Validation loss: 2.335492253435788

Epoch: 6| Step: 13
Training loss: 0.622845823561174
Validation loss: 2.3927093187282864

Epoch: 446| Step: 0
Training loss: 1.2108068088024995
Validation loss: 2.403024827995567

Epoch: 6| Step: 1
Training loss: 1.1312842221642398
Validation loss: 2.4371025154713566

Epoch: 6| Step: 2
Training loss: 1.1246437992340685
Validation loss: 2.3596465197598184

Epoch: 6| Step: 3
Training loss: 0.8754439930476571
Validation loss: 2.3451402900890628

Epoch: 6| Step: 4
Training loss: 1.8637637107544365
Validation loss: 2.4145372444761377

Epoch: 6| Step: 5
Training loss: 0.862619655712528
Validation loss: 2.3477123835891396

Epoch: 6| Step: 6
Training loss: 0.8846862285770617
Validation loss: 2.3786229951817015

Epoch: 6| Step: 7
Training loss: 1.1293681430661269
Validation loss: 2.378067326411992

Epoch: 6| Step: 8
Training loss: 0.9550394311723439
Validation loss: 2.398027582289432

Epoch: 6| Step: 9
Training loss: 0.96999454541
Validation loss: 2.3254947784683617

Epoch: 6| Step: 10
Training loss: 0.9172405195102366
Validation loss: 2.3839048434708014

Epoch: 6| Step: 11
Training loss: 0.9831686044906589
Validation loss: 2.3735489544083452

Epoch: 6| Step: 12
Training loss: 0.8566627009061264
Validation loss: 2.3784964255413445

Epoch: 6| Step: 13
Training loss: 1.0056828908811706
Validation loss: 2.3415495345472865

Epoch: 447| Step: 0
Training loss: 0.9701395835925556
Validation loss: 2.3617002680675374

Epoch: 6| Step: 1
Training loss: 0.893956795356783
Validation loss: 2.382115155487073

Epoch: 6| Step: 2
Training loss: 1.1270750829332399
Validation loss: 2.3644939248678263

Epoch: 6| Step: 3
Training loss: 0.9517719169900832
Validation loss: 2.3828968115888554

Epoch: 6| Step: 4
Training loss: 1.0372912001482657
Validation loss: 2.4236940013285104

Epoch: 6| Step: 5
Training loss: 1.1282309125810979
Validation loss: 2.4601802058544635

Epoch: 6| Step: 6
Training loss: 0.9325828346196796
Validation loss: 2.423238841704451

Epoch: 6| Step: 7
Training loss: 0.8611619923199403
Validation loss: 2.3975704435351513

Epoch: 6| Step: 8
Training loss: 1.0851268349623109
Validation loss: 2.412861451289456

Epoch: 6| Step: 9
Training loss: 1.165013686333024
Validation loss: 2.4220146485607974

Epoch: 6| Step: 10
Training loss: 0.7695489097156724
Validation loss: 2.362608583512346

Epoch: 6| Step: 11
Training loss: 1.8261932208603726
Validation loss: 2.3967678453571177

Epoch: 6| Step: 12
Training loss: 0.6898024973301795
Validation loss: 2.422567357903108

Epoch: 6| Step: 13
Training loss: 1.2821847250766836
Validation loss: 2.346406678180125

Epoch: 448| Step: 0
Training loss: 1.0261689057178325
Validation loss: 2.433696877308456

Epoch: 6| Step: 1
Training loss: 1.9131411456349314
Validation loss: 2.366230743730109

Epoch: 6| Step: 2
Training loss: 1.0318836230744308
Validation loss: 2.415771221592882

Epoch: 6| Step: 3
Training loss: 0.702166094179944
Validation loss: 2.4290888995616093

Epoch: 6| Step: 4
Training loss: 0.8451839553768834
Validation loss: 2.4073466761157523

Epoch: 6| Step: 5
Training loss: 0.9439186981193681
Validation loss: 2.366505419580389

Epoch: 6| Step: 6
Training loss: 1.2540245119221014
Validation loss: 2.2993872646252242

Epoch: 6| Step: 7
Training loss: 0.7816063259059106
Validation loss: 2.3599805874405884

Epoch: 6| Step: 8
Training loss: 1.059159469059805
Validation loss: 2.371370035539419

Epoch: 6| Step: 9
Training loss: 0.984651799113182
Validation loss: 2.363497461747387

Epoch: 6| Step: 10
Training loss: 0.9757260211497354
Validation loss: 2.3737062693447304

Epoch: 6| Step: 11
Training loss: 1.0586833282520027
Validation loss: 2.4014068177085286

Epoch: 6| Step: 12
Training loss: 0.8756928765987674
Validation loss: 2.3465400195987045

Epoch: 6| Step: 13
Training loss: 1.0935853561731097
Validation loss: 2.345899291821443

Epoch: 449| Step: 0
Training loss: 0.8060833204215446
Validation loss: 2.4454999312804833

Epoch: 6| Step: 1
Training loss: 1.9633662771991867
Validation loss: 2.458799384399562

Epoch: 6| Step: 2
Training loss: 1.0423223085160953
Validation loss: 2.426853908649049

Epoch: 6| Step: 3
Training loss: 0.9092485215366731
Validation loss: 2.460175454083614

Epoch: 6| Step: 4
Training loss: 0.9853640840035365
Validation loss: 2.4573720944083397

Epoch: 6| Step: 5
Training loss: 0.749702553576084
Validation loss: 2.496505329265187

Epoch: 6| Step: 6
Training loss: 0.9875760181960695
Validation loss: 2.3581995169240586

Epoch: 6| Step: 7
Training loss: 0.7470535974564922
Validation loss: 2.4064628497345257

Epoch: 6| Step: 8
Training loss: 1.4307814618267032
Validation loss: 2.393901861409351

Epoch: 6| Step: 9
Training loss: 1.1452837868873458
Validation loss: 2.3926240382122255

Epoch: 6| Step: 10
Training loss: 1.182379978371498
Validation loss: 2.4054849807136316

Epoch: 6| Step: 11
Training loss: 0.9151310014490165
Validation loss: 2.3509887806548835

Epoch: 6| Step: 12
Training loss: 0.7707057838761432
Validation loss: 2.3202718227977033

Epoch: 6| Step: 13
Training loss: 0.3720115555152889
Validation loss: 2.4023441704537016

Epoch: 450| Step: 0
Training loss: 1.0977570294038062
Validation loss: 2.3873527775893404

Epoch: 6| Step: 1
Training loss: 1.8018337657602028
Validation loss: 2.4006916620567846

Epoch: 6| Step: 2
Training loss: 0.8900721992717975
Validation loss: 2.3413626573523376

Epoch: 6| Step: 3
Training loss: 0.9704049955501267
Validation loss: 2.3412602682606622

Epoch: 6| Step: 4
Training loss: 0.7884224287929377
Validation loss: 2.378505693876851

Epoch: 6| Step: 5
Training loss: 0.9334604335709578
Validation loss: 2.4597067718395205

Epoch: 6| Step: 6
Training loss: 0.8354630594539523
Validation loss: 2.316012782254336

Epoch: 6| Step: 7
Training loss: 1.0373496371776019
Validation loss: 2.4063155143096253

Epoch: 6| Step: 8
Training loss: 1.1234981260534462
Validation loss: 2.3478802620213677

Epoch: 6| Step: 9
Training loss: 0.6578154738261582
Validation loss: 2.407768164788549

Epoch: 6| Step: 10
Training loss: 1.004636862325603
Validation loss: 2.401473508187272

Epoch: 6| Step: 11
Training loss: 0.7644190730491573
Validation loss: 2.3614290474166206

Epoch: 6| Step: 12
Training loss: 0.8898289787265476
Validation loss: 2.415192313099008

Epoch: 6| Step: 13
Training loss: 0.7842054160946037
Validation loss: 2.4292728315670407

Epoch: 451| Step: 0
Training loss: 0.9584795833337469
Validation loss: 2.4723592517377315

Epoch: 6| Step: 1
Training loss: 0.6308443994781889
Validation loss: 2.3784782078053417

Epoch: 6| Step: 2
Training loss: 1.087711723588795
Validation loss: 2.4307881552114057

Epoch: 6| Step: 3
Training loss: 1.257001105706359
Validation loss: 2.4343949940875422

Epoch: 6| Step: 4
Training loss: 0.6056316279707051
Validation loss: 2.3808205000145777

Epoch: 6| Step: 5
Training loss: 1.2420163786479275
Validation loss: 2.4043683281965307

Epoch: 6| Step: 6
Training loss: 1.0616170917316596
Validation loss: 2.3911105145561176

Epoch: 6| Step: 7
Training loss: 2.0221479275904493
Validation loss: 2.425925115297838

Epoch: 6| Step: 8
Training loss: 0.705044732399401
Validation loss: 2.393486637807897

Epoch: 6| Step: 9
Training loss: 0.683567417182547
Validation loss: 2.376375447735266

Epoch: 6| Step: 10
Training loss: 0.7536354962325226
Validation loss: 2.4149665200462516

Epoch: 6| Step: 11
Training loss: 1.138544510642662
Validation loss: 2.445221552592025

Epoch: 6| Step: 12
Training loss: 0.9216711174464818
Validation loss: 2.3194680388242883

Epoch: 6| Step: 13
Training loss: 1.0953931727065833
Validation loss: 2.4825110093168927

Epoch: 452| Step: 0
Training loss: 0.6830897625964234
Validation loss: 2.435873813311385

Epoch: 6| Step: 1
Training loss: 1.0401700076201499
Validation loss: 2.4429821836328216

Epoch: 6| Step: 2
Training loss: 1.791073131574053
Validation loss: 2.4168272173729175

Epoch: 6| Step: 3
Training loss: 0.7956610015371279
Validation loss: 2.3058936793268185

Epoch: 6| Step: 4
Training loss: 0.8399405135367415
Validation loss: 2.4223250950995587

Epoch: 6| Step: 5
Training loss: 1.0070071292234652
Validation loss: 2.375943623048888

Epoch: 6| Step: 6
Training loss: 0.9259317010240241
Validation loss: 2.401465549751528

Epoch: 6| Step: 7
Training loss: 0.9623528888291378
Validation loss: 2.341678822663601

Epoch: 6| Step: 8
Training loss: 1.0000381462450882
Validation loss: 2.3158683014555685

Epoch: 6| Step: 9
Training loss: 1.1787914384534246
Validation loss: 2.390821009871137

Epoch: 6| Step: 10
Training loss: 0.7350168061443467
Validation loss: 2.3365784216915575

Epoch: 6| Step: 11
Training loss: 1.0434808509689126
Validation loss: 2.347800094753787

Epoch: 6| Step: 12
Training loss: 0.9032034473601743
Validation loss: 2.3434160482743778

Epoch: 6| Step: 13
Training loss: 1.1340252402757975
Validation loss: 2.331304307046813

Epoch: 453| Step: 0
Training loss: 0.8344265125389299
Validation loss: 2.4352156950123156

Epoch: 6| Step: 1
Training loss: 0.8608702050024687
Validation loss: 2.4574754016386926

Epoch: 6| Step: 2
Training loss: 0.736229968421848
Validation loss: 2.4274188190122064

Epoch: 6| Step: 3
Training loss: 0.929712567672646
Validation loss: 2.4132911731401747

Epoch: 6| Step: 4
Training loss: 1.0648846512773686
Validation loss: 2.404746927636586

Epoch: 6| Step: 5
Training loss: 0.7717088976221669
Validation loss: 2.4566505565385848

Epoch: 6| Step: 6
Training loss: 1.3290300314978243
Validation loss: 2.4195546970572144

Epoch: 6| Step: 7
Training loss: 1.1698677674583622
Validation loss: 2.415774750113634

Epoch: 6| Step: 8
Training loss: 1.0474063037492505
Validation loss: 2.3924435583180177

Epoch: 6| Step: 9
Training loss: 0.7799840206563516
Validation loss: 2.3603869308618664

Epoch: 6| Step: 10
Training loss: 0.9043536240503871
Validation loss: 2.3946603213859445

Epoch: 6| Step: 11
Training loss: 0.6468575774716809
Validation loss: 2.330733399012954

Epoch: 6| Step: 12
Training loss: 1.8301593514149677
Validation loss: 2.433457094158964

Epoch: 6| Step: 13
Training loss: 1.0165407014157808
Validation loss: 2.341326484790178

Epoch: 454| Step: 0
Training loss: 0.7978245930216513
Validation loss: 2.31613283346132

Epoch: 6| Step: 1
Training loss: 0.8122862754839199
Validation loss: 2.3161241833145367

Epoch: 6| Step: 2
Training loss: 1.0332237198332872
Validation loss: 2.3879941259642288

Epoch: 6| Step: 3
Training loss: 0.7352113628099836
Validation loss: 2.4488170098233026

Epoch: 6| Step: 4
Training loss: 0.8703021228657881
Validation loss: 2.4698862171722893

Epoch: 6| Step: 5
Training loss: 1.0548881622444366
Validation loss: 2.3980369916218987

Epoch: 6| Step: 6
Training loss: 0.8474480861191394
Validation loss: 2.329951083649363

Epoch: 6| Step: 7
Training loss: 0.9340946657290454
Validation loss: 2.3613857498831736

Epoch: 6| Step: 8
Training loss: 0.7924096903803943
Validation loss: 2.3746747040782403

Epoch: 6| Step: 9
Training loss: 0.9466026266917931
Validation loss: 2.3583538847713057

Epoch: 6| Step: 10
Training loss: 0.8978082858450456
Validation loss: 2.3531993058546137

Epoch: 6| Step: 11
Training loss: 1.769149772837701
Validation loss: 2.3917424432604633

Epoch: 6| Step: 12
Training loss: 1.1118158701483665
Validation loss: 2.402036877606185

Epoch: 6| Step: 13
Training loss: 1.1921914936763722
Validation loss: 2.4510351909275796

Epoch: 455| Step: 0
Training loss: 0.7268823719388839
Validation loss: 2.3803581552713915

Epoch: 6| Step: 1
Training loss: 0.937484995404015
Validation loss: 2.3751847972983664

Epoch: 6| Step: 2
Training loss: 0.8091410751761406
Validation loss: 2.4174797004468185

Epoch: 6| Step: 3
Training loss: 1.9016027240996856
Validation loss: 2.363520095133736

Epoch: 6| Step: 4
Training loss: 0.9683281995426029
Validation loss: 2.432194832859316

Epoch: 6| Step: 5
Training loss: 0.8657906081226235
Validation loss: 2.404118956238558

Epoch: 6| Step: 6
Training loss: 0.6674396806601458
Validation loss: 2.4423534473893356

Epoch: 6| Step: 7
Training loss: 0.8922169161087594
Validation loss: 2.385944437215577

Epoch: 6| Step: 8
Training loss: 0.8832067098970809
Validation loss: 2.4691947021420537

Epoch: 6| Step: 9
Training loss: 0.8138137246888713
Validation loss: 2.403435452320293

Epoch: 6| Step: 10
Training loss: 0.8772492450418428
Validation loss: 2.3477255058027615

Epoch: 6| Step: 11
Training loss: 1.2858637106062323
Validation loss: 2.382993000361414

Epoch: 6| Step: 12
Training loss: 0.6945377062056569
Validation loss: 2.4293332980783044

Epoch: 6| Step: 13
Training loss: 1.357715119446427
Validation loss: 2.4133222760387003

Epoch: 456| Step: 0
Training loss: 0.7942054763336158
Validation loss: 2.416692036321233

Epoch: 6| Step: 1
Training loss: 1.009607889336232
Validation loss: 2.3707819410611477

Epoch: 6| Step: 2
Training loss: 0.9011430554686489
Validation loss: 2.322711977683645

Epoch: 6| Step: 3
Training loss: 1.0049401091764705
Validation loss: 2.406205322720233

Epoch: 6| Step: 4
Training loss: 0.9862093712351594
Validation loss: 2.440553140808075

Epoch: 6| Step: 5
Training loss: 0.8899083851691101
Validation loss: 2.4037387220988733

Epoch: 6| Step: 6
Training loss: 1.0404527584645233
Validation loss: 2.399821570537693

Epoch: 6| Step: 7
Training loss: 0.9726892488695892
Validation loss: 2.379922659351435

Epoch: 6| Step: 8
Training loss: 1.238832657844164
Validation loss: 2.289561168247574

Epoch: 6| Step: 9
Training loss: 0.8526537141907271
Validation loss: 2.46495196611937

Epoch: 6| Step: 10
Training loss: 1.8967362932901821
Validation loss: 2.457561093363829

Epoch: 6| Step: 11
Training loss: 0.82624113184892
Validation loss: 2.34896854148942

Epoch: 6| Step: 12
Training loss: 0.6043592562592391
Validation loss: 2.389740697447214

Epoch: 6| Step: 13
Training loss: 1.126648066600403
Validation loss: 2.429295750723734

Epoch: 457| Step: 0
Training loss: 0.9753680439307082
Validation loss: 2.347167603399982

Epoch: 6| Step: 1
Training loss: 1.0080972904907177
Validation loss: 2.404519407935007

Epoch: 6| Step: 2
Training loss: 0.8378077468253465
Validation loss: 2.3208384871492362

Epoch: 6| Step: 3
Training loss: 1.0379446800205485
Validation loss: 2.3979157552416877

Epoch: 6| Step: 4
Training loss: 0.6376047814967691
Validation loss: 2.413062331057864

Epoch: 6| Step: 5
Training loss: 1.0825658365892727
Validation loss: 2.3965644038468037

Epoch: 6| Step: 6
Training loss: 0.8922284065128322
Validation loss: 2.3547703670131566

Epoch: 6| Step: 7
Training loss: 1.0128899353236842
Validation loss: 2.390960314351907

Epoch: 6| Step: 8
Training loss: 1.098505526480579
Validation loss: 2.378805065725909

Epoch: 6| Step: 9
Training loss: 1.8192688401811328
Validation loss: 2.3715478443653715

Epoch: 6| Step: 10
Training loss: 0.731772498584812
Validation loss: 2.2911555793309

Epoch: 6| Step: 11
Training loss: 0.9698204463754387
Validation loss: 2.3730671697306045

Epoch: 6| Step: 12
Training loss: 1.0434996436008344
Validation loss: 2.3497990395525736

Epoch: 6| Step: 13
Training loss: 1.3334903723902345
Validation loss: 2.418863382978532

Epoch: 458| Step: 0
Training loss: 1.7931750475978396
Validation loss: 2.373720177209404

Epoch: 6| Step: 1
Training loss: 0.9634043965203507
Validation loss: 2.429818817104674

Epoch: 6| Step: 2
Training loss: 0.6636159854232823
Validation loss: 2.408902363559672

Epoch: 6| Step: 3
Training loss: 1.197494410300698
Validation loss: 2.3411982141934757

Epoch: 6| Step: 4
Training loss: 0.992575592073814
Validation loss: 2.4294364131298867

Epoch: 6| Step: 5
Training loss: 1.0276215616420867
Validation loss: 2.427989933165229

Epoch: 6| Step: 6
Training loss: 0.8529251814806839
Validation loss: 2.3768367346687382

Epoch: 6| Step: 7
Training loss: 1.112471436551768
Validation loss: 2.3872187835328433

Epoch: 6| Step: 8
Training loss: 0.8263416882310962
Validation loss: 2.429836964323701

Epoch: 6| Step: 9
Training loss: 0.9208062005396855
Validation loss: 2.4238516488027404

Epoch: 6| Step: 10
Training loss: 0.8722594804628518
Validation loss: 2.3605271620041504

Epoch: 6| Step: 11
Training loss: 0.7331349474792227
Validation loss: 2.3599442244432725

Epoch: 6| Step: 12
Training loss: 1.1178935027640307
Validation loss: 2.3742174036831973

Epoch: 6| Step: 13
Training loss: 1.3738345929411961
Validation loss: 2.366946246245725

Epoch: 459| Step: 0
Training loss: 0.8720498077271632
Validation loss: 2.353179796301514

Epoch: 6| Step: 1
Training loss: 0.9882048324774079
Validation loss: 2.4069290742432172

Epoch: 6| Step: 2
Training loss: 0.8817220046074421
Validation loss: 2.3581747669271267

Epoch: 6| Step: 3
Training loss: 1.1741011265606256
Validation loss: 2.4331811917888855

Epoch: 6| Step: 4
Training loss: 0.6709179826801802
Validation loss: 2.412052228560466

Epoch: 6| Step: 5
Training loss: 0.7692694823903847
Validation loss: 2.427048337295833

Epoch: 6| Step: 6
Training loss: 1.9292458094380438
Validation loss: 2.410622985846319

Epoch: 6| Step: 7
Training loss: 0.7262093290670558
Validation loss: 2.427187895226836

Epoch: 6| Step: 8
Training loss: 0.6466643667753686
Validation loss: 2.4034890949560084

Epoch: 6| Step: 9
Training loss: 0.8506060487316411
Validation loss: 2.36070610190407

Epoch: 6| Step: 10
Training loss: 1.001602022102405
Validation loss: 2.358672202176029

Epoch: 6| Step: 11
Training loss: 1.0323487410692453
Validation loss: 2.3373011160227706

Epoch: 6| Step: 12
Training loss: 0.8413135530632269
Validation loss: 2.3597553427146667

Epoch: 6| Step: 13
Training loss: 1.236978898968584
Validation loss: 2.3341303012212586

Epoch: 460| Step: 0
Training loss: 1.5123275595483225
Validation loss: 2.4045573176525177

Epoch: 6| Step: 1
Training loss: 0.8764440337449445
Validation loss: 2.286791061876388

Epoch: 6| Step: 2
Training loss: 1.8398709629257388
Validation loss: 2.4017679208165625

Epoch: 6| Step: 3
Training loss: 0.8898793495565974
Validation loss: 2.3571978507436278

Epoch: 6| Step: 4
Training loss: 1.0705708658280244
Validation loss: 2.34968291019527

Epoch: 6| Step: 5
Training loss: 0.9650171409823929
Validation loss: 2.330144714856818

Epoch: 6| Step: 6
Training loss: 0.8820606845103715
Validation loss: 2.314351790188724

Epoch: 6| Step: 7
Training loss: 0.8323840257550867
Validation loss: 2.413153387758049

Epoch: 6| Step: 8
Training loss: 0.8287113920629057
Validation loss: 2.3608146762088604

Epoch: 6| Step: 9
Training loss: 0.959914119971968
Validation loss: 2.3749533488382526

Epoch: 6| Step: 10
Training loss: 1.0316393724034543
Validation loss: 2.402800739747731

Epoch: 6| Step: 11
Training loss: 0.8091039844543544
Validation loss: 2.421650709232003

Epoch: 6| Step: 12
Training loss: 0.6717834410270795
Validation loss: 2.3876230596967987

Epoch: 6| Step: 13
Training loss: 0.8939861319125546
Validation loss: 2.3543931890373315

Epoch: 461| Step: 0
Training loss: 1.3597546628243309
Validation loss: 2.3657151665173157

Epoch: 6| Step: 1
Training loss: 0.97450050862095
Validation loss: 2.497516355132398

Epoch: 6| Step: 2
Training loss: 0.6301053622484545
Validation loss: 2.407126266212861

Epoch: 6| Step: 3
Training loss: 0.9312978309790414
Validation loss: 2.4377964040443523

Epoch: 6| Step: 4
Training loss: 1.2270524813924504
Validation loss: 2.3783622284126844

Epoch: 6| Step: 5
Training loss: 0.8440406440015205
Validation loss: 2.4381319672404542

Epoch: 6| Step: 6
Training loss: 1.888891449939014
Validation loss: 2.4162935224185467

Epoch: 6| Step: 7
Training loss: 0.7528448984815789
Validation loss: 2.403388292829625

Epoch: 6| Step: 8
Training loss: 1.119406250858762
Validation loss: 2.380155373515902

Epoch: 6| Step: 9
Training loss: 0.8976819385807001
Validation loss: 2.3908200008510825

Epoch: 6| Step: 10
Training loss: 0.9869247897961951
Validation loss: 2.375139367289546

Epoch: 6| Step: 11
Training loss: 0.8261919672982517
Validation loss: 2.4131700306519104

Epoch: 6| Step: 12
Training loss: 0.7544192609468138
Validation loss: 2.3208873251237314

Epoch: 6| Step: 13
Training loss: 0.7723121548008454
Validation loss: 2.3783630799548567

Epoch: 462| Step: 0
Training loss: 1.8848758645505053
Validation loss: 2.4117930119428292

Epoch: 6| Step: 1
Training loss: 0.6030466177018515
Validation loss: 2.29875401912657

Epoch: 6| Step: 2
Training loss: 0.8569830464496719
Validation loss: 2.441229370272645

Epoch: 6| Step: 3
Training loss: 0.8429388456369926
Validation loss: 2.326000960585217

Epoch: 6| Step: 4
Training loss: 0.7484424630719283
Validation loss: 2.4154830561706313

Epoch: 6| Step: 5
Training loss: 0.7142786178917552
Validation loss: 2.3245622609397367

Epoch: 6| Step: 6
Training loss: 0.8922548606015491
Validation loss: 2.392974685374952

Epoch: 6| Step: 7
Training loss: 0.9547233312597472
Validation loss: 2.42645048886582

Epoch: 6| Step: 8
Training loss: 1.082668681316271
Validation loss: 2.398244380975563

Epoch: 6| Step: 9
Training loss: 0.8301321214055374
Validation loss: 2.373421712906019

Epoch: 6| Step: 10
Training loss: 1.1531817993400266
Validation loss: 2.313572773073259

Epoch: 6| Step: 11
Training loss: 0.829706014365542
Validation loss: 2.3456445814927296

Epoch: 6| Step: 12
Training loss: 0.7975688979902118
Validation loss: 2.4315116414870355

Epoch: 6| Step: 13
Training loss: 0.9012001023255657
Validation loss: 2.459657970911713

Epoch: 463| Step: 0
Training loss: 0.884135579836956
Validation loss: 2.4223292829425724

Epoch: 6| Step: 1
Training loss: 0.755011820163788
Validation loss: 2.4534718508837705

Epoch: 6| Step: 2
Training loss: 0.8552323106075429
Validation loss: 2.374505278091556

Epoch: 6| Step: 3
Training loss: 0.7823270240307688
Validation loss: 2.3790164301467223

Epoch: 6| Step: 4
Training loss: 1.9047061108750956
Validation loss: 2.3243127081583994

Epoch: 6| Step: 5
Training loss: 0.6490263505767551
Validation loss: 2.382290414696796

Epoch: 6| Step: 6
Training loss: 1.3002933354651192
Validation loss: 2.473358136066991

Epoch: 6| Step: 7
Training loss: 0.8608724206049686
Validation loss: 2.4246116586032675

Epoch: 6| Step: 8
Training loss: 0.6793878267370558
Validation loss: 2.407496348625011

Epoch: 6| Step: 9
Training loss: 0.623464534049096
Validation loss: 2.369887503915372

Epoch: 6| Step: 10
Training loss: 1.0414328249082543
Validation loss: 2.4098765858375133

Epoch: 6| Step: 11
Training loss: 0.960085855856889
Validation loss: 2.3518482531077165

Epoch: 6| Step: 12
Training loss: 1.0631093914269871
Validation loss: 2.3771056732125646

Epoch: 6| Step: 13
Training loss: 0.6894611649949501
Validation loss: 2.3637301761778997

Epoch: 464| Step: 0
Training loss: 0.876985409148751
Validation loss: 2.2922119416691378

Epoch: 6| Step: 1
Training loss: 0.9810727451370581
Validation loss: 2.43616465741301

Epoch: 6| Step: 2
Training loss: 0.8012446853532851
Validation loss: 2.311696235193251

Epoch: 6| Step: 3
Training loss: 0.9464564692043448
Validation loss: 2.3755968269041863

Epoch: 6| Step: 4
Training loss: 0.8582301056153707
Validation loss: 2.3721614842703076

Epoch: 6| Step: 5
Training loss: 0.5242440287241318
Validation loss: 2.3688844311084845

Epoch: 6| Step: 6
Training loss: 0.9558514231860447
Validation loss: 2.275896418379355

Epoch: 6| Step: 7
Training loss: 1.0711587498013546
Validation loss: 2.3272800975734826

Epoch: 6| Step: 8
Training loss: 0.7292543812627679
Validation loss: 2.3599791502687695

Epoch: 6| Step: 9
Training loss: 0.7267230276975547
Validation loss: 2.4296574396355712

Epoch: 6| Step: 10
Training loss: 1.1103712095268712
Validation loss: 2.3975140043365033

Epoch: 6| Step: 11
Training loss: 0.7519168993658414
Validation loss: 2.41363669354112

Epoch: 6| Step: 12
Training loss: 2.113075232203218
Validation loss: 2.4518435174571267

Epoch: 6| Step: 13
Training loss: 0.772494695145253
Validation loss: 2.3935642627570677

Epoch: 465| Step: 0
Training loss: 0.8833783792010328
Validation loss: 2.44629264446315

Epoch: 6| Step: 1
Training loss: 1.9838298739702485
Validation loss: 2.3486021365838234

Epoch: 6| Step: 2
Training loss: 0.6922235776570934
Validation loss: 2.3400692888323866

Epoch: 6| Step: 3
Training loss: 0.8980911914299596
Validation loss: 2.3794164499282053

Epoch: 6| Step: 4
Training loss: 0.9253079133852494
Validation loss: 2.3126637102362158

Epoch: 6| Step: 5
Training loss: 1.0258625797241716
Validation loss: 2.429291732658091

Epoch: 6| Step: 6
Training loss: 1.04826518886997
Validation loss: 2.378293931581801

Epoch: 6| Step: 7
Training loss: 0.5927365839906847
Validation loss: 2.362969786919438

Epoch: 6| Step: 8
Training loss: 0.9980701660305203
Validation loss: 2.4339416926211226

Epoch: 6| Step: 9
Training loss: 0.8173336620433866
Validation loss: 2.369404861667506

Epoch: 6| Step: 10
Training loss: 0.9474504742725821
Validation loss: 2.400585972057984

Epoch: 6| Step: 11
Training loss: 0.9437701039983465
Validation loss: 2.354347243494924

Epoch: 6| Step: 12
Training loss: 0.7909286262801178
Validation loss: 2.4072987146673257

Epoch: 6| Step: 13
Training loss: 0.9640537379035128
Validation loss: 2.4211425224027177

Epoch: 466| Step: 0
Training loss: 0.9418437779952881
Validation loss: 2.3435930392302713

Epoch: 6| Step: 1
Training loss: 0.8892784982575629
Validation loss: 2.389035635379262

Epoch: 6| Step: 2
Training loss: 0.6578632009000077
Validation loss: 2.395686836275785

Epoch: 6| Step: 3
Training loss: 0.8058585007441369
Validation loss: 2.416354462255791

Epoch: 6| Step: 4
Training loss: 1.0630957111538022
Validation loss: 2.3602044312040475

Epoch: 6| Step: 5
Training loss: 0.9275803287505308
Validation loss: 2.3731655641960483

Epoch: 6| Step: 6
Training loss: 0.710608018254512
Validation loss: 2.452593089773384

Epoch: 6| Step: 7
Training loss: 0.6574911460715465
Validation loss: 2.3862732182638977

Epoch: 6| Step: 8
Training loss: 0.559558888263821
Validation loss: 2.4356595788337003

Epoch: 6| Step: 9
Training loss: 0.7317155611244458
Validation loss: 2.335364616334843

Epoch: 6| Step: 10
Training loss: 1.0323334984077648
Validation loss: 2.396578074764148

Epoch: 6| Step: 11
Training loss: 0.8452398075007104
Validation loss: 2.4090275240408476

Epoch: 6| Step: 12
Training loss: 1.8465607764713277
Validation loss: 2.4302897985308136

Epoch: 6| Step: 13
Training loss: 1.2250482724857616
Validation loss: 2.2811076487450666

Epoch: 467| Step: 0
Training loss: 1.2044191212433897
Validation loss: 2.328838172260455

Epoch: 6| Step: 1
Training loss: 0.8344284054812935
Validation loss: 2.329732384746605

Epoch: 6| Step: 2
Training loss: 1.8407908470163323
Validation loss: 2.363522805181545

Epoch: 6| Step: 3
Training loss: 0.6842214046199409
Validation loss: 2.3913367006466677

Epoch: 6| Step: 4
Training loss: 1.3143563086123469
Validation loss: 2.416810977291824

Epoch: 6| Step: 5
Training loss: 1.0120085665675722
Validation loss: 2.3387625642679946

Epoch: 6| Step: 6
Training loss: 0.9110699434658691
Validation loss: 2.3886853335094504

Epoch: 6| Step: 7
Training loss: 1.1006342446557953
Validation loss: 2.344348941964052

Epoch: 6| Step: 8
Training loss: 0.8255038976687046
Validation loss: 2.4176646418465952

Epoch: 6| Step: 9
Training loss: 1.098965769858608
Validation loss: 2.3734175716247967

Epoch: 6| Step: 10
Training loss: 0.6511026557329773
Validation loss: 2.3304120145268334

Epoch: 6| Step: 11
Training loss: 1.0267462207472924
Validation loss: 2.3689857869682225

Epoch: 6| Step: 12
Training loss: 0.6732684478640386
Validation loss: 2.381634403468553

Epoch: 6| Step: 13
Training loss: 0.785766288658887
Validation loss: 2.360415279257435

Epoch: 468| Step: 0
Training loss: 0.897415608287632
Validation loss: 2.363817803806287

Epoch: 6| Step: 1
Training loss: 1.0290357341697036
Validation loss: 2.321122715093404

Epoch: 6| Step: 2
Training loss: 0.858206353161956
Validation loss: 2.414909985282386

Epoch: 6| Step: 3
Training loss: 0.9577263623783137
Validation loss: 2.4341223510742807

Epoch: 6| Step: 4
Training loss: 0.9034543819426993
Validation loss: 2.340276668743026

Epoch: 6| Step: 5
Training loss: 0.8920470813676747
Validation loss: 2.4533798804357723

Epoch: 6| Step: 6
Training loss: 0.9226489293698718
Validation loss: 2.3465333246299016

Epoch: 6| Step: 7
Training loss: 0.9400091607580814
Validation loss: 2.3639937845780015

Epoch: 6| Step: 8
Training loss: 0.6690793313871901
Validation loss: 2.321168798637869

Epoch: 6| Step: 9
Training loss: 0.6836054773687138
Validation loss: 2.356345055712244

Epoch: 6| Step: 10
Training loss: 1.241906908121638
Validation loss: 2.3924573824402926

Epoch: 6| Step: 11
Training loss: 0.7441787509713085
Validation loss: 2.4299561765773623

Epoch: 6| Step: 12
Training loss: 1.7881186715113717
Validation loss: 2.38141928183506

Epoch: 6| Step: 13
Training loss: 0.5377560138907016
Validation loss: 2.313013062548097

Epoch: 469| Step: 0
Training loss: 0.806170716934119
Validation loss: 2.3435603791785082

Epoch: 6| Step: 1
Training loss: 0.7465444272178298
Validation loss: 2.3464790048711595

Epoch: 6| Step: 2
Training loss: 1.0664426916135015
Validation loss: 2.4177123414616393

Epoch: 6| Step: 3
Training loss: 1.0546767622789626
Validation loss: 2.4682838900248805

Epoch: 6| Step: 4
Training loss: 0.6406084849392059
Validation loss: 2.317683564445839

Epoch: 6| Step: 5
Training loss: 0.7841368173018602
Validation loss: 2.435336316687473

Epoch: 6| Step: 6
Training loss: 1.0207223183089782
Validation loss: 2.3503467514755916

Epoch: 6| Step: 7
Training loss: 0.9873162183078817
Validation loss: 2.2723292071057335

Epoch: 6| Step: 8
Training loss: 1.0217354868807127
Validation loss: 2.3940501492671107

Epoch: 6| Step: 9
Training loss: 0.6558280451132017
Validation loss: 2.426960631266114

Epoch: 6| Step: 10
Training loss: 0.8735441630684351
Validation loss: 2.39769515092777

Epoch: 6| Step: 11
Training loss: 0.9055678661428873
Validation loss: 2.364063945490285

Epoch: 6| Step: 12
Training loss: 0.7428817312984146
Validation loss: 2.2991095025943338

Epoch: 6| Step: 13
Training loss: 2.267789766750432
Validation loss: 2.3238203642596433

Epoch: 470| Step: 0
Training loss: 1.0686131930768246
Validation loss: 2.428102236020864

Epoch: 6| Step: 1
Training loss: 0.7606199506656304
Validation loss: 2.3504194073892197

Epoch: 6| Step: 2
Training loss: 1.782864959506656
Validation loss: 2.3935160851159814

Epoch: 6| Step: 3
Training loss: 0.9458629487284361
Validation loss: 2.3383075695512865

Epoch: 6| Step: 4
Training loss: 0.7164101037906672
Validation loss: 2.4455323573727505

Epoch: 6| Step: 5
Training loss: 1.1242002187424973
Validation loss: 2.3936883349173392

Epoch: 6| Step: 6
Training loss: 0.6175908569336119
Validation loss: 2.364017689059132

Epoch: 6| Step: 7
Training loss: 0.7988893816528899
Validation loss: 2.3396495474380403

Epoch: 6| Step: 8
Training loss: 0.6170830457155673
Validation loss: 2.399192553056645

Epoch: 6| Step: 9
Training loss: 0.8743008136157766
Validation loss: 2.396729577110394

Epoch: 6| Step: 10
Training loss: 0.8108390924798737
Validation loss: 2.3568738721886384

Epoch: 6| Step: 11
Training loss: 0.7911367064688939
Validation loss: 2.4009914484142834

Epoch: 6| Step: 12
Training loss: 0.8723301345607176
Validation loss: 2.340300272142979

Epoch: 6| Step: 13
Training loss: 1.0072200719458924
Validation loss: 2.443254577976189

Epoch: 471| Step: 0
Training loss: 0.7169290363596014
Validation loss: 2.3780291334690182

Epoch: 6| Step: 1
Training loss: 0.8204974374748537
Validation loss: 2.4239407676861537

Epoch: 6| Step: 2
Training loss: 0.9954664761001322
Validation loss: 2.4382890613132697

Epoch: 6| Step: 3
Training loss: 1.2386296019954195
Validation loss: 2.457150257168986

Epoch: 6| Step: 4
Training loss: 1.0420190151661506
Validation loss: 2.4061764568825175

Epoch: 6| Step: 5
Training loss: 0.6518553544519445
Validation loss: 2.4514480522172883

Epoch: 6| Step: 6
Training loss: 0.7862924354515369
Validation loss: 2.390670656361673

Epoch: 6| Step: 7
Training loss: 0.9553757342323638
Validation loss: 2.38329370925955

Epoch: 6| Step: 8
Training loss: 0.627467315970085
Validation loss: 2.34482681094208

Epoch: 6| Step: 9
Training loss: 1.1471241298413268
Validation loss: 2.239593714932998

Epoch: 6| Step: 10
Training loss: 0.9257354725010227
Validation loss: 2.362449209484729

Epoch: 6| Step: 11
Training loss: 0.8457991829603664
Validation loss: 2.3471502522122747

Epoch: 6| Step: 12
Training loss: 1.8403903934721355
Validation loss: 2.4326650955540488

Epoch: 6| Step: 13
Training loss: 0.8747748017023523
Validation loss: 2.317805322044412

Epoch: 472| Step: 0
Training loss: 0.7910953434463417
Validation loss: 2.4102220835918353

Epoch: 6| Step: 1
Training loss: 0.8193257891602775
Validation loss: 2.337775115302276

Epoch: 6| Step: 2
Training loss: 1.0560469166925006
Validation loss: 2.308447135707582

Epoch: 6| Step: 3
Training loss: 0.7295394943402208
Validation loss: 2.355604559347762

Epoch: 6| Step: 4
Training loss: 0.7821703258401446
Validation loss: 2.34843250964288

Epoch: 6| Step: 5
Training loss: 1.14276481472603
Validation loss: 2.385501491616311

Epoch: 6| Step: 6
Training loss: 0.7408760128307161
Validation loss: 2.3777208777511474

Epoch: 6| Step: 7
Training loss: 0.9802649236728526
Validation loss: 2.370589272678726

Epoch: 6| Step: 8
Training loss: 0.8903351696980442
Validation loss: 2.469759598497756

Epoch: 6| Step: 9
Training loss: 0.7155315654677473
Validation loss: 2.4006313733011013

Epoch: 6| Step: 10
Training loss: 0.7745788706718812
Validation loss: 2.376816858264744

Epoch: 6| Step: 11
Training loss: 0.863546580970564
Validation loss: 2.4397428704328648

Epoch: 6| Step: 12
Training loss: 1.9172948208766754
Validation loss: 2.3998992998350497

Epoch: 6| Step: 13
Training loss: 0.6021551705329504
Validation loss: 2.4226915880930897

Epoch: 473| Step: 0
Training loss: 0.7934722805025026
Validation loss: 2.4036982920364824

Epoch: 6| Step: 1
Training loss: 1.0063786323736723
Validation loss: 2.3618770893469545

Epoch: 6| Step: 2
Training loss: 0.8566785644813327
Validation loss: 2.3202059440167107

Epoch: 6| Step: 3
Training loss: 0.8071224076228096
Validation loss: 2.334759215751331

Epoch: 6| Step: 4
Training loss: 1.8480144258406737
Validation loss: 2.3789755023466257

Epoch: 6| Step: 5
Training loss: 0.8928471333078892
Validation loss: 2.4046240678803343

Epoch: 6| Step: 6
Training loss: 0.882798017534952
Validation loss: 2.290771212849293

Epoch: 6| Step: 7
Training loss: 0.7888895732879655
Validation loss: 2.4302071638575544

Epoch: 6| Step: 8
Training loss: 0.960618035782021
Validation loss: 2.271126474668868

Epoch: 6| Step: 9
Training loss: 1.0893017915079746
Validation loss: 2.328542762851969

Epoch: 6| Step: 10
Training loss: 0.7501373165310093
Validation loss: 2.3816189729274475

Epoch: 6| Step: 11
Training loss: 1.278444428389002
Validation loss: 2.3776199988498354

Epoch: 6| Step: 12
Training loss: 0.8609576131198622
Validation loss: 2.3538378254345558

Epoch: 6| Step: 13
Training loss: 0.9184184494716586
Validation loss: 2.3372557953348734

Epoch: 474| Step: 0
Training loss: 0.7197439949895497
Validation loss: 2.3810638848943473

Epoch: 6| Step: 1
Training loss: 0.7393113473432873
Validation loss: 2.4398317713701507

Epoch: 6| Step: 2
Training loss: 0.9575161697974526
Validation loss: 2.4214509611956823

Epoch: 6| Step: 3
Training loss: 1.1511873294037598
Validation loss: 2.3792112348839622

Epoch: 6| Step: 4
Training loss: 0.874803793570932
Validation loss: 2.3309909644422904

Epoch: 6| Step: 5
Training loss: 0.7331330775525702
Validation loss: 2.3810693371887592

Epoch: 6| Step: 6
Training loss: 0.743675426943945
Validation loss: 2.382829850791136

Epoch: 6| Step: 7
Training loss: 0.967517160613387
Validation loss: 2.3742700673768375

Epoch: 6| Step: 8
Training loss: 0.9365476539511967
Validation loss: 2.45324919123494

Epoch: 6| Step: 9
Training loss: 1.8309645160088894
Validation loss: 2.4315679394425738

Epoch: 6| Step: 10
Training loss: 1.0651483627638387
Validation loss: 2.3532381469017944

Epoch: 6| Step: 11
Training loss: 1.0516118733801896
Validation loss: 2.357365511512273

Epoch: 6| Step: 12
Training loss: 0.9603915020231089
Validation loss: 2.4069304274631964

Epoch: 6| Step: 13
Training loss: 0.5598539262805466
Validation loss: 2.4346466338778754

Epoch: 475| Step: 0
Training loss: 0.970001243266066
Validation loss: 2.329089700232622

Epoch: 6| Step: 1
Training loss: 0.5457680807591629
Validation loss: 2.3217354218399713

Epoch: 6| Step: 2
Training loss: 0.6998285373091273
Validation loss: 2.3764958789987913

Epoch: 6| Step: 3
Training loss: 0.9597112072743292
Validation loss: 2.37246285449645

Epoch: 6| Step: 4
Training loss: 0.9626845938298096
Validation loss: 2.3146167785015686

Epoch: 6| Step: 5
Training loss: 1.0994934779828534
Validation loss: 2.3342243683720514

Epoch: 6| Step: 6
Training loss: 0.6538802457353635
Validation loss: 2.3418991640030296

Epoch: 6| Step: 7
Training loss: 1.0737709915542824
Validation loss: 2.3506310186296977

Epoch: 6| Step: 8
Training loss: 1.073998223990565
Validation loss: 2.355159912258921

Epoch: 6| Step: 9
Training loss: 0.7170110481294193
Validation loss: 2.366507891133172

Epoch: 6| Step: 10
Training loss: 1.926913534021022
Validation loss: 2.4063352994019103

Epoch: 6| Step: 11
Training loss: 0.4776798501016694
Validation loss: 2.3634228594693685

Epoch: 6| Step: 12
Training loss: 0.8762394777392681
Validation loss: 2.4418673140744867

Epoch: 6| Step: 13
Training loss: 0.9894205093279181
Validation loss: 2.3630154481815366

Epoch: 476| Step: 0
Training loss: 1.9323792005044549
Validation loss: 2.4710892528913844

Epoch: 6| Step: 1
Training loss: 0.833777873361142
Validation loss: 2.374841062455309

Epoch: 6| Step: 2
Training loss: 0.6354472564671658
Validation loss: 2.440864323674052

Epoch: 6| Step: 3
Training loss: 0.9374271682423225
Validation loss: 2.423550213562713

Epoch: 6| Step: 4
Training loss: 0.6615566996525996
Validation loss: 2.4713877870532137

Epoch: 6| Step: 5
Training loss: 0.963237800453567
Validation loss: 2.450905071243683

Epoch: 6| Step: 6
Training loss: 1.0603419434326662
Validation loss: 2.3637588174384057

Epoch: 6| Step: 7
Training loss: 0.7840295555275546
Validation loss: 2.3567604410534653

Epoch: 6| Step: 8
Training loss: 0.5217478225984273
Validation loss: 2.369144747787064

Epoch: 6| Step: 9
Training loss: 0.6626037057643999
Validation loss: 2.375508670057319

Epoch: 6| Step: 10
Training loss: 1.0842212864875946
Validation loss: 2.3736366121538617

Epoch: 6| Step: 11
Training loss: 0.9260134506360975
Validation loss: 2.2887908282674405

Epoch: 6| Step: 12
Training loss: 0.9726756143748853
Validation loss: 2.4033442258375373

Epoch: 6| Step: 13
Training loss: 0.8517526886664957
Validation loss: 2.3802875365512803

Epoch: 477| Step: 0
Training loss: 0.7144276392809097
Validation loss: 2.3317561803699447

Epoch: 6| Step: 1
Training loss: 1.0850804741192892
Validation loss: 2.4120305825368686

Epoch: 6| Step: 2
Training loss: 0.9698208458618722
Validation loss: 2.4229428575842635

Epoch: 6| Step: 3
Training loss: 0.829063315795543
Validation loss: 2.2997838945147486

Epoch: 6| Step: 4
Training loss: 1.0515386978335044
Validation loss: 2.329277940695154

Epoch: 6| Step: 5
Training loss: 1.8310706379513606
Validation loss: 2.4071337341303125

Epoch: 6| Step: 6
Training loss: 0.6988027603211717
Validation loss: 2.385472397816641

Epoch: 6| Step: 7
Training loss: 0.770802256670837
Validation loss: 2.416424120300466

Epoch: 6| Step: 8
Training loss: 0.7384205439522131
Validation loss: 2.37130256005449

Epoch: 6| Step: 9
Training loss: 1.1305674965207286
Validation loss: 2.4308233614188133

Epoch: 6| Step: 10
Training loss: 0.7140885830378811
Validation loss: 2.370194151157611

Epoch: 6| Step: 11
Training loss: 0.7160730267130784
Validation loss: 2.3199109753112923

Epoch: 6| Step: 12
Training loss: 0.9264076785447972
Validation loss: 2.301238308081927

Epoch: 6| Step: 13
Training loss: 1.104852403475494
Validation loss: 2.3726082931328296

Epoch: 478| Step: 0
Training loss: 0.7714516161953199
Validation loss: 2.2838514494515247

Epoch: 6| Step: 1
Training loss: 0.8134227794439286
Validation loss: 2.3439829802849106

Epoch: 6| Step: 2
Training loss: 0.849292424154949
Validation loss: 2.3898436381793395

Epoch: 6| Step: 3
Training loss: 0.9854262657316308
Validation loss: 2.3682916097542255

Epoch: 6| Step: 4
Training loss: 0.675430647909086
Validation loss: 2.377549335730894

Epoch: 6| Step: 5
Training loss: 0.8049223103559565
Validation loss: 2.411073042138042

Epoch: 6| Step: 6
Training loss: 0.9203986291138255
Validation loss: 2.430680264869053

Epoch: 6| Step: 7
Training loss: 0.9069690482589893
Validation loss: 2.3721340019603505

Epoch: 6| Step: 8
Training loss: 0.8416042948421973
Validation loss: 2.390701676625028

Epoch: 6| Step: 9
Training loss: 0.9316341311950208
Validation loss: 2.414143460438047

Epoch: 6| Step: 10
Training loss: 1.999363619171883
Validation loss: 2.404447002306635

Epoch: 6| Step: 11
Training loss: 1.09510457763161
Validation loss: 2.341158684466407

Epoch: 6| Step: 12
Training loss: 0.8513912063644534
Validation loss: 2.3682627884101923

Epoch: 6| Step: 13
Training loss: 0.85403510375317
Validation loss: 2.2675086609955746

Epoch: 479| Step: 0
Training loss: 0.739431746264989
Validation loss: 2.2949705473329662

Epoch: 6| Step: 1
Training loss: 0.9355240024645637
Validation loss: 2.330161184891678

Epoch: 6| Step: 2
Training loss: 0.9777559540912834
Validation loss: 2.404017219697728

Epoch: 6| Step: 3
Training loss: 0.7395695743265963
Validation loss: 2.383554011801044

Epoch: 6| Step: 4
Training loss: 0.7962543838356344
Validation loss: 2.332795351022541

Epoch: 6| Step: 5
Training loss: 1.087479628448855
Validation loss: 2.427412413120207

Epoch: 6| Step: 6
Training loss: 0.8425022011453643
Validation loss: 2.36009282644428

Epoch: 6| Step: 7
Training loss: 0.8003355693359577
Validation loss: 2.4132362223608226

Epoch: 6| Step: 8
Training loss: 0.7638036121587651
Validation loss: 2.4005232905753395

Epoch: 6| Step: 9
Training loss: 1.805213554302868
Validation loss: 2.3890609520260004

Epoch: 6| Step: 10
Training loss: 0.9645421101032736
Validation loss: 2.361727970027097

Epoch: 6| Step: 11
Training loss: 0.8017711940303819
Validation loss: 2.365036935048492

Epoch: 6| Step: 12
Training loss: 1.1555848141373246
Validation loss: 2.3148012038574763

Epoch: 6| Step: 13
Training loss: 0.9320950469496145
Validation loss: 2.3640570106076892

Epoch: 480| Step: 0
Training loss: 0.6223856607241597
Validation loss: 2.3609439398184886

Epoch: 6| Step: 1
Training loss: 0.8165722545883499
Validation loss: 2.3838703257125693

Epoch: 6| Step: 2
Training loss: 0.7217948109398761
Validation loss: 2.4223171014534097

Epoch: 6| Step: 3
Training loss: 0.8777796327461355
Validation loss: 2.4183316808666238

Epoch: 6| Step: 4
Training loss: 0.7541824783508284
Validation loss: 2.3344795077033296

Epoch: 6| Step: 5
Training loss: 0.743965628965725
Validation loss: 2.480530071719796

Epoch: 6| Step: 6
Training loss: 1.7956602551577303
Validation loss: 2.3718959156053288

Epoch: 6| Step: 7
Training loss: 0.8391348752537863
Validation loss: 2.415804046718326

Epoch: 6| Step: 8
Training loss: 0.8545069753184698
Validation loss: 2.411927625751973

Epoch: 6| Step: 9
Training loss: 0.8386653706227747
Validation loss: 2.4113320086975594

Epoch: 6| Step: 10
Training loss: 0.7830737761042532
Validation loss: 2.354849873498202

Epoch: 6| Step: 11
Training loss: 1.1518123112477123
Validation loss: 2.378017363260936

Epoch: 6| Step: 12
Training loss: 0.8588675995087196
Validation loss: 2.336184088156

Epoch: 6| Step: 13
Training loss: 1.1491840556993453
Validation loss: 2.4152245007306874

Epoch: 481| Step: 0
Training loss: 0.7544347462228185
Validation loss: 2.4209723466587243

Epoch: 6| Step: 1
Training loss: 0.861345494240083
Validation loss: 2.443801206856822

Epoch: 6| Step: 2
Training loss: 0.6251261107052167
Validation loss: 2.3712733985349757

Epoch: 6| Step: 3
Training loss: 0.9818281802858814
Validation loss: 2.3065732632277514

Epoch: 6| Step: 4
Training loss: 0.9207633800316418
Validation loss: 2.372934010617574

Epoch: 6| Step: 5
Training loss: 0.9680235815643757
Validation loss: 2.3582112550491288

Epoch: 6| Step: 6
Training loss: 0.6786373180832034
Validation loss: 2.3644457718292147

Epoch: 6| Step: 7
Training loss: 0.843418409393664
Validation loss: 2.366306674563004

Epoch: 6| Step: 8
Training loss: 0.7996256235444352
Validation loss: 2.3513625557387514

Epoch: 6| Step: 9
Training loss: 1.7640304116505898
Validation loss: 2.411014608994011

Epoch: 6| Step: 10
Training loss: 1.1167819480792407
Validation loss: 2.306435973961082

Epoch: 6| Step: 11
Training loss: 0.9581384909937272
Validation loss: 2.3529241689532414

Epoch: 6| Step: 12
Training loss: 0.9771498477856229
Validation loss: 2.403707343745334

Epoch: 6| Step: 13
Training loss: 0.9748914230240943
Validation loss: 2.344335444900939

Epoch: 482| Step: 0
Training loss: 0.6191724414051284
Validation loss: 2.416283597985307

Epoch: 6| Step: 1
Training loss: 0.97933417098211
Validation loss: 2.2852010400878973

Epoch: 6| Step: 2
Training loss: 0.8077441557374972
Validation loss: 2.385061588415273

Epoch: 6| Step: 3
Training loss: 0.8536394321899113
Validation loss: 2.3668456608985333

Epoch: 6| Step: 4
Training loss: 1.0898508051161933
Validation loss: 2.413870969829081

Epoch: 6| Step: 5
Training loss: 0.7994631456060066
Validation loss: 2.380605148684822

Epoch: 6| Step: 6
Training loss: 0.8110606208492009
Validation loss: 2.3280749748159186

Epoch: 6| Step: 7
Training loss: 0.674791195150762
Validation loss: 2.351760719085272

Epoch: 6| Step: 8
Training loss: 0.8623098716709608
Validation loss: 2.3486659035739144

Epoch: 6| Step: 9
Training loss: 0.5922050956588006
Validation loss: 2.392745984140723

Epoch: 6| Step: 10
Training loss: 0.6898202324009006
Validation loss: 2.3943331336930074

Epoch: 6| Step: 11
Training loss: 2.09637707683926
Validation loss: 2.406539784478645

Epoch: 6| Step: 12
Training loss: 0.7522522170495946
Validation loss: 2.3854707368844146

Epoch: 6| Step: 13
Training loss: 0.782845546306614
Validation loss: 2.354963626356421

Epoch: 483| Step: 0
Training loss: 0.751065093974424
Validation loss: 2.312556277463042

Epoch: 6| Step: 1
Training loss: 0.6733331603893524
Validation loss: 2.44400553101013

Epoch: 6| Step: 2
Training loss: 1.0495685258532341
Validation loss: 2.347083785469313

Epoch: 6| Step: 3
Training loss: 0.8116098810054112
Validation loss: 2.3716950480664587

Epoch: 6| Step: 4
Training loss: 0.922690887188626
Validation loss: 2.3421513410962786

Epoch: 6| Step: 5
Training loss: 0.6805474552226075
Validation loss: 2.336833716497014

Epoch: 6| Step: 6
Training loss: 0.8592189994016661
Validation loss: 2.4347369359942506

Epoch: 6| Step: 7
Training loss: 1.0848797373768775
Validation loss: 2.332779910632489

Epoch: 6| Step: 8
Training loss: 0.7246298157310007
Validation loss: 2.3825317927555334

Epoch: 6| Step: 9
Training loss: 0.5091509858862945
Validation loss: 2.376124148897219

Epoch: 6| Step: 10
Training loss: 1.0121739957638214
Validation loss: 2.312065163448243

Epoch: 6| Step: 11
Training loss: 1.8041334746774986
Validation loss: 2.4660892397998864

Epoch: 6| Step: 12
Training loss: 0.9889499377278762
Validation loss: 2.355179081032827

Epoch: 6| Step: 13
Training loss: 0.6118298016883276
Validation loss: 2.3792933230256454

Epoch: 484| Step: 0
Training loss: 0.9719892919131106
Validation loss: 2.3628516076246453

Epoch: 6| Step: 1
Training loss: 0.7849731611413926
Validation loss: 2.3586001591750803

Epoch: 6| Step: 2
Training loss: 0.46650148566378463
Validation loss: 2.4268355157009127

Epoch: 6| Step: 3
Training loss: 0.7821870143765425
Validation loss: 2.395084749062031

Epoch: 6| Step: 4
Training loss: 0.5809705144356693
Validation loss: 2.356143224747155

Epoch: 6| Step: 5
Training loss: 1.1362203967242672
Validation loss: 2.336085941839873

Epoch: 6| Step: 6
Training loss: 0.9331799471928088
Validation loss: 2.4574613236017573

Epoch: 6| Step: 7
Training loss: 0.9977352603940983
Validation loss: 2.4094934624334057

Epoch: 6| Step: 8
Training loss: 1.7328316635021546
Validation loss: 2.3736401158258396

Epoch: 6| Step: 9
Training loss: 1.152211740982155
Validation loss: 2.3977845609127497

Epoch: 6| Step: 10
Training loss: 0.6924765110507981
Validation loss: 2.331014003639469

Epoch: 6| Step: 11
Training loss: 0.5785294741686391
Validation loss: 2.372309121599187

Epoch: 6| Step: 12
Training loss: 0.8350258963675139
Validation loss: 2.23417065551765

Epoch: 6| Step: 13
Training loss: 0.8212550606419265
Validation loss: 2.338527915554771

Epoch: 485| Step: 0
Training loss: 0.9429024484202693
Validation loss: 2.3549608427750077

Epoch: 6| Step: 1
Training loss: 0.6690657681238783
Validation loss: 2.302242770390686

Epoch: 6| Step: 2
Training loss: 0.588605300591504
Validation loss: 2.3512668273155812

Epoch: 6| Step: 3
Training loss: 0.8657551182202614
Validation loss: 2.3031337488811685

Epoch: 6| Step: 4
Training loss: 1.0252327933775627
Validation loss: 2.345235783238377

Epoch: 6| Step: 5
Training loss: 0.9461053093126099
Validation loss: 2.3585174334182355

Epoch: 6| Step: 6
Training loss: 0.7139772259902889
Validation loss: 2.4191830592203596

Epoch: 6| Step: 7
Training loss: 1.7129787304966846
Validation loss: 2.3425198975508352

Epoch: 6| Step: 8
Training loss: 0.8240090415259471
Validation loss: 2.3597737006478674

Epoch: 6| Step: 9
Training loss: 0.8173741348152348
Validation loss: 2.3149146222937786

Epoch: 6| Step: 10
Training loss: 0.9245230579255043
Validation loss: 2.359066544327102

Epoch: 6| Step: 11
Training loss: 0.7588634871776861
Validation loss: 2.341117909000619

Epoch: 6| Step: 12
Training loss: 0.8382528451335985
Validation loss: 2.405684360033545

Epoch: 6| Step: 13
Training loss: 0.8413157847446415
Validation loss: 2.2733333794830743

Epoch: 486| Step: 0
Training loss: 0.7703533912313179
Validation loss: 2.3480925169738542

Epoch: 6| Step: 1
Training loss: 1.1141539783558945
Validation loss: 2.3486155791093086

Epoch: 6| Step: 2
Training loss: 0.8349534776142445
Validation loss: 2.341257859843899

Epoch: 6| Step: 3
Training loss: 0.8011167986243622
Validation loss: 2.3930416269139263

Epoch: 6| Step: 4
Training loss: 1.019533354658388
Validation loss: 2.3379833725172974

Epoch: 6| Step: 5
Training loss: 0.8387396363529128
Validation loss: 2.3661843693071134

Epoch: 6| Step: 6
Training loss: 0.846849400319918
Validation loss: 2.395123660650785

Epoch: 6| Step: 7
Training loss: 0.7919562504490224
Validation loss: 2.4200526923366414

Epoch: 6| Step: 8
Training loss: 0.732725848380059
Validation loss: 2.3885558024046913

Epoch: 6| Step: 9
Training loss: 0.7012379224692548
Validation loss: 2.3889244154771543

Epoch: 6| Step: 10
Training loss: 0.698444982569678
Validation loss: 2.360201548442575

Epoch: 6| Step: 11
Training loss: 0.9563901349775834
Validation loss: 2.36069364152611

Epoch: 6| Step: 12
Training loss: 0.9360190774713677
Validation loss: 2.37260730446071

Epoch: 6| Step: 13
Training loss: 2.292040037314752
Validation loss: 2.374896221559714

Epoch: 487| Step: 0
Training loss: 1.105372933592564
Validation loss: 2.396168622653341

Epoch: 6| Step: 1
Training loss: 0.9192537120633135
Validation loss: 2.2982613355523167

Epoch: 6| Step: 2
Training loss: 0.4965521729381518
Validation loss: 2.3720127839851695

Epoch: 6| Step: 3
Training loss: 1.030066822902806
Validation loss: 2.3839920317205667

Epoch: 6| Step: 4
Training loss: 0.7046819191857596
Validation loss: 2.2846004455583495

Epoch: 6| Step: 5
Training loss: 1.00691289450375
Validation loss: 2.3722258656262705

Epoch: 6| Step: 6
Training loss: 0.8477168610872708
Validation loss: 2.323051530022533

Epoch: 6| Step: 7
Training loss: 0.8082216300339281
Validation loss: 2.3148298469337942

Epoch: 6| Step: 8
Training loss: 1.8812665488697018
Validation loss: 2.330935562096227

Epoch: 6| Step: 9
Training loss: 0.8366332679202069
Validation loss: 2.297788213968625

Epoch: 6| Step: 10
Training loss: 0.8828182051482724
Validation loss: 2.3636821610505283

Epoch: 6| Step: 11
Training loss: 0.5890230190898705
Validation loss: 2.3663975814262814

Epoch: 6| Step: 12
Training loss: 0.9108012782951099
Validation loss: 2.366131220108165

Epoch: 6| Step: 13
Training loss: 1.2590347890675608
Validation loss: 2.299032822116379

Epoch: 488| Step: 0
Training loss: 0.7253094604638874
Validation loss: 2.3388528021927244

Epoch: 6| Step: 1
Training loss: 1.1133913219981908
Validation loss: 2.3831634827831083

Epoch: 6| Step: 2
Training loss: 0.7915393367229088
Validation loss: 2.3918507068020003

Epoch: 6| Step: 3
Training loss: 0.8074613003270676
Validation loss: 2.3628153300412187

Epoch: 6| Step: 4
Training loss: 1.0751339429756834
Validation loss: 2.418545346691953

Epoch: 6| Step: 5
Training loss: 1.2306343088335572
Validation loss: 2.3918007754056814

Epoch: 6| Step: 6
Training loss: 1.0443196780735278
Validation loss: 2.3532916472075898

Epoch: 6| Step: 7
Training loss: 0.5386954730468766
Validation loss: 2.3313705564590745

Epoch: 6| Step: 8
Training loss: 0.9838894448822344
Validation loss: 2.34261115622706

Epoch: 6| Step: 9
Training loss: 1.160839149549984
Validation loss: 2.294274726199421

Epoch: 6| Step: 10
Training loss: 0.6163190695413754
Validation loss: 2.39623637739428

Epoch: 6| Step: 11
Training loss: 0.7057133610681011
Validation loss: 2.3286447891080826

Epoch: 6| Step: 12
Training loss: 0.7179467232099181
Validation loss: 2.405400082801215

Epoch: 6| Step: 13
Training loss: 2.219793692101125
Validation loss: 2.325546312095545

Epoch: 489| Step: 0
Training loss: 0.7723123477430287
Validation loss: 2.346131307435244

Epoch: 6| Step: 1
Training loss: 0.8135549592231834
Validation loss: 2.3230295948897957

Epoch: 6| Step: 2
Training loss: 0.6299256775930607
Validation loss: 2.364364944252774

Epoch: 6| Step: 3
Training loss: 0.7813722133412861
Validation loss: 2.3798473740838206

Epoch: 6| Step: 4
Training loss: 0.8941854616508413
Validation loss: 2.3206100430535233

Epoch: 6| Step: 5
Training loss: 0.6601012393219723
Validation loss: 2.3367460884942135

Epoch: 6| Step: 6
Training loss: 0.8701402380701884
Validation loss: 2.369079182719485

Epoch: 6| Step: 7
Training loss: 0.9378849193013367
Validation loss: 2.3804604377144964

Epoch: 6| Step: 8
Training loss: 0.6687437101763548
Validation loss: 2.317408542986215

Epoch: 6| Step: 9
Training loss: 0.8543289464608971
Validation loss: 2.4317389935379623

Epoch: 6| Step: 10
Training loss: 0.7019658388441634
Validation loss: 2.4244212314630786

Epoch: 6| Step: 11
Training loss: 1.670608040452038
Validation loss: 2.404351989568088

Epoch: 6| Step: 12
Training loss: 0.6414830114266274
Validation loss: 2.412454864880552

Epoch: 6| Step: 13
Training loss: 0.5910588815293343
Validation loss: 2.3830481703349835

Epoch: 490| Step: 0
Training loss: 1.0473945808624463
Validation loss: 2.3838475715179817

Epoch: 6| Step: 1
Training loss: 1.696015875674565
Validation loss: 2.3737684185890706

Epoch: 6| Step: 2
Training loss: 0.7797934878673956
Validation loss: 2.360223194050066

Epoch: 6| Step: 3
Training loss: 1.184897079746583
Validation loss: 2.354178578808269

Epoch: 6| Step: 4
Training loss: 0.7962147090163582
Validation loss: 2.3911219522762575

Epoch: 6| Step: 5
Training loss: 0.5952052302597315
Validation loss: 2.37158378946873

Epoch: 6| Step: 6
Training loss: 0.7793062061334369
Validation loss: 2.37605978955022

Epoch: 6| Step: 7
Training loss: 0.7062638475529025
Validation loss: 2.3532996781401514

Epoch: 6| Step: 8
Training loss: 0.9104408179483443
Validation loss: 2.3529854147747598

Epoch: 6| Step: 9
Training loss: 0.7631945276727959
Validation loss: 2.395313199702213

Epoch: 6| Step: 10
Training loss: 1.0721653403268971
Validation loss: 2.413470612409262

Epoch: 6| Step: 11
Training loss: 0.8502450603755506
Validation loss: 2.4459110468267604

Epoch: 6| Step: 12
Training loss: 0.6807672540059043
Validation loss: 2.37678804322395

Epoch: 6| Step: 13
Training loss: 0.8084440968188675
Validation loss: 2.437123310819594

Epoch: 491| Step: 0
Training loss: 1.931394185236157
Validation loss: 2.330980036732381

Epoch: 6| Step: 1
Training loss: 0.8901753545381311
Validation loss: 2.435624028876261

Epoch: 6| Step: 2
Training loss: 0.9778695781527711
Validation loss: 2.338956520973819

Epoch: 6| Step: 3
Training loss: 0.7794350714273665
Validation loss: 2.2978006751799946

Epoch: 6| Step: 4
Training loss: 0.7223536502226525
Validation loss: 2.324342720804593

Epoch: 6| Step: 5
Training loss: 0.8525509478427682
Validation loss: 2.3368185968035196

Epoch: 6| Step: 6
Training loss: 0.852657174474639
Validation loss: 2.2866483727995197

Epoch: 6| Step: 7
Training loss: 0.7241385850703758
Validation loss: 2.3559529066041742

Epoch: 6| Step: 8
Training loss: 0.7631705509372135
Validation loss: 2.3819355712516157

Epoch: 6| Step: 9
Training loss: 0.611365393334417
Validation loss: 2.3981493341577402

Epoch: 6| Step: 10
Training loss: 0.7294867539618386
Validation loss: 2.3120097178555015

Epoch: 6| Step: 11
Training loss: 0.9059303969768966
Validation loss: 2.3488758558257983

Epoch: 6| Step: 12
Training loss: 0.7831333728656265
Validation loss: 2.3986030711991715

Epoch: 6| Step: 13
Training loss: 0.4707981504387772
Validation loss: 2.3883755260204382

Epoch: 492| Step: 0
Training loss: 0.6538422784539415
Validation loss: 2.459219729127928

Epoch: 6| Step: 1
Training loss: 0.8493323565087723
Validation loss: 2.3451024518371004

Epoch: 6| Step: 2
Training loss: 1.0789992616242576
Validation loss: 2.4971524931769844

Epoch: 6| Step: 3
Training loss: 0.7091462342007964
Validation loss: 2.395568036500333

Epoch: 6| Step: 4
Training loss: 0.5735558556592415
Validation loss: 2.3956823097199895

Epoch: 6| Step: 5
Training loss: 0.6639049343096992
Validation loss: 2.327066944600853

Epoch: 6| Step: 6
Training loss: 0.6909188314371822
Validation loss: 2.4027138947184685

Epoch: 6| Step: 7
Training loss: 1.035830871710048
Validation loss: 2.3989195504085736

Epoch: 6| Step: 8
Training loss: 0.5928340673469816
Validation loss: 2.3783269495070334

Epoch: 6| Step: 9
Training loss: 0.9170260519613884
Validation loss: 2.3821063133828178

Epoch: 6| Step: 10
Training loss: 1.8433210229491335
Validation loss: 2.396531995545271

Epoch: 6| Step: 11
Training loss: 0.9635203316190891
Validation loss: 2.3489133950912007

Epoch: 6| Step: 12
Training loss: 0.9046860386864648
Validation loss: 2.3679773661824126

Epoch: 6| Step: 13
Training loss: 1.2602659666067395
Validation loss: 2.3306503655637094

Epoch: 493| Step: 0
Training loss: 0.8875030208589962
Validation loss: 2.4003195521697585

Epoch: 6| Step: 1
Training loss: 1.012470805371259
Validation loss: 2.3366517690323776

Epoch: 6| Step: 2
Training loss: 0.720176111246636
Validation loss: 2.407093578891095

Epoch: 6| Step: 3
Training loss: 0.9357355680094217
Validation loss: 2.32242481865156

Epoch: 6| Step: 4
Training loss: 0.6271611994392609
Validation loss: 2.3599542337199657

Epoch: 6| Step: 5
Training loss: 0.6780936308606247
Validation loss: 2.3345318066142666

Epoch: 6| Step: 6
Training loss: 1.7937987158137962
Validation loss: 2.3489657988248998

Epoch: 6| Step: 7
Training loss: 0.5589468047007274
Validation loss: 2.4008326655817553

Epoch: 6| Step: 8
Training loss: 1.0351878611218477
Validation loss: 2.4197035121903236

Epoch: 6| Step: 9
Training loss: 0.7630169882476754
Validation loss: 2.4274964941900157

Epoch: 6| Step: 10
Training loss: 0.7962067738152644
Validation loss: 2.4112660342354215

Epoch: 6| Step: 11
Training loss: 1.2007017130374642
Validation loss: 2.3881346779583743

Epoch: 6| Step: 12
Training loss: 0.710489991581308
Validation loss: 2.3107219368949634

Epoch: 6| Step: 13
Training loss: 0.4857815501450488
Validation loss: 2.379589026540132

Epoch: 494| Step: 0
Training loss: 0.6670417152883084
Validation loss: 2.328018573652711

Epoch: 6| Step: 1
Training loss: 1.9132638315986608
Validation loss: 2.335441233461544

Epoch: 6| Step: 2
Training loss: 0.6766512568094077
Validation loss: 2.346950694502655

Epoch: 6| Step: 3
Training loss: 0.6618289860192205
Validation loss: 2.2968925021695314

Epoch: 6| Step: 4
Training loss: 1.035710427554231
Validation loss: 2.290173684323302

Epoch: 6| Step: 5
Training loss: 0.7581692671844078
Validation loss: 2.3406471019527033

Epoch: 6| Step: 6
Training loss: 0.7069100544785265
Validation loss: 2.348593370520328

Epoch: 6| Step: 7
Training loss: 0.6686445465012117
Validation loss: 2.4080124308238315

Epoch: 6| Step: 8
Training loss: 0.8594509784750396
Validation loss: 2.3114725838761268

Epoch: 6| Step: 9
Training loss: 0.9798975644779468
Validation loss: 2.343681086685858

Epoch: 6| Step: 10
Training loss: 0.8429534118784223
Validation loss: 2.353399424134551

Epoch: 6| Step: 11
Training loss: 0.9611929577196816
Validation loss: 2.3749298383261657

Epoch: 6| Step: 12
Training loss: 1.098216283887226
Validation loss: 2.297034694401418

Epoch: 6| Step: 13
Training loss: 0.4818183738003082
Validation loss: 2.3815871599707004

Epoch: 495| Step: 0
Training loss: 0.6472171192031685
Validation loss: 2.3980360390910294

Epoch: 6| Step: 1
Training loss: 0.7584817821399508
Validation loss: 2.408402476755409

Epoch: 6| Step: 2
Training loss: 0.9174080292758892
Validation loss: 2.3535151576982623

Epoch: 6| Step: 3
Training loss: 1.0910727295099636
Validation loss: 2.410880254707685

Epoch: 6| Step: 4
Training loss: 0.7428740287593403
Validation loss: 2.3676019749275596

Epoch: 6| Step: 5
Training loss: 0.6073452818438794
Validation loss: 2.3717897725536017

Epoch: 6| Step: 6
Training loss: 0.9133147743409273
Validation loss: 2.291464206742734

Epoch: 6| Step: 7
Training loss: 1.2185241783445022
Validation loss: 2.3932139949542415

Epoch: 6| Step: 8
Training loss: 0.8351834541650436
Validation loss: 2.3593061665691133

Epoch: 6| Step: 9
Training loss: 0.7619732944960184
Validation loss: 2.4625169369810704

Epoch: 6| Step: 10
Training loss: 0.6758029691700935
Validation loss: 2.2775437718137646

Epoch: 6| Step: 11
Training loss: 1.7606311494383367
Validation loss: 2.278592918707446

Epoch: 6| Step: 12
Training loss: 0.8919542331693685
Validation loss: 2.4393128731012603

Epoch: 6| Step: 13
Training loss: 0.65921474787403
Validation loss: 2.3875107061258487

Epoch: 496| Step: 0
Training loss: 0.7092929305273538
Validation loss: 2.367123139189188

Epoch: 6| Step: 1
Training loss: 1.754687027154113
Validation loss: 2.36617199086727

Epoch: 6| Step: 2
Training loss: 0.7305052641039874
Validation loss: 2.3127589237404385

Epoch: 6| Step: 3
Training loss: 0.6846235094066396
Validation loss: 2.413608977678577

Epoch: 6| Step: 4
Training loss: 0.8439732009104202
Validation loss: 2.3660756155912948

Epoch: 6| Step: 5
Training loss: 1.055685404827335
Validation loss: 2.356947243822738

Epoch: 6| Step: 6
Training loss: 1.1480344726889422
Validation loss: 2.2708826002331204

Epoch: 6| Step: 7
Training loss: 0.6870955447940683
Validation loss: 2.390178148851468

Epoch: 6| Step: 8
Training loss: 0.9572903029494729
Validation loss: 2.316406344072208

Epoch: 6| Step: 9
Training loss: 0.7667029441322211
Validation loss: 2.3693272502142975

Epoch: 6| Step: 10
Training loss: 0.9776831338754839
Validation loss: 2.337683912939477

Epoch: 6| Step: 11
Training loss: 0.7700850145051712
Validation loss: 2.3060065497717934

Epoch: 6| Step: 12
Training loss: 0.6303136490606635
Validation loss: 2.3464664853317343

Epoch: 6| Step: 13
Training loss: 0.5977357798998477
Validation loss: 2.3667519592879405

Epoch: 497| Step: 0
Training loss: 1.7193552512085448
Validation loss: 2.409682044609746

Epoch: 6| Step: 1
Training loss: 0.8417980079023699
Validation loss: 2.3383454234696144

Epoch: 6| Step: 2
Training loss: 0.5006031034922062
Validation loss: 2.3681082940731804

Epoch: 6| Step: 3
Training loss: 0.8553207478458339
Validation loss: 2.2805767540850788

Epoch: 6| Step: 4
Training loss: 0.6410576824592232
Validation loss: 2.3757313766365153

Epoch: 6| Step: 5
Training loss: 0.6921319978045725
Validation loss: 2.3423945926081142

Epoch: 6| Step: 6
Training loss: 1.0822446316634156
Validation loss: 2.35627747854221

Epoch: 6| Step: 7
Training loss: 0.8001878353977193
Validation loss: 2.3005881198941354

Epoch: 6| Step: 8
Training loss: 0.8336203001561673
Validation loss: 2.3317740237649147

Epoch: 6| Step: 9
Training loss: 0.7447285169670336
Validation loss: 2.3095817721901923

Epoch: 6| Step: 10
Training loss: 0.7283522599144953
Validation loss: 2.2991210350536377

Epoch: 6| Step: 11
Training loss: 0.9052553308809841
Validation loss: 2.3933310247314097

Epoch: 6| Step: 12
Training loss: 0.7767855302844903
Validation loss: 2.310596935723739

Epoch: 6| Step: 13
Training loss: 1.1126036606402865
Validation loss: 2.394311944213582

Epoch: 498| Step: 0
Training loss: 0.8745015291251875
Validation loss: 2.3913400304422034

Epoch: 6| Step: 1
Training loss: 0.7681481959888837
Validation loss: 2.3931770790815543

Epoch: 6| Step: 2
Training loss: 1.868900869652146
Validation loss: 2.400115802878247

Epoch: 6| Step: 3
Training loss: 0.7779296124128094
Validation loss: 2.2995196401281515

Epoch: 6| Step: 4
Training loss: 0.597953323631769
Validation loss: 2.359692481627382

Epoch: 6| Step: 5
Training loss: 1.1242858421341537
Validation loss: 2.408979167183772

Epoch: 6| Step: 6
Training loss: 1.107681109514955
Validation loss: 2.3321492201757072

Epoch: 6| Step: 7
Training loss: 0.8750397468803648
Validation loss: 2.346855335309691

Epoch: 6| Step: 8
Training loss: 0.8993683015363167
Validation loss: 2.3196993505521095

Epoch: 6| Step: 9
Training loss: 0.6818082324660355
Validation loss: 2.363675514093512

Epoch: 6| Step: 10
Training loss: 0.8600687867755314
Validation loss: 2.3418239344361953

Epoch: 6| Step: 11
Training loss: 0.9462546075585284
Validation loss: 2.3056141192773683

Epoch: 6| Step: 12
Training loss: 0.8201519400275705
Validation loss: 2.337642580616678

Epoch: 6| Step: 13
Training loss: 0.698741707488177
Validation loss: 2.2723040605283265

Epoch: 499| Step: 0
Training loss: 0.7401337165132407
Validation loss: 2.352656149271794

Epoch: 6| Step: 1
Training loss: 1.723402212132715
Validation loss: 2.4041525173476446

Epoch: 6| Step: 2
Training loss: 0.5911456260736805
Validation loss: 2.325307038774478

Epoch: 6| Step: 3
Training loss: 0.948124447082479
Validation loss: 2.3664951579776186

Epoch: 6| Step: 4
Training loss: 0.8873955584577616
Validation loss: 2.2839441027178804

Epoch: 6| Step: 5
Training loss: 0.7123769084947025
Validation loss: 2.3800575311076724

Epoch: 6| Step: 6
Training loss: 0.5620486249828326
Validation loss: 2.375557427654679

Epoch: 6| Step: 7
Training loss: 1.0681664329247218
Validation loss: 2.36299503186147

Epoch: 6| Step: 8
Training loss: 0.9419579689728369
Validation loss: 2.29460106598275

Epoch: 6| Step: 9
Training loss: 0.587916427502312
Validation loss: 2.3588805728818816

Epoch: 6| Step: 10
Training loss: 0.7113442567339952
Validation loss: 2.333130835024597

Epoch: 6| Step: 11
Training loss: 0.7922530303275986
Validation loss: 2.366755325838202

Epoch: 6| Step: 12
Training loss: 0.7589927606124309
Validation loss: 2.3368216543201736

Epoch: 6| Step: 13
Training loss: 0.8965991908663508
Validation loss: 2.4169019532225606

Epoch: 500| Step: 0
Training loss: 0.5156241041233487
Validation loss: 2.441079450363992

Epoch: 6| Step: 1
Training loss: 0.7986570142370727
Validation loss: 2.3423578039255086

Epoch: 6| Step: 2
Training loss: 0.8445955560781832
Validation loss: 2.3418683993360703

Epoch: 6| Step: 3
Training loss: 0.7013267622292048
Validation loss: 2.389997213947864

Epoch: 6| Step: 4
Training loss: 0.6143903483184054
Validation loss: 2.3462603643846447

Epoch: 6| Step: 5
Training loss: 1.0046750104967346
Validation loss: 2.3633205610216192

Epoch: 6| Step: 6
Training loss: 1.1270045858762059
Validation loss: 2.3618406057572896

Epoch: 6| Step: 7
Training loss: 0.9869160023845162
Validation loss: 2.389375491336571

Epoch: 6| Step: 8
Training loss: 0.7726116973714293
Validation loss: 2.3527542989950287

Epoch: 6| Step: 9
Training loss: 0.8099683052502417
Validation loss: 2.3400232241883647

Epoch: 6| Step: 10
Training loss: 0.7979731753054611
Validation loss: 2.381035463638551

Epoch: 6| Step: 11
Training loss: 0.9802884243801693
Validation loss: 2.305890721996858

Epoch: 6| Step: 12
Training loss: 1.7630395780287176
Validation loss: 2.313835712791188

Epoch: 6| Step: 13
Training loss: 0.6834354762364387
Validation loss: 2.3844029232549024

Epoch: 501| Step: 0
Training loss: 0.7460050679973033
Validation loss: 2.334750825672748

Epoch: 6| Step: 1
Training loss: 0.6632080415149598
Validation loss: 2.3640709082762963

Epoch: 6| Step: 2
Training loss: 0.8355602946369675
Validation loss: 2.316304053230875

Epoch: 6| Step: 3
Training loss: 0.6760745872707044
Validation loss: 2.4463873434625696

Epoch: 6| Step: 4
Training loss: 0.7994972914506122
Validation loss: 2.3916000226653487

Epoch: 6| Step: 5
Training loss: 0.9341614086764274
Validation loss: 2.428859048615229

Epoch: 6| Step: 6
Training loss: 0.7534664630425635
Validation loss: 2.314985043650514

Epoch: 6| Step: 7
Training loss: 0.6917410648693952
Validation loss: 2.3784775427723432

Epoch: 6| Step: 8
Training loss: 0.9047852221271225
Validation loss: 2.3818367544340626

Epoch: 6| Step: 9
Training loss: 0.8344217980223015
Validation loss: 2.3751639011133268

Epoch: 6| Step: 10
Training loss: 0.8372062253264011
Validation loss: 2.3715178886153776

Epoch: 6| Step: 11
Training loss: 1.7777173666160313
Validation loss: 2.3612172128466313

Epoch: 6| Step: 12
Training loss: 1.0088737873197244
Validation loss: 2.3853095661485337

Epoch: 6| Step: 13
Training loss: 0.6753914872225216
Validation loss: 2.3397339664262926

Epoch: 502| Step: 0
Training loss: 0.8117163620474004
Validation loss: 2.3455691512656975

Epoch: 6| Step: 1
Training loss: 0.9506539377878038
Validation loss: 2.3405606539781685

Epoch: 6| Step: 2
Training loss: 0.7006319565304295
Validation loss: 2.3380113368462543

Epoch: 6| Step: 3
Training loss: 0.5792590694219633
Validation loss: 2.4418217388387244

Epoch: 6| Step: 4
Training loss: 0.8298986263299172
Validation loss: 2.355632093565572

Epoch: 6| Step: 5
Training loss: 0.7172441464328542
Validation loss: 2.3495722644765156

Epoch: 6| Step: 6
Training loss: 0.6316814204189816
Validation loss: 2.3710159873127745

Epoch: 6| Step: 7
Training loss: 1.0372155776307934
Validation loss: 2.3257626886124636

Epoch: 6| Step: 8
Training loss: 0.8995845935371575
Validation loss: 2.394045102400798

Epoch: 6| Step: 9
Training loss: 0.9867398450805863
Validation loss: 2.3151211847946596

Epoch: 6| Step: 10
Training loss: 0.6733577689923897
Validation loss: 2.371687986328391

Epoch: 6| Step: 11
Training loss: 0.8541746759426841
Validation loss: 2.340622492200891

Epoch: 6| Step: 12
Training loss: 0.7655148329590261
Validation loss: 2.3169165443825124

Epoch: 6| Step: 13
Training loss: 2.254203684203788
Validation loss: 2.4065037127350144

Epoch: 503| Step: 0
Training loss: 0.8940354351599238
Validation loss: 2.34403244012164

Epoch: 6| Step: 1
Training loss: 1.2787871531946429
Validation loss: 2.346187948455914

Epoch: 6| Step: 2
Training loss: 0.7623351122067136
Validation loss: 2.329415380469292

Epoch: 6| Step: 3
Training loss: 0.8622782131809749
Validation loss: 2.352065453697147

Epoch: 6| Step: 4
Training loss: 0.640020806637447
Validation loss: 2.362185790116913

Epoch: 6| Step: 5
Training loss: 0.8006810567559515
Validation loss: 2.329404974735497

Epoch: 6| Step: 6
Training loss: 0.9714526654058421
Validation loss: 2.3944227966287936

Epoch: 6| Step: 7
Training loss: 0.6325381119746329
Validation loss: 2.3930070840023747

Epoch: 6| Step: 8
Training loss: 0.7319333494464653
Validation loss: 2.4069931764126307

Epoch: 6| Step: 9
Training loss: 0.9109049979377346
Validation loss: 2.3354397702116927

Epoch: 6| Step: 10
Training loss: 0.5006328987898603
Validation loss: 2.3927256731080773

Epoch: 6| Step: 11
Training loss: 1.7269511756290599
Validation loss: 2.39366051231299

Epoch: 6| Step: 12
Training loss: 0.7254503002692229
Validation loss: 2.3891673884615727

Epoch: 6| Step: 13
Training loss: 0.8610907333451315
Validation loss: 2.418856704832897

Epoch: 504| Step: 0
Training loss: 0.6019015161965764
Validation loss: 2.3491072377766278

Epoch: 6| Step: 1
Training loss: 0.7255758333593665
Validation loss: 2.34794167926585

Epoch: 6| Step: 2
Training loss: 0.6361522377615831
Validation loss: 2.3324780733402783

Epoch: 6| Step: 3
Training loss: 0.7758496364788589
Validation loss: 2.353827038371968

Epoch: 6| Step: 4
Training loss: 1.0425631416647676
Validation loss: 2.3749467426021686

Epoch: 6| Step: 5
Training loss: 0.6241116647928789
Validation loss: 2.388946870204488

Epoch: 6| Step: 6
Training loss: 0.6184713795977885
Validation loss: 2.3553443929875018

Epoch: 6| Step: 7
Training loss: 0.9261645718611986
Validation loss: 2.384108066283906

Epoch: 6| Step: 8
Training loss: 0.9460891811723587
Validation loss: 2.3295513812271382

Epoch: 6| Step: 9
Training loss: 0.661235401302493
Validation loss: 2.3227740526853475

Epoch: 6| Step: 10
Training loss: 1.8022849864995396
Validation loss: 2.3576866856402856

Epoch: 6| Step: 11
Training loss: 0.45120551244013796
Validation loss: 2.3979316999258313

Epoch: 6| Step: 12
Training loss: 0.8500354268601202
Validation loss: 2.374762347797999

Epoch: 6| Step: 13
Training loss: 0.8208533184568363
Validation loss: 2.4117338569356885

Epoch: 505| Step: 0
Training loss: 0.7743346665464373
Validation loss: 2.3509493375813704

Epoch: 6| Step: 1
Training loss: 0.6850012322226808
Validation loss: 2.3087668846649962

Epoch: 6| Step: 2
Training loss: 0.6830798806230473
Validation loss: 2.3321316011541775

Epoch: 6| Step: 3
Training loss: 0.9755667836368147
Validation loss: 2.348704032610331

Epoch: 6| Step: 4
Training loss: 0.6242547360241718
Validation loss: 2.37885896040433

Epoch: 6| Step: 5
Training loss: 0.8116211172504809
Validation loss: 2.393150041109424

Epoch: 6| Step: 6
Training loss: 0.8473501751554298
Validation loss: 2.3958051914383143

Epoch: 6| Step: 7
Training loss: 0.993543584246767
Validation loss: 2.379425933396266

Epoch: 6| Step: 8
Training loss: 1.6700844847272573
Validation loss: 2.368854898107468

Epoch: 6| Step: 9
Training loss: 0.740801953451061
Validation loss: 2.3925019381968293

Epoch: 6| Step: 10
Training loss: 0.8416007537023448
Validation loss: 2.3511966247217106

Epoch: 6| Step: 11
Training loss: 0.6328979010705835
Validation loss: 2.3486448762348613

Epoch: 6| Step: 12
Training loss: 0.6676457834528149
Validation loss: 2.3261140015585893

Epoch: 6| Step: 13
Training loss: 0.6298793112487477
Validation loss: 2.4200694811106254

Epoch: 506| Step: 0
Training loss: 1.828702590859777
Validation loss: 2.404825661318481

Epoch: 6| Step: 1
Training loss: 0.7942522682563397
Validation loss: 2.4143284981224875

Epoch: 6| Step: 2
Training loss: 0.7464649016247213
Validation loss: 2.403536451925288

Epoch: 6| Step: 3
Training loss: 0.6327285239932016
Validation loss: 2.410265915281479

Epoch: 6| Step: 4
Training loss: 0.8265052285210751
Validation loss: 2.3136714195512553

Epoch: 6| Step: 5
Training loss: 0.8190576310287769
Validation loss: 2.360522856371607

Epoch: 6| Step: 6
Training loss: 0.47016667231185966
Validation loss: 2.304993495576968

Epoch: 6| Step: 7
Training loss: 0.8406871730119482
Validation loss: 2.2883542480001737

Epoch: 6| Step: 8
Training loss: 0.7059615035449036
Validation loss: 2.3309480660678874

Epoch: 6| Step: 9
Training loss: 0.7064963999640985
Validation loss: 2.4280542147083026

Epoch: 6| Step: 10
Training loss: 0.9193086301185424
Validation loss: 2.3675028760333623

Epoch: 6| Step: 11
Training loss: 1.0093056905943016
Validation loss: 2.3760390941933967

Epoch: 6| Step: 12
Training loss: 0.7283942809308273
Validation loss: 2.3837806944262008

Epoch: 6| Step: 13
Training loss: 0.7978904462511771
Validation loss: 2.306636812835005

Epoch: 507| Step: 0
Training loss: 0.8151844501059559
Validation loss: 2.3756267538823193

Epoch: 6| Step: 1
Training loss: 0.911640316188942
Validation loss: 2.337261245622125

Epoch: 6| Step: 2
Training loss: 1.7991304257470822
Validation loss: 2.392373751763353

Epoch: 6| Step: 3
Training loss: 1.3028527339030718
Validation loss: 2.357222082983353

Epoch: 6| Step: 4
Training loss: 0.7531216348280059
Validation loss: 2.3510879688109823

Epoch: 6| Step: 5
Training loss: 0.6008813643161114
Validation loss: 2.34560781700582

Epoch: 6| Step: 6
Training loss: 0.7169120342662644
Validation loss: 2.3489464156369606

Epoch: 6| Step: 7
Training loss: 0.7402953271254862
Validation loss: 2.397875643960209

Epoch: 6| Step: 8
Training loss: 0.8904235678979397
Validation loss: 2.349926535482008

Epoch: 6| Step: 9
Training loss: 0.92025073869132
Validation loss: 2.3105611291967056

Epoch: 6| Step: 10
Training loss: 0.6037678854921157
Validation loss: 2.367489052383038

Epoch: 6| Step: 11
Training loss: 0.6103418212113264
Validation loss: 2.381360117287614

Epoch: 6| Step: 12
Training loss: 0.6905984847558415
Validation loss: 2.3362643089100508

Epoch: 6| Step: 13
Training loss: 0.9021295070210537
Validation loss: 2.399553447714255

Epoch: 508| Step: 0
Training loss: 0.6914966330208387
Validation loss: 2.2461275744644444

Epoch: 6| Step: 1
Training loss: 0.8019275926928311
Validation loss: 2.393329736125495

Epoch: 6| Step: 2
Training loss: 1.8861364883840515
Validation loss: 2.3600829394153973

Epoch: 6| Step: 3
Training loss: 0.5359344949443414
Validation loss: 2.271261648031668

Epoch: 6| Step: 4
Training loss: 0.8144006506392647
Validation loss: 2.4123152234956007

Epoch: 6| Step: 5
Training loss: 0.6171788323675017
Validation loss: 2.4395648780914163

Epoch: 6| Step: 6
Training loss: 0.5948663055656666
Validation loss: 2.4026389096007144

Epoch: 6| Step: 7
Training loss: 1.1891299655938548
Validation loss: 2.379236544546978

Epoch: 6| Step: 8
Training loss: 0.8251906174746244
Validation loss: 2.3870286071243463

Epoch: 6| Step: 9
Training loss: 0.6704745223562072
Validation loss: 2.403181049755754

Epoch: 6| Step: 10
Training loss: 0.48488238125124794
Validation loss: 2.3741235853852665

Epoch: 6| Step: 11
Training loss: 0.7078853527580462
Validation loss: 2.4128072031388683

Epoch: 6| Step: 12
Training loss: 0.829342073708297
Validation loss: 2.3961623776880465

Epoch: 6| Step: 13
Training loss: 0.6551261543041033
Validation loss: 2.356204045794356

Epoch: 509| Step: 0
Training loss: 0.6146019970489938
Validation loss: 2.3914936484019544

Epoch: 6| Step: 1
Training loss: 0.5716753314040935
Validation loss: 2.361032402693956

Epoch: 6| Step: 2
Training loss: 1.0094950625226602
Validation loss: 2.3619228059235753

Epoch: 6| Step: 3
Training loss: 0.46998379775791527
Validation loss: 2.34261827169138

Epoch: 6| Step: 4
Training loss: 0.6605037248753319
Validation loss: 2.4106258216044503

Epoch: 6| Step: 5
Training loss: 0.9309283398667053
Validation loss: 2.4266868273413573

Epoch: 6| Step: 6
Training loss: 1.0222115781881802
Validation loss: 2.3231762274242334

Epoch: 6| Step: 7
Training loss: 0.9861946242225202
Validation loss: 2.3801521759039588

Epoch: 6| Step: 8
Training loss: 0.6382895909188127
Validation loss: 2.3532905883251254

Epoch: 6| Step: 9
Training loss: 1.0115742819603433
Validation loss: 2.3221392745888205

Epoch: 6| Step: 10
Training loss: 0.845488769993571
Validation loss: 2.3435218163985474

Epoch: 6| Step: 11
Training loss: 1.6724725528854065
Validation loss: 2.3597096873561125

Epoch: 6| Step: 12
Training loss: 0.7061518052291241
Validation loss: 2.303058889920679

Epoch: 6| Step: 13
Training loss: 0.31996317167250726
Validation loss: 2.3708337478843506

Epoch: 510| Step: 0
Training loss: 0.765267113320718
Validation loss: 2.376004595417277

Epoch: 6| Step: 1
Training loss: 0.870234968474775
Validation loss: 2.329317247764325

Epoch: 6| Step: 2
Training loss: 0.680820704295933
Validation loss: 2.3802549949501297

Epoch: 6| Step: 3
Training loss: 0.8959099086295708
Validation loss: 2.3268264978073456

Epoch: 6| Step: 4
Training loss: 1.0319691664614008
Validation loss: 2.3572537277534464

Epoch: 6| Step: 5
Training loss: 0.5461371757912008
Validation loss: 2.3617657894073822

Epoch: 6| Step: 6
Training loss: 0.8835833399637518
Validation loss: 2.3860128900411355

Epoch: 6| Step: 7
Training loss: 0.57342063816652
Validation loss: 2.3447496837637285

Epoch: 6| Step: 8
Training loss: 0.8326136024106197
Validation loss: 2.3632679950339344

Epoch: 6| Step: 9
Training loss: 0.7585654696409317
Validation loss: 2.359539875652494

Epoch: 6| Step: 10
Training loss: 0.7496519075684775
Validation loss: 2.3536126529131587

Epoch: 6| Step: 11
Training loss: 1.841774544929421
Validation loss: 2.349465381049761

Epoch: 6| Step: 12
Training loss: 0.5619331523687621
Validation loss: 2.236998757164571

Epoch: 6| Step: 13
Training loss: 1.1170209747196165
Validation loss: 2.307739582851463

Epoch: 511| Step: 0
Training loss: 0.5550239509706973
Validation loss: 2.389832899123589

Epoch: 6| Step: 1
Training loss: 0.6413448290392717
Validation loss: 2.376318976049633

Epoch: 6| Step: 2
Training loss: 0.8878844409060996
Validation loss: 2.3152592767128812

Epoch: 6| Step: 3
Training loss: 0.8655628760454974
Validation loss: 2.308608999022025

Epoch: 6| Step: 4
Training loss: 1.7561188401086973
Validation loss: 2.3033382703778287

Epoch: 6| Step: 5
Training loss: 0.7596631606175774
Validation loss: 2.3647027447441724

Epoch: 6| Step: 6
Training loss: 0.9087861845428788
Validation loss: 2.397847264807233

Epoch: 6| Step: 7
Training loss: 0.6472212634081781
Validation loss: 2.353548655046061

Epoch: 6| Step: 8
Training loss: 0.7043741785702997
Validation loss: 2.414042526551698

Epoch: 6| Step: 9
Training loss: 0.8658460947539812
Validation loss: 2.402596764455423

Epoch: 6| Step: 10
Training loss: 0.8382172559218478
Validation loss: 2.3681959875754512

Epoch: 6| Step: 11
Training loss: 0.7395742487461395
Validation loss: 2.382583160095675

Epoch: 6| Step: 12
Training loss: 1.0212995606329875
Validation loss: 2.3704699245577756

Epoch: 6| Step: 13
Training loss: 0.5588747131561929
Validation loss: 2.3691277285294694

Epoch: 512| Step: 0
Training loss: 1.7506783396866061
Validation loss: 2.3662039623218885

Epoch: 6| Step: 1
Training loss: 0.4696035243818416
Validation loss: 2.3876300764521727

Epoch: 6| Step: 2
Training loss: 0.8088394013035809
Validation loss: 2.316488085289671

Epoch: 6| Step: 3
Training loss: 0.6175597070484689
Validation loss: 2.2916501317774793

Epoch: 6| Step: 4
Training loss: 0.6812087169002693
Validation loss: 2.3031094172865783

Epoch: 6| Step: 5
Training loss: 0.9325524432492229
Validation loss: 2.318820921283147

Epoch: 6| Step: 6
Training loss: 0.8477279703061615
Validation loss: 2.3675369120697933

Epoch: 6| Step: 7
Training loss: 0.9766078480681928
Validation loss: 2.3235584926439996

Epoch: 6| Step: 8
Training loss: 0.7754294436176085
Validation loss: 2.381452324248198

Epoch: 6| Step: 9
Training loss: 0.6012138247958129
Validation loss: 2.3315284563362524

Epoch: 6| Step: 10
Training loss: 0.8662404568189171
Validation loss: 2.417680143476413

Epoch: 6| Step: 11
Training loss: 1.0283804764495732
Validation loss: 2.2537375982565075

Epoch: 6| Step: 12
Training loss: 0.9404328565058886
Validation loss: 2.351496410902709

Epoch: 6| Step: 13
Training loss: 1.0299830890859814
Validation loss: 2.384267791947118

Epoch: 513| Step: 0
Training loss: 0.5139147398291765
Validation loss: 2.299771347067234

Epoch: 6| Step: 1
Training loss: 1.754545099691426
Validation loss: 2.311511461734216

Epoch: 6| Step: 2
Training loss: 0.8133076541656311
Validation loss: 2.3907634768190538

Epoch: 6| Step: 3
Training loss: 0.7975790616012307
Validation loss: 2.3401263307389475

Epoch: 6| Step: 4
Training loss: 0.6362594867216387
Validation loss: 2.3968585333246692

Epoch: 6| Step: 5
Training loss: 0.8684523696971626
Validation loss: 2.362751746905373

Epoch: 6| Step: 6
Training loss: 0.9937013506227267
Validation loss: 2.295076020247326

Epoch: 6| Step: 7
Training loss: 0.9138115758539631
Validation loss: 2.3909048640079056

Epoch: 6| Step: 8
Training loss: 0.6690838301428691
Validation loss: 2.4170455663874604

Epoch: 6| Step: 9
Training loss: 0.7678563048272613
Validation loss: 2.317422452972309

Epoch: 6| Step: 10
Training loss: 0.7564249214715713
Validation loss: 2.2995383395855487

Epoch: 6| Step: 11
Training loss: 0.6385630476972493
Validation loss: 2.361692805742351

Epoch: 6| Step: 12
Training loss: 0.5275764234603812
Validation loss: 2.3396092984794237

Epoch: 6| Step: 13
Training loss: 1.026704248312289
Validation loss: 2.304101722208656

Epoch: 514| Step: 0
Training loss: 1.7969455207586524
Validation loss: 2.299600046827598

Epoch: 6| Step: 1
Training loss: 0.564079107954096
Validation loss: 2.2830815522313856

Epoch: 6| Step: 2
Training loss: 0.6814865768941065
Validation loss: 2.343262335245928

Epoch: 6| Step: 3
Training loss: 1.0389082944783614
Validation loss: 2.345325046293224

Epoch: 6| Step: 4
Training loss: 0.6611116707378266
Validation loss: 2.323559280418058

Epoch: 6| Step: 5
Training loss: 0.6912631732727074
Validation loss: 2.361568846499276

Epoch: 6| Step: 6
Training loss: 0.6997980669513856
Validation loss: 2.389877830985671

Epoch: 6| Step: 7
Training loss: 0.7927982541654979
Validation loss: 2.332987092371149

Epoch: 6| Step: 8
Training loss: 0.9809159858437021
Validation loss: 2.305853608851057

Epoch: 6| Step: 9
Training loss: 0.6067935846562943
Validation loss: 2.35153970191879

Epoch: 6| Step: 10
Training loss: 0.7586958151610776
Validation loss: 2.3286641056875093

Epoch: 6| Step: 11
Training loss: 0.849480805589384
Validation loss: 2.360717246035093

Epoch: 6| Step: 12
Training loss: 0.7231459736729158
Validation loss: 2.3031471462311743

Epoch: 6| Step: 13
Training loss: 0.7520970194479201
Validation loss: 2.4504619727887307

Epoch: 515| Step: 0
Training loss: 0.68180099830504
Validation loss: 2.3602544390605305

Epoch: 6| Step: 1
Training loss: 0.5665761758507738
Validation loss: 2.4038227988371443

Epoch: 6| Step: 2
Training loss: 0.7982672702105048
Validation loss: 2.4138433246281963

Epoch: 6| Step: 3
Training loss: 0.8607692851870774
Validation loss: 2.316883918244038

Epoch: 6| Step: 4
Training loss: 0.6260086027565838
Validation loss: 2.3607589030303515

Epoch: 6| Step: 5
Training loss: 1.7382281691772625
Validation loss: 2.3427520880788837

Epoch: 6| Step: 6
Training loss: 0.47550991946923815
Validation loss: 2.322478749497999

Epoch: 6| Step: 7
Training loss: 0.7328823422333035
Validation loss: 2.4563187088455414

Epoch: 6| Step: 8
Training loss: 0.887123116538392
Validation loss: 2.4611554001327343

Epoch: 6| Step: 9
Training loss: 0.9450895819009371
Validation loss: 2.3965227573447208

Epoch: 6| Step: 10
Training loss: 0.7847889662708729
Validation loss: 2.370473073315191

Epoch: 6| Step: 11
Training loss: 0.7059452716050054
Validation loss: 2.44272849253941

Epoch: 6| Step: 12
Training loss: 0.8047800844132442
Validation loss: 2.3510701967601806

Epoch: 6| Step: 13
Training loss: 0.4373060205123232
Validation loss: 2.354831812490695

Epoch: 516| Step: 0
Training loss: 0.671148084366054
Validation loss: 2.349615836712333

Epoch: 6| Step: 1
Training loss: 0.9612803894120467
Validation loss: 2.3160251952208215

Epoch: 6| Step: 2
Training loss: 0.8263566912906586
Validation loss: 2.245288529411789

Epoch: 6| Step: 3
Training loss: 0.7167412427055221
Validation loss: 2.334150810209661

Epoch: 6| Step: 4
Training loss: 0.7572617249864109
Validation loss: 2.385746968245304

Epoch: 6| Step: 5
Training loss: 0.554248098494899
Validation loss: 2.381763055413666

Epoch: 6| Step: 6
Training loss: 1.833849819719543
Validation loss: 2.317053614289453

Epoch: 6| Step: 7
Training loss: 0.9215486886485851
Validation loss: 2.3033119113460137

Epoch: 6| Step: 8
Training loss: 0.9003643437519829
Validation loss: 2.283142176049292

Epoch: 6| Step: 9
Training loss: 0.8810463176203731
Validation loss: 2.333026207833541

Epoch: 6| Step: 10
Training loss: 0.6781274716380558
Validation loss: 2.4085201192555115

Epoch: 6| Step: 11
Training loss: 0.5900956935784905
Validation loss: 2.3636278010073486

Epoch: 6| Step: 12
Training loss: 0.5930572282924881
Validation loss: 2.3842153555395624

Epoch: 6| Step: 13
Training loss: 0.8214630051616336
Validation loss: 2.3563356381960645

Epoch: 517| Step: 0
Training loss: 0.807743528509589
Validation loss: 2.339186811378777

Epoch: 6| Step: 1
Training loss: 0.6060669927549521
Validation loss: 2.348400594266727

Epoch: 6| Step: 2
Training loss: 0.5790314913422928
Validation loss: 2.3790488841631845

Epoch: 6| Step: 3
Training loss: 0.8001799768417353
Validation loss: 2.3853087794224495

Epoch: 6| Step: 4
Training loss: 0.9613967356404006
Validation loss: 2.3149400358022567

Epoch: 6| Step: 5
Training loss: 1.851272624699867
Validation loss: 2.3012212500437568

Epoch: 6| Step: 6
Training loss: 0.8911593992240036
Validation loss: 2.27351419916915

Epoch: 6| Step: 7
Training loss: 0.823234911034624
Validation loss: 2.3055310101204705

Epoch: 6| Step: 8
Training loss: 0.5006584064419819
Validation loss: 2.311623630904564

Epoch: 6| Step: 9
Training loss: 0.767119603153444
Validation loss: 2.368171237587512

Epoch: 6| Step: 10
Training loss: 0.8280571963785129
Validation loss: 2.2898176958429683

Epoch: 6| Step: 11
Training loss: 0.7493651802876764
Validation loss: 2.3125281206110166

Epoch: 6| Step: 12
Training loss: 0.931912812272387
Validation loss: 2.4424642574781625

Epoch: 6| Step: 13
Training loss: 1.1722718647654453
Validation loss: 2.3219670497976543

Epoch: 518| Step: 0
Training loss: 1.7477052493296876
Validation loss: 2.3693330719729806

Epoch: 6| Step: 1
Training loss: 0.8567715831316572
Validation loss: 2.407061551456464

Epoch: 6| Step: 2
Training loss: 0.7695891072941826
Validation loss: 2.3908943712435233

Epoch: 6| Step: 3
Training loss: 0.6672333578747807
Validation loss: 2.416640784012208

Epoch: 6| Step: 4
Training loss: 0.7569893367726845
Validation loss: 2.379783980466593

Epoch: 6| Step: 5
Training loss: 1.1292706069873342
Validation loss: 2.338294415590555

Epoch: 6| Step: 6
Training loss: 0.6875446045017544
Validation loss: 2.3342122855723724

Epoch: 6| Step: 7
Training loss: 0.7384932279282748
Validation loss: 2.3513822678959824

Epoch: 6| Step: 8
Training loss: 0.8023792975851871
Validation loss: 2.423907167498838

Epoch: 6| Step: 9
Training loss: 0.7796289792775052
Validation loss: 2.366880189732935

Epoch: 6| Step: 10
Training loss: 0.48638943205328117
Validation loss: 2.3952323916072134

Epoch: 6| Step: 11
Training loss: 0.8811548587493028
Validation loss: 2.338481342568015

Epoch: 6| Step: 12
Training loss: 0.6953627750351405
Validation loss: 2.440507376109531

Epoch: 6| Step: 13
Training loss: 0.43295135680621666
Validation loss: 2.292698409959107

Epoch: 519| Step: 0
Training loss: 0.6021146840927735
Validation loss: 2.3494631695419237

Epoch: 6| Step: 1
Training loss: 0.8436697815802786
Validation loss: 2.4300162716085323

Epoch: 6| Step: 2
Training loss: 0.8752803353416498
Validation loss: 2.3662713513464304

Epoch: 6| Step: 3
Training loss: 0.5037434632892427
Validation loss: 2.2452552289550263

Epoch: 6| Step: 4
Training loss: 0.5401352698389958
Validation loss: 2.3577642072869986

Epoch: 6| Step: 5
Training loss: 0.6765198392390749
Validation loss: 2.350301568905526

Epoch: 6| Step: 6
Training loss: 0.5503062371022688
Validation loss: 2.3856617515549656

Epoch: 6| Step: 7
Training loss: 0.7625339938231211
Validation loss: 2.3520770344185307

Epoch: 6| Step: 8
Training loss: 0.7704938880039321
Validation loss: 2.3971465383127297

Epoch: 6| Step: 9
Training loss: 0.8878098887076507
Validation loss: 2.4142589505751575

Epoch: 6| Step: 10
Training loss: 0.8458054548908948
Validation loss: 2.415310249527906

Epoch: 6| Step: 11
Training loss: 0.6142679040804577
Validation loss: 2.330584610203799

Epoch: 6| Step: 12
Training loss: 0.9182260355658907
Validation loss: 2.3832116750032624

Epoch: 6| Step: 13
Training loss: 2.1969726367161453
Validation loss: 2.348724716687785

Epoch: 520| Step: 0
Training loss: 0.7029043063207817
Validation loss: 2.3369588780653325

Epoch: 6| Step: 1
Training loss: 1.9254708494536985
Validation loss: 2.392103300712404

Epoch: 6| Step: 2
Training loss: 0.5286857765278795
Validation loss: 2.3936081949164025

Epoch: 6| Step: 3
Training loss: 0.5982790425923139
Validation loss: 2.30372484339252

Epoch: 6| Step: 4
Training loss: 0.831839633422007
Validation loss: 2.260863023645857

Epoch: 6| Step: 5
Training loss: 0.6222592580389337
Validation loss: 2.409828141231177

Epoch: 6| Step: 6
Training loss: 0.8567406939893574
Validation loss: 2.2974342143706052

Epoch: 6| Step: 7
Training loss: 0.9178567371611364
Validation loss: 2.33826108536868

Epoch: 6| Step: 8
Training loss: 0.6916197754197043
Validation loss: 2.3908394241442714

Epoch: 6| Step: 9
Training loss: 0.6275571961191585
Validation loss: 2.3706080214609178

Epoch: 6| Step: 10
Training loss: 0.7102471657481267
Validation loss: 2.3444145316088205

Epoch: 6| Step: 11
Training loss: 0.9085152038578491
Validation loss: 2.388549113580091

Epoch: 6| Step: 12
Training loss: 0.9684945046461467
Validation loss: 2.3904900359596737

Epoch: 6| Step: 13
Training loss: 0.8505078705833323
Validation loss: 2.3279634061612327

Epoch: 521| Step: 0
Training loss: 0.6583294393528889
Validation loss: 2.365150518797083

Epoch: 6| Step: 1
Training loss: 0.6932792509822642
Validation loss: 2.3816181537658263

Epoch: 6| Step: 2
Training loss: 0.7147350958290616
Validation loss: 2.389477028372008

Epoch: 6| Step: 3
Training loss: 0.969753668368807
Validation loss: 2.3316253348964997

Epoch: 6| Step: 4
Training loss: 0.9414943796274714
Validation loss: 2.4506615938123004

Epoch: 6| Step: 5
Training loss: 0.49863940128884743
Validation loss: 2.361088580925433

Epoch: 6| Step: 6
Training loss: 1.7325515784530405
Validation loss: 2.405942622628539

Epoch: 6| Step: 7
Training loss: 0.9773735035759096
Validation loss: 2.3586773801615797

Epoch: 6| Step: 8
Training loss: 0.7155067412767254
Validation loss: 2.325193137170765

Epoch: 6| Step: 9
Training loss: 0.7898674437820536
Validation loss: 2.373536027615523

Epoch: 6| Step: 10
Training loss: 0.643298872492505
Validation loss: 2.261361740913062

Epoch: 6| Step: 11
Training loss: 0.9293132317134987
Validation loss: 2.3626902757396926

Epoch: 6| Step: 12
Training loss: 0.8969244448227573
Validation loss: 2.453447634087244

Epoch: 6| Step: 13
Training loss: 0.6439732766204525
Validation loss: 2.3682982280595386

Epoch: 522| Step: 0
Training loss: 0.598061766834589
Validation loss: 2.257626390399583

Epoch: 6| Step: 1
Training loss: 0.7223711018269835
Validation loss: 2.346182704116052

Epoch: 6| Step: 2
Training loss: 0.6828213496911361
Validation loss: 2.4190063826541843

Epoch: 6| Step: 3
Training loss: 0.8616471856594085
Validation loss: 2.3137733481279024

Epoch: 6| Step: 4
Training loss: 0.7176173033840606
Validation loss: 2.323789080030539

Epoch: 6| Step: 5
Training loss: 0.5779374823732684
Validation loss: 2.336919231650851

Epoch: 6| Step: 6
Training loss: 0.8614599425467269
Validation loss: 2.346690205627742

Epoch: 6| Step: 7
Training loss: 0.6056623826038986
Validation loss: 2.390576170089463

Epoch: 6| Step: 8
Training loss: 0.6874442944933529
Validation loss: 2.3602746412171904

Epoch: 6| Step: 9
Training loss: 1.9042395323898484
Validation loss: 2.391064093018761

Epoch: 6| Step: 10
Training loss: 0.9538842600944225
Validation loss: 2.3574947288114187

Epoch: 6| Step: 11
Training loss: 0.5502798083947912
Validation loss: 2.350975835862455

Epoch: 6| Step: 12
Training loss: 0.9686842865344517
Validation loss: 2.4028543869508847

Epoch: 6| Step: 13
Training loss: 0.7017068761085553
Validation loss: 2.3152172049445685

Epoch: 523| Step: 0
Training loss: 1.0219570255314463
Validation loss: 2.3885136024983713

Epoch: 6| Step: 1
Training loss: 1.6708462839108265
Validation loss: 2.3399404223349385

Epoch: 6| Step: 2
Training loss: 0.595909708192179
Validation loss: 2.3162372735475554

Epoch: 6| Step: 3
Training loss: 1.005592681194733
Validation loss: 2.367369979506502

Epoch: 6| Step: 4
Training loss: 0.6996727007944497
Validation loss: 2.354737786868763

Epoch: 6| Step: 5
Training loss: 0.4876106692899698
Validation loss: 2.3475870270991646

Epoch: 6| Step: 6
Training loss: 0.4679372257829517
Validation loss: 2.271922689494975

Epoch: 6| Step: 7
Training loss: 0.5500601518856314
Validation loss: 2.367982628835451

Epoch: 6| Step: 8
Training loss: 0.7194489107848396
Validation loss: 2.280406018683593

Epoch: 6| Step: 9
Training loss: 0.7840614087130272
Validation loss: 2.3146471693957533

Epoch: 6| Step: 10
Training loss: 0.8525292045311716
Validation loss: 2.3788372691002566

Epoch: 6| Step: 11
Training loss: 0.6078966744394858
Validation loss: 2.4014235345383006

Epoch: 6| Step: 12
Training loss: 0.7614646683484637
Validation loss: 2.372208079564512

Epoch: 6| Step: 13
Training loss: 0.7209343267998477
Validation loss: 2.3109443329703123

Epoch: 524| Step: 0
Training loss: 0.9871272711571328
Validation loss: 2.3814669431144337

Epoch: 6| Step: 1
Training loss: 0.8706987794174659
Validation loss: 2.357634426815911

Epoch: 6| Step: 2
Training loss: 0.5141172617583372
Validation loss: 2.4511887811282755

Epoch: 6| Step: 3
Training loss: 0.6425942879820983
Validation loss: 2.4109604625716785

Epoch: 6| Step: 4
Training loss: 0.6487848201954999
Validation loss: 2.376843902990282

Epoch: 6| Step: 5
Training loss: 0.7063382372128586
Validation loss: 2.3138837767651

Epoch: 6| Step: 6
Training loss: 0.5671080352351171
Validation loss: 2.321746696712518

Epoch: 6| Step: 7
Training loss: 0.9056017958127875
Validation loss: 2.3601243621181514

Epoch: 6| Step: 8
Training loss: 0.6442425861709212
Validation loss: 2.2747426384513227

Epoch: 6| Step: 9
Training loss: 0.7691002815325426
Validation loss: 2.3261129898185744

Epoch: 6| Step: 10
Training loss: 0.8770101481973848
Validation loss: 2.338089557996639

Epoch: 6| Step: 11
Training loss: 1.807685772436038
Validation loss: 2.3091518891392964

Epoch: 6| Step: 12
Training loss: 1.0913375406885188
Validation loss: 2.3121290527436886

Epoch: 6| Step: 13
Training loss: 0.9107683603811467
Validation loss: 2.2845704011950825

Epoch: 525| Step: 0
Training loss: 0.7164641395400874
Validation loss: 2.3910007887875797

Epoch: 6| Step: 1
Training loss: 0.6814518533241327
Validation loss: 2.2772975130273205

Epoch: 6| Step: 2
Training loss: 0.777274507285295
Validation loss: 2.3456035615869064

Epoch: 6| Step: 3
Training loss: 0.5665412741891613
Validation loss: 2.398462619605192

Epoch: 6| Step: 4
Training loss: 0.5826742217856565
Validation loss: 2.3935818622795484

Epoch: 6| Step: 5
Training loss: 0.9684667788545163
Validation loss: 2.416447327886061

Epoch: 6| Step: 6
Training loss: 0.6490272230278417
Validation loss: 2.3400151750801554

Epoch: 6| Step: 7
Training loss: 1.6973322075008266
Validation loss: 2.3697805893693316

Epoch: 6| Step: 8
Training loss: 1.0076729729640463
Validation loss: 2.3149215991867966

Epoch: 6| Step: 9
Training loss: 0.8860334193060134
Validation loss: 2.3681590600611586

Epoch: 6| Step: 10
Training loss: 0.669334220605746
Validation loss: 2.3252801994681995

Epoch: 6| Step: 11
Training loss: 0.6195943475559635
Validation loss: 2.307904286698773

Epoch: 6| Step: 12
Training loss: 0.6991081363411317
Validation loss: 2.2770026732573405

Epoch: 6| Step: 13
Training loss: 0.9688956243519561
Validation loss: 2.3345863176023207

Epoch: 526| Step: 0
Training loss: 0.5576023293568299
Validation loss: 2.3432746870112666

Epoch: 6| Step: 1
Training loss: 0.6806143656338616
Validation loss: 2.3579234625362067

Epoch: 6| Step: 2
Training loss: 0.8761029104506001
Validation loss: 2.273036829999559

Epoch: 6| Step: 3
Training loss: 1.7677687737092869
Validation loss: 2.364356312260321

Epoch: 6| Step: 4
Training loss: 0.7167181236808241
Validation loss: 2.4071809661480024

Epoch: 6| Step: 5
Training loss: 1.030508294839805
Validation loss: 2.34418073025547

Epoch: 6| Step: 6
Training loss: 0.6329677532624189
Validation loss: 2.3118041426363796

Epoch: 6| Step: 7
Training loss: 0.6712556690282137
Validation loss: 2.352240614600451

Epoch: 6| Step: 8
Training loss: 0.8562233440398861
Validation loss: 2.3560300152309948

Epoch: 6| Step: 9
Training loss: 0.6927141653020967
Validation loss: 2.3339536076084415

Epoch: 6| Step: 10
Training loss: 0.7854178073648792
Validation loss: 2.468987734485101

Epoch: 6| Step: 11
Training loss: 0.7679811152629821
Validation loss: 2.309264230928062

Epoch: 6| Step: 12
Training loss: 0.7630983818841874
Validation loss: 2.378358197865422

Epoch: 6| Step: 13
Training loss: 0.8111204025601506
Validation loss: 2.363670059637706

Epoch: 527| Step: 0
Training loss: 0.8864747438506853
Validation loss: 2.3876938791256253

Epoch: 6| Step: 1
Training loss: 1.7564834656755668
Validation loss: 2.364495000417611

Epoch: 6| Step: 2
Training loss: 0.8016264014399127
Validation loss: 2.3349701195313286

Epoch: 6| Step: 3
Training loss: 0.6498440344466596
Validation loss: 2.374213839855279

Epoch: 6| Step: 4
Training loss: 1.104266857903768
Validation loss: 2.3701628435669475

Epoch: 6| Step: 5
Training loss: 0.815743610921724
Validation loss: 2.379682703159934

Epoch: 6| Step: 6
Training loss: 0.7673479273734224
Validation loss: 2.3777703986134706

Epoch: 6| Step: 7
Training loss: 0.625011515511285
Validation loss: 2.3527368342794692

Epoch: 6| Step: 8
Training loss: 0.753688800661651
Validation loss: 2.343152651120481

Epoch: 6| Step: 9
Training loss: 0.7412242461003617
Validation loss: 2.386132250421315

Epoch: 6| Step: 10
Training loss: 0.7517601657353886
Validation loss: 2.3679977996313473

Epoch: 6| Step: 11
Training loss: 0.7762558575346221
Validation loss: 2.3438344184138122

Epoch: 6| Step: 12
Training loss: 0.6894637585217082
Validation loss: 2.3826210250324538

Epoch: 6| Step: 13
Training loss: 0.7302098758987771
Validation loss: 2.319870833109891

Epoch: 528| Step: 0
Training loss: 0.7360057580479036
Validation loss: 2.3781396927457226

Epoch: 6| Step: 1
Training loss: 1.6976097469219003
Validation loss: 2.3361969667659186

Epoch: 6| Step: 2
Training loss: 0.6741075461611087
Validation loss: 2.387393434527158

Epoch: 6| Step: 3
Training loss: 0.5659289749826245
Validation loss: 2.324887907718061

Epoch: 6| Step: 4
Training loss: 0.7278572769116785
Validation loss: 2.385380762710118

Epoch: 6| Step: 5
Training loss: 0.5854513058533742
Validation loss: 2.3456523664666715

Epoch: 6| Step: 6
Training loss: 0.9764886446681772
Validation loss: 2.3695175143939218

Epoch: 6| Step: 7
Training loss: 0.8064035062515954
Validation loss: 2.334732054670568

Epoch: 6| Step: 8
Training loss: 0.8771262221070303
Validation loss: 2.298490918960561

Epoch: 6| Step: 9
Training loss: 0.6344162904051872
Validation loss: 2.342889175114418

Epoch: 6| Step: 10
Training loss: 0.5919640937464575
Validation loss: 2.379929482832972

Epoch: 6| Step: 11
Training loss: 0.5874916573195914
Validation loss: 2.268686819557022

Epoch: 6| Step: 12
Training loss: 0.8354651997485262
Validation loss: 2.363035522583947

Epoch: 6| Step: 13
Training loss: 0.7862826186844731
Validation loss: 2.3401078630425785

Epoch: 529| Step: 0
Training loss: 0.7751126115261414
Validation loss: 2.361165235197852

Epoch: 6| Step: 1
Training loss: 0.719981051500316
Validation loss: 2.3777936864316627

Epoch: 6| Step: 2
Training loss: 0.632061618787343
Validation loss: 2.3112741972441175

Epoch: 6| Step: 3
Training loss: 0.8272425430252272
Validation loss: 2.344101479266656

Epoch: 6| Step: 4
Training loss: 0.6609006217606146
Validation loss: 2.365598209176461

Epoch: 6| Step: 5
Training loss: 0.5410664668793181
Validation loss: 2.3251984216847292

Epoch: 6| Step: 6
Training loss: 1.7079706815039166
Validation loss: 2.3536209746647456

Epoch: 6| Step: 7
Training loss: 0.7855376271026456
Validation loss: 2.3506185784619062

Epoch: 6| Step: 8
Training loss: 1.0307030816975613
Validation loss: 2.425234844920504

Epoch: 6| Step: 9
Training loss: 0.5383321264664829
Validation loss: 2.3770032830835666

Epoch: 6| Step: 10
Training loss: 0.6554197781879592
Validation loss: 2.387844391620508

Epoch: 6| Step: 11
Training loss: 0.6512401405437485
Validation loss: 2.3524213024053733

Epoch: 6| Step: 12
Training loss: 0.9405239608588154
Validation loss: 2.3668303614045225

Epoch: 6| Step: 13
Training loss: 0.7632096006095478
Validation loss: 2.3931598793672837

Epoch: 530| Step: 0
Training loss: 1.8821810221350785
Validation loss: 2.2616296704916827

Epoch: 6| Step: 1
Training loss: 0.7754928175607743
Validation loss: 2.266848117514907

Epoch: 6| Step: 2
Training loss: 0.8677223549420133
Validation loss: 2.366302631336009

Epoch: 6| Step: 3
Training loss: 0.5313913213466246
Validation loss: 2.4042488708392784

Epoch: 6| Step: 4
Training loss: 0.6963335747956545
Validation loss: 2.3011517421325975

Epoch: 6| Step: 5
Training loss: 0.8155492272385573
Validation loss: 2.360257335877613

Epoch: 6| Step: 6
Training loss: 0.7310876927019895
Validation loss: 2.4004340546903458

Epoch: 6| Step: 7
Training loss: 0.5860463359206927
Validation loss: 2.325480755814988

Epoch: 6| Step: 8
Training loss: 0.7690271963288359
Validation loss: 2.3158886976372846

Epoch: 6| Step: 9
Training loss: 0.662832130094681
Validation loss: 2.2937209809803467

Epoch: 6| Step: 10
Training loss: 0.553845935760612
Validation loss: 2.3210535242753436

Epoch: 6| Step: 11
Training loss: 0.7513764783673045
Validation loss: 2.3242656098796193

Epoch: 6| Step: 12
Training loss: 0.8623728050207317
Validation loss: 2.3154928196602254

Epoch: 6| Step: 13
Training loss: 0.8188830318554903
Validation loss: 2.4197769037525734

Epoch: 531| Step: 0
Training loss: 0.7007927467313222
Validation loss: 2.372479321428268

Epoch: 6| Step: 1
Training loss: 0.5575953277204688
Validation loss: 2.45038525890464

Epoch: 6| Step: 2
Training loss: 0.8912389546441557
Validation loss: 2.427440371115944

Epoch: 6| Step: 3
Training loss: 0.5708306454040655
Validation loss: 2.408435889293515

Epoch: 6| Step: 4
Training loss: 0.9783800834542219
Validation loss: 2.315908771511237

Epoch: 6| Step: 5
Training loss: 1.6406712843406164
Validation loss: 2.3433136198090727

Epoch: 6| Step: 6
Training loss: 0.7253589300689177
Validation loss: 2.3582456151596087

Epoch: 6| Step: 7
Training loss: 0.7515366230592195
Validation loss: 2.3472390208749863

Epoch: 6| Step: 8
Training loss: 0.6319303132551084
Validation loss: 2.37481432363257

Epoch: 6| Step: 9
Training loss: 0.8278880950062565
Validation loss: 2.3705379947536604

Epoch: 6| Step: 10
Training loss: 0.8273044335494455
Validation loss: 2.3667565476737926

Epoch: 6| Step: 11
Training loss: 0.6850898066701576
Validation loss: 2.4154402733123788

Epoch: 6| Step: 12
Training loss: 0.8583421916566291
Validation loss: 2.3397771841711177

Epoch: 6| Step: 13
Training loss: 0.5773875714139429
Validation loss: 2.285160467092926

Epoch: 532| Step: 0
Training loss: 0.9468238036160657
Validation loss: 2.265308597636769

Epoch: 6| Step: 1
Training loss: 1.1225796731145319
Validation loss: 2.308452842805109

Epoch: 6| Step: 2
Training loss: 0.7203983810101606
Validation loss: 2.333475506497287

Epoch: 6| Step: 3
Training loss: 0.6760253465403787
Validation loss: 2.4106908644618015

Epoch: 6| Step: 4
Training loss: 0.7416316711727546
Validation loss: 2.2772788864881064

Epoch: 6| Step: 5
Training loss: 1.5970684733082232
Validation loss: 2.3040126317876743

Epoch: 6| Step: 6
Training loss: 0.749940750642769
Validation loss: 2.375796357250017

Epoch: 6| Step: 7
Training loss: 0.8395921907044482
Validation loss: 2.3875023049238897

Epoch: 6| Step: 8
Training loss: 0.7856196843515979
Validation loss: 2.413695497615306

Epoch: 6| Step: 9
Training loss: 0.9057300654635906
Validation loss: 2.370986746040154

Epoch: 6| Step: 10
Training loss: 0.8153709893029297
Validation loss: 2.3637241741369595

Epoch: 6| Step: 11
Training loss: 0.6046014542189588
Validation loss: 2.3741808311364014

Epoch: 6| Step: 12
Training loss: 0.69375717142196
Validation loss: 2.415123826445537

Epoch: 6| Step: 13
Training loss: 0.48199655726398355
Validation loss: 2.3528300916125495

Epoch: 533| Step: 0
Training loss: 0.6570150366561894
Validation loss: 2.3328829911578812

Epoch: 6| Step: 1
Training loss: 0.53407518107279
Validation loss: 2.361020491290843

Epoch: 6| Step: 2
Training loss: 0.9171618872320482
Validation loss: 2.390701969373328

Epoch: 6| Step: 3
Training loss: 0.5080331176415623
Validation loss: 2.4248271445823617

Epoch: 6| Step: 4
Training loss: 0.7737807080733882
Validation loss: 2.363884154119253

Epoch: 6| Step: 5
Training loss: 0.9779965057310624
Validation loss: 2.336028620745666

Epoch: 6| Step: 6
Training loss: 0.6607887353155161
Validation loss: 2.3680652778031446

Epoch: 6| Step: 7
Training loss: 1.5933530724604912
Validation loss: 2.342186073626173

Epoch: 6| Step: 8
Training loss: 0.7759276867482955
Validation loss: 2.326515345492696

Epoch: 6| Step: 9
Training loss: 0.7746736685444094
Validation loss: 2.314953835481838

Epoch: 6| Step: 10
Training loss: 0.6272617424253109
Validation loss: 2.4119402519216284

Epoch: 6| Step: 11
Training loss: 0.5602274659241053
Validation loss: 2.397684819125237

Epoch: 6| Step: 12
Training loss: 0.7085448024208905
Validation loss: 2.3982271481199384

Epoch: 6| Step: 13
Training loss: 0.727041189362307
Validation loss: 2.306771724076554

Epoch: 534| Step: 0
Training loss: 0.5608295432421344
Validation loss: 2.3790817402114803

Epoch: 6| Step: 1
Training loss: 0.6009885849368487
Validation loss: 2.3259418572510526

Epoch: 6| Step: 2
Training loss: 0.7100686853389729
Validation loss: 2.348838697422342

Epoch: 6| Step: 3
Training loss: 0.7981955861637937
Validation loss: 2.3440766509567705

Epoch: 6| Step: 4
Training loss: 0.7636532988569502
Validation loss: 2.377280328485272

Epoch: 6| Step: 5
Training loss: 0.6951832597612317
Validation loss: 2.384264948494832

Epoch: 6| Step: 6
Training loss: 0.6286864281552403
Validation loss: 2.4098273327223976

Epoch: 6| Step: 7
Training loss: 0.7636912311725362
Validation loss: 2.396106079184966

Epoch: 6| Step: 8
Training loss: 0.573553907132386
Validation loss: 2.3950816246331774

Epoch: 6| Step: 9
Training loss: 0.8358148146112139
Validation loss: 2.303439909405079

Epoch: 6| Step: 10
Training loss: 1.7959394590288467
Validation loss: 2.3978529162883047

Epoch: 6| Step: 11
Training loss: 0.730509466168679
Validation loss: 2.3905677968188734

Epoch: 6| Step: 12
Training loss: 0.3694586216724791
Validation loss: 2.3967756477173725

Epoch: 6| Step: 13
Training loss: 0.7472548313029355
Validation loss: 2.3765967905135477

Epoch: 535| Step: 0
Training loss: 0.719529889796128
Validation loss: 2.364976573678824

Epoch: 6| Step: 1
Training loss: 0.618486317408455
Validation loss: 2.4078439090104733

Epoch: 6| Step: 2
Training loss: 0.49328942546769805
Validation loss: 2.3147956342369644

Epoch: 6| Step: 3
Training loss: 0.6201801898821105
Validation loss: 2.391548475418129

Epoch: 6| Step: 4
Training loss: 0.610592921028373
Validation loss: 2.3763137760905755

Epoch: 6| Step: 5
Training loss: 0.7780569820473447
Validation loss: 2.4204627082913985

Epoch: 6| Step: 6
Training loss: 0.6920438294463517
Validation loss: 2.3634504219211925

Epoch: 6| Step: 7
Training loss: 0.6884566500334061
Validation loss: 2.332905968263153

Epoch: 6| Step: 8
Training loss: 0.9763476936605734
Validation loss: 2.3831600490502307

Epoch: 6| Step: 9
Training loss: 0.7066082611179803
Validation loss: 2.3921469081881437

Epoch: 6| Step: 10
Training loss: 1.6471729942729554
Validation loss: 2.3357816034976624

Epoch: 6| Step: 11
Training loss: 0.8718437763488803
Validation loss: 2.3800870761684267

Epoch: 6| Step: 12
Training loss: 0.7062254049018905
Validation loss: 2.3671771270980626

Epoch: 6| Step: 13
Training loss: 0.4640311824622045
Validation loss: 2.385285635372612

Epoch: 536| Step: 0
Training loss: 0.8219885279929261
Validation loss: 2.3356684174017426

Epoch: 6| Step: 1
Training loss: 0.7693684981913519
Validation loss: 2.2881422109761296

Epoch: 6| Step: 2
Training loss: 1.7116517270162697
Validation loss: 2.3396959580151737

Epoch: 6| Step: 3
Training loss: 0.7748184976003302
Validation loss: 2.3066767913516255

Epoch: 6| Step: 4
Training loss: 0.9651742593037015
Validation loss: 2.3384885566564377

Epoch: 6| Step: 5
Training loss: 0.7032599001857849
Validation loss: 2.3746428779791726

Epoch: 6| Step: 6
Training loss: 0.735633380683343
Validation loss: 2.350956416904468

Epoch: 6| Step: 7
Training loss: 0.6040246045598987
Validation loss: 2.2700118273936987

Epoch: 6| Step: 8
Training loss: 0.7531008989585299
Validation loss: 2.3887436007898124

Epoch: 6| Step: 9
Training loss: 0.8856682289142299
Validation loss: 2.369376160982173

Epoch: 6| Step: 10
Training loss: 0.6126130710087214
Validation loss: 2.433633496952386

Epoch: 6| Step: 11
Training loss: 0.6229818184589107
Validation loss: 2.3431716817987036

Epoch: 6| Step: 12
Training loss: 0.8420858219178536
Validation loss: 2.3986340097182497

Epoch: 6| Step: 13
Training loss: 0.3650039925422215
Validation loss: 2.4368577084100904

Epoch: 537| Step: 0
Training loss: 1.0064346594221694
Validation loss: 2.342323751976269

Epoch: 6| Step: 1
Training loss: 0.7563200736880685
Validation loss: 2.3834924721189386

Epoch: 6| Step: 2
Training loss: 0.8432410435883743
Validation loss: 2.339565527005758

Epoch: 6| Step: 3
Training loss: 0.6472439409490289
Validation loss: 2.347965891297385

Epoch: 6| Step: 4
Training loss: 0.7699067027679064
Validation loss: 2.3822891841483265

Epoch: 6| Step: 5
Training loss: 0.6287275972792841
Validation loss: 2.289387892430401

Epoch: 6| Step: 6
Training loss: 0.5740963292835617
Validation loss: 2.3327865923227207

Epoch: 6| Step: 7
Training loss: 0.4677159188412293
Validation loss: 2.3340281099991382

Epoch: 6| Step: 8
Training loss: 0.7044927222131149
Validation loss: 2.3486696824497124

Epoch: 6| Step: 9
Training loss: 0.5895258065545397
Validation loss: 2.3644407571866064

Epoch: 6| Step: 10
Training loss: 0.9036373097716744
Validation loss: 2.3676165824028326

Epoch: 6| Step: 11
Training loss: 1.658098161338549
Validation loss: 2.358401030055803

Epoch: 6| Step: 12
Training loss: 0.6897062317932126
Validation loss: 2.3562299834005827

Epoch: 6| Step: 13
Training loss: 0.8577696978898663
Validation loss: 2.372559608375328

Epoch: 538| Step: 0
Training loss: 0.5901116779474468
Validation loss: 2.3504274557706286

Epoch: 6| Step: 1
Training loss: 0.6811832762773719
Validation loss: 2.3445141296606873

Epoch: 6| Step: 2
Training loss: 0.5996975166076642
Validation loss: 2.3291214399452027

Epoch: 6| Step: 3
Training loss: 0.693518692840051
Validation loss: 2.3374177662184366

Epoch: 6| Step: 4
Training loss: 0.7212888410347362
Validation loss: 2.2966607006187263

Epoch: 6| Step: 5
Training loss: 0.6640036837392334
Validation loss: 2.384713303817082

Epoch: 6| Step: 6
Training loss: 1.6504060823518005
Validation loss: 2.3084361612492166

Epoch: 6| Step: 7
Training loss: 0.548279729250182
Validation loss: 2.3440728088994174

Epoch: 6| Step: 8
Training loss: 0.951367242633377
Validation loss: 2.3515200870193906

Epoch: 6| Step: 9
Training loss: 0.584108626502099
Validation loss: 2.3378645891975167

Epoch: 6| Step: 10
Training loss: 0.7621055990073758
Validation loss: 2.3786364448040707

Epoch: 6| Step: 11
Training loss: 0.6137671519910876
Validation loss: 2.3587527966022055

Epoch: 6| Step: 12
Training loss: 0.8722307457038351
Validation loss: 2.316547468002995

Epoch: 6| Step: 13
Training loss: 0.7700352446428985
Validation loss: 2.35854921841726

Epoch: 539| Step: 0
Training loss: 0.8318754954805911
Validation loss: 2.311081499734867

Epoch: 6| Step: 1
Training loss: 0.6131334065863283
Validation loss: 2.386771362341349

Epoch: 6| Step: 2
Training loss: 0.6366285950660127
Validation loss: 2.364859112039571

Epoch: 6| Step: 3
Training loss: 1.858997979928941
Validation loss: 2.331732759847877

Epoch: 6| Step: 4
Training loss: 0.5783261387411397
Validation loss: 2.37986640541268

Epoch: 6| Step: 5
Training loss: 0.8846234339966603
Validation loss: 2.387900730308002

Epoch: 6| Step: 6
Training loss: 0.6107554815813836
Validation loss: 2.3401980178714665

Epoch: 6| Step: 7
Training loss: 0.9198432775398702
Validation loss: 2.359199432097295

Epoch: 6| Step: 8
Training loss: 0.6245523995756882
Validation loss: 2.3453070920230505

Epoch: 6| Step: 9
Training loss: 0.7450895891790564
Validation loss: 2.4594028535169827

Epoch: 6| Step: 10
Training loss: 0.5411800313747682
Validation loss: 2.3887946494286307

Epoch: 6| Step: 11
Training loss: 0.65451155599442
Validation loss: 2.3364905904551008

Epoch: 6| Step: 12
Training loss: 0.7534526587044763
Validation loss: 2.338932029895181

Epoch: 6| Step: 13
Training loss: 0.804642203824588
Validation loss: 2.34927107057853

Epoch: 540| Step: 0
Training loss: 0.5914165924256405
Validation loss: 2.392224579824974

Epoch: 6| Step: 1
Training loss: 0.48287152173406334
Validation loss: 2.340518335727188

Epoch: 6| Step: 2
Training loss: 0.6508076107186217
Validation loss: 2.319484322723987

Epoch: 6| Step: 3
Training loss: 0.6093768339863103
Validation loss: 2.353378012066097

Epoch: 6| Step: 4
Training loss: 0.7860902004658451
Validation loss: 2.2873199089405634

Epoch: 6| Step: 5
Training loss: 0.7578796278333926
Validation loss: 2.3213813866191444

Epoch: 6| Step: 6
Training loss: 0.6652936630126692
Validation loss: 2.3103112225321016

Epoch: 6| Step: 7
Training loss: 0.6861980204187034
Validation loss: 2.402339380051715

Epoch: 6| Step: 8
Training loss: 1.7261170377910258
Validation loss: 2.3744417342915476

Epoch: 6| Step: 9
Training loss: 0.7542438443001931
Validation loss: 2.3489333886478083

Epoch: 6| Step: 10
Training loss: 0.9423114018239975
Validation loss: 2.3674594459369955

Epoch: 6| Step: 11
Training loss: 0.8287597239112293
Validation loss: 2.458928777994113

Epoch: 6| Step: 12
Training loss: 0.5863096962408227
Validation loss: 2.346179961472973

Epoch: 6| Step: 13
Training loss: 0.8200435379146784
Validation loss: 2.3359185508634126

Epoch: 541| Step: 0
Training loss: 0.6914248490930038
Validation loss: 2.3463384542114047

Epoch: 6| Step: 1
Training loss: 0.49939084198593925
Validation loss: 2.4237672472027714

Epoch: 6| Step: 2
Training loss: 0.8791817127464961
Validation loss: 2.426925738212241

Epoch: 6| Step: 3
Training loss: 1.6728877627614098
Validation loss: 2.4178857218047987

Epoch: 6| Step: 4
Training loss: 0.5182777139234281
Validation loss: 2.343168755106206

Epoch: 6| Step: 5
Training loss: 0.7185034951142931
Validation loss: 2.3218513314546763

Epoch: 6| Step: 6
Training loss: 0.7583444046078675
Validation loss: 2.3109619404689328

Epoch: 6| Step: 7
Training loss: 1.0236443463443416
Validation loss: 2.3625735332493334

Epoch: 6| Step: 8
Training loss: 0.6379640489078505
Validation loss: 2.292828995794081

Epoch: 6| Step: 9
Training loss: 0.6320962030822675
Validation loss: 2.3435719073049555

Epoch: 6| Step: 10
Training loss: 0.5058982863612653
Validation loss: 2.3192331391692385

Epoch: 6| Step: 11
Training loss: 0.7345432332288133
Validation loss: 2.404665568744935

Epoch: 6| Step: 12
Training loss: 0.5676597930268428
Validation loss: 2.3205433585625577

Epoch: 6| Step: 13
Training loss: 0.8187763544747755
Validation loss: 2.4526883628862115

Epoch: 542| Step: 0
Training loss: 0.5528313379867943
Validation loss: 2.3890851534915045

Epoch: 6| Step: 1
Training loss: 0.5916866791613591
Validation loss: 2.3673997110626575

Epoch: 6| Step: 2
Training loss: 0.7110295078979015
Validation loss: 2.30124064753655

Epoch: 6| Step: 3
Training loss: 0.46425618776029887
Validation loss: 2.3886080705447967

Epoch: 6| Step: 4
Training loss: 0.8697702934395464
Validation loss: 2.368445381528216

Epoch: 6| Step: 5
Training loss: 1.6727762377917081
Validation loss: 2.3863610483503646

Epoch: 6| Step: 6
Training loss: 0.8790325158867595
Validation loss: 2.2972130905066224

Epoch: 6| Step: 7
Training loss: 0.4851901363511003
Validation loss: 2.376790022482732

Epoch: 6| Step: 8
Training loss: 0.6623726830414064
Validation loss: 2.3437524643751746

Epoch: 6| Step: 9
Training loss: 0.7256045846096081
Validation loss: 2.362651487000152

Epoch: 6| Step: 10
Training loss: 0.6272847377056996
Validation loss: 2.3654197867527422

Epoch: 6| Step: 11
Training loss: 0.9750706378095187
Validation loss: 2.35954542114319

Epoch: 6| Step: 12
Training loss: 0.685231454129964
Validation loss: 2.2798458649118047

Epoch: 6| Step: 13
Training loss: 0.6040892852907115
Validation loss: 2.3536759187268372

Epoch: 543| Step: 0
Training loss: 0.633981637249557
Validation loss: 2.3237838877399675

Epoch: 6| Step: 1
Training loss: 0.8536377214966078
Validation loss: 2.372291080585502

Epoch: 6| Step: 2
Training loss: 0.7027243214302108
Validation loss: 2.2901636443235334

Epoch: 6| Step: 3
Training loss: 0.563079720686759
Validation loss: 2.339071946574359

Epoch: 6| Step: 4
Training loss: 0.9017950924840286
Validation loss: 2.3368751903825964

Epoch: 6| Step: 5
Training loss: 1.7661379178843915
Validation loss: 2.2969746124742336

Epoch: 6| Step: 6
Training loss: 0.6154748840103836
Validation loss: 2.4015819932878513

Epoch: 6| Step: 7
Training loss: 0.6202392698249297
Validation loss: 2.3123227988044333

Epoch: 6| Step: 8
Training loss: 0.5940010142526413
Validation loss: 2.327515431946827

Epoch: 6| Step: 9
Training loss: 0.8718383754024607
Validation loss: 2.3494000876343786

Epoch: 6| Step: 10
Training loss: 0.794380434739485
Validation loss: 2.41256048441344

Epoch: 6| Step: 11
Training loss: 0.7158227272565426
Validation loss: 2.3550681906187494

Epoch: 6| Step: 12
Training loss: 0.9423972647551947
Validation loss: 2.394946530129057

Epoch: 6| Step: 13
Training loss: 0.48288958961809064
Validation loss: 2.3419679721210067

Epoch: 544| Step: 0
Training loss: 0.5861361866097226
Validation loss: 2.3484629418862477

Epoch: 6| Step: 1
Training loss: 0.7017634879142067
Validation loss: 2.3184686298393364

Epoch: 6| Step: 2
Training loss: 0.7238562029329905
Validation loss: 2.425562947522886

Epoch: 6| Step: 3
Training loss: 0.7834446408616245
Validation loss: 2.3429908031457334

Epoch: 6| Step: 4
Training loss: 0.8507140596338452
Validation loss: 2.3876676734545774

Epoch: 6| Step: 5
Training loss: 0.8009294698359544
Validation loss: 2.340926206118692

Epoch: 6| Step: 6
Training loss: 0.7105603737411341
Validation loss: 2.3572617152800013

Epoch: 6| Step: 7
Training loss: 1.640117167032355
Validation loss: 2.3505579733503628

Epoch: 6| Step: 8
Training loss: 0.618112763842054
Validation loss: 2.4149540185097553

Epoch: 6| Step: 9
Training loss: 0.3385930450284244
Validation loss: 2.375092174854874

Epoch: 6| Step: 10
Training loss: 0.6882205568328075
Validation loss: 2.3743924765546462

Epoch: 6| Step: 11
Training loss: 0.7456786114203935
Validation loss: 2.369813739430862

Epoch: 6| Step: 12
Training loss: 0.5616260733306565
Validation loss: 2.380855575071656

Epoch: 6| Step: 13
Training loss: 0.9420593339027495
Validation loss: 2.35719907753326

Epoch: 545| Step: 0
Training loss: 0.7600992838106017
Validation loss: 2.379380943151949

Epoch: 6| Step: 1
Training loss: 0.8188626510348153
Validation loss: 2.4079484361697157

Epoch: 6| Step: 2
Training loss: 0.5831210283673645
Validation loss: 2.326222116337904

Epoch: 6| Step: 3
Training loss: 0.7818570639476401
Validation loss: 2.349168412868074

Epoch: 6| Step: 4
Training loss: 0.6652594381864918
Validation loss: 2.337945542343428

Epoch: 6| Step: 5
Training loss: 0.7217906820091639
Validation loss: 2.305029863220993

Epoch: 6| Step: 6
Training loss: 0.7109206899814459
Validation loss: 2.350185650910666

Epoch: 6| Step: 7
Training loss: 0.7059328177179867
Validation loss: 2.370795383261732

Epoch: 6| Step: 8
Training loss: 1.6052871935577941
Validation loss: 2.352802961537823

Epoch: 6| Step: 9
Training loss: 0.6417655561052987
Validation loss: 2.3393450595603418

Epoch: 6| Step: 10
Training loss: 0.7741854355435706
Validation loss: 2.3681603201441304

Epoch: 6| Step: 11
Training loss: 0.7057423302993465
Validation loss: 2.3331300329015625

Epoch: 6| Step: 12
Training loss: 0.8462792739988775
Validation loss: 2.345429360395203

Epoch: 6| Step: 13
Training loss: 0.5745461497217567
Validation loss: 2.3127064894012617

Epoch: 546| Step: 0
Training loss: 0.7166575782406602
Validation loss: 2.298681597146369

Epoch: 6| Step: 1
Training loss: 0.5273864728787729
Validation loss: 2.360849383922475

Epoch: 6| Step: 2
Training loss: 0.646474740224537
Validation loss: 2.2994246499322935

Epoch: 6| Step: 3
Training loss: 0.626081484661862
Validation loss: 2.3180129463657955

Epoch: 6| Step: 4
Training loss: 0.7786103860362773
Validation loss: 2.3123544382779384

Epoch: 6| Step: 5
Training loss: 0.8035080793932364
Validation loss: 2.3583175787650776

Epoch: 6| Step: 6
Training loss: 0.7420693956066141
Validation loss: 2.381292614286238

Epoch: 6| Step: 7
Training loss: 0.7221107692389321
Validation loss: 2.352165403527133

Epoch: 6| Step: 8
Training loss: 0.6510108075775657
Validation loss: 2.3133013644090985

Epoch: 6| Step: 9
Training loss: 0.5292456345195679
Validation loss: 2.335997782605794

Epoch: 6| Step: 10
Training loss: 0.5197588199896479
Validation loss: 2.3715999576692592

Epoch: 6| Step: 11
Training loss: 0.8806165203934331
Validation loss: 2.346777464504885

Epoch: 6| Step: 12
Training loss: 1.7461530773486904
Validation loss: 2.387896796649075

Epoch: 6| Step: 13
Training loss: 0.8812069767399158
Validation loss: 2.3287744226779483

Epoch: 547| Step: 0
Training loss: 0.7390427068596296
Validation loss: 2.3517692054530284

Epoch: 6| Step: 1
Training loss: 0.7132838588637642
Validation loss: 2.336750795042051

Epoch: 6| Step: 2
Training loss: 0.5484062555439079
Validation loss: 2.338651646342122

Epoch: 6| Step: 3
Training loss: 1.5624882506882471
Validation loss: 2.365987994652801

Epoch: 6| Step: 4
Training loss: 0.7281829647191128
Validation loss: 2.2860692738043493

Epoch: 6| Step: 5
Training loss: 0.4947769832105463
Validation loss: 2.3164922171234745

Epoch: 6| Step: 6
Training loss: 0.8383299202846369
Validation loss: 2.418482100335039

Epoch: 6| Step: 7
Training loss: 1.0021648220521298
Validation loss: 2.3747517337796826

Epoch: 6| Step: 8
Training loss: 0.6455801780408229
Validation loss: 2.406652917836585

Epoch: 6| Step: 9
Training loss: 0.41960172647292837
Validation loss: 2.3910414592842177

Epoch: 6| Step: 10
Training loss: 0.6243806631387024
Validation loss: 2.3733280365244065

Epoch: 6| Step: 11
Training loss: 0.9274882743073689
Validation loss: 2.453323435655859

Epoch: 6| Step: 12
Training loss: 0.6109972902587515
Validation loss: 2.390223213655351

Epoch: 6| Step: 13
Training loss: 0.7600256859680113
Validation loss: 2.400005835095357

Epoch: 548| Step: 0
Training loss: 0.5292936655770721
Validation loss: 2.328948759500986

Epoch: 6| Step: 1
Training loss: 0.7200631295449659
Validation loss: 2.3129674521632473

Epoch: 6| Step: 2
Training loss: 1.6395065128049309
Validation loss: 2.326877153592212

Epoch: 6| Step: 3
Training loss: 0.5329251805068558
Validation loss: 2.3296264885182416

Epoch: 6| Step: 4
Training loss: 0.7572293741736312
Validation loss: 2.300798519663115

Epoch: 6| Step: 5
Training loss: 0.7211060263600261
Validation loss: 2.4241641221593078

Epoch: 6| Step: 6
Training loss: 0.6481803246173506
Validation loss: 2.370514509664648

Epoch: 6| Step: 7
Training loss: 0.6275199395693444
Validation loss: 2.3644154105805733

Epoch: 6| Step: 8
Training loss: 0.7530102321821169
Validation loss: 2.430383940193585

Epoch: 6| Step: 9
Training loss: 0.8543758988951257
Validation loss: 2.3167082070918257

Epoch: 6| Step: 10
Training loss: 0.7963974213480336
Validation loss: 2.3652054286061532

Epoch: 6| Step: 11
Training loss: 0.8983405019395078
Validation loss: 2.3360638701065786

Epoch: 6| Step: 12
Training loss: 0.8326470330562703
Validation loss: 2.2697659613757737

Epoch: 6| Step: 13
Training loss: 0.5794700749481957
Validation loss: 2.364815464274279

Epoch: 549| Step: 0
Training loss: 0.902596937716695
Validation loss: 2.3592542522206124

Epoch: 6| Step: 1
Training loss: 0.5371271858730142
Validation loss: 2.4011122006492287

Epoch: 6| Step: 2
Training loss: 0.6350230003306526
Validation loss: 2.368640741788586

Epoch: 6| Step: 3
Training loss: 0.6033207847368609
Validation loss: 2.3301110658946644

Epoch: 6| Step: 4
Training loss: 0.8451857889647945
Validation loss: 2.3027117175065257

Epoch: 6| Step: 5
Training loss: 0.7008619340699569
Validation loss: 2.3751407326849905

Epoch: 6| Step: 6
Training loss: 0.8841923420588035
Validation loss: 2.453033254305677

Epoch: 6| Step: 7
Training loss: 0.6247798054955618
Validation loss: 2.307615197792876

Epoch: 6| Step: 8
Training loss: 1.7222223751861068
Validation loss: 2.348253065709894

Epoch: 6| Step: 9
Training loss: 1.124286902444876
Validation loss: 2.3767961328271014

Epoch: 6| Step: 10
Training loss: 0.771564334636993
Validation loss: 2.343609026425772

Epoch: 6| Step: 11
Training loss: 0.5877004169966326
Validation loss: 2.3814574763861116

Epoch: 6| Step: 12
Training loss: 0.5317044277991859
Validation loss: 2.3375061466315437

Epoch: 6| Step: 13
Training loss: 0.5502896380725651
Validation loss: 2.2471718052955536

Epoch: 550| Step: 0
Training loss: 0.878113859927287
Validation loss: 2.324484527550019

Epoch: 6| Step: 1
Training loss: 0.5174046927606808
Validation loss: 2.2772596701814733

Epoch: 6| Step: 2
Training loss: 0.7035509514716077
Validation loss: 2.313567760080828

Epoch: 6| Step: 3
Training loss: 0.5926457979390423
Validation loss: 2.3779075535112195

Epoch: 6| Step: 4
Training loss: 0.6079249613847268
Validation loss: 2.32165496904967

Epoch: 6| Step: 5
Training loss: 0.6658702479129006
Validation loss: 2.312286452455418

Epoch: 6| Step: 6
Training loss: 0.5910839659011936
Validation loss: 2.397841527246659

Epoch: 6| Step: 7
Training loss: 0.5624039356005808
Validation loss: 2.3271706582348464

Epoch: 6| Step: 8
Training loss: 0.6045980283799046
Validation loss: 2.330568059010753

Epoch: 6| Step: 9
Training loss: 0.7910667120366373
Validation loss: 2.393860253189382

Epoch: 6| Step: 10
Training loss: 0.7913425853009498
Validation loss: 2.347832128576602

Epoch: 6| Step: 11
Training loss: 1.7113095231776898
Validation loss: 2.447261948085938

Epoch: 6| Step: 12
Training loss: 0.8351455930452766
Validation loss: 2.3596516521493904

Epoch: 6| Step: 13
Training loss: 0.5392638120832158
Validation loss: 2.3802173314817865

Epoch: 551| Step: 0
Training loss: 0.754231832298745
Validation loss: 2.3596483569479694

Epoch: 6| Step: 1
Training loss: 0.9675088437979784
Validation loss: 2.378323837556694

Epoch: 6| Step: 2
Training loss: 0.8150548747375637
Validation loss: 2.3173320863532467

Epoch: 6| Step: 3
Training loss: 0.6014309528735375
Validation loss: 2.416397870263305

Epoch: 6| Step: 4
Training loss: 0.4847821247449744
Validation loss: 2.3091210331788665

Epoch: 6| Step: 5
Training loss: 0.8548122308017614
Validation loss: 2.323754454795697

Epoch: 6| Step: 6
Training loss: 0.8174462515984273
Validation loss: 2.320914502421057

Epoch: 6| Step: 7
Training loss: 0.7443857665288245
Validation loss: 2.3893553876999345

Epoch: 6| Step: 8
Training loss: 0.5273707347606073
Validation loss: 2.3861719348967703

Epoch: 6| Step: 9
Training loss: 0.8442894659196444
Validation loss: 2.340542092773017

Epoch: 6| Step: 10
Training loss: 1.6005150323678468
Validation loss: 2.3845774794623726

Epoch: 6| Step: 11
Training loss: 0.6941437059461821
Validation loss: 2.3464450810146147

Epoch: 6| Step: 12
Training loss: 0.7162867089629339
Validation loss: 2.3395180279049947

Epoch: 6| Step: 13
Training loss: 0.47505811975680773
Validation loss: 2.3380704431899657

Epoch: 552| Step: 0
Training loss: 0.770002733820236
Validation loss: 2.4397262406824662

Epoch: 6| Step: 1
Training loss: 0.5000873429781225
Validation loss: 2.3626880253418028

Epoch: 6| Step: 2
Training loss: 0.6575996734217485
Validation loss: 2.363590973494898

Epoch: 6| Step: 3
Training loss: 0.6588021560666091
Validation loss: 2.2637275407880537

Epoch: 6| Step: 4
Training loss: 1.698455147884035
Validation loss: 2.4156495168392382

Epoch: 6| Step: 5
Training loss: 0.5649969259954903
Validation loss: 2.365165922374211

Epoch: 6| Step: 6
Training loss: 0.6150451126842856
Validation loss: 2.324333076564085

Epoch: 6| Step: 7
Training loss: 0.8839737672797244
Validation loss: 2.361434856621086

Epoch: 6| Step: 8
Training loss: 0.7284549145803698
Validation loss: 2.358208195912925

Epoch: 6| Step: 9
Training loss: 0.6452098395313899
Validation loss: 2.346567625764296

Epoch: 6| Step: 10
Training loss: 0.7942762822865838
Validation loss: 2.2928653464596422

Epoch: 6| Step: 11
Training loss: 0.6777584720252322
Validation loss: 2.4215989647895664

Epoch: 6| Step: 12
Training loss: 0.6808767328550174
Validation loss: 2.3694745053143036

Epoch: 6| Step: 13
Training loss: 0.8517704631003297
Validation loss: 2.4128416463986544

Epoch: 553| Step: 0
Training loss: 0.6114061202242387
Validation loss: 2.361365671769515

Epoch: 6| Step: 1
Training loss: 0.7362569273669727
Validation loss: 2.317734114773249

Epoch: 6| Step: 2
Training loss: 0.4745599540442202
Validation loss: 2.302518310641525

Epoch: 6| Step: 3
Training loss: 0.9192747524851537
Validation loss: 2.4152286738187163

Epoch: 6| Step: 4
Training loss: 1.6777761540745393
Validation loss: 2.393656176849946

Epoch: 6| Step: 5
Training loss: 0.6729544019797031
Validation loss: 2.3640646763899396

Epoch: 6| Step: 6
Training loss: 0.6505435156755511
Validation loss: 2.3440541475446506

Epoch: 6| Step: 7
Training loss: 0.7092945691863345
Validation loss: 2.3682987822903514

Epoch: 6| Step: 8
Training loss: 0.7638596403899572
Validation loss: 2.31897572210711

Epoch: 6| Step: 9
Training loss: 0.7013176471632488
Validation loss: 2.3497754901087813

Epoch: 6| Step: 10
Training loss: 0.48604170856347567
Validation loss: 2.349396231367628

Epoch: 6| Step: 11
Training loss: 0.6612822731377542
Validation loss: 2.4089064076531086

Epoch: 6| Step: 12
Training loss: 0.700643143499766
Validation loss: 2.343787166615243

Epoch: 6| Step: 13
Training loss: 0.6979208893909148
Validation loss: 2.3616110030224706

Epoch: 554| Step: 0
Training loss: 0.7356477219565454
Validation loss: 2.4541511090427224

Epoch: 6| Step: 1
Training loss: 0.47300486673428127
Validation loss: 2.3151749076256705

Epoch: 6| Step: 2
Training loss: 0.5868341324849616
Validation loss: 2.336565449729184

Epoch: 6| Step: 3
Training loss: 0.650590150029869
Validation loss: 2.3785720553543164

Epoch: 6| Step: 4
Training loss: 0.8268056832667714
Validation loss: 2.324589665467341

Epoch: 6| Step: 5
Training loss: 0.4786206188624054
Validation loss: 2.3916028691880076

Epoch: 6| Step: 6
Training loss: 0.7529750073124044
Validation loss: 2.330837415302353

Epoch: 6| Step: 7
Training loss: 0.916152846219343
Validation loss: 2.3964492901322356

Epoch: 6| Step: 8
Training loss: 0.7483139159041744
Validation loss: 2.3887582796724876

Epoch: 6| Step: 9
Training loss: 0.6967810221028959
Validation loss: 2.34146791987651

Epoch: 6| Step: 10
Training loss: 0.8174288610250812
Validation loss: 2.4327355806447195

Epoch: 6| Step: 11
Training loss: 0.5897847834537694
Validation loss: 2.3373656728210794

Epoch: 6| Step: 12
Training loss: 1.6198358642174229
Validation loss: 2.3691606144987953

Epoch: 6| Step: 13
Training loss: 0.6442282918352479
Validation loss: 2.3846335830260985

Epoch: 555| Step: 0
Training loss: 0.6771310764988662
Validation loss: 2.3401239666190223

Epoch: 6| Step: 1
Training loss: 0.641417524863613
Validation loss: 2.471555958191488

Epoch: 6| Step: 2
Training loss: 0.668939877230428
Validation loss: 2.3537434872670193

Epoch: 6| Step: 3
Training loss: 0.6593043004682444
Validation loss: 2.256522506343394

Epoch: 6| Step: 4
Training loss: 0.8259603170879656
Validation loss: 2.362649309807564

Epoch: 6| Step: 5
Training loss: 0.6436946641416089
Validation loss: 2.4250495695835452

Epoch: 6| Step: 6
Training loss: 0.7438502107956743
Validation loss: 2.352436062993375

Epoch: 6| Step: 7
Training loss: 0.702490605159128
Validation loss: 2.3349033971925497

Epoch: 6| Step: 8
Training loss: 0.6451258373229194
Validation loss: 2.3608430607323925

Epoch: 6| Step: 9
Training loss: 0.8338724101396204
Validation loss: 2.3165416967409107

Epoch: 6| Step: 10
Training loss: 1.5797357176412619
Validation loss: 2.361738870528839

Epoch: 6| Step: 11
Training loss: 0.48076305834769345
Validation loss: 2.2996181514367406

Epoch: 6| Step: 12
Training loss: 0.5985401324517937
Validation loss: 2.3143526780215864

Epoch: 6| Step: 13
Training loss: 0.4420513064653921
Validation loss: 2.353709485128781

Epoch: 556| Step: 0
Training loss: 0.41877312667525146
Validation loss: 2.3447498532335387

Epoch: 6| Step: 1
Training loss: 0.47874133956287024
Validation loss: 2.341958783044217

Epoch: 6| Step: 2
Training loss: 1.5776204728494618
Validation loss: 2.3734125662168255

Epoch: 6| Step: 3
Training loss: 0.4544145715370105
Validation loss: 2.330186858990396

Epoch: 6| Step: 4
Training loss: 0.7086398546051803
Validation loss: 2.3588700248829264

Epoch: 6| Step: 5
Training loss: 0.6300402067615033
Validation loss: 2.33990960726349

Epoch: 6| Step: 6
Training loss: 0.6232596963678272
Validation loss: 2.348823347215556

Epoch: 6| Step: 7
Training loss: 0.9008619684213954
Validation loss: 2.3301567312825124

Epoch: 6| Step: 8
Training loss: 0.7693706674089699
Validation loss: 2.3199628467965367

Epoch: 6| Step: 9
Training loss: 0.6738861501284626
Validation loss: 2.334998015645127

Epoch: 6| Step: 10
Training loss: 0.5637853824059533
Validation loss: 2.329105447965555

Epoch: 6| Step: 11
Training loss: 0.5827585578889041
Validation loss: 2.3676409489284795

Epoch: 6| Step: 12
Training loss: 0.9111558066979748
Validation loss: 2.31242815264721

Epoch: 6| Step: 13
Training loss: 0.8405835464069844
Validation loss: 2.2824401751287406

Epoch: 557| Step: 0
Training loss: 0.6774474094361891
Validation loss: 2.410084303580158

Epoch: 6| Step: 1
Training loss: 0.8172787471323485
Validation loss: 2.282590762302968

Epoch: 6| Step: 2
Training loss: 0.7896994861799648
Validation loss: 2.319846251048924

Epoch: 6| Step: 3
Training loss: 0.650784897078499
Validation loss: 2.333536471769555

Epoch: 6| Step: 4
Training loss: 0.7123751095853534
Validation loss: 2.3456623930116365

Epoch: 6| Step: 5
Training loss: 0.5719196979585592
Validation loss: 2.3247594176766606

Epoch: 6| Step: 6
Training loss: 0.5199815333278516
Validation loss: 2.2700290600986133

Epoch: 6| Step: 7
Training loss: 0.5689685087389416
Validation loss: 2.3590261354500996

Epoch: 6| Step: 8
Training loss: 0.7781017192743631
Validation loss: 2.3786100924614426

Epoch: 6| Step: 9
Training loss: 0.6759913564417205
Validation loss: 2.2967015554539643

Epoch: 6| Step: 10
Training loss: 0.5414013090362337
Validation loss: 2.2996575039440548

Epoch: 6| Step: 11
Training loss: 0.7667613257836289
Validation loss: 2.3133082309134143

Epoch: 6| Step: 12
Training loss: 0.5375633956428041
Validation loss: 2.3532198850549104

Epoch: 6| Step: 13
Training loss: 2.1418140756464954
Validation loss: 2.339909516327423

Epoch: 558| Step: 0
Training loss: 0.632477471474366
Validation loss: 2.317275856837241

Epoch: 6| Step: 1
Training loss: 0.7730526592853605
Validation loss: 2.30436207187637

Epoch: 6| Step: 2
Training loss: 0.7717139566430593
Validation loss: 2.436605542323336

Epoch: 6| Step: 3
Training loss: 0.7745353151622211
Validation loss: 2.3987699385632166

Epoch: 6| Step: 4
Training loss: 0.43985236787907767
Validation loss: 2.3684707055724696

Epoch: 6| Step: 5
Training loss: 0.5843960640930755
Validation loss: 2.3027693747475535

Epoch: 6| Step: 6
Training loss: 0.8269244074171005
Validation loss: 2.303326857535633

Epoch: 6| Step: 7
Training loss: 0.6894420374338083
Validation loss: 2.3884941919547558

Epoch: 6| Step: 8
Training loss: 0.47060567393143093
Validation loss: 2.3558513643717283

Epoch: 6| Step: 9
Training loss: 0.6569342452026603
Validation loss: 2.4367800054929623

Epoch: 6| Step: 10
Training loss: 0.42091012040140985
Validation loss: 2.2751044265073226

Epoch: 6| Step: 11
Training loss: 0.9550912306184793
Validation loss: 2.3663603290045176

Epoch: 6| Step: 12
Training loss: 0.6352190481674929
Validation loss: 2.3509775380669278

Epoch: 6| Step: 13
Training loss: 2.0551607580490048
Validation loss: 2.3782341508426144

Epoch: 559| Step: 0
Training loss: 0.7725652149289449
Validation loss: 2.35237107844183

Epoch: 6| Step: 1
Training loss: 0.6030850649247403
Validation loss: 2.3982551347449355

Epoch: 6| Step: 2
Training loss: 0.6588027893862013
Validation loss: 2.300123840081541

Epoch: 6| Step: 3
Training loss: 0.5762761684359377
Validation loss: 2.403722610094468

Epoch: 6| Step: 4
Training loss: 0.5593100803146854
Validation loss: 2.389904711551556

Epoch: 6| Step: 5
Training loss: 0.5825473622071236
Validation loss: 2.3315759972529357

Epoch: 6| Step: 6
Training loss: 0.7313075426072378
Validation loss: 2.3773596202652256

Epoch: 6| Step: 7
Training loss: 0.7165759835053912
Validation loss: 2.3160218213445942

Epoch: 6| Step: 8
Training loss: 1.646880440458689
Validation loss: 2.345465640192539

Epoch: 6| Step: 9
Training loss: 0.7334452485893017
Validation loss: 2.3056837717457728

Epoch: 6| Step: 10
Training loss: 0.516141777009804
Validation loss: 2.2875783756124872

Epoch: 6| Step: 11
Training loss: 0.7447245952221058
Validation loss: 2.3709988571434604

Epoch: 6| Step: 12
Training loss: 0.5486424902567913
Validation loss: 2.3578727093906076

Epoch: 6| Step: 13
Training loss: 0.664873368604236
Validation loss: 2.4236232453525828

Epoch: 560| Step: 0
Training loss: 0.666774708715197
Validation loss: 2.409763756487326

Epoch: 6| Step: 1
Training loss: 0.8332092828608009
Validation loss: 2.379152293972066

Epoch: 6| Step: 2
Training loss: 0.6901208167796596
Validation loss: 2.3300394887199665

Epoch: 6| Step: 3
Training loss: 0.5570290264497225
Validation loss: 2.3760689476277546

Epoch: 6| Step: 4
Training loss: 0.5363254444252591
Validation loss: 2.3639335934054997

Epoch: 6| Step: 5
Training loss: 1.6397132883430414
Validation loss: 2.3553850794464277

Epoch: 6| Step: 6
Training loss: 0.6949537187370445
Validation loss: 2.4021066979051575

Epoch: 6| Step: 7
Training loss: 0.7229882379844045
Validation loss: 2.3080622888584714

Epoch: 6| Step: 8
Training loss: 0.6262713138585289
Validation loss: 2.243103459957839

Epoch: 6| Step: 9
Training loss: 0.5296643097338722
Validation loss: 2.3162793829575588

Epoch: 6| Step: 10
Training loss: 0.5936632594946635
Validation loss: 2.331043988843522

Epoch: 6| Step: 11
Training loss: 0.8947808862702138
Validation loss: 2.291952422626737

Epoch: 6| Step: 12
Training loss: 0.7805442674242208
Validation loss: 2.296535429730555

Epoch: 6| Step: 13
Training loss: 0.8296511640332828
Validation loss: 2.3045848419646506

Epoch: 561| Step: 0
Training loss: 1.5784157966627619
Validation loss: 2.369398330847699

Epoch: 6| Step: 1
Training loss: 0.7424825383069318
Validation loss: 2.401984270907331

Epoch: 6| Step: 2
Training loss: 0.7794681446914393
Validation loss: 2.305699868357279

Epoch: 6| Step: 3
Training loss: 0.5727815353090648
Validation loss: 2.300365980807966

Epoch: 6| Step: 4
Training loss: 0.48556295968234175
Validation loss: 2.301671525608604

Epoch: 6| Step: 5
Training loss: 0.9816804366989104
Validation loss: 2.3260138735335874

Epoch: 6| Step: 6
Training loss: 0.6698551867687502
Validation loss: 2.387390470770769

Epoch: 6| Step: 7
Training loss: 0.6224401503444353
Validation loss: 2.433027506385613

Epoch: 6| Step: 8
Training loss: 0.550481593003584
Validation loss: 2.3630554329983697

Epoch: 6| Step: 9
Training loss: 0.6501194385686023
Validation loss: 2.32497679696274

Epoch: 6| Step: 10
Training loss: 0.8141254159114225
Validation loss: 2.374460566020287

Epoch: 6| Step: 11
Training loss: 0.6400267901624915
Validation loss: 2.366220548650692

Epoch: 6| Step: 12
Training loss: 0.5910789239018812
Validation loss: 2.2987627680933342

Epoch: 6| Step: 13
Training loss: 0.7363213657706383
Validation loss: 2.2973354944736473

Epoch: 562| Step: 0
Training loss: 0.6920317067644133
Validation loss: 2.373832553870727

Epoch: 6| Step: 1
Training loss: 0.8019481066041837
Validation loss: 2.322483988859846

Epoch: 6| Step: 2
Training loss: 1.6173491466285874
Validation loss: 2.289579945678707

Epoch: 6| Step: 3
Training loss: 0.6048394162676386
Validation loss: 2.365958085532425

Epoch: 6| Step: 4
Training loss: 0.5193188455386575
Validation loss: 2.3511713872132898

Epoch: 6| Step: 5
Training loss: 0.7296555832738051
Validation loss: 2.274397514525861

Epoch: 6| Step: 6
Training loss: 0.8647760421590053
Validation loss: 2.2712496033243648

Epoch: 6| Step: 7
Training loss: 0.7582169859226969
Validation loss: 2.348960908295777

Epoch: 6| Step: 8
Training loss: 0.9101081147788117
Validation loss: 2.37774076492723

Epoch: 6| Step: 9
Training loss: 0.717000698453704
Validation loss: 2.323323266148242

Epoch: 6| Step: 10
Training loss: 0.43016310293196225
Validation loss: 2.32256692186341

Epoch: 6| Step: 11
Training loss: 0.716795544532144
Validation loss: 2.3650525312276875

Epoch: 6| Step: 12
Training loss: 0.4320441728697596
Validation loss: 2.3565348646027555

Epoch: 6| Step: 13
Training loss: 0.42945734275618996
Validation loss: 2.3923770565405653

Epoch: 563| Step: 0
Training loss: 0.5383557648704473
Validation loss: 2.3486367551606637

Epoch: 6| Step: 1
Training loss: 0.5244537849939229
Validation loss: 2.301036651523715

Epoch: 6| Step: 2
Training loss: 0.8469797766364303
Validation loss: 2.305548390982211

Epoch: 6| Step: 3
Training loss: 0.8029992624851893
Validation loss: 2.363054104557743

Epoch: 6| Step: 4
Training loss: 0.7238984849374607
Validation loss: 2.3817395060984636

Epoch: 6| Step: 5
Training loss: 0.6043980144548906
Validation loss: 2.420515815235088

Epoch: 6| Step: 6
Training loss: 0.5921818956900049
Validation loss: 2.3786442209553993

Epoch: 6| Step: 7
Training loss: 0.6127767735503103
Validation loss: 2.365773753008661

Epoch: 6| Step: 8
Training loss: 0.8190546473621895
Validation loss: 2.3353542277784074

Epoch: 6| Step: 9
Training loss: 0.7069520010187288
Validation loss: 2.3729347722764946

Epoch: 6| Step: 10
Training loss: 1.6250888360022944
Validation loss: 2.3424615623202842

Epoch: 6| Step: 11
Training loss: 0.7270160203031745
Validation loss: 2.2784318147110847

Epoch: 6| Step: 12
Training loss: 0.5477233573513898
Validation loss: 2.275700597921333

Epoch: 6| Step: 13
Training loss: 0.6935559276246371
Validation loss: 2.3569310131763452

Epoch: 564| Step: 0
Training loss: 0.8225075553848494
Validation loss: 2.295942733293442

Epoch: 6| Step: 1
Training loss: 0.637028671382937
Validation loss: 2.399708475674202

Epoch: 6| Step: 2
Training loss: 0.6573371510755904
Validation loss: 2.316548631106997

Epoch: 6| Step: 3
Training loss: 0.4884154783765006
Validation loss: 2.3201087416656625

Epoch: 6| Step: 4
Training loss: 1.5724837442112767
Validation loss: 2.304695328771644

Epoch: 6| Step: 5
Training loss: 0.4952815157468219
Validation loss: 2.3505982202440356

Epoch: 6| Step: 6
Training loss: 0.6877125281508664
Validation loss: 2.214907301766719

Epoch: 6| Step: 7
Training loss: 0.7457519067681719
Validation loss: 2.3319155402109453

Epoch: 6| Step: 8
Training loss: 0.7926165169582432
Validation loss: 2.368789173771692

Epoch: 6| Step: 9
Training loss: 0.8146846817137592
Validation loss: 2.3050325903193354

Epoch: 6| Step: 10
Training loss: 0.5747619706359564
Validation loss: 2.351438128286359

Epoch: 6| Step: 11
Training loss: 0.7691011727726503
Validation loss: 2.302810581542521

Epoch: 6| Step: 12
Training loss: 0.621702603544883
Validation loss: 2.2873467593588943

Epoch: 6| Step: 13
Training loss: 0.6515502443693264
Validation loss: 2.293668955290733

Epoch: 565| Step: 0
Training loss: 0.5749989354082287
Validation loss: 2.339196913858935

Epoch: 6| Step: 1
Training loss: 0.3738446916598474
Validation loss: 2.289582568012529

Epoch: 6| Step: 2
Training loss: 1.7325130468760763
Validation loss: 2.3729602293698746

Epoch: 6| Step: 3
Training loss: 0.6348571007179376
Validation loss: 2.354808560508651

Epoch: 6| Step: 4
Training loss: 0.49356522060155056
Validation loss: 2.29500026899749

Epoch: 6| Step: 5
Training loss: 0.6044546186515711
Validation loss: 2.3578954984274523

Epoch: 6| Step: 6
Training loss: 0.4911728648907962
Validation loss: 2.372165211127794

Epoch: 6| Step: 7
Training loss: 0.5972014797536654
Validation loss: 2.31114441623261

Epoch: 6| Step: 8
Training loss: 0.6266098746561788
Validation loss: 2.312720656018221

Epoch: 6| Step: 9
Training loss: 0.8088432701017155
Validation loss: 2.444179505833047

Epoch: 6| Step: 10
Training loss: 0.6991014009172746
Validation loss: 2.29671692752474

Epoch: 6| Step: 11
Training loss: 0.803783316151642
Validation loss: 2.319870105967768

Epoch: 6| Step: 12
Training loss: 0.5935867486687944
Validation loss: 2.3983170267744085

Epoch: 6| Step: 13
Training loss: 0.590099708650275
Validation loss: 2.3971168340127695

Epoch: 566| Step: 0
Training loss: 0.7479702982538861
Validation loss: 2.326373712127636

Epoch: 6| Step: 1
Training loss: 0.758210303907885
Validation loss: 2.2686963161480116

Epoch: 6| Step: 2
Training loss: 0.742628990169041
Validation loss: 2.376903534260847

Epoch: 6| Step: 3
Training loss: 0.6339814257127155
Validation loss: 2.3585067462927225

Epoch: 6| Step: 4
Training loss: 0.46635494301414443
Validation loss: 2.283100267298004

Epoch: 6| Step: 5
Training loss: 0.7331562073968821
Validation loss: 2.381481553279012

Epoch: 6| Step: 6
Training loss: 0.8583610795607307
Validation loss: 2.299597788200719

Epoch: 6| Step: 7
Training loss: 0.4046671181042042
Validation loss: 2.2587793074771834

Epoch: 6| Step: 8
Training loss: 0.5610302691665955
Validation loss: 2.3839861871524017

Epoch: 6| Step: 9
Training loss: 0.5565034396124395
Validation loss: 2.374229189490192

Epoch: 6| Step: 10
Training loss: 1.6965213807611264
Validation loss: 2.3477916049585854

Epoch: 6| Step: 11
Training loss: 0.5476529174355017
Validation loss: 2.381321859272684

Epoch: 6| Step: 12
Training loss: 0.46912313550989737
Validation loss: 2.399412726944067

Epoch: 6| Step: 13
Training loss: 0.962735889064939
Validation loss: 2.3788506304884685

Epoch: 567| Step: 0
Training loss: 0.8261531890848222
Validation loss: 2.372447578259658

Epoch: 6| Step: 1
Training loss: 0.5137630425257155
Validation loss: 2.328858944989331

Epoch: 6| Step: 2
Training loss: 1.6366484633765217
Validation loss: 2.354032119694314

Epoch: 6| Step: 3
Training loss: 0.7057348347303711
Validation loss: 2.3296013595759275

Epoch: 6| Step: 4
Training loss: 0.7928524965655794
Validation loss: 2.3564882243044787

Epoch: 6| Step: 5
Training loss: 0.6171867515462852
Validation loss: 2.3216079747616076

Epoch: 6| Step: 6
Training loss: 0.774017232311248
Validation loss: 2.4226364965672182

Epoch: 6| Step: 7
Training loss: 0.601849499892125
Validation loss: 2.318843231215261

Epoch: 6| Step: 8
Training loss: 0.6908418323636731
Validation loss: 2.293571121220895

Epoch: 6| Step: 9
Training loss: 0.5216250569178762
Validation loss: 2.26669685262538

Epoch: 6| Step: 10
Training loss: 0.8209448783783987
Validation loss: 2.2912849311557406

Epoch: 6| Step: 11
Training loss: 0.7264048087338997
Validation loss: 2.3296221549367586

Epoch: 6| Step: 12
Training loss: 0.5710647272962296
Validation loss: 2.423546662512741

Epoch: 6| Step: 13
Training loss: 0.39199596150419946
Validation loss: 2.2993208276106873

Epoch: 568| Step: 0
Training loss: 0.6206496228253734
Validation loss: 2.3366303911073683

Epoch: 6| Step: 1
Training loss: 0.6467183314983583
Validation loss: 2.3395742570398608

Epoch: 6| Step: 2
Training loss: 0.6332352250638685
Validation loss: 2.358080815350561

Epoch: 6| Step: 3
Training loss: 0.7984685111695483
Validation loss: 2.29716609393533

Epoch: 6| Step: 4
Training loss: 0.531671413003828
Validation loss: 2.3467284618063515

Epoch: 6| Step: 5
Training loss: 0.7920288754772083
Validation loss: 2.4394027365970476

Epoch: 6| Step: 6
Training loss: 0.827336241604286
Validation loss: 2.3350062774772677

Epoch: 6| Step: 7
Training loss: 0.3767518805891663
Validation loss: 2.291858926428992

Epoch: 6| Step: 8
Training loss: 0.6039723270089471
Validation loss: 2.330431840091892

Epoch: 6| Step: 9
Training loss: 0.5772622088301416
Validation loss: 2.365322708845021

Epoch: 6| Step: 10
Training loss: 0.826917595836647
Validation loss: 2.4099227327584103

Epoch: 6| Step: 11
Training loss: 1.7035743050723768
Validation loss: 2.32483065898477

Epoch: 6| Step: 12
Training loss: 0.7576263828412874
Validation loss: 2.307729431532906

Epoch: 6| Step: 13
Training loss: 0.5544153002312099
Validation loss: 2.3151915057468013

Epoch: 569| Step: 0
Training loss: 0.6491545883037712
Validation loss: 2.311101397946053

Epoch: 6| Step: 1
Training loss: 0.718181966143989
Validation loss: 2.321850318961351

Epoch: 6| Step: 2
Training loss: 0.6946480394310887
Validation loss: 2.3773874813231433

Epoch: 6| Step: 3
Training loss: 0.8284199027628314
Validation loss: 2.3058710645504528

Epoch: 6| Step: 4
Training loss: 0.5628591556475047
Validation loss: 2.3246566507469364

Epoch: 6| Step: 5
Training loss: 0.5743389393109807
Validation loss: 2.3237378775702027

Epoch: 6| Step: 6
Training loss: 0.6991016566940494
Validation loss: 2.3367288299739304

Epoch: 6| Step: 7
Training loss: 1.6305289476264602
Validation loss: 2.356325848552356

Epoch: 6| Step: 8
Training loss: 0.8824076779301265
Validation loss: 2.363181396587822

Epoch: 6| Step: 9
Training loss: 0.6389230123566074
Validation loss: 2.3022319651247933

Epoch: 6| Step: 10
Training loss: 0.6835725617531043
Validation loss: 2.3761480446298213

Epoch: 6| Step: 11
Training loss: 0.5185280773282115
Validation loss: 2.368995753714631

Epoch: 6| Step: 12
Training loss: 0.6038315079049253
Validation loss: 2.340054945972447

Epoch: 6| Step: 13
Training loss: 0.5127611099892019
Validation loss: 2.437956223284549

Epoch: 570| Step: 0
Training loss: 0.39108472474581774
Validation loss: 2.3679187995673665

Epoch: 6| Step: 1
Training loss: 0.8777687680577455
Validation loss: 2.4046602637702894

Epoch: 6| Step: 2
Training loss: 0.7296674280448742
Validation loss: 2.3131329447087134

Epoch: 6| Step: 3
Training loss: 0.3615358322714428
Validation loss: 2.3448692728301097

Epoch: 6| Step: 4
Training loss: 0.8520190563690017
Validation loss: 2.2558635445811817

Epoch: 6| Step: 5
Training loss: 0.44813168894458877
Validation loss: 2.348050127022339

Epoch: 6| Step: 6
Training loss: 0.6996865013289214
Validation loss: 2.3699919916940737

Epoch: 6| Step: 7
Training loss: 0.674187583689226
Validation loss: 2.343135017462864

Epoch: 6| Step: 8
Training loss: 0.5131766539303151
Validation loss: 2.3588335502117235

Epoch: 6| Step: 9
Training loss: 0.7243405894942849
Validation loss: 2.3240795556737495

Epoch: 6| Step: 10
Training loss: 0.7443566596961122
Validation loss: 2.346330499972992

Epoch: 6| Step: 11
Training loss: 1.6511601386500332
Validation loss: 2.35072594738046

Epoch: 6| Step: 12
Training loss: 0.6633382550333334
Validation loss: 2.359688958332354

Epoch: 6| Step: 13
Training loss: 0.5940425553603382
Validation loss: 2.3280940681798272

Epoch: 571| Step: 0
Training loss: 0.5734059556397632
Validation loss: 2.2950849625154444

Epoch: 6| Step: 1
Training loss: 0.8328217525576546
Validation loss: 2.2994292310734403

Epoch: 6| Step: 2
Training loss: 0.7981959968719806
Validation loss: 2.302723986748108

Epoch: 6| Step: 3
Training loss: 1.632167049764077
Validation loss: 2.386151578649344

Epoch: 6| Step: 4
Training loss: 0.6854990102898529
Validation loss: 2.299703195484942

Epoch: 6| Step: 5
Training loss: 0.8179468831488718
Validation loss: 2.354223830167662

Epoch: 6| Step: 6
Training loss: 0.6270045084114371
Validation loss: 2.390546988985772

Epoch: 6| Step: 7
Training loss: 0.7295522397000471
Validation loss: 2.3100768610960953

Epoch: 6| Step: 8
Training loss: 0.45521615354104267
Validation loss: 2.28402053549392

Epoch: 6| Step: 9
Training loss: 0.773849531683497
Validation loss: 2.320399935451101

Epoch: 6| Step: 10
Training loss: 0.6643742446679803
Validation loss: 2.388725221875156

Epoch: 6| Step: 11
Training loss: 0.6137977417598237
Validation loss: 2.376932142977039

Epoch: 6| Step: 12
Training loss: 0.47787323475281424
Validation loss: 2.421545082826733

Epoch: 6| Step: 13
Training loss: 0.9363389455005348
Validation loss: 2.3552590091109638

Epoch: 572| Step: 0
Training loss: 0.7131104012950026
Validation loss: 2.343756350710342

Epoch: 6| Step: 1
Training loss: 0.6137620535480743
Validation loss: 2.3437809713087927

Epoch: 6| Step: 2
Training loss: 0.7238456217529118
Validation loss: 2.335910187447475

Epoch: 6| Step: 3
Training loss: 0.7795538227714981
Validation loss: 2.363558302616116

Epoch: 6| Step: 4
Training loss: 0.5826991812249017
Validation loss: 2.267053248850046

Epoch: 6| Step: 5
Training loss: 0.8737399701810278
Validation loss: 2.3520029309861195

Epoch: 6| Step: 6
Training loss: 0.6161053985802503
Validation loss: 2.3904505411397063

Epoch: 6| Step: 7
Training loss: 0.6509599227449616
Validation loss: 2.3524042607829374

Epoch: 6| Step: 8
Training loss: 0.7970564018667722
Validation loss: 2.365158507294823

Epoch: 6| Step: 9
Training loss: 0.6280839650429013
Validation loss: 2.3133763241222662

Epoch: 6| Step: 10
Training loss: 0.8388463684980235
Validation loss: 2.3439687384801577

Epoch: 6| Step: 11
Training loss: 0.561255243357611
Validation loss: 2.3578342904464877

Epoch: 6| Step: 12
Training loss: 0.6760096522324951
Validation loss: 2.3552775250870246

Epoch: 6| Step: 13
Training loss: 2.164278095399215
Validation loss: 2.357783913765094

Epoch: 573| Step: 0
Training loss: 0.5657123392864282
Validation loss: 2.3566969137520206

Epoch: 6| Step: 1
Training loss: 0.5248264843439432
Validation loss: 2.400213273290163

Epoch: 6| Step: 2
Training loss: 0.6997349927150874
Validation loss: 2.362150128525912

Epoch: 6| Step: 3
Training loss: 0.5699571521448493
Validation loss: 2.3692888720180667

Epoch: 6| Step: 4
Training loss: 0.7613309215261379
Validation loss: 2.3776844313333263

Epoch: 6| Step: 5
Training loss: 0.5801749614201885
Validation loss: 2.3879059082558216

Epoch: 6| Step: 6
Training loss: 1.6811633346513
Validation loss: 2.325493461092182

Epoch: 6| Step: 7
Training loss: 0.8794796577863999
Validation loss: 2.3506728783592656

Epoch: 6| Step: 8
Training loss: 0.40553370931143773
Validation loss: 2.312044162494237

Epoch: 6| Step: 9
Training loss: 0.5840379058901143
Validation loss: 2.3569413430678976

Epoch: 6| Step: 10
Training loss: 0.362851206236915
Validation loss: 2.380142713640168

Epoch: 6| Step: 11
Training loss: 0.6486411866311119
Validation loss: 2.3685243867584704

Epoch: 6| Step: 12
Training loss: 0.7678505605751351
Validation loss: 2.3891791632921375

Epoch: 6| Step: 13
Training loss: 0.7439343824958234
Validation loss: 2.371445369940711

Epoch: 574| Step: 0
Training loss: 0.6936770074265457
Validation loss: 2.2897827970598224

Epoch: 6| Step: 1
Training loss: 0.590992749484361
Validation loss: 2.2873218630640424

Epoch: 6| Step: 2
Training loss: 0.6059449322988837
Validation loss: 2.382634848043063

Epoch: 6| Step: 3
Training loss: 0.6731834091587806
Validation loss: 2.2616939977946724

Epoch: 6| Step: 4
Training loss: 1.6486199445236986
Validation loss: 2.3516707093777414

Epoch: 6| Step: 5
Training loss: 0.5440049746545367
Validation loss: 2.309354615737977

Epoch: 6| Step: 6
Training loss: 0.6930947671940672
Validation loss: 2.345678810921975

Epoch: 6| Step: 7
Training loss: 0.8652994721252673
Validation loss: 2.3380702041579515

Epoch: 6| Step: 8
Training loss: 0.6523989808235418
Validation loss: 2.381407117151003

Epoch: 6| Step: 9
Training loss: 0.744991186845098
Validation loss: 2.3206500017908187

Epoch: 6| Step: 10
Training loss: 0.5224493578046484
Validation loss: 2.3486811325590717

Epoch: 6| Step: 11
Training loss: 0.6277617471705585
Validation loss: 2.4331770911087576

Epoch: 6| Step: 12
Training loss: 0.395421562680375
Validation loss: 2.326907940735351

Epoch: 6| Step: 13
Training loss: 0.8247621019856733
Validation loss: 2.3583986255555063

Epoch: 575| Step: 0
Training loss: 0.5550258840075253
Validation loss: 2.3392084991076536

Epoch: 6| Step: 1
Training loss: 0.8322188832936566
Validation loss: 2.3559153910927186

Epoch: 6| Step: 2
Training loss: 0.43066823183147795
Validation loss: 2.3193595804715987

Epoch: 6| Step: 3
Training loss: 0.4880725414548914
Validation loss: 2.3651075072643093

Epoch: 6| Step: 4
Training loss: 0.541145612063713
Validation loss: 2.3745964119722123

Epoch: 6| Step: 5
Training loss: 0.595875949491557
Validation loss: 2.3646397582323906

Epoch: 6| Step: 6
Training loss: 0.6697005860104389
Validation loss: 2.354328361952705

Epoch: 6| Step: 7
Training loss: 0.678687840350022
Validation loss: 2.332102637427225

Epoch: 6| Step: 8
Training loss: 1.5888766409810193
Validation loss: 2.3684483224477475

Epoch: 6| Step: 9
Training loss: 0.7390193176557963
Validation loss: 2.357505174219958

Epoch: 6| Step: 10
Training loss: 0.5586747864316738
Validation loss: 2.314278928024206

Epoch: 6| Step: 11
Training loss: 0.6680523557932204
Validation loss: 2.3591068981769627

Epoch: 6| Step: 12
Training loss: 0.7562023242393113
Validation loss: 2.348422239480234

Epoch: 6| Step: 13
Training loss: 0.8437470683294157
Validation loss: 2.2869362441092633

Epoch: 576| Step: 0
Training loss: 0.7704787641689477
Validation loss: 2.2809177909166256

Epoch: 6| Step: 1
Training loss: 0.4798212417893414
Validation loss: 2.3547689212179077

Epoch: 6| Step: 2
Training loss: 0.6925510476505231
Validation loss: 2.374711731070134

Epoch: 6| Step: 3
Training loss: 0.8185289521337101
Validation loss: 2.285231192830347

Epoch: 6| Step: 4
Training loss: 0.4687169540200973
Validation loss: 2.340251581859217

Epoch: 6| Step: 5
Training loss: 1.6227864815139268
Validation loss: 2.332248362614615

Epoch: 6| Step: 6
Training loss: 0.5047728309890436
Validation loss: 2.4162381364726695

Epoch: 6| Step: 7
Training loss: 0.7336052858138312
Validation loss: 2.366510316643124

Epoch: 6| Step: 8
Training loss: 0.5232881930902405
Validation loss: 2.336002936225045

Epoch: 6| Step: 9
Training loss: 0.6753909356473403
Validation loss: 2.377119245737192

Epoch: 6| Step: 10
Training loss: 0.8971573707467001
Validation loss: 2.3489517842285093

Epoch: 6| Step: 11
Training loss: 0.8031495220433449
Validation loss: 2.331157440711956

Epoch: 6| Step: 12
Training loss: 0.6038666725761064
Validation loss: 2.3208837324255724

Epoch: 6| Step: 13
Training loss: 0.8713862522478404
Validation loss: 2.314038391047516

Epoch: 577| Step: 0
Training loss: 0.5058667392268319
Validation loss: 2.224782111954591

Epoch: 6| Step: 1
Training loss: 0.7459040695261482
Validation loss: 2.3667723166619794

Epoch: 6| Step: 2
Training loss: 0.8167761005986991
Validation loss: 2.3289326551569043

Epoch: 6| Step: 3
Training loss: 0.5979377233361886
Validation loss: 2.2662859955639605

Epoch: 6| Step: 4
Training loss: 1.6692058612083427
Validation loss: 2.3698471616359127

Epoch: 6| Step: 5
Training loss: 0.7226017699454619
Validation loss: 2.3164393122721245

Epoch: 6| Step: 6
Training loss: 0.6946525656581707
Validation loss: 2.2966641140995403

Epoch: 6| Step: 7
Training loss: 0.5659722605772207
Validation loss: 2.42242129936113

Epoch: 6| Step: 8
Training loss: 0.6988052978540253
Validation loss: 2.315224501211374

Epoch: 6| Step: 9
Training loss: 0.5255298075620158
Validation loss: 2.314298489684689

Epoch: 6| Step: 10
Training loss: 0.8778992033387656
Validation loss: 2.263323840209088

Epoch: 6| Step: 11
Training loss: 0.6797501546109673
Validation loss: 2.3667634843950984

Epoch: 6| Step: 12
Training loss: 0.5337070975828263
Validation loss: 2.3521223736203396

Epoch: 6| Step: 13
Training loss: 0.57787822921019
Validation loss: 2.3294187008295637

Epoch: 578| Step: 0
Training loss: 0.53309770037932
Validation loss: 2.288870831191769

Epoch: 6| Step: 1
Training loss: 0.5722999953015834
Validation loss: 2.308825905787266

Epoch: 6| Step: 2
Training loss: 0.6249942540858312
Validation loss: 2.3076541639672166

Epoch: 6| Step: 3
Training loss: 0.592235063036809
Validation loss: 2.3647890083258245

Epoch: 6| Step: 4
Training loss: 0.6273389205651716
Validation loss: 2.2316489231898213

Epoch: 6| Step: 5
Training loss: 0.6232305752190339
Validation loss: 2.2476734930994655

Epoch: 6| Step: 6
Training loss: 0.8294929865471046
Validation loss: 2.3323812988966344

Epoch: 6| Step: 7
Training loss: 0.7552520125462355
Validation loss: 2.359420633041124

Epoch: 6| Step: 8
Training loss: 0.5537667490232336
Validation loss: 2.300883752950611

Epoch: 6| Step: 9
Training loss: 0.6810616600351405
Validation loss: 2.373708334874339

Epoch: 6| Step: 10
Training loss: 1.6373214886456435
Validation loss: 2.3149407323774134

Epoch: 6| Step: 11
Training loss: 0.5357827188288684
Validation loss: 2.304783176489167

Epoch: 6| Step: 12
Training loss: 0.8054367207061391
Validation loss: 2.387891008876574

Epoch: 6| Step: 13
Training loss: 0.4230889409532465
Validation loss: 2.354628973181255

Epoch: 579| Step: 0
Training loss: 0.9247077480212266
Validation loss: 2.3102905008044594

Epoch: 6| Step: 1
Training loss: 0.8516245128205223
Validation loss: 2.3125247815419256

Epoch: 6| Step: 2
Training loss: 0.4478279144125833
Validation loss: 2.3766920995094334

Epoch: 6| Step: 3
Training loss: 0.5755688631433191
Validation loss: 2.339672077326411

Epoch: 6| Step: 4
Training loss: 0.6765290241020702
Validation loss: 2.2767496212944764

Epoch: 6| Step: 5
Training loss: 0.6492550762860865
Validation loss: 2.3132410411374886

Epoch: 6| Step: 6
Training loss: 1.6062081298120783
Validation loss: 2.30458907634515

Epoch: 6| Step: 7
Training loss: 0.6521679761346854
Validation loss: 2.3068885897434397

Epoch: 6| Step: 8
Training loss: 0.4690722311638275
Validation loss: 2.264004027250908

Epoch: 6| Step: 9
Training loss: 0.6790617770152977
Validation loss: 2.3209789682513717

Epoch: 6| Step: 10
Training loss: 0.7072777081452581
Validation loss: 2.347556122384367

Epoch: 6| Step: 11
Training loss: 0.6345542908040486
Validation loss: 2.3912950167031486

Epoch: 6| Step: 12
Training loss: 0.41205375983123654
Validation loss: 2.3989767435927374

Epoch: 6| Step: 13
Training loss: 0.7668578284469981
Validation loss: 2.2992421092828135

Epoch: 580| Step: 0
Training loss: 1.0480134382114348
Validation loss: 2.428045981241583

Epoch: 6| Step: 1
Training loss: 0.6385711683850049
Validation loss: 2.2679325673362816

Epoch: 6| Step: 2
Training loss: 0.7156403069337512
Validation loss: 2.2941186352125404

Epoch: 6| Step: 3
Training loss: 0.7053393780780406
Validation loss: 2.3548908831196353

Epoch: 6| Step: 4
Training loss: 0.6149325402408075
Validation loss: 2.276499980414015

Epoch: 6| Step: 5
Training loss: 0.6993755399209292
Validation loss: 2.327696102299696

Epoch: 6| Step: 6
Training loss: 0.5791812475230669
Validation loss: 2.305015493628311

Epoch: 6| Step: 7
Training loss: 1.5607721311780385
Validation loss: 2.3205291888832624

Epoch: 6| Step: 8
Training loss: 0.7506582629784758
Validation loss: 2.321402722203181

Epoch: 6| Step: 9
Training loss: 0.7011943590389913
Validation loss: 2.318705740819333

Epoch: 6| Step: 10
Training loss: 0.6830843089864099
Validation loss: 2.2974977433863306

Epoch: 6| Step: 11
Training loss: 0.4877452349671985
Validation loss: 2.358450264160531

Epoch: 6| Step: 12
Training loss: 0.6218887615118911
Validation loss: 2.2997223828299127

Epoch: 6| Step: 13
Training loss: 0.6837723852813538
Validation loss: 2.354346668557465

Epoch: 581| Step: 0
Training loss: 0.752962302207848
Validation loss: 2.2879936301146087

Epoch: 6| Step: 1
Training loss: 0.6825428759902211
Validation loss: 2.2989765821558814

Epoch: 6| Step: 2
Training loss: 0.76052751560582
Validation loss: 2.362929167047398

Epoch: 6| Step: 3
Training loss: 0.7135636170809461
Validation loss: 2.348907014667154

Epoch: 6| Step: 4
Training loss: 0.8332307792184108
Validation loss: 2.3514367186008154

Epoch: 6| Step: 5
Training loss: 0.7504181490948268
Validation loss: 2.381284059804123

Epoch: 6| Step: 6
Training loss: 0.5391802728234258
Validation loss: 2.294653600661568

Epoch: 6| Step: 7
Training loss: 0.45068607350304724
Validation loss: 2.3134815535274234

Epoch: 6| Step: 8
Training loss: 1.5377847237298417
Validation loss: 2.3456113559870837

Epoch: 6| Step: 9
Training loss: 0.3896393356598678
Validation loss: 2.2958674399857797

Epoch: 6| Step: 10
Training loss: 0.682100332285609
Validation loss: 2.352582696114581

Epoch: 6| Step: 11
Training loss: 0.636870851662315
Validation loss: 2.378307396539147

Epoch: 6| Step: 12
Training loss: 0.8526612638829758
Validation loss: 2.290172533011035

Epoch: 6| Step: 13
Training loss: 0.7742282408778295
Validation loss: 2.272094926662266

Epoch: 582| Step: 0
Training loss: 0.7277501152166906
Validation loss: 2.289741443143762

Epoch: 6| Step: 1
Training loss: 0.5956856646871226
Validation loss: 2.2596612069269897

Epoch: 6| Step: 2
Training loss: 0.7615100672551712
Validation loss: 2.2865916325939897

Epoch: 6| Step: 3
Training loss: 0.5746561836559198
Validation loss: 2.3561939248388084

Epoch: 6| Step: 4
Training loss: 0.6083005088503012
Validation loss: 2.2850459128709737

Epoch: 6| Step: 5
Training loss: 1.598478744437109
Validation loss: 2.322112233067222

Epoch: 6| Step: 6
Training loss: 0.5259958347964272
Validation loss: 2.35452385480526

Epoch: 6| Step: 7
Training loss: 0.7143867574476824
Validation loss: 2.404951575482915

Epoch: 6| Step: 8
Training loss: 0.5591683533506163
Validation loss: 2.493745676569882

Epoch: 6| Step: 9
Training loss: 0.5935676696301575
Validation loss: 2.3402616622157497

Epoch: 6| Step: 10
Training loss: 0.8721201370888819
Validation loss: 2.393570918287905

Epoch: 6| Step: 11
Training loss: 0.6033721061844203
Validation loss: 2.345180295453722

Epoch: 6| Step: 12
Training loss: 0.5705113521519665
Validation loss: 2.339178099077953

Epoch: 6| Step: 13
Training loss: 0.7830942130525665
Validation loss: 2.329205258180516

Epoch: 583| Step: 0
Training loss: 0.4598346058866049
Validation loss: 2.359108561913537

Epoch: 6| Step: 1
Training loss: 0.8363025616832939
Validation loss: 2.30906714229711

Epoch: 6| Step: 2
Training loss: 0.5747558261896282
Validation loss: 2.31129075571744

Epoch: 6| Step: 3
Training loss: 0.4074384837728983
Validation loss: 2.3222882446091577

Epoch: 6| Step: 4
Training loss: 0.46675339500283614
Validation loss: 2.3167126295650524

Epoch: 6| Step: 5
Training loss: 1.541366324509455
Validation loss: 2.3174786131113443

Epoch: 6| Step: 6
Training loss: 0.7244830985457357
Validation loss: 2.368510987953135

Epoch: 6| Step: 7
Training loss: 0.8010016533457138
Validation loss: 2.394498166444904

Epoch: 6| Step: 8
Training loss: 0.44129125396840807
Validation loss: 2.3183206440490225

Epoch: 6| Step: 9
Training loss: 0.7471510500694442
Validation loss: 2.257068944062894

Epoch: 6| Step: 10
Training loss: 0.7367630946222476
Validation loss: 2.3455343179998835

Epoch: 6| Step: 11
Training loss: 0.5019294347256398
Validation loss: 2.3905205196761248

Epoch: 6| Step: 12
Training loss: 0.42605414088609267
Validation loss: 2.331388794544924

Epoch: 6| Step: 13
Training loss: 0.5967987990544945
Validation loss: 2.2788366787121808

Epoch: 584| Step: 0
Training loss: 0.6436180118322925
Validation loss: 2.3279744454905233

Epoch: 6| Step: 1
Training loss: 0.561979821540326
Validation loss: 2.30720554154862

Epoch: 6| Step: 2
Training loss: 0.8426478216059923
Validation loss: 2.350633966568459

Epoch: 6| Step: 3
Training loss: 0.5213749802963703
Validation loss: 2.337586776599322

Epoch: 6| Step: 4
Training loss: 0.6646185174037198
Validation loss: 2.346905801019116

Epoch: 6| Step: 5
Training loss: 0.5473496693153042
Validation loss: 2.350690725938194

Epoch: 6| Step: 6
Training loss: 0.6108173271682464
Validation loss: 2.384860219472907

Epoch: 6| Step: 7
Training loss: 0.509180632174442
Validation loss: 2.3499452862973507

Epoch: 6| Step: 8
Training loss: 0.5075518599448211
Validation loss: 2.3959151032463595

Epoch: 6| Step: 9
Training loss: 0.8163685767137625
Validation loss: 2.268961767862074

Epoch: 6| Step: 10
Training loss: 0.53447747168244
Validation loss: 2.312411434358908

Epoch: 6| Step: 11
Training loss: 1.6373788599530403
Validation loss: 2.37384971866901

Epoch: 6| Step: 12
Training loss: 0.9248523156087953
Validation loss: 2.3525184860619945

Epoch: 6| Step: 13
Training loss: 0.49227482157345537
Validation loss: 2.327038998579514

Epoch: 585| Step: 0
Training loss: 0.572111610284252
Validation loss: 2.344030030725283

Epoch: 6| Step: 1
Training loss: 0.6038307675740483
Validation loss: 2.3004204683618465

Epoch: 6| Step: 2
Training loss: 0.6477963598571288
Validation loss: 2.3716543582010594

Epoch: 6| Step: 3
Training loss: 0.58968037749064
Validation loss: 2.2753988610272224

Epoch: 6| Step: 4
Training loss: 0.7407403992833128
Validation loss: 2.311085361141571

Epoch: 6| Step: 5
Training loss: 1.5351967842632923
Validation loss: 2.2685975994939973

Epoch: 6| Step: 6
Training loss: 0.7690193293737814
Validation loss: 2.329027748430213

Epoch: 6| Step: 7
Training loss: 0.723458458285841
Validation loss: 2.3039207677831968

Epoch: 6| Step: 8
Training loss: 0.6612043018090353
Validation loss: 2.3445249948356195

Epoch: 6| Step: 9
Training loss: 0.7585289704530547
Validation loss: 2.3041947633588316

Epoch: 6| Step: 10
Training loss: 0.574291847403155
Validation loss: 2.3103583356410273

Epoch: 6| Step: 11
Training loss: 0.5480231358123809
Validation loss: 2.333842516055836

Epoch: 6| Step: 12
Training loss: 0.45061885083535946
Validation loss: 2.3787947725812386

Epoch: 6| Step: 13
Training loss: 0.5916640381239767
Validation loss: 2.348259336555385

Epoch: 586| Step: 0
Training loss: 0.759779903012931
Validation loss: 2.3771485355959974

Epoch: 6| Step: 1
Training loss: 0.647316526760841
Validation loss: 2.321343764635993

Epoch: 6| Step: 2
Training loss: 0.563447419310396
Validation loss: 2.3422206195702113

Epoch: 6| Step: 3
Training loss: 0.5100954530717074
Validation loss: 2.357336635428121

Epoch: 6| Step: 4
Training loss: 0.6421334951669401
Validation loss: 2.3294585761487894

Epoch: 6| Step: 5
Training loss: 0.4667408163334902
Validation loss: 2.2568002867325445

Epoch: 6| Step: 6
Training loss: 0.5990339618426256
Validation loss: 2.316054673812519

Epoch: 6| Step: 7
Training loss: 0.7212657438176331
Validation loss: 2.273863271290372

Epoch: 6| Step: 8
Training loss: 0.5217716982816489
Validation loss: 2.244074199726606

Epoch: 6| Step: 9
Training loss: 0.6135421003805375
Validation loss: 2.311910617909742

Epoch: 6| Step: 10
Training loss: 0.6371489867450723
Validation loss: 2.357565540662845

Epoch: 6| Step: 11
Training loss: 0.7589354699085763
Validation loss: 2.3634505108667976

Epoch: 6| Step: 12
Training loss: 1.5807155836884454
Validation loss: 2.3388340860345473

Epoch: 6| Step: 13
Training loss: 0.5977922172714906
Validation loss: 2.3070704256550014

Epoch: 587| Step: 0
Training loss: 0.5881524500992921
Validation loss: 2.3271828838999213

Epoch: 6| Step: 1
Training loss: 0.7755493462835314
Validation loss: 2.3238988523660855

Epoch: 6| Step: 2
Training loss: 0.49980928837043787
Validation loss: 2.3052671887776253

Epoch: 6| Step: 3
Training loss: 0.7798013989996854
Validation loss: 2.331600823436516

Epoch: 6| Step: 4
Training loss: 0.84395921727039
Validation loss: 2.304126880578705

Epoch: 6| Step: 5
Training loss: 0.5569748795116464
Validation loss: 2.394950427053695

Epoch: 6| Step: 6
Training loss: 0.5331817175511709
Validation loss: 2.264670737167977

Epoch: 6| Step: 7
Training loss: 0.693672689649411
Validation loss: 2.299876721873863

Epoch: 6| Step: 8
Training loss: 0.6518491366075289
Validation loss: 2.337649850482263

Epoch: 6| Step: 9
Training loss: 1.5711708569681047
Validation loss: 2.385752838587695

Epoch: 6| Step: 10
Training loss: 0.6503457406167378
Validation loss: 2.2966289420555204

Epoch: 6| Step: 11
Training loss: 0.6509275310923235
Validation loss: 2.3147186095186507

Epoch: 6| Step: 12
Training loss: 0.6837839352487141
Validation loss: 2.307032875327797

Epoch: 6| Step: 13
Training loss: 0.6963098637923275
Validation loss: 2.362148764303896

Epoch: 588| Step: 0
Training loss: 0.8558494034520985
Validation loss: 2.375210630168875

Epoch: 6| Step: 1
Training loss: 0.5959463154661362
Validation loss: 2.2987042168530776

Epoch: 6| Step: 2
Training loss: 0.5747916808294847
Validation loss: 2.320710382135487

Epoch: 6| Step: 3
Training loss: 0.6763239318781127
Validation loss: 2.321927883283677

Epoch: 6| Step: 4
Training loss: 0.6628090191740283
Validation loss: 2.2656121241932428

Epoch: 6| Step: 5
Training loss: 0.5207192741116229
Validation loss: 2.3856750572592667

Epoch: 6| Step: 6
Training loss: 0.496184453406869
Validation loss: 2.2526121278918865

Epoch: 6| Step: 7
Training loss: 0.42443177089270756
Validation loss: 2.2419733179077777

Epoch: 6| Step: 8
Training loss: 0.82142868397398
Validation loss: 2.3498936408049977

Epoch: 6| Step: 9
Training loss: 1.5340822457219836
Validation loss: 2.3346357815986662

Epoch: 6| Step: 10
Training loss: 0.46047863507282916
Validation loss: 2.2678116918735185

Epoch: 6| Step: 11
Training loss: 0.3743739664321413
Validation loss: 2.2583101256935776

Epoch: 6| Step: 12
Training loss: 0.513300685427513
Validation loss: 2.29189758889923

Epoch: 6| Step: 13
Training loss: 0.6531888091023396
Validation loss: 2.3333632907467865

Epoch: 589| Step: 0
Training loss: 0.7057951348547562
Validation loss: 2.3515415792366205

Epoch: 6| Step: 1
Training loss: 0.7469816666412615
Validation loss: 2.318473761607293

Epoch: 6| Step: 2
Training loss: 0.22887368963367524
Validation loss: 2.2797702547603507

Epoch: 6| Step: 3
Training loss: 0.6098104779341995
Validation loss: 2.303141621892986

Epoch: 6| Step: 4
Training loss: 1.5818724752742856
Validation loss: 2.318945902007459

Epoch: 6| Step: 5
Training loss: 0.695609554314655
Validation loss: 2.3020532758542793

Epoch: 6| Step: 6
Training loss: 0.40698967133709085
Validation loss: 2.3256377099020926

Epoch: 6| Step: 7
Training loss: 0.719973393716891
Validation loss: 2.3813443695395353

Epoch: 6| Step: 8
Training loss: 0.40053395752885673
Validation loss: 2.3436002075018574

Epoch: 6| Step: 9
Training loss: 0.6723437780849656
Validation loss: 2.3187213036757357

Epoch: 6| Step: 10
Training loss: 0.7738065513441963
Validation loss: 2.3708881065255127

Epoch: 6| Step: 11
Training loss: 0.47239086487781373
Validation loss: 2.3136230132064983

Epoch: 6| Step: 12
Training loss: 0.6422564968346275
Validation loss: 2.3859665691747605

Epoch: 6| Step: 13
Training loss: 0.31441747569950607
Validation loss: 2.33824902178397

Epoch: 590| Step: 0
Training loss: 1.6722109448181848
Validation loss: 2.3598265943369343

Epoch: 6| Step: 1
Training loss: 0.7771935629368512
Validation loss: 2.3108924548551033

Epoch: 6| Step: 2
Training loss: 0.40084489313350563
Validation loss: 2.2814825599387163

Epoch: 6| Step: 3
Training loss: 0.7211663636319422
Validation loss: 2.2996412273604774

Epoch: 6| Step: 4
Training loss: 0.7022421274297299
Validation loss: 2.3121448056707186

Epoch: 6| Step: 5
Training loss: 0.7184075908234366
Validation loss: 2.3219584666529722

Epoch: 6| Step: 6
Training loss: 0.44793298233242923
Validation loss: 2.275597215217261

Epoch: 6| Step: 7
Training loss: 0.5585112877646808
Validation loss: 2.3260404255308686

Epoch: 6| Step: 8
Training loss: 0.630301095635238
Validation loss: 2.2232541404115445

Epoch: 6| Step: 9
Training loss: 0.6545431783740728
Validation loss: 2.3295820254572193

Epoch: 6| Step: 10
Training loss: 0.7163789034650399
Validation loss: 2.3608479147025907

Epoch: 6| Step: 11
Training loss: 0.6669796765160825
Validation loss: 2.3126874746276087

Epoch: 6| Step: 12
Training loss: 0.5701524170161019
Validation loss: 2.3222800608953262

Epoch: 6| Step: 13
Training loss: 0.7360321178477323
Validation loss: 2.340345920554828

Epoch: 591| Step: 0
Training loss: 0.6973177251932019
Validation loss: 2.298041428048816

Epoch: 6| Step: 1
Training loss: 0.6472271573429297
Validation loss: 2.3122144454611977

Epoch: 6| Step: 2
Training loss: 0.7187463096855629
Validation loss: 2.314884310218089

Epoch: 6| Step: 3
Training loss: 0.8022981744022037
Validation loss: 2.280485906564063

Epoch: 6| Step: 4
Training loss: 0.7878760302907751
Validation loss: 2.310098154598842

Epoch: 6| Step: 5
Training loss: 0.5875929271982554
Validation loss: 2.3161263251005306

Epoch: 6| Step: 6
Training loss: 0.5435092897472263
Validation loss: 2.3275938097713422

Epoch: 6| Step: 7
Training loss: 0.6828009231249397
Validation loss: 2.319058526314339

Epoch: 6| Step: 8
Training loss: 1.65383591247827
Validation loss: 2.3369058534875773

Epoch: 6| Step: 9
Training loss: 0.6025428215416576
Validation loss: 2.284064613801616

Epoch: 6| Step: 10
Training loss: 0.5131156433590559
Validation loss: 2.3752657186309274

Epoch: 6| Step: 11
Training loss: 0.8658270259281092
Validation loss: 2.3179682008116016

Epoch: 6| Step: 12
Training loss: 0.4751820974397836
Validation loss: 2.3053062146570333

Epoch: 6| Step: 13
Training loss: 0.266154518782004
Validation loss: 2.3515544260682457

Epoch: 592| Step: 0
Training loss: 0.5964031171628977
Validation loss: 2.3131512016297555

Epoch: 6| Step: 1
Training loss: 1.5386632411120897
Validation loss: 2.2757319281414894

Epoch: 6| Step: 2
Training loss: 0.7742392882732243
Validation loss: 2.3133672403414183

Epoch: 6| Step: 3
Training loss: 0.6658019900633411
Validation loss: 2.3323378347399526

Epoch: 6| Step: 4
Training loss: 0.4363374932768132
Validation loss: 2.4271151492034124

Epoch: 6| Step: 5
Training loss: 0.6945280300275998
Validation loss: 2.3102020091460322

Epoch: 6| Step: 6
Training loss: 0.4785928624936056
Validation loss: 2.3523413204105466

Epoch: 6| Step: 7
Training loss: 0.5276765126683104
Validation loss: 2.347044187203352

Epoch: 6| Step: 8
Training loss: 0.8659752285301916
Validation loss: 2.2595649325442997

Epoch: 6| Step: 9
Training loss: 0.5966340842043956
Validation loss: 2.3671972674675916

Epoch: 6| Step: 10
Training loss: 0.48874994290149093
Validation loss: 2.462133224596258

Epoch: 6| Step: 11
Training loss: 0.47483788785739606
Validation loss: 2.3010108482623965

Epoch: 6| Step: 12
Training loss: 0.5700339590798446
Validation loss: 2.2819818942855408

Epoch: 6| Step: 13
Training loss: 0.5892274681221215
Validation loss: 2.3781312120845985

Epoch: 593| Step: 0
Training loss: 0.5851920408500314
Validation loss: 2.3764294552292644

Epoch: 6| Step: 1
Training loss: 0.7377318098772402
Validation loss: 2.399701060499683

Epoch: 6| Step: 2
Training loss: 0.5011817556523696
Validation loss: 2.3853132934210453

Epoch: 6| Step: 3
Training loss: 1.589321941250631
Validation loss: 2.3684660490686635

Epoch: 6| Step: 4
Training loss: 0.6374183976548082
Validation loss: 2.3096953548029595

Epoch: 6| Step: 5
Training loss: 0.46628302858584975
Validation loss: 2.398947621928603

Epoch: 6| Step: 6
Training loss: 0.5283209894144231
Validation loss: 2.322862001387718

Epoch: 6| Step: 7
Training loss: 0.5537031331260791
Validation loss: 2.3442944376290495

Epoch: 6| Step: 8
Training loss: 0.7764993806972846
Validation loss: 2.3208632580821424

Epoch: 6| Step: 9
Training loss: 0.559953541701846
Validation loss: 2.2862665643177573

Epoch: 6| Step: 10
Training loss: 0.5189907733155886
Validation loss: 2.2888959503257382

Epoch: 6| Step: 11
Training loss: 0.515847822652431
Validation loss: 2.333644372304953

Epoch: 6| Step: 12
Training loss: 0.6512770926465151
Validation loss: 2.2828007123632603

Epoch: 6| Step: 13
Training loss: 0.8032363101992981
Validation loss: 2.3144228295875116

Epoch: 594| Step: 0
Training loss: 0.6536497645367548
Validation loss: 2.3498516450045357

Epoch: 6| Step: 1
Training loss: 0.6706976666503331
Validation loss: 2.3760911289537856

Epoch: 6| Step: 2
Training loss: 0.7413841718596142
Validation loss: 2.27264366982437

Epoch: 6| Step: 3
Training loss: 0.5825343677712969
Validation loss: 2.349055530205261

Epoch: 6| Step: 4
Training loss: 1.5182960020068823
Validation loss: 2.3550407434255365

Epoch: 6| Step: 5
Training loss: 0.47881933422362444
Validation loss: 2.2909343938567415

Epoch: 6| Step: 6
Training loss: 0.8025894962449528
Validation loss: 2.276063350481181

Epoch: 6| Step: 7
Training loss: 0.5325574493759652
Validation loss: 2.4218544622073765

Epoch: 6| Step: 8
Training loss: 0.7944637168608109
Validation loss: 2.3786105165715155

Epoch: 6| Step: 9
Training loss: 0.6467053822188575
Validation loss: 2.321504634335411

Epoch: 6| Step: 10
Training loss: 0.666699748907218
Validation loss: 2.3337994888469855

Epoch: 6| Step: 11
Training loss: 0.4390465954109343
Validation loss: 2.3485851431130347

Epoch: 6| Step: 12
Training loss: 0.6047001051266634
Validation loss: 2.273965266658446

Epoch: 6| Step: 13
Training loss: 0.43815878246738066
Validation loss: 2.3118315021199627

Epoch: 595| Step: 0
Training loss: 0.8465238117489857
Validation loss: 2.3175334920238657

Epoch: 6| Step: 1
Training loss: 0.6108072517659023
Validation loss: 2.4187259383415904

Epoch: 6| Step: 2
Training loss: 0.5873502865219814
Validation loss: 2.288638822063515

Epoch: 6| Step: 3
Training loss: 0.5507587130649987
Validation loss: 2.3524697195557147

Epoch: 6| Step: 4
Training loss: 0.6220148801434275
Validation loss: 2.2780806782073357

Epoch: 6| Step: 5
Training loss: 0.6233123405086841
Validation loss: 2.279809846414622

Epoch: 6| Step: 6
Training loss: 0.5751601307185419
Validation loss: 2.3382008158873417

Epoch: 6| Step: 7
Training loss: 0.8088851993173019
Validation loss: 2.413091679716194

Epoch: 6| Step: 8
Training loss: 0.6965064181670856
Validation loss: 2.4110775281032493

Epoch: 6| Step: 9
Training loss: 0.559710260436431
Validation loss: 2.346870562116074

Epoch: 6| Step: 10
Training loss: 0.7638589771271355
Validation loss: 2.276688809238588

Epoch: 6| Step: 11
Training loss: 0.7227956276593013
Validation loss: 2.357873267702897

Epoch: 6| Step: 12
Training loss: 0.6842572289427512
Validation loss: 2.2905059561696457

Epoch: 6| Step: 13
Training loss: 2.0491543956428995
Validation loss: 2.3572480191757776

Epoch: 596| Step: 0
Training loss: 0.4726327937587552
Validation loss: 2.335596877175708

Epoch: 6| Step: 1
Training loss: 0.45414023285971405
Validation loss: 2.279920031020002

Epoch: 6| Step: 2
Training loss: 0.5476849688565399
Validation loss: 2.3486095024205533

Epoch: 6| Step: 3
Training loss: 0.6812033357299448
Validation loss: 2.2504759505019067

Epoch: 6| Step: 4
Training loss: 0.45546610914874813
Validation loss: 2.3378450054072135

Epoch: 6| Step: 5
Training loss: 0.7769433145109866
Validation loss: 2.3145066623008925

Epoch: 6| Step: 6
Training loss: 1.6295714998152901
Validation loss: 2.251809215430801

Epoch: 6| Step: 7
Training loss: 0.660101171599806
Validation loss: 2.24658750695239

Epoch: 6| Step: 8
Training loss: 0.7100084123650366
Validation loss: 2.3396462032462493

Epoch: 6| Step: 9
Training loss: 0.7200231471579489
Validation loss: 2.366345356802173

Epoch: 6| Step: 10
Training loss: 0.6084921383534029
Validation loss: 2.262448382543744

Epoch: 6| Step: 11
Training loss: 0.658017638923734
Validation loss: 2.363631237084563

Epoch: 6| Step: 12
Training loss: 0.6836079405265396
Validation loss: 2.285796645168701

Epoch: 6| Step: 13
Training loss: 0.5873733221607716
Validation loss: 2.30656445719334

Epoch: 597| Step: 0
Training loss: 0.5302778212223842
Validation loss: 2.3473360887117134

Epoch: 6| Step: 1
Training loss: 0.7447512866902577
Validation loss: 2.312628902355851

Epoch: 6| Step: 2
Training loss: 0.722083777420016
Validation loss: 2.3321364654156866

Epoch: 6| Step: 3
Training loss: 0.694193550457856
Validation loss: 2.2646087137975406

Epoch: 6| Step: 4
Training loss: 0.7067627792255565
Validation loss: 2.3726904984276938

Epoch: 6| Step: 5
Training loss: 0.4368273127537687
Validation loss: 2.239189737985129

Epoch: 6| Step: 6
Training loss: 0.7001738392025822
Validation loss: 2.245357178289141

Epoch: 6| Step: 7
Training loss: 0.7517020462771525
Validation loss: 2.299110249683128

Epoch: 6| Step: 8
Training loss: 1.5818662957743646
Validation loss: 2.2549581327581483

Epoch: 6| Step: 9
Training loss: 0.4745577246421797
Validation loss: 2.253724720226923

Epoch: 6| Step: 10
Training loss: 0.8145494289773423
Validation loss: 2.373515036717239

Epoch: 6| Step: 11
Training loss: 0.5394147192164889
Validation loss: 2.258015134120541

Epoch: 6| Step: 12
Training loss: 0.43279744820983934
Validation loss: 2.3403342204408264

Epoch: 6| Step: 13
Training loss: 0.4603452757323977
Validation loss: 2.30064962904682

Epoch: 598| Step: 0
Training loss: 0.6428982479335629
Validation loss: 2.3383985124288706

Epoch: 6| Step: 1
Training loss: 0.612934865138942
Validation loss: 2.192704211238893

Epoch: 6| Step: 2
Training loss: 0.47769633630637703
Validation loss: 2.258153693830454

Epoch: 6| Step: 3
Training loss: 0.8962182541336449
Validation loss: 2.3301260123694676

Epoch: 6| Step: 4
Training loss: 0.5583717064932213
Validation loss: 2.2895417722983784

Epoch: 6| Step: 5
Training loss: 0.48916096594909686
Validation loss: 2.2770220271192203

Epoch: 6| Step: 6
Training loss: 1.4766492061285934
Validation loss: 2.3536542428601717

Epoch: 6| Step: 7
Training loss: 0.4950525215249996
Validation loss: 2.3291809369822514

Epoch: 6| Step: 8
Training loss: 0.5428192152311802
Validation loss: 2.2806903283495923

Epoch: 6| Step: 9
Training loss: 0.49372742456420987
Validation loss: 2.3083164974533217

Epoch: 6| Step: 10
Training loss: 0.8806052507469664
Validation loss: 2.281187553073612

Epoch: 6| Step: 11
Training loss: 0.4571480235059047
Validation loss: 2.258616833335775

Epoch: 6| Step: 12
Training loss: 0.5211525765175341
Validation loss: 2.2877196171279683

Epoch: 6| Step: 13
Training loss: 0.5763757118827942
Validation loss: 2.3057284621644456

Epoch: 599| Step: 0
Training loss: 0.47520092805240377
Validation loss: 2.3078372067511217

Epoch: 6| Step: 1
Training loss: 0.6895660005409899
Validation loss: 2.398155403977038

Epoch: 6| Step: 2
Training loss: 0.6927619186747215
Validation loss: 2.3761795711360163

Epoch: 6| Step: 3
Training loss: 0.5720438348406414
Validation loss: 2.4086248969955655

Epoch: 6| Step: 4
Training loss: 0.5318714602091494
Validation loss: 2.3808140500414665

Epoch: 6| Step: 5
Training loss: 0.7086412424408621
Validation loss: 2.4059314620821306

Epoch: 6| Step: 6
Training loss: 0.5462128854446907
Validation loss: 2.2999510484999584

Epoch: 6| Step: 7
Training loss: 0.643117892464232
Validation loss: 2.410593086022128

Epoch: 6| Step: 8
Training loss: 0.45323360720035594
Validation loss: 2.324562215722936

Epoch: 6| Step: 9
Training loss: 0.6263616511091608
Validation loss: 2.33178922784147

Epoch: 6| Step: 10
Training loss: 0.7248827888845218
Validation loss: 2.3098664479864577

Epoch: 6| Step: 11
Training loss: 0.5396323025942515
Validation loss: 2.3514171429091713

Epoch: 6| Step: 12
Training loss: 1.5676132460575498
Validation loss: 2.3024711707218075

Epoch: 6| Step: 13
Training loss: 0.5668334665192685
Validation loss: 2.2754212682784476

Epoch: 600| Step: 0
Training loss: 0.5478211800757473
Validation loss: 2.217693841809859

Epoch: 6| Step: 1
Training loss: 0.6202392938497886
Validation loss: 2.3065246212211945

Epoch: 6| Step: 2
Training loss: 0.4835054991871913
Validation loss: 2.3489278879537507

Epoch: 6| Step: 3
Training loss: 0.5383454128165962
Validation loss: 2.3374755177233815

Epoch: 6| Step: 4
Training loss: 0.5196871989530883
Validation loss: 2.290616852339657

Epoch: 6| Step: 5
Training loss: 0.37844565013422277
Validation loss: 2.3654688108285007

Epoch: 6| Step: 6
Training loss: 0.6758529977802955
Validation loss: 2.297215730910459

Epoch: 6| Step: 7
Training loss: 0.6104330023791937
Validation loss: 2.3136306721270063

Epoch: 6| Step: 8
Training loss: 0.7893038088001126
Validation loss: 2.346128772347174

Epoch: 6| Step: 9
Training loss: 1.6441085888439366
Validation loss: 2.289317937890217

Epoch: 6| Step: 10
Training loss: 0.5489670384227758
Validation loss: 2.2928001662015385

Epoch: 6| Step: 11
Training loss: 0.49770029013856937
Validation loss: 2.329627850876626

Epoch: 6| Step: 12
Training loss: 0.5869510784948735
Validation loss: 2.360422278057989

Epoch: 6| Step: 13
Training loss: 0.527497474022553
Validation loss: 2.331969005864143

Epoch: 601| Step: 0
Training loss: 0.4641407531368257
Validation loss: 2.3633829372749706

Epoch: 6| Step: 1
Training loss: 0.48927862918753884
Validation loss: 2.2662680963905797

Epoch: 6| Step: 2
Training loss: 0.6617791806925539
Validation loss: 2.3033514572933993

Epoch: 6| Step: 3
Training loss: 0.7489364553624275
Validation loss: 2.3854770576630298

Epoch: 6| Step: 4
Training loss: 0.4894602465282738
Validation loss: 2.307592305483528

Epoch: 6| Step: 5
Training loss: 0.5968864569637932
Validation loss: 2.269889758184547

Epoch: 6| Step: 6
Training loss: 0.4054780007190944
Validation loss: 2.309147569590557

Epoch: 6| Step: 7
Training loss: 0.48045456097748734
Validation loss: 2.2936495479728665

Epoch: 6| Step: 8
Training loss: 0.5614333370733432
Validation loss: 2.3810089348889925

Epoch: 6| Step: 9
Training loss: 0.5383740880713568
Validation loss: 2.294172483894647

Epoch: 6| Step: 10
Training loss: 0.49482290938937984
Validation loss: 2.3475144527931806

Epoch: 6| Step: 11
Training loss: 0.7070609028536099
Validation loss: 2.32545873445624

Epoch: 6| Step: 12
Training loss: 0.5470835424346795
Validation loss: 2.2897528486857235

Epoch: 6| Step: 13
Training loss: 1.9509065159309857
Validation loss: 2.247649425693396

Epoch: 602| Step: 0
Training loss: 0.6035389571633276
Validation loss: 2.353072639038239

Epoch: 6| Step: 1
Training loss: 1.5417886204639923
Validation loss: 2.3796280280297943

Epoch: 6| Step: 2
Training loss: 0.5638192389317748
Validation loss: 2.3460118061961346

Epoch: 6| Step: 3
Training loss: 0.6624348158527797
Validation loss: 2.30214886582974

Epoch: 6| Step: 4
Training loss: 0.5078625580983928
Validation loss: 2.2697662999354473

Epoch: 6| Step: 5
Training loss: 0.5195388219754832
Validation loss: 2.333861802796899

Epoch: 6| Step: 6
Training loss: 0.47062345281602463
Validation loss: 2.3465351240138963

Epoch: 6| Step: 7
Training loss: 0.7500075101476401
Validation loss: 2.3050223458887507

Epoch: 6| Step: 8
Training loss: 0.6459083872427581
Validation loss: 2.288054703053505

Epoch: 6| Step: 9
Training loss: 0.5613442043690594
Validation loss: 2.3589712502536613

Epoch: 6| Step: 10
Training loss: 0.7635001845668727
Validation loss: 2.2777392694856595

Epoch: 6| Step: 11
Training loss: 0.6204033619325353
Validation loss: 2.3654265117186957

Epoch: 6| Step: 12
Training loss: 0.5741210127712192
Validation loss: 2.2995124180588866

Epoch: 6| Step: 13
Training loss: 0.5068613093793257
Validation loss: 2.3518942387490127

Epoch: 603| Step: 0
Training loss: 0.5394457684677556
Validation loss: 2.355347518972407

Epoch: 6| Step: 1
Training loss: 0.5199516717754216
Validation loss: 2.319137621342898

Epoch: 6| Step: 2
Training loss: 0.5733006462170046
Validation loss: 2.3452243119352283

Epoch: 6| Step: 3
Training loss: 0.4319129878559735
Validation loss: 2.333826153836584

Epoch: 6| Step: 4
Training loss: 0.5370158720991811
Validation loss: 2.32493147641551

Epoch: 6| Step: 5
Training loss: 0.6817827705016296
Validation loss: 2.3016331409306474

Epoch: 6| Step: 6
Training loss: 0.6391754032003781
Validation loss: 2.3418516224688037

Epoch: 6| Step: 7
Training loss: 0.489256502861661
Validation loss: 2.275221245785056

Epoch: 6| Step: 8
Training loss: 1.4790332447465648
Validation loss: 2.3588888711585585

Epoch: 6| Step: 9
Training loss: 0.5695282233514936
Validation loss: 2.40489651676327

Epoch: 6| Step: 10
Training loss: 0.345741162120267
Validation loss: 2.3198068967758427

Epoch: 6| Step: 11
Training loss: 0.6527007034355827
Validation loss: 2.376500133577857

Epoch: 6| Step: 12
Training loss: 0.6696901949544806
Validation loss: 2.3204870980399934

Epoch: 6| Step: 13
Training loss: 0.7521615668383915
Validation loss: 2.450011554311563

Epoch: 604| Step: 0
Training loss: 0.6369575567522936
Validation loss: 2.294425856223238

Epoch: 6| Step: 1
Training loss: 0.7086964592734457
Validation loss: 2.3022241675074273

Epoch: 6| Step: 2
Training loss: 0.542689299539484
Validation loss: 2.42247855888941

Epoch: 6| Step: 3
Training loss: 0.44001197037344597
Validation loss: 2.375384416756622

Epoch: 6| Step: 4
Training loss: 0.44278198826243903
Validation loss: 2.293177552036288

Epoch: 6| Step: 5
Training loss: 0.49666712509151184
Validation loss: 2.3317035261941177

Epoch: 6| Step: 6
Training loss: 1.6167222980221803
Validation loss: 2.3114769714482746

Epoch: 6| Step: 7
Training loss: 0.38839767598700276
Validation loss: 2.3618662041364273

Epoch: 6| Step: 8
Training loss: 0.5908792765805382
Validation loss: 2.33912483656326

Epoch: 6| Step: 9
Training loss: 0.7458477713254766
Validation loss: 2.3915780044756954

Epoch: 6| Step: 10
Training loss: 0.7389339407791804
Validation loss: 2.2251740469245624

Epoch: 6| Step: 11
Training loss: 0.49699779048904413
Validation loss: 2.366319582074764

Epoch: 6| Step: 12
Training loss: 0.5828730237282258
Validation loss: 2.2848658554324026

Epoch: 6| Step: 13
Training loss: 0.7467095195728983
Validation loss: 2.2940883802539775

Epoch: 605| Step: 0
Training loss: 0.7064867399311737
Validation loss: 2.3928951857136065

Epoch: 6| Step: 1
Training loss: 0.7076653013789692
Validation loss: 2.328900338256799

Epoch: 6| Step: 2
Training loss: 0.6517647555092618
Validation loss: 2.316965086614393

Epoch: 6| Step: 3
Training loss: 0.5329757317337646
Validation loss: 2.362375880679807

Epoch: 6| Step: 4
Training loss: 0.9046340873908063
Validation loss: 2.365286111488111

Epoch: 6| Step: 5
Training loss: 0.5109355261528316
Validation loss: 2.3748976011281138

Epoch: 6| Step: 6
Training loss: 1.5119607421228982
Validation loss: 2.2761757719317552

Epoch: 6| Step: 7
Training loss: 0.35280399459236617
Validation loss: 2.237239348394382

Epoch: 6| Step: 8
Training loss: 0.6243862476424065
Validation loss: 2.3184439259288534

Epoch: 6| Step: 9
Training loss: 0.41004953358491925
Validation loss: 2.2987132582049865

Epoch: 6| Step: 10
Training loss: 0.8170405210113807
Validation loss: 2.3239806653999837

Epoch: 6| Step: 11
Training loss: 0.5136390066328202
Validation loss: 2.4012292442503687

Epoch: 6| Step: 12
Training loss: 0.6512041931736697
Validation loss: 2.3242128643217472

Epoch: 6| Step: 13
Training loss: 1.043157496143295
Validation loss: 2.2992923938371392

Epoch: 606| Step: 0
Training loss: 0.5497932229616901
Validation loss: 2.388800898630461

Epoch: 6| Step: 1
Training loss: 0.6656125546576914
Validation loss: 2.383142738314028

Epoch: 6| Step: 2
Training loss: 0.5856406159084795
Validation loss: 2.3559352784361596

Epoch: 6| Step: 3
Training loss: 0.6831900794396089
Validation loss: 2.310114633831882

Epoch: 6| Step: 4
Training loss: 0.701655930073009
Validation loss: 2.3341004523198614

Epoch: 6| Step: 5
Training loss: 0.6374172287855921
Validation loss: 2.421005279162724

Epoch: 6| Step: 6
Training loss: 0.8056838894340655
Validation loss: 2.393708740596775

Epoch: 6| Step: 7
Training loss: 0.6542724604819967
Validation loss: 2.3452521341755506

Epoch: 6| Step: 8
Training loss: 0.5542006975733986
Validation loss: 2.3215666935837316

Epoch: 6| Step: 9
Training loss: 0.5355689413587245
Validation loss: 2.288104093999714

Epoch: 6| Step: 10
Training loss: 1.5405681235935713
Validation loss: 2.2663936851292212

Epoch: 6| Step: 11
Training loss: 0.9399936889375705
Validation loss: 2.393445648968297

Epoch: 6| Step: 12
Training loss: 0.5183416816319207
Validation loss: 2.2860285850106927

Epoch: 6| Step: 13
Training loss: 0.62953642554486
Validation loss: 2.3156757327202806

Epoch: 607| Step: 0
Training loss: 0.7391209746570025
Validation loss: 2.3630298854733307

Epoch: 6| Step: 1
Training loss: 0.7293130636844782
Validation loss: 2.303107572843495

Epoch: 6| Step: 2
Training loss: 0.47197418812511654
Validation loss: 2.2855850567649583

Epoch: 6| Step: 3
Training loss: 0.6798522135778269
Validation loss: 2.3385839207465944

Epoch: 6| Step: 4
Training loss: 0.42146832680399887
Validation loss: 2.2845762902535713

Epoch: 6| Step: 5
Training loss: 0.5252878592009147
Validation loss: 2.329331418463756

Epoch: 6| Step: 6
Training loss: 0.5517890583744731
Validation loss: 2.348735973879462

Epoch: 6| Step: 7
Training loss: 0.9416982743914105
Validation loss: 2.3122277990663167

Epoch: 6| Step: 8
Training loss: 0.828014222419145
Validation loss: 2.325443566711403

Epoch: 6| Step: 9
Training loss: 0.7299437650811306
Validation loss: 2.39981736424837

Epoch: 6| Step: 10
Training loss: 1.4756436996212234
Validation loss: 2.3092151604569713

Epoch: 6| Step: 11
Training loss: 0.5937640539814928
Validation loss: 2.3357176614663477

Epoch: 6| Step: 12
Training loss: 0.766128685761715
Validation loss: 2.2824010109966126

Epoch: 6| Step: 13
Training loss: 0.32967355300908024
Validation loss: 2.2846087460099094

Epoch: 608| Step: 0
Training loss: 0.5832102566261935
Validation loss: 2.356423766005947

Epoch: 6| Step: 1
Training loss: 0.7300756283998536
Validation loss: 2.296303272838575

Epoch: 6| Step: 2
Training loss: 0.8065690200465276
Validation loss: 2.3475795401144346

Epoch: 6| Step: 3
Training loss: 1.524611895845261
Validation loss: 2.3355689640664004

Epoch: 6| Step: 4
Training loss: 0.7174987682637665
Validation loss: 2.3218457097372474

Epoch: 6| Step: 5
Training loss: 0.5339027258645318
Validation loss: 2.3218744409151104

Epoch: 6| Step: 6
Training loss: 0.5638030641707301
Validation loss: 2.290039044588406

Epoch: 6| Step: 7
Training loss: 0.4246973187039272
Validation loss: 2.3617791363854463

Epoch: 6| Step: 8
Training loss: 0.7946112398375675
Validation loss: 2.331803794153161

Epoch: 6| Step: 9
Training loss: 0.5510814470908484
Validation loss: 2.34246906128539

Epoch: 6| Step: 10
Training loss: 0.4529416272299209
Validation loss: 2.347504874263063

Epoch: 6| Step: 11
Training loss: 0.27428715713918334
Validation loss: 2.3426222080593875

Epoch: 6| Step: 12
Training loss: 0.4341058027282974
Validation loss: 2.3483537861378125

Epoch: 6| Step: 13
Training loss: 0.6866560437559733
Validation loss: 2.2826653300174233

Epoch: 609| Step: 0
Training loss: 1.5605629166982908
Validation loss: 2.2875735477230346

Epoch: 6| Step: 1
Training loss: 0.6900321107109841
Validation loss: 2.32734360995138

Epoch: 6| Step: 2
Training loss: 0.38645614030460834
Validation loss: 2.360970927481818

Epoch: 6| Step: 3
Training loss: 0.547003540191492
Validation loss: 2.3265355414487296

Epoch: 6| Step: 4
Training loss: 0.4750085102122038
Validation loss: 2.249723161053111

Epoch: 6| Step: 5
Training loss: 0.5096560247117747
Validation loss: 2.354893341279194

Epoch: 6| Step: 6
Training loss: 0.6754833292397004
Validation loss: 2.368137496733269

Epoch: 6| Step: 7
Training loss: 0.46331133817133135
Validation loss: 2.3020446540977044

Epoch: 6| Step: 8
Training loss: 0.9361535894363309
Validation loss: 2.4033418769690824

Epoch: 6| Step: 9
Training loss: 0.5646275973358442
Validation loss: 2.3342851888849756

Epoch: 6| Step: 10
Training loss: 0.531470365259741
Validation loss: 2.2799513476732187

Epoch: 6| Step: 11
Training loss: 0.66915700862355
Validation loss: 2.349109579759988

Epoch: 6| Step: 12
Training loss: 0.5575803086466694
Validation loss: 2.4082979900606634

Epoch: 6| Step: 13
Training loss: 0.3989699303092717
Validation loss: 2.322380287255939

Epoch: 610| Step: 0
Training loss: 0.7286131847193886
Validation loss: 2.3813763262278678

Epoch: 6| Step: 1
Training loss: 0.473088153830455
Validation loss: 2.3942583111863596

Epoch: 6| Step: 2
Training loss: 0.38876351277824855
Validation loss: 2.389376755251716

Epoch: 6| Step: 3
Training loss: 0.8137478049932781
Validation loss: 2.369074380242322

Epoch: 6| Step: 4
Training loss: 0.5315569103290195
Validation loss: 2.3004621473907525

Epoch: 6| Step: 5
Training loss: 0.653305053532743
Validation loss: 2.313166582416982

Epoch: 6| Step: 6
Training loss: 0.5293499121187648
Validation loss: 2.2891658681363136

Epoch: 6| Step: 7
Training loss: 0.597681979953191
Validation loss: 2.3287503876085607

Epoch: 6| Step: 8
Training loss: 0.6992536568053352
Validation loss: 2.310673103743251

Epoch: 6| Step: 9
Training loss: 1.526712584755895
Validation loss: 2.36365733505596

Epoch: 6| Step: 10
Training loss: 0.5870289618676242
Validation loss: 2.2684537942750587

Epoch: 6| Step: 11
Training loss: 0.5825760614891385
Validation loss: 2.287405916813481

Epoch: 6| Step: 12
Training loss: 0.3269755347808611
Validation loss: 2.2960813422291166

Epoch: 6| Step: 13
Training loss: 0.6632914835541435
Validation loss: 2.2658560239397363

Epoch: 611| Step: 0
Training loss: 0.5604029879501924
Validation loss: 2.327621890110564

Epoch: 6| Step: 1
Training loss: 0.5677042590587134
Validation loss: 2.2970997433443543

Epoch: 6| Step: 2
Training loss: 0.6044626798807657
Validation loss: 2.225442729344016

Epoch: 6| Step: 3
Training loss: 1.5266157595852141
Validation loss: 2.340174664033774

Epoch: 6| Step: 4
Training loss: 0.6899764368622601
Validation loss: 2.3455193899236004

Epoch: 6| Step: 5
Training loss: 0.7135244399912618
Validation loss: 2.3424120600118203

Epoch: 6| Step: 6
Training loss: 0.6832978398323946
Validation loss: 2.3224005268982095

Epoch: 6| Step: 7
Training loss: 0.6059843267768267
Validation loss: 2.318610510580132

Epoch: 6| Step: 8
Training loss: 0.5967520062812797
Validation loss: 2.26230060553344

Epoch: 6| Step: 9
Training loss: 0.5455918653986442
Validation loss: 2.3192948629285954

Epoch: 6| Step: 10
Training loss: 0.5784970194872516
Validation loss: 2.302632296230005

Epoch: 6| Step: 11
Training loss: 0.9462177576495578
Validation loss: 2.34467078275645

Epoch: 6| Step: 12
Training loss: 0.4392681156237506
Validation loss: 2.3791932920026366

Epoch: 6| Step: 13
Training loss: 0.7838217938773056
Validation loss: 2.3027964842125037

Epoch: 612| Step: 0
Training loss: 0.42694082635056424
Validation loss: 2.3734473997056784

Epoch: 6| Step: 1
Training loss: 0.6077366102446988
Validation loss: 2.332575052590387

Epoch: 6| Step: 2
Training loss: 0.5021931412100477
Validation loss: 2.3462149812876087

Epoch: 6| Step: 3
Training loss: 0.7186807516159209
Validation loss: 2.2978471399857594

Epoch: 6| Step: 4
Training loss: 0.3726595320647039
Validation loss: 2.3964279578279566

Epoch: 6| Step: 5
Training loss: 1.4772206610727607
Validation loss: 2.354487322604608

Epoch: 6| Step: 6
Training loss: 0.4374950953617379
Validation loss: 2.3591754027281344

Epoch: 6| Step: 7
Training loss: 0.45160231761210967
Validation loss: 2.3279893032692005

Epoch: 6| Step: 8
Training loss: 0.6309348849525315
Validation loss: 2.435164688338235

Epoch: 6| Step: 9
Training loss: 0.5262818559260652
Validation loss: 2.304686435749969

Epoch: 6| Step: 10
Training loss: 0.6655385386588252
Validation loss: 2.288254493295881

Epoch: 6| Step: 11
Training loss: 0.5552054123029276
Validation loss: 2.392859224335651

Epoch: 6| Step: 12
Training loss: 0.511461906912673
Validation loss: 2.314371131907764

Epoch: 6| Step: 13
Training loss: 0.9101711484811169
Validation loss: 2.3894838589021137

Epoch: 613| Step: 0
Training loss: 0.5723602685359283
Validation loss: 2.3329646270426143

Epoch: 6| Step: 1
Training loss: 0.4089818763110063
Validation loss: 2.3404303346893736

Epoch: 6| Step: 2
Training loss: 0.5148607427776785
Validation loss: 2.3014062860187523

Epoch: 6| Step: 3
Training loss: 1.5949009498047553
Validation loss: 2.343224767536806

Epoch: 6| Step: 4
Training loss: 0.4948628541699384
Validation loss: 2.340661560567791

Epoch: 6| Step: 5
Training loss: 0.6544988975078485
Validation loss: 2.3225806834022626

Epoch: 6| Step: 6
Training loss: 0.7676782130246673
Validation loss: 2.3850522369933382

Epoch: 6| Step: 7
Training loss: 0.5329416213656321
Validation loss: 2.3467572652308197

Epoch: 6| Step: 8
Training loss: 0.709114167914594
Validation loss: 2.3411330195436757

Epoch: 6| Step: 9
Training loss: 0.6695497107436733
Validation loss: 2.317987360835799

Epoch: 6| Step: 10
Training loss: 0.5392372843127873
Validation loss: 2.3175298139273433

Epoch: 6| Step: 11
Training loss: 0.7375241388799441
Validation loss: 2.315098913740859

Epoch: 6| Step: 12
Training loss: 0.7775746294983811
Validation loss: 2.377111560041762

Epoch: 6| Step: 13
Training loss: 0.559143782624468
Validation loss: 2.3265612985313417

Epoch: 614| Step: 0
Training loss: 0.7014616895942243
Validation loss: 2.3158250842034422

Epoch: 6| Step: 1
Training loss: 0.4560604217626231
Validation loss: 2.3327416400037837

Epoch: 6| Step: 2
Training loss: 0.42040586746278946
Validation loss: 2.2812034252681204

Epoch: 6| Step: 3
Training loss: 1.5529508619720416
Validation loss: 2.381127678326122

Epoch: 6| Step: 4
Training loss: 0.49169829443320984
Validation loss: 2.3578237448342585

Epoch: 6| Step: 5
Training loss: 0.633804885361099
Validation loss: 2.393281915822862

Epoch: 6| Step: 6
Training loss: 0.7182910946894755
Validation loss: 2.3311091516764604

Epoch: 6| Step: 7
Training loss: 0.46761929514815226
Validation loss: 2.3247582459989204

Epoch: 6| Step: 8
Training loss: 0.6015542265087767
Validation loss: 2.2738019056845507

Epoch: 6| Step: 9
Training loss: 0.5819066573565076
Validation loss: 2.312758065778893

Epoch: 6| Step: 10
Training loss: 0.5266971721546458
Validation loss: 2.4136505386073352

Epoch: 6| Step: 11
Training loss: 0.49868048960329625
Validation loss: 2.2634650707180115

Epoch: 6| Step: 12
Training loss: 0.5724044995842159
Validation loss: 2.3509472656867207

Epoch: 6| Step: 13
Training loss: 0.46246911023059745
Validation loss: 2.327128022680707

Epoch: 615| Step: 0
Training loss: 0.45782756715528794
Validation loss: 2.3961783056875285

Epoch: 6| Step: 1
Training loss: 0.7990988200455251
Validation loss: 2.3603316906439353

Epoch: 6| Step: 2
Training loss: 0.5682192495327405
Validation loss: 2.373959064937538

Epoch: 6| Step: 3
Training loss: 0.5092623041845414
Validation loss: 2.3582736044679815

Epoch: 6| Step: 4
Training loss: 0.4842307429691813
Validation loss: 2.351864438167755

Epoch: 6| Step: 5
Training loss: 0.48235595499852624
Validation loss: 2.3713497214193233

Epoch: 6| Step: 6
Training loss: 0.6494715844399814
Validation loss: 2.3223847083109352

Epoch: 6| Step: 7
Training loss: 0.6067678972645288
Validation loss: 2.289254644378488

Epoch: 6| Step: 8
Training loss: 0.7215018872839762
Validation loss: 2.3956016585453086

Epoch: 6| Step: 9
Training loss: 0.5294043794246174
Validation loss: 2.325045612464247

Epoch: 6| Step: 10
Training loss: 0.5281703263644809
Validation loss: 2.291898074636827

Epoch: 6| Step: 11
Training loss: 0.3546871563409829
Validation loss: 2.304071614472376

Epoch: 6| Step: 12
Training loss: 0.7534504436581988
Validation loss: 2.330074396290232

Epoch: 6| Step: 13
Training loss: 1.9432541095077227
Validation loss: 2.3939535898286897

Epoch: 616| Step: 0
Training loss: 0.6146225566524516
Validation loss: 2.3678097617250575

Epoch: 6| Step: 1
Training loss: 0.6002365957127446
Validation loss: 2.3852735086778507

Epoch: 6| Step: 2
Training loss: 0.5980920885412682
Validation loss: 2.2949643989765196

Epoch: 6| Step: 3
Training loss: 1.5714470859155256
Validation loss: 2.37732038610557

Epoch: 6| Step: 4
Training loss: 0.4426388873065802
Validation loss: 2.3119589148467936

Epoch: 6| Step: 5
Training loss: 0.5068442871346801
Validation loss: 2.3223649525875993

Epoch: 6| Step: 6
Training loss: 0.7085856848345021
Validation loss: 2.3176860731290363

Epoch: 6| Step: 7
Training loss: 0.5989603761278782
Validation loss: 2.2763679825957923

Epoch: 6| Step: 8
Training loss: 0.5096145932311846
Validation loss: 2.307445026492526

Epoch: 6| Step: 9
Training loss: 0.6322865125099361
Validation loss: 2.3639229275125992

Epoch: 6| Step: 10
Training loss: 0.7433829066791138
Validation loss: 2.2835999276684897

Epoch: 6| Step: 11
Training loss: 0.4989409854503877
Validation loss: 2.3490578209467956

Epoch: 6| Step: 12
Training loss: 0.6587440916444287
Validation loss: 2.308606169543172

Epoch: 6| Step: 13
Training loss: 0.4437810262391124
Validation loss: 2.3340055459503515

Epoch: 617| Step: 0
Training loss: 0.6485078842386757
Validation loss: 2.3044712416389057

Epoch: 6| Step: 1
Training loss: 0.5736292713278083
Validation loss: 2.365160136424768

Epoch: 6| Step: 2
Training loss: 0.4454320780505863
Validation loss: 2.3789212584563035

Epoch: 6| Step: 3
Training loss: 0.3667081382266072
Validation loss: 2.343496844658156

Epoch: 6| Step: 4
Training loss: 0.47053795603546184
Validation loss: 2.3632267087932592

Epoch: 6| Step: 5
Training loss: 0.5165697170891121
Validation loss: 2.3462210532514702

Epoch: 6| Step: 6
Training loss: 0.6826693797316817
Validation loss: 2.3159931476259352

Epoch: 6| Step: 7
Training loss: 0.5122340279765825
Validation loss: 2.37278315303663

Epoch: 6| Step: 8
Training loss: 0.5910044485625067
Validation loss: 2.3851057610271913

Epoch: 6| Step: 9
Training loss: 0.5565340709761512
Validation loss: 2.351022331445468

Epoch: 6| Step: 10
Training loss: 0.5768520672208519
Validation loss: 2.3156060359398

Epoch: 6| Step: 11
Training loss: 1.5040130973610872
Validation loss: 2.3366918703543

Epoch: 6| Step: 12
Training loss: 0.5274868523735508
Validation loss: 2.262342973244581

Epoch: 6| Step: 13
Training loss: 0.33044230668706437
Validation loss: 2.337687616351868

Epoch: 618| Step: 0
Training loss: 0.6763523973725493
Validation loss: 2.3256510018651158

Epoch: 6| Step: 1
Training loss: 0.635605171779564
Validation loss: 2.384997694900495

Epoch: 6| Step: 2
Training loss: 0.5878913600574853
Validation loss: 2.3274125542928386

Epoch: 6| Step: 3
Training loss: 0.5967591477848793
Validation loss: 2.223033683895233

Epoch: 6| Step: 4
Training loss: 0.5554891622792597
Validation loss: 2.3048699486292077

Epoch: 6| Step: 5
Training loss: 0.6947823979008765
Validation loss: 2.366735150295136

Epoch: 6| Step: 6
Training loss: 0.6717696439953643
Validation loss: 2.3988653647561273

Epoch: 6| Step: 7
Training loss: 0.48382028995614823
Validation loss: 2.370137509479868

Epoch: 6| Step: 8
Training loss: 1.5756741367714733
Validation loss: 2.3599936740283645

Epoch: 6| Step: 9
Training loss: 0.542452175387988
Validation loss: 2.2794809285132525

Epoch: 6| Step: 10
Training loss: 0.711814716455906
Validation loss: 2.3572794112879394

Epoch: 6| Step: 11
Training loss: 0.5705240197052384
Validation loss: 2.3370109810788793

Epoch: 6| Step: 12
Training loss: 0.4444761453273596
Validation loss: 2.325680314905678

Epoch: 6| Step: 13
Training loss: 0.6068821806242215
Validation loss: 2.2707614392447684

Epoch: 619| Step: 0
Training loss: 0.5816036163914863
Validation loss: 2.3006187724365796

Epoch: 6| Step: 1
Training loss: 0.7221068897429476
Validation loss: 2.3661310922582803

Epoch: 6| Step: 2
Training loss: 0.6076903899635209
Validation loss: 2.3522770160358157

Epoch: 6| Step: 3
Training loss: 0.539323715830723
Validation loss: 2.2967474771380045

Epoch: 6| Step: 4
Training loss: 0.652466494039789
Validation loss: 2.298748505420276

Epoch: 6| Step: 5
Training loss: 0.5934192840689158
Validation loss: 2.3565103108940644

Epoch: 6| Step: 6
Training loss: 0.47182293408875947
Validation loss: 2.3611932620990634

Epoch: 6| Step: 7
Training loss: 0.5652975873524851
Validation loss: 2.261091343036574

Epoch: 6| Step: 8
Training loss: 0.5166533647896331
Validation loss: 2.2845686854204224

Epoch: 6| Step: 9
Training loss: 0.4495169934931464
Validation loss: 2.3691049295879876

Epoch: 6| Step: 10
Training loss: 1.5144125424532193
Validation loss: 2.2969835769274285

Epoch: 6| Step: 11
Training loss: 0.5639005021552542
Validation loss: 2.392748923049404

Epoch: 6| Step: 12
Training loss: 0.5956521434543315
Validation loss: 2.343541455031885

Epoch: 6| Step: 13
Training loss: 0.5194739690193863
Validation loss: 2.3251456708258145

Epoch: 620| Step: 0
Training loss: 0.5036602158910723
Validation loss: 2.259425135250992

Epoch: 6| Step: 1
Training loss: 0.7989423152572863
Validation loss: 2.319014016504734

Epoch: 6| Step: 2
Training loss: 0.5208821909558926
Validation loss: 2.330218988621835

Epoch: 6| Step: 3
Training loss: 0.5374506750318522
Validation loss: 2.3290779920043048

Epoch: 6| Step: 4
Training loss: 0.6785821806263759
Validation loss: 2.3403418029013046

Epoch: 6| Step: 5
Training loss: 1.5315330399484084
Validation loss: 2.340375795508006

Epoch: 6| Step: 6
Training loss: 0.4032954838755985
Validation loss: 2.322045570739303

Epoch: 6| Step: 7
Training loss: 0.4922834333144846
Validation loss: 2.3767809405296827

Epoch: 6| Step: 8
Training loss: 0.8147416004147079
Validation loss: 2.330425140099441

Epoch: 6| Step: 9
Training loss: 0.36448727659302804
Validation loss: 2.3186024070392546

Epoch: 6| Step: 10
Training loss: 0.6874105438640769
Validation loss: 2.325497891662326

Epoch: 6| Step: 11
Training loss: 0.5478105988717045
Validation loss: 2.312489301417867

Epoch: 6| Step: 12
Training loss: 0.6449682430463294
Validation loss: 2.3865433062803554

Epoch: 6| Step: 13
Training loss: 0.6019572411952798
Validation loss: 2.303642803700941

Epoch: 621| Step: 0
Training loss: 0.5857514658285597
Validation loss: 2.295137532193833

Epoch: 6| Step: 1
Training loss: 0.6003237516430013
Validation loss: 2.3362949147426844

Epoch: 6| Step: 2
Training loss: 0.8051890319511174
Validation loss: 2.338512488896926

Epoch: 6| Step: 3
Training loss: 0.36127116811170834
Validation loss: 2.27441930803952

Epoch: 6| Step: 4
Training loss: 0.43651503996484364
Validation loss: 2.345199440855423

Epoch: 6| Step: 5
Training loss: 0.43023504569903787
Validation loss: 2.284535277493626

Epoch: 6| Step: 6
Training loss: 0.6522525792171413
Validation loss: 2.3175958097066918

Epoch: 6| Step: 7
Training loss: 0.6051443399901691
Validation loss: 2.327162243000599

Epoch: 6| Step: 8
Training loss: 0.5893291982691604
Validation loss: 2.278955492112152

Epoch: 6| Step: 9
Training loss: 0.6501175132310112
Validation loss: 2.3355379672817107

Epoch: 6| Step: 10
Training loss: 1.698281777410156
Validation loss: 2.354275175405829

Epoch: 6| Step: 11
Training loss: 0.31122033851111647
Validation loss: 2.3127989150366544

Epoch: 6| Step: 12
Training loss: 0.6095352206752342
Validation loss: 2.3917309468747225

Epoch: 6| Step: 13
Training loss: 0.6271418112253591
Validation loss: 2.345865008235545

Epoch: 622| Step: 0
Training loss: 0.53757620204764
Validation loss: 2.291094298121695

Epoch: 6| Step: 1
Training loss: 0.5408672032773995
Validation loss: 2.30686927002494

Epoch: 6| Step: 2
Training loss: 1.5223037021916956
Validation loss: 2.271171022767956

Epoch: 6| Step: 3
Training loss: 0.6628854979551148
Validation loss: 2.306822494626906

Epoch: 6| Step: 4
Training loss: 0.605015911452654
Validation loss: 2.333861744578818

Epoch: 6| Step: 5
Training loss: 0.4824601748935101
Validation loss: 2.2941570104061264

Epoch: 6| Step: 6
Training loss: 0.5109346803826508
Validation loss: 2.3256229024137074

Epoch: 6| Step: 7
Training loss: 0.6919376249495001
Validation loss: 2.329565008790926

Epoch: 6| Step: 8
Training loss: 0.588754140146848
Validation loss: 2.343286406358541

Epoch: 6| Step: 9
Training loss: 0.7181945810895941
Validation loss: 2.3453368734477498

Epoch: 6| Step: 10
Training loss: 0.6341093926083483
Validation loss: 2.3285999528006487

Epoch: 6| Step: 11
Training loss: 0.5568135043268013
Validation loss: 2.287825338600753

Epoch: 6| Step: 12
Training loss: 0.6808671032745467
Validation loss: 2.3752190845607104

Epoch: 6| Step: 13
Training loss: 0.6148907382949377
Validation loss: 2.2788600654740705

Epoch: 623| Step: 0
Training loss: 0.3786747411985792
Validation loss: 2.2838970721952006

Epoch: 6| Step: 1
Training loss: 0.6513314301657553
Validation loss: 2.2915064609347695

Epoch: 6| Step: 2
Training loss: 0.5879974521643395
Validation loss: 2.359325834089486

Epoch: 6| Step: 3
Training loss: 0.6299688945766124
Validation loss: 2.309527451378232

Epoch: 6| Step: 4
Training loss: 0.9500845896555293
Validation loss: 2.316775081089943

Epoch: 6| Step: 5
Training loss: 1.5898238047255493
Validation loss: 2.2919790985337545

Epoch: 6| Step: 6
Training loss: 0.44405780513249343
Validation loss: 2.3505196758858276

Epoch: 6| Step: 7
Training loss: 0.6252836060794884
Validation loss: 2.2979926712678376

Epoch: 6| Step: 8
Training loss: 0.5366844854842158
Validation loss: 2.3270580585802363

Epoch: 6| Step: 9
Training loss: 0.45882338277352697
Validation loss: 2.240032773853021

Epoch: 6| Step: 10
Training loss: 0.5746213059836668
Validation loss: 2.2116076036118177

Epoch: 6| Step: 11
Training loss: 0.567803389497686
Validation loss: 2.241610678907468

Epoch: 6| Step: 12
Training loss: 0.5529023848583791
Validation loss: 2.276617633446083

Epoch: 6| Step: 13
Training loss: 0.6062897561005864
Validation loss: 2.30039329969204

Epoch: 624| Step: 0
Training loss: 0.6437415631676552
Validation loss: 2.3288782584164633

Epoch: 6| Step: 1
Training loss: 0.5921932189987338
Validation loss: 2.2677506039626376

Epoch: 6| Step: 2
Training loss: 0.5383135527066016
Validation loss: 2.3985895721451898

Epoch: 6| Step: 3
Training loss: 0.6504231579407986
Validation loss: 2.2984081010087207

Epoch: 6| Step: 4
Training loss: 0.5525944940533639
Validation loss: 2.348167667442071

Epoch: 6| Step: 5
Training loss: 0.6909400100696921
Validation loss: 2.297963022890846

Epoch: 6| Step: 6
Training loss: 1.523561365031605
Validation loss: 2.321076220862605

Epoch: 6| Step: 7
Training loss: 0.5741117468545284
Validation loss: 2.2560154284537526

Epoch: 6| Step: 8
Training loss: 0.38761028443186474
Validation loss: 2.3069078320655776

Epoch: 6| Step: 9
Training loss: 0.43346090257719216
Validation loss: 2.237574754122617

Epoch: 6| Step: 10
Training loss: 0.44299223903161034
Validation loss: 2.333924052472852

Epoch: 6| Step: 11
Training loss: 0.5329095500364486
Validation loss: 2.3240513839982784

Epoch: 6| Step: 12
Training loss: 0.61754397467354
Validation loss: 2.2887524403869977

Epoch: 6| Step: 13
Training loss: 0.6099673839745127
Validation loss: 2.291456672317281

Epoch: 625| Step: 0
Training loss: 0.5507835496353949
Validation loss: 2.2944197432793123

Epoch: 6| Step: 1
Training loss: 0.39849961488530444
Validation loss: 2.363388552933607

Epoch: 6| Step: 2
Training loss: 0.6237241358545268
Validation loss: 2.246950345622529

Epoch: 6| Step: 3
Training loss: 0.5749526750743353
Validation loss: 2.3360021378318363

Epoch: 6| Step: 4
Training loss: 0.6081802687273377
Validation loss: 2.3054257113876298

Epoch: 6| Step: 5
Training loss: 0.5792244946359829
Validation loss: 2.3170949045089997

Epoch: 6| Step: 6
Training loss: 0.47793253970649424
Validation loss: 2.3174298570687615

Epoch: 6| Step: 7
Training loss: 1.5551175236831558
Validation loss: 2.2864360121951797

Epoch: 6| Step: 8
Training loss: 0.6596056882652909
Validation loss: 2.3019657315630715

Epoch: 6| Step: 9
Training loss: 0.4982382761862674
Validation loss: 2.2924387094670595

Epoch: 6| Step: 10
Training loss: 0.5116100923913972
Validation loss: 2.2897677229967868

Epoch: 6| Step: 11
Training loss: 0.5069104913405118
Validation loss: 2.284279676266309

Epoch: 6| Step: 12
Training loss: 0.49395004939911075
Validation loss: 2.2602405892534936

Epoch: 6| Step: 13
Training loss: 0.7255341830991403
Validation loss: 2.3004590370914335

Epoch: 626| Step: 0
Training loss: 0.497137578523577
Validation loss: 2.2747203558123

Epoch: 6| Step: 1
Training loss: 0.3412285139145665
Validation loss: 2.2926525139604665

Epoch: 6| Step: 2
Training loss: 0.7119228535176102
Validation loss: 2.3417999719955764

Epoch: 6| Step: 3
Training loss: 0.4154142949920773
Validation loss: 2.2734299165445373

Epoch: 6| Step: 4
Training loss: 0.6766722433756143
Validation loss: 2.317894762170487

Epoch: 6| Step: 5
Training loss: 0.47994911192318934
Validation loss: 2.388028473003755

Epoch: 6| Step: 6
Training loss: 0.5381349517043844
Validation loss: 2.2573109741905557

Epoch: 6| Step: 7
Training loss: 1.5266972805407504
Validation loss: 2.340427661981441

Epoch: 6| Step: 8
Training loss: 0.6173547204350426
Validation loss: 2.381846416622398

Epoch: 6| Step: 9
Training loss: 0.5086069495016211
Validation loss: 2.3819994608027453

Epoch: 6| Step: 10
Training loss: 0.4584064172506109
Validation loss: 2.3302600169582375

Epoch: 6| Step: 11
Training loss: 0.4976814874450894
Validation loss: 2.289347813566769

Epoch: 6| Step: 12
Training loss: 0.4822184948653851
Validation loss: 2.350153418455007

Epoch: 6| Step: 13
Training loss: 0.5949211115591119
Validation loss: 2.323784388600968

Epoch: 627| Step: 0
Training loss: 1.5684616796587225
Validation loss: 2.35188995055812

Epoch: 6| Step: 1
Training loss: 0.5181092326361549
Validation loss: 2.293249192585156

Epoch: 6| Step: 2
Training loss: 0.5386075850774592
Validation loss: 2.362450555085502

Epoch: 6| Step: 3
Training loss: 0.4828135641635661
Validation loss: 2.250868659244564

Epoch: 6| Step: 4
Training loss: 0.3774617375946961
Validation loss: 2.2696182341336084

Epoch: 6| Step: 5
Training loss: 0.5382795314456873
Validation loss: 2.3005983055093493

Epoch: 6| Step: 6
Training loss: 0.2918282370712376
Validation loss: 2.382049120878278

Epoch: 6| Step: 7
Training loss: 0.5385634282017687
Validation loss: 2.3413486936007524

Epoch: 6| Step: 8
Training loss: 0.7169927594445757
Validation loss: 2.324101250907269

Epoch: 6| Step: 9
Training loss: 0.4123161484188416
Validation loss: 2.2983256303202944

Epoch: 6| Step: 10
Training loss: 0.5129404989428891
Validation loss: 2.314752217539088

Epoch: 6| Step: 11
Training loss: 0.8368813008647407
Validation loss: 2.3190945553863083

Epoch: 6| Step: 12
Training loss: 0.42947606173119335
Validation loss: 2.324287485368049

Epoch: 6| Step: 13
Training loss: 0.5604070296280252
Validation loss: 2.303209427413278

Epoch: 628| Step: 0
Training loss: 0.8370113427545532
Validation loss: 2.2975300389259568

Epoch: 6| Step: 1
Training loss: 0.6198694410065217
Validation loss: 2.312180759529812

Epoch: 6| Step: 2
Training loss: 0.41383935205556355
Validation loss: 2.3712233241254665

Epoch: 6| Step: 3
Training loss: 0.4981094919372879
Validation loss: 2.331198472326674

Epoch: 6| Step: 4
Training loss: 0.4341466488711168
Validation loss: 2.3117383552375914

Epoch: 6| Step: 5
Training loss: 0.4440719323226956
Validation loss: 2.3511723183868662

Epoch: 6| Step: 6
Training loss: 0.39396505991927105
Validation loss: 2.3117743298343454

Epoch: 6| Step: 7
Training loss: 1.4554379012011915
Validation loss: 2.3855715218344784

Epoch: 6| Step: 8
Training loss: 0.580930706228635
Validation loss: 2.331447869755753

Epoch: 6| Step: 9
Training loss: 0.6200384135036501
Validation loss: 2.2944309819884685

Epoch: 6| Step: 10
Training loss: 0.670312706295951
Validation loss: 2.3059245765274228

Epoch: 6| Step: 11
Training loss: 0.7191861529342224
Validation loss: 2.3023634076542825

Epoch: 6| Step: 12
Training loss: 0.5135781380300187
Validation loss: 2.27631326899628

Epoch: 6| Step: 13
Training loss: 0.4791704018765142
Validation loss: 2.326051626633291

Epoch: 629| Step: 0
Training loss: 0.7094150632728654
Validation loss: 2.358165662746111

Epoch: 6| Step: 1
Training loss: 0.655674045862868
Validation loss: 2.273824388428121

Epoch: 6| Step: 2
Training loss: 0.6336490141336036
Validation loss: 2.3130022422027

Epoch: 6| Step: 3
Training loss: 0.527188709214683
Validation loss: 2.3153671769881314

Epoch: 6| Step: 4
Training loss: 0.5751498970275724
Validation loss: 2.2926621315657174

Epoch: 6| Step: 5
Training loss: 0.43730608866212833
Validation loss: 2.30550659457535

Epoch: 6| Step: 6
Training loss: 0.4312451825356577
Validation loss: 2.336619464536833

Epoch: 6| Step: 7
Training loss: 0.7318517067816039
Validation loss: 2.319321689702276

Epoch: 6| Step: 8
Training loss: 0.6173695163085502
Validation loss: 2.3530240801284066

Epoch: 6| Step: 9
Training loss: 0.6325379235127758
Validation loss: 2.3176601499383866

Epoch: 6| Step: 10
Training loss: 0.6267405830028858
Validation loss: 2.3019821047479825

Epoch: 6| Step: 11
Training loss: 0.5335744605759751
Validation loss: 2.357901016255113

Epoch: 6| Step: 12
Training loss: 0.428434382677041
Validation loss: 2.340560869754325

Epoch: 6| Step: 13
Training loss: 1.8616721444773645
Validation loss: 2.3271654905641683

Epoch: 630| Step: 0
Training loss: 0.38507857400253104
Validation loss: 2.3453542074450207

Epoch: 6| Step: 1
Training loss: 0.5911605233763286
Validation loss: 2.3828366568026915

Epoch: 6| Step: 2
Training loss: 0.47479150362278394
Validation loss: 2.2694946899485324

Epoch: 6| Step: 3
Training loss: 0.5052789134114815
Validation loss: 2.2430532101273983

Epoch: 6| Step: 4
Training loss: 0.4112410051875282
Validation loss: 2.2812859485607184

Epoch: 6| Step: 5
Training loss: 0.6518650468558371
Validation loss: 2.2533028116608667

Epoch: 6| Step: 6
Training loss: 0.6794653781690887
Validation loss: 2.2328477879772364

Epoch: 6| Step: 7
Training loss: 0.5640344882254771
Validation loss: 2.312766872894206

Epoch: 6| Step: 8
Training loss: 0.6121511799279435
Validation loss: 2.2706298733214756

Epoch: 6| Step: 9
Training loss: 0.5702915449081242
Validation loss: 2.289055546206085

Epoch: 6| Step: 10
Training loss: 1.475857359426559
Validation loss: 2.2532799341553122

Epoch: 6| Step: 11
Training loss: 0.5301035965581422
Validation loss: 2.333193092116336

Epoch: 6| Step: 12
Training loss: 0.544205060814623
Validation loss: 2.362481496095721

Epoch: 6| Step: 13
Training loss: 0.7525806533325898
Validation loss: 2.330239051263845

Epoch: 631| Step: 0
Training loss: 0.49942003827628073
Validation loss: 2.3550663727174546

Epoch: 6| Step: 1
Training loss: 0.5984426074893215
Validation loss: 2.4039155055123813

Epoch: 6| Step: 2
Training loss: 0.4698018828533747
Validation loss: 2.3624515176236494

Epoch: 6| Step: 3
Training loss: 0.5261263606062262
Validation loss: 2.3832708726485037

Epoch: 6| Step: 4
Training loss: 0.6310702700684867
Validation loss: 2.3065395543729768

Epoch: 6| Step: 5
Training loss: 0.8502478995382762
Validation loss: 2.3563584192510674

Epoch: 6| Step: 6
Training loss: 0.3905361455949488
Validation loss: 2.3527478864913065

Epoch: 6| Step: 7
Training loss: 0.5158576440500477
Validation loss: 2.322560392347574

Epoch: 6| Step: 8
Training loss: 0.5893024461814877
Validation loss: 2.3612923473151333

Epoch: 6| Step: 9
Training loss: 0.6285089458065634
Validation loss: 2.2597548077844025

Epoch: 6| Step: 10
Training loss: 0.5106335263608466
Validation loss: 2.3257711518994024

Epoch: 6| Step: 11
Training loss: 0.4868956628560045
Validation loss: 2.335959491165966

Epoch: 6| Step: 12
Training loss: 1.455054775793156
Validation loss: 2.3292820085684416

Epoch: 6| Step: 13
Training loss: 0.6637637868983153
Validation loss: 2.2734374515110716

Epoch: 632| Step: 0
Training loss: 0.5513594277863182
Validation loss: 2.359142880701289

Epoch: 6| Step: 1
Training loss: 0.6387342136768904
Validation loss: 2.257762570160317

Epoch: 6| Step: 2
Training loss: 0.5777325715919601
Validation loss: 2.372803791437735

Epoch: 6| Step: 3
Training loss: 0.6977078827721443
Validation loss: 2.3138980015421944

Epoch: 6| Step: 4
Training loss: 0.49868830347050214
Validation loss: 2.2838643391700537

Epoch: 6| Step: 5
Training loss: 0.6404857251499559
Validation loss: 2.2959586692972636

Epoch: 6| Step: 6
Training loss: 1.585931486672713
Validation loss: 2.251676728847224

Epoch: 6| Step: 7
Training loss: 0.6125899385087433
Validation loss: 2.4237253679074815

Epoch: 6| Step: 8
Training loss: 0.7668843713512664
Validation loss: 2.3472274894612375

Epoch: 6| Step: 9
Training loss: 0.8241037586864756
Validation loss: 2.25257246222879

Epoch: 6| Step: 10
Training loss: 0.3877616460442082
Validation loss: 2.3466872789535995

Epoch: 6| Step: 11
Training loss: 0.6188538184874225
Validation loss: 2.391595148034323

Epoch: 6| Step: 12
Training loss: 0.3451615309926471
Validation loss: 2.312843762815584

Epoch: 6| Step: 13
Training loss: 0.5002189097411076
Validation loss: 2.2848561320795127

Epoch: 633| Step: 0
Training loss: 0.5949236663771351
Validation loss: 2.316134387495783

Epoch: 6| Step: 1
Training loss: 0.37775121215408713
Validation loss: 2.3377828393014184

Epoch: 6| Step: 2
Training loss: 0.4629546656350716
Validation loss: 2.309455836797585

Epoch: 6| Step: 3
Training loss: 0.40083643587237466
Validation loss: 2.316457302425506

Epoch: 6| Step: 4
Training loss: 0.4774404006482382
Validation loss: 2.3229773162321496

Epoch: 6| Step: 5
Training loss: 0.5741040121652926
Validation loss: 2.3549119461325954

Epoch: 6| Step: 6
Training loss: 0.5732675575997961
Validation loss: 2.3295869330085512

Epoch: 6| Step: 7
Training loss: 0.6241665050810268
Validation loss: 2.279791035741645

Epoch: 6| Step: 8
Training loss: 1.5455392792621174
Validation loss: 2.3285531261985164

Epoch: 6| Step: 9
Training loss: 0.4486401355961147
Validation loss: 2.3314725331913575

Epoch: 6| Step: 10
Training loss: 0.681537390818784
Validation loss: 2.295144107612378

Epoch: 6| Step: 11
Training loss: 0.6197856347140471
Validation loss: 2.3582962597255954

Epoch: 6| Step: 12
Training loss: 0.45493591116611914
Validation loss: 2.2389648678639436

Epoch: 6| Step: 13
Training loss: 0.8472770862498845
Validation loss: 2.3529823134347208

Epoch: 634| Step: 0
Training loss: 0.5553192516940435
Validation loss: 2.385095524095057

Epoch: 6| Step: 1
Training loss: 0.7053406033982558
Validation loss: 2.324095198367829

Epoch: 6| Step: 2
Training loss: 0.7372789795290488
Validation loss: 2.3243784760579635

Epoch: 6| Step: 3
Training loss: 1.5265104942873178
Validation loss: 2.3461447870644228

Epoch: 6| Step: 4
Training loss: 0.5595168376090153
Validation loss: 2.405858462264841

Epoch: 6| Step: 5
Training loss: 0.537225273805902
Validation loss: 2.359690533657639

Epoch: 6| Step: 6
Training loss: 0.5017186370440807
Validation loss: 2.3473981710975784

Epoch: 6| Step: 7
Training loss: 0.6512177394557244
Validation loss: 2.2474915400388764

Epoch: 6| Step: 8
Training loss: 0.4367073576231155
Validation loss: 2.336544862090684

Epoch: 6| Step: 9
Training loss: 0.6266982847042663
Validation loss: 2.2739378191100994

Epoch: 6| Step: 10
Training loss: 0.5986919031647318
Validation loss: 2.3432390395736618

Epoch: 6| Step: 11
Training loss: 0.5543717573688207
Validation loss: 2.2911919218596233

Epoch: 6| Step: 12
Training loss: 0.46640015347328573
Validation loss: 2.3260651107580994

Epoch: 6| Step: 13
Training loss: 0.5217173195379754
Validation loss: 2.326048549173523

Epoch: 635| Step: 0
Training loss: 0.42946851525463015
Validation loss: 2.3479410481664917

Epoch: 6| Step: 1
Training loss: 0.5773731188085863
Validation loss: 2.2621151961019805

Epoch: 6| Step: 2
Training loss: 0.5045005487508974
Validation loss: 2.3421838845244083

Epoch: 6| Step: 3
Training loss: 0.3774374977689169
Validation loss: 2.3548858165594657

Epoch: 6| Step: 4
Training loss: 0.5587978923677307
Validation loss: 2.394751589099394

Epoch: 6| Step: 5
Training loss: 0.6699532815672501
Validation loss: 2.355178167771102

Epoch: 6| Step: 6
Training loss: 0.639543597532996
Validation loss: 2.3441652019075576

Epoch: 6| Step: 7
Training loss: 0.4468095444712109
Validation loss: 2.3094222715897237

Epoch: 6| Step: 8
Training loss: 0.35827759412721133
Validation loss: 2.3528081208415554

Epoch: 6| Step: 9
Training loss: 0.5229953207714756
Validation loss: 2.2743124846024867

Epoch: 6| Step: 10
Training loss: 0.355801960640116
Validation loss: 2.297463853949785

Epoch: 6| Step: 11
Training loss: 1.4231618570372393
Validation loss: 2.3555307573501167

Epoch: 6| Step: 12
Training loss: 0.49501057517189767
Validation loss: 2.2827617868866814

Epoch: 6| Step: 13
Training loss: 0.4672783798316369
Validation loss: 2.3516527144358004

Epoch: 636| Step: 0
Training loss: 0.6296904514139453
Validation loss: 2.291456088312967

Epoch: 6| Step: 1
Training loss: 0.43397488038589743
Validation loss: 2.3482479488011054

Epoch: 6| Step: 2
Training loss: 1.5038181031391733
Validation loss: 2.3242292920110765

Epoch: 6| Step: 3
Training loss: 0.44993573895552363
Validation loss: 2.267008304893194

Epoch: 6| Step: 4
Training loss: 0.49837058524000755
Validation loss: 2.300673008300314

Epoch: 6| Step: 5
Training loss: 0.7889148082937588
Validation loss: 2.303132078102825

Epoch: 6| Step: 6
Training loss: 0.6050223889424866
Validation loss: 2.3710081482996967

Epoch: 6| Step: 7
Training loss: 0.33162519645972677
Validation loss: 2.309090199843561

Epoch: 6| Step: 8
Training loss: 0.5916453252444716
Validation loss: 2.3289937156797076

Epoch: 6| Step: 9
Training loss: 0.5476853225544576
Validation loss: 2.2943844133622764

Epoch: 6| Step: 10
Training loss: 0.47360273442671075
Validation loss: 2.273918392773939

Epoch: 6| Step: 11
Training loss: 0.434636211756426
Validation loss: 2.3301441944590295

Epoch: 6| Step: 12
Training loss: 0.5678364291316181
Validation loss: 2.333557849474693

Epoch: 6| Step: 13
Training loss: 0.44898907968456747
Validation loss: 2.359590336529953

Epoch: 637| Step: 0
Training loss: 0.6405764770739707
Validation loss: 2.3299140913352385

Epoch: 6| Step: 1
Training loss: 0.7174148598109574
Validation loss: 2.2809903992662153

Epoch: 6| Step: 2
Training loss: 0.6471561042247234
Validation loss: 2.301684277662927

Epoch: 6| Step: 3
Training loss: 0.40290412026601885
Validation loss: 2.316957501784815

Epoch: 6| Step: 4
Training loss: 0.44737052520236453
Validation loss: 2.294742749444704

Epoch: 6| Step: 5
Training loss: 0.5750472650590118
Validation loss: 2.325753980036623

Epoch: 6| Step: 6
Training loss: 0.4735865934177958
Validation loss: 2.332204647553402

Epoch: 6| Step: 7
Training loss: 0.6684174174127127
Validation loss: 2.295122149823968

Epoch: 6| Step: 8
Training loss: 1.4065210716928371
Validation loss: 2.3559885325114527

Epoch: 6| Step: 9
Training loss: 0.5343867986614645
Validation loss: 2.411761380157706

Epoch: 6| Step: 10
Training loss: 0.6902344250854405
Validation loss: 2.317383356229425

Epoch: 6| Step: 11
Training loss: 0.4524515343102046
Validation loss: 2.3711219141661384

Epoch: 6| Step: 12
Training loss: 0.4136576382615962
Validation loss: 2.3317794335426143

Epoch: 6| Step: 13
Training loss: 0.7375115716963889
Validation loss: 2.3099469606521486

Epoch: 638| Step: 0
Training loss: 0.49345754823066873
Validation loss: 2.2035121596451965

Epoch: 6| Step: 1
Training loss: 0.6237568412665507
Validation loss: 2.2778586862565646

Epoch: 6| Step: 2
Training loss: 0.4697993295499939
Validation loss: 2.2288717359045456

Epoch: 6| Step: 3
Training loss: 0.4818271569672382
Validation loss: 2.3493893623086004

Epoch: 6| Step: 4
Training loss: 0.679753398989183
Validation loss: 2.3321700532767347

Epoch: 6| Step: 5
Training loss: 0.6351636372379451
Validation loss: 2.352192606349064

Epoch: 6| Step: 6
Training loss: 0.6759766312769712
Validation loss: 2.3403102055024814

Epoch: 6| Step: 7
Training loss: 0.526838130860095
Validation loss: 2.3145573473617325

Epoch: 6| Step: 8
Training loss: 0.4842819309036599
Validation loss: 2.343369847576542

Epoch: 6| Step: 9
Training loss: 1.480556515631127
Validation loss: 2.2898254282289074

Epoch: 6| Step: 10
Training loss: 0.6544983966274454
Validation loss: 2.3298536355026482

Epoch: 6| Step: 11
Training loss: 0.5234607577494618
Validation loss: 2.337458825035266

Epoch: 6| Step: 12
Training loss: 0.4511654345560506
Validation loss: 2.288189250038391

Epoch: 6| Step: 13
Training loss: 0.45486025854650425
Validation loss: 2.2890727251409584

Epoch: 639| Step: 0
Training loss: 0.6003063264337731
Validation loss: 2.3426551919807124

Epoch: 6| Step: 1
Training loss: 0.6690715364418769
Validation loss: 2.300352294775943

Epoch: 6| Step: 2
Training loss: 0.8092417309008304
Validation loss: 2.3125404724641343

Epoch: 6| Step: 3
Training loss: 0.45195481045341923
Validation loss: 2.291724679908046

Epoch: 6| Step: 4
Training loss: 0.5805505697466214
Validation loss: 2.2771365332584987

Epoch: 6| Step: 5
Training loss: 0.4018709311865165
Validation loss: 2.3276475812039936

Epoch: 6| Step: 6
Training loss: 0.49925501278312445
Validation loss: 2.3495478213141925

Epoch: 6| Step: 7
Training loss: 0.719670079989847
Validation loss: 2.3643175476006824

Epoch: 6| Step: 8
Training loss: 0.5629797584967157
Validation loss: 2.308763318077076

Epoch: 6| Step: 9
Training loss: 0.5845191318833315
Validation loss: 2.3341173041208365

Epoch: 6| Step: 10
Training loss: 1.3697502748837571
Validation loss: 2.2603662265098308

Epoch: 6| Step: 11
Training loss: 0.524121307549274
Validation loss: 2.2957731183181975

Epoch: 6| Step: 12
Training loss: 0.4976980596013995
Validation loss: 2.3092920656701446

Epoch: 6| Step: 13
Training loss: 0.3716526841554129
Validation loss: 2.2812180774639272

Epoch: 640| Step: 0
Training loss: 0.4833840570333775
Validation loss: 2.3483770357118656

Epoch: 6| Step: 1
Training loss: 0.46000755381601593
Validation loss: 2.279477237376699

Epoch: 6| Step: 2
Training loss: 0.6187102931219368
Validation loss: 2.3083259556709694

Epoch: 6| Step: 3
Training loss: 0.5369361736897101
Validation loss: 2.296850108763168

Epoch: 6| Step: 4
Training loss: 1.4716120491102769
Validation loss: 2.346293689143725

Epoch: 6| Step: 5
Training loss: 0.5320812061847814
Validation loss: 2.299179111271558

Epoch: 6| Step: 6
Training loss: 0.3463754742982908
Validation loss: 2.211247946064775

Epoch: 6| Step: 7
Training loss: 0.7213634577587759
Validation loss: 2.2716790015390487

Epoch: 6| Step: 8
Training loss: 0.7409044116936752
Validation loss: 2.322682756319386

Epoch: 6| Step: 9
Training loss: 0.5151194203441846
Validation loss: 2.341888176081926

Epoch: 6| Step: 10
Training loss: 0.4646476845015605
Validation loss: 2.3011812591878034

Epoch: 6| Step: 11
Training loss: 0.5110552905734536
Validation loss: 2.3219756318065317

Epoch: 6| Step: 12
Training loss: 0.45818881624714664
Validation loss: 2.3349806684473

Epoch: 6| Step: 13
Training loss: 0.434974345431791
Validation loss: 2.2565016758097407

Epoch: 641| Step: 0
Training loss: 0.566605605196806
Validation loss: 2.306570678549548

Epoch: 6| Step: 1
Training loss: 0.5148639553429312
Validation loss: 2.33171078818941

Epoch: 6| Step: 2
Training loss: 0.6047938861952933
Validation loss: 2.3511786130669545

Epoch: 6| Step: 3
Training loss: 0.6013808037956139
Validation loss: 2.306016877099944

Epoch: 6| Step: 4
Training loss: 0.44948430712233234
Validation loss: 2.3193237876379555

Epoch: 6| Step: 5
Training loss: 0.4708098927573414
Validation loss: 2.305745315633261

Epoch: 6| Step: 6
Training loss: 0.7284382633318148
Validation loss: 2.3549725692834356

Epoch: 6| Step: 7
Training loss: 0.6309991451414819
Validation loss: 2.3910588500742125

Epoch: 6| Step: 8
Training loss: 1.4749565473718647
Validation loss: 2.2854087171963067

Epoch: 6| Step: 9
Training loss: 0.4937985710204481
Validation loss: 2.2844647467968757

Epoch: 6| Step: 10
Training loss: 0.6094182317021549
Validation loss: 2.3081489343920762

Epoch: 6| Step: 11
Training loss: 0.3848221829280218
Validation loss: 2.257062155212618

Epoch: 6| Step: 12
Training loss: 0.7575488860971055
Validation loss: 2.2435034640757445

Epoch: 6| Step: 13
Training loss: 0.4138371376120585
Validation loss: 2.240402222687076

Epoch: 642| Step: 0
Training loss: 0.5835702505831861
Validation loss: 2.311983407234636

Epoch: 6| Step: 1
Training loss: 0.6553292627332677
Validation loss: 2.268610265117923

Epoch: 6| Step: 2
Training loss: 0.4715734010603073
Validation loss: 2.318512208593024

Epoch: 6| Step: 3
Training loss: 0.662304739697566
Validation loss: 2.328451508803526

Epoch: 6| Step: 4
Training loss: 0.4513765011416214
Validation loss: 2.2785078445116955

Epoch: 6| Step: 5
Training loss: 0.5386183747410624
Validation loss: 2.365133588945863

Epoch: 6| Step: 6
Training loss: 0.48673777964024145
Validation loss: 2.2931004361842393

Epoch: 6| Step: 7
Training loss: 0.36717175389068746
Validation loss: 2.2952448998560375

Epoch: 6| Step: 8
Training loss: 1.3731188477146983
Validation loss: 2.2988106018809824

Epoch: 6| Step: 9
Training loss: 0.7041817882614639
Validation loss: 2.2789005616489018

Epoch: 6| Step: 10
Training loss: 0.4157373276555226
Validation loss: 2.3643085478545216

Epoch: 6| Step: 11
Training loss: 0.6253000731141319
Validation loss: 2.2769143442638424

Epoch: 6| Step: 12
Training loss: 0.5827730303533499
Validation loss: 2.3217638987654214

Epoch: 6| Step: 13
Training loss: 0.6275512124246899
Validation loss: 2.297028930475124

Epoch: 643| Step: 0
Training loss: 0.620725774621847
Validation loss: 2.33491702398804

Epoch: 6| Step: 1
Training loss: 0.6555587897674429
Validation loss: 2.3025002647440633

Epoch: 6| Step: 2
Training loss: 0.4589817128205707
Validation loss: 2.3238832932945157

Epoch: 6| Step: 3
Training loss: 0.38867802830718234
Validation loss: 2.325739159234299

Epoch: 6| Step: 4
Training loss: 0.5595037610487537
Validation loss: 2.3634494294181754

Epoch: 6| Step: 5
Training loss: 0.6971835774679394
Validation loss: 2.39154547393254

Epoch: 6| Step: 6
Training loss: 0.6290832175772125
Validation loss: 2.3508799859132092

Epoch: 6| Step: 7
Training loss: 0.4196629812899644
Validation loss: 2.3055576100912507

Epoch: 6| Step: 8
Training loss: 0.41282566248826086
Validation loss: 2.2774309749401818

Epoch: 6| Step: 9
Training loss: 0.4584942087412995
Validation loss: 2.3221081923784235

Epoch: 6| Step: 10
Training loss: 0.8427398073773334
Validation loss: 2.299713903385354

Epoch: 6| Step: 11
Training loss: 0.5119133499181301
Validation loss: 2.3264165042108935

Epoch: 6| Step: 12
Training loss: 0.41927529168769634
Validation loss: 2.303036415394643

Epoch: 6| Step: 13
Training loss: 1.9680152006221294
Validation loss: 2.3608102516499727

Epoch: 644| Step: 0
Training loss: 0.4421111024026379
Validation loss: 2.360583625936588

Epoch: 6| Step: 1
Training loss: 0.6873559800933255
Validation loss: 2.275750500315282

Epoch: 6| Step: 2
Training loss: 1.3948001121548301
Validation loss: 2.3044429548504524

Epoch: 6| Step: 3
Training loss: 0.5329696088038594
Validation loss: 2.241053385849889

Epoch: 6| Step: 4
Training loss: 0.5927879168330455
Validation loss: 2.2566509674657245

Epoch: 6| Step: 5
Training loss: 0.40236798926364065
Validation loss: 2.2727147467259647

Epoch: 6| Step: 6
Training loss: 0.5746996675730989
Validation loss: 2.3444929032510586

Epoch: 6| Step: 7
Training loss: 0.6794468026000272
Validation loss: 2.305782222053773

Epoch: 6| Step: 8
Training loss: 0.6183704194500149
Validation loss: 2.3177233219987095

Epoch: 6| Step: 9
Training loss: 0.44998895711064973
Validation loss: 2.2987559562811635

Epoch: 6| Step: 10
Training loss: 0.48172293931869825
Validation loss: 2.3633141186105737

Epoch: 6| Step: 11
Training loss: 0.45566467010418293
Validation loss: 2.323103490845528

Epoch: 6| Step: 12
Training loss: 0.685800554338867
Validation loss: 2.3865358781299686

Epoch: 6| Step: 13
Training loss: 0.6700452685364793
Validation loss: 2.3781934219415017

Epoch: 645| Step: 0
Training loss: 0.5471963210949844
Validation loss: 2.3181832454117592

Epoch: 6| Step: 1
Training loss: 0.6819244274892892
Validation loss: 2.3162755783552353

Epoch: 6| Step: 2
Training loss: 0.6105880401264697
Validation loss: 2.401628437824067

Epoch: 6| Step: 3
Training loss: 0.5072129451552801
Validation loss: 2.316442459770518

Epoch: 6| Step: 4
Training loss: 0.7710638904297716
Validation loss: 2.323535816993871

Epoch: 6| Step: 5
Training loss: 0.5594047847468845
Validation loss: 2.287508379183832

Epoch: 6| Step: 6
Training loss: 0.5480905919165912
Validation loss: 2.2922871856125684

Epoch: 6| Step: 7
Training loss: 1.523827214400883
Validation loss: 2.3157231075534566

Epoch: 6| Step: 8
Training loss: 0.5096824841278833
Validation loss: 2.3534543031085158

Epoch: 6| Step: 9
Training loss: 0.5117099266165148
Validation loss: 2.31902744592605

Epoch: 6| Step: 10
Training loss: 0.7822143706134772
Validation loss: 2.3239756235627564

Epoch: 6| Step: 11
Training loss: 0.4528684712075456
Validation loss: 2.3092081052628926

Epoch: 6| Step: 12
Training loss: 0.35509853157517607
Validation loss: 2.2426520231536147

Epoch: 6| Step: 13
Training loss: 0.4784235028711673
Validation loss: 2.367364625068638

Epoch: 646| Step: 0
Training loss: 0.4582786166157386
Validation loss: 2.279844426139439

Epoch: 6| Step: 1
Training loss: 0.6593823608783057
Validation loss: 2.3537230978062214

Epoch: 6| Step: 2
Training loss: 0.5914294924886809
Validation loss: 2.280685937191503

Epoch: 6| Step: 3
Training loss: 0.5457438623709682
Validation loss: 2.2540278108819916

Epoch: 6| Step: 4
Training loss: 0.5055126636892265
Validation loss: 2.260530522711705

Epoch: 6| Step: 5
Training loss: 0.5219301754228891
Validation loss: 2.3038669700212955

Epoch: 6| Step: 6
Training loss: 1.4677134975597892
Validation loss: 2.267416308482826

Epoch: 6| Step: 7
Training loss: 0.6159765701637459
Validation loss: 2.302445771014965

Epoch: 6| Step: 8
Training loss: 0.5297739054104891
Validation loss: 2.3010982205460833

Epoch: 6| Step: 9
Training loss: 0.5529817492662076
Validation loss: 2.2579127196959843

Epoch: 6| Step: 10
Training loss: 0.5226612028106808
Validation loss: 2.3318895745692174

Epoch: 6| Step: 11
Training loss: 0.6947921777710948
Validation loss: 2.3290230592975445

Epoch: 6| Step: 12
Training loss: 0.5421441492344949
Validation loss: 2.3360876016696825

Epoch: 6| Step: 13
Training loss: 0.48929866840996844
Validation loss: 2.297336907784796

Epoch: 647| Step: 0
Training loss: 0.5037396177637116
Validation loss: 2.252469596610715

Epoch: 6| Step: 1
Training loss: 0.5309362607046733
Validation loss: 2.263287467027253

Epoch: 6| Step: 2
Training loss: 0.5438179127167657
Validation loss: 2.3529011961156256

Epoch: 6| Step: 3
Training loss: 0.5966555126930668
Validation loss: 2.435618283996541

Epoch: 6| Step: 4
Training loss: 0.61587416065299
Validation loss: 2.2942974737173696

Epoch: 6| Step: 5
Training loss: 0.7465249059064958
Validation loss: 2.3879397187014852

Epoch: 6| Step: 6
Training loss: 0.5933772975281683
Validation loss: 2.3168858438363076

Epoch: 6| Step: 7
Training loss: 0.5803432693499996
Validation loss: 2.3463601107999676

Epoch: 6| Step: 8
Training loss: 0.49269896378053
Validation loss: 2.3313059400404117

Epoch: 6| Step: 9
Training loss: 0.6584997668921219
Validation loss: 2.3378810574821385

Epoch: 6| Step: 10
Training loss: 1.5318154828428823
Validation loss: 2.3482147961586146

Epoch: 6| Step: 11
Training loss: 0.4245989421836696
Validation loss: 2.2632062017992114

Epoch: 6| Step: 12
Training loss: 0.44945768553264925
Validation loss: 2.32581872948272

Epoch: 6| Step: 13
Training loss: 0.6038519653557446
Validation loss: 2.29362454349155

Epoch: 648| Step: 0
Training loss: 0.5661404479284485
Validation loss: 2.2717268029878785

Epoch: 6| Step: 1
Training loss: 0.6897146793293922
Validation loss: 2.3202906826078133

Epoch: 6| Step: 2
Training loss: 0.545385348200629
Validation loss: 2.3191216674687145

Epoch: 6| Step: 3
Training loss: 1.3838994985594284
Validation loss: 2.2978184414101563

Epoch: 6| Step: 4
Training loss: 0.646400745894927
Validation loss: 2.263053464933341

Epoch: 6| Step: 5
Training loss: 0.7668915995672109
Validation loss: 2.3133263224366987

Epoch: 6| Step: 6
Training loss: 0.348665914379868
Validation loss: 2.2470403778554715

Epoch: 6| Step: 7
Training loss: 0.5621724764654421
Validation loss: 2.302680773299366

Epoch: 6| Step: 8
Training loss: 0.5489867717559771
Validation loss: 2.252922542525541

Epoch: 6| Step: 9
Training loss: 0.42940303749818876
Validation loss: 2.358269589864711

Epoch: 6| Step: 10
Training loss: 0.6268310665736062
Validation loss: 2.366622213471602

Epoch: 6| Step: 11
Training loss: 0.6618303369252371
Validation loss: 2.322059247596926

Epoch: 6| Step: 12
Training loss: 0.5445404905741963
Validation loss: 2.3314509695025842

Epoch: 6| Step: 13
Training loss: 0.5574854279225949
Validation loss: 2.303880261847366

Epoch: 649| Step: 0
Training loss: 0.5341591560839525
Validation loss: 2.3602020415753446

Epoch: 6| Step: 1
Training loss: 0.5311833788667801
Validation loss: 2.372303349559583

Epoch: 6| Step: 2
Training loss: 0.6691861129950161
Validation loss: 2.386000398505917

Epoch: 6| Step: 3
Training loss: 1.3860848280776816
Validation loss: 2.356763822964023

Epoch: 6| Step: 4
Training loss: 0.4939033330573571
Validation loss: 2.3497337114946135

Epoch: 6| Step: 5
Training loss: 0.6534665433029051
Validation loss: 2.3327022213910875

Epoch: 6| Step: 6
Training loss: 0.5650956084369515
Validation loss: 2.2944100676770356

Epoch: 6| Step: 7
Training loss: 0.6168074584594103
Validation loss: 2.2897991241272404

Epoch: 6| Step: 8
Training loss: 0.6403594978774904
Validation loss: 2.359154729863761

Epoch: 6| Step: 9
Training loss: 0.5665750712342953
Validation loss: 2.342904070709738

Epoch: 6| Step: 10
Training loss: 0.3841882430318111
Validation loss: 2.3298519636667745

Epoch: 6| Step: 11
Training loss: 0.5919339867818784
Validation loss: 2.288310490949285

Epoch: 6| Step: 12
Training loss: 0.48094234540951136
Validation loss: 2.286982060896126

Epoch: 6| Step: 13
Training loss: 0.5073338820681735
Validation loss: 2.33187546613966

Epoch: 650| Step: 0
Training loss: 0.44564990596002
Validation loss: 2.4242872912964173

Epoch: 6| Step: 1
Training loss: 0.35446261448104144
Validation loss: 2.2650983527179016

Epoch: 6| Step: 2
Training loss: 0.663334885440461
Validation loss: 2.3526924440289596

Epoch: 6| Step: 3
Training loss: 0.6496654282160594
Validation loss: 2.250001761505276

Epoch: 6| Step: 4
Training loss: 1.5457448202259554
Validation loss: 2.3023652298671555

Epoch: 6| Step: 5
Training loss: 0.6220983861220716
Validation loss: 2.3275723849991405

Epoch: 6| Step: 6
Training loss: 0.5173238453539836
Validation loss: 2.243314388046252

Epoch: 6| Step: 7
Training loss: 0.3893676357889363
Validation loss: 2.33972740483267

Epoch: 6| Step: 8
Training loss: 0.7103393889279007
Validation loss: 2.3818415774606767

Epoch: 6| Step: 9
Training loss: 0.46426759805023515
Validation loss: 2.3127529434979803

Epoch: 6| Step: 10
Training loss: 0.322657745394809
Validation loss: 2.3095258884579755

Epoch: 6| Step: 11
Training loss: 0.5634939630687693
Validation loss: 2.212375094790159

Epoch: 6| Step: 12
Training loss: 0.7420456198551801
Validation loss: 2.3153832765888485

Epoch: 6| Step: 13
Training loss: 0.7610588932533007
Validation loss: 2.3388196314677487

Testing loss: 2.967259140002428
